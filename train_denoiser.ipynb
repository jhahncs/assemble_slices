{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a3c0f7e8-9606-4c1a-a14c-18705bc59aee",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'data': {'batch_size': 3, 'val_batch_size': 3, 'num_workers': 10, 'data_fn': 'shape.{}.txt', 'data_dir': '/data/jhahn/data/shape_dataset/pc_data/shape/train/', 'data_val_dir': '/data/jhahn/data/shape_dataset/pc_data/shape/val/', 'rot_range': -1, 'overfit': -1, 'min_num_part': 2, 'max_num_part': 20, 'mesh_data_dir': '/data/jhahn/data/shape_dataset/data/'}, 'ae': {'ae_name': {'_target_': 'puzzlefusion_plusplus.denoiser.model.modules.encoder.VQVAE'}, 'n_embeddings': 1024, 'embedding_dim': 16, 'num_point': 25, 'num_dim': 64, 'local_decode_pts': 40, 'beta': 0.25}, 'hydra': {'output_subdir': None, 'run': {'dir': '.'}}, 'defaults': ['_self_', 'encoder', 'data', 'model', {'override hydra/hydra_logging': 'disabled'}, {'override hydra/job_logging': 'disabled'}], 'project_root_path': '/data/jhahn/data/shape_dataset/', 'experiment_output_path': '/data/jhahn/data/shape_dataset/output/denoiser/${experiment_name}/', 'ckpt_path': None, 'experiment_name': 'shape_epoch10', 'train_seed': 123, 'test_seed': 123, 'logger': {'_target_': 'pytorch_lightning.loggers.WandbLogger', 'project': 'puzzlefusion_plusplus', 'name': '${experiment_name}', 'save_dir': '${experiment_output_path}/training'}, 'trainer': {'accelerator': 'gpu', 'max_epochs': 1, 'num_sanity_val_steps': 1, 'check_val_every_n_epoch': 1, 'profiler': 'simple', 'precision': 32}, 'checkpoint_monitor': {'_target_': 'pytorch_lightning.callbacks.ModelCheckpoint', 'monitor': 'eval/part_acc', 'mode': 'max', 'save_last': True, 'save_top_k': 3, 'every_n_epochs': '${trainer.check_val_every_n_epoch}', 'filename': '{epoch}', 'dirpath': '${experiment_output_path}/training'}, 'model': {'model_name': {'_target_': 'puzzlefusion_plusplus.denoiser.model.denoiser.Denoiser'}, 'encoder_weights_path': '/data/jhahn/data/shape_dataset//output/autoencoder/shape_epoch10/training/last.ckpt', 'multiple_ref_parts': True, 'num_dim': 64, 'num_point': 25, 'out_channels': 7, 'std': 1, 'multires': 10, 'embed_dim': 512, 'num_layers': 6, 'num_heads': 8, 'dropout_rate': 0.1, 'DDPM_TRAIN_STEPS': 1000, 'DDPM_BETA_SCHEDULE': 'linear', 'timestep_spacing': 'leading', 'PREDICT_TYPE': 'epsilon', 'BETA_START': 0.0001, 'BETA_END': 0.02, 'num_inference_steps': 20, 'lr_scheduler': {'_target_': 'torch.optim.lr_scheduler.MultiStepLR', 'milestones': [1200, 1700], 'gamma': 0.5}}}"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "import torch\n",
    "import hydra\n",
    "import pytorch_lightning as pl\n",
    "from pytorch_lightning.callbacks import LearningRateMonitor\n",
    "from omegaconf import OmegaConf,open_dict\n",
    "import omegaconf\n",
    "\n",
    "config_home_dir = './config'\n",
    "\n",
    "\n",
    "data_home_dir = '/disk2/data/breaking_bad/'\n",
    "data_home_dir = '/data/jhahn/data/shape_dataset/'\n",
    "data_type_name = 'shape'\n",
    "\n",
    "\n",
    "\n",
    "cfg_denoiser_data = omegaconf.OmegaConf.load(config_home_dir+'/denoiser/data.yaml')\n",
    "cfg_denoiser_encode = omegaconf.OmegaConf.load(config_home_dir+'/denoiser/encoder.yaml')\n",
    "cfg_denoiser_global_config = omegaconf.OmegaConf.load(config_home_dir+'/denoiser/global_config.yaml')\n",
    "cfg_denoiser_model = omegaconf.OmegaConf.load(config_home_dir+'/denoiser/model.yaml')\n",
    "\n",
    "cfg = OmegaConf.merge(\n",
    "\n",
    "    cfg_denoiser_data,\n",
    "    cfg_denoiser_encode,\n",
    "    cfg_denoiser_global_config,\n",
    "    cfg_denoiser_model\n",
    ")\n",
    "\n",
    "cfg.project_root_path = data_home_dir\n",
    "\n",
    "cfg.data.data_dir = data_home_dir+f'pc_data/{data_type_name}/train/'\n",
    "cfg.data.data_val_dir = data_home_dir+f'pc_data/{data_type_name}/val/'\n",
    "cfg.data.mesh_data_dir = data_home_dir+'data/'\n",
    "cfg.data.data_fn = data_type_name+\".{}.txt\"\n",
    "cfg.data.batch_size = 3\n",
    "cfg.data.val_batch_size= 3\n",
    "\n",
    "cfg.experiment_name = 'shape_epoch10'\n",
    "cfg.model.encoder_weights_path =  f'{data_home_dir}/output/autoencoder/{cfg.experiment_name}'+'/training/last.ckpt'\n",
    "\n",
    "\n",
    "cfg.ckpt_path= None\n",
    "cfg.experiment_output_path = data_home_dir+'output/denoiser/${experiment_name}/'\n",
    "cfg.trainer.max_epochs =  1\n",
    "cfg.trainer.check_val_every_n_epoch =  1\n",
    "\n",
    "#cfg.model.model_name = 'jahn_src.denoiser_jhahn'\n",
    "\n",
    "#cfg.trainer.strategy='ddp'\n",
    "# In[4]:\n",
    "\n",
    "\n",
    "def init_callbacks(cfg):\n",
    "    checkpoint_monitor = hydra.utils.instantiate(cfg.checkpoint_monitor)\n",
    "    lr_monitor = LearningRateMonitor(logging_interval=\"epoch\")\n",
    "    # print_callback = PrintCallback()\n",
    "    return [checkpoint_monitor, lr_monitor]\n",
    "\n",
    "cfg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "54e779d2-4439-4996-81de-c0e1c7736050",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Seed set to 123\n"
     ]
    }
   ],
   "source": [
    "# fix the seed\n",
    "pl.seed_everything(cfg.train_seed, workers=True)\n",
    "\n",
    "# create directories for training outputs\n",
    "os.makedirs(os.path.join(cfg.experiment_output_path, \"training\"), exist_ok=True)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "3afc5232-b348-4202-a521-3a1a58328cb0",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 100/100 [00:00<00:00, 392.62it/s]\n",
      "100%|██████████| 10/10 [00:00<00:00, 533.08it/s]\n"
     ]
    }
   ],
   "source": [
    "import importlib\n",
    "import jahn_src.data_loader_jhahn\n",
    "import puzzlefusion_plusplus.denoiser.model.denoiser\n",
    "import jahn_src.slice_util\n",
    "importlib.reload(jahn_src.slice_util)\n",
    "importlib.reload(jahn_src.data_loader_jhahn)\n",
    "importlib.reload(puzzlefusion_plusplus.denoiser.model.denoiser)\n",
    "\n",
    "from puzzlefusion_plusplus.denoiser.model import denoiser\n",
    "from jahn_src.data_loader_jhahn import build_geometry_dataloader\n",
    "\n",
    "\n",
    "# initialize data\n",
    "train_loader, val_loader = build_geometry_dataloader(cfg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "7328031d-4f2f-4ea5-bad7-858f32cef6e3",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "_item = None\n",
    "train_count = 0\n",
    "val_count = 0\n",
    "for nth_batch, batch in enumerate(train_loader):\n",
    "    print(nth_batch, len(batch), batch.keys())\n",
    "    for _i in range(len(batch['mesh_file_path'])):\n",
    "        \n",
    "        print(batch[\"data_id\"][_i], batch[\"mesh_file_path\"][_i])\n",
    "        #_item_gt = batch[\"part_pcs_gt\"][_i].tolist()\n",
    "        #_item_rt = batch[\"part_pcs\"][_i].tolist()\n",
    "        print('part_trans',batch[\"part_trans\"][_i].shape,batch[\"part_trans\"][_i])\n",
    "        print('noise_rots',batch[\"noise_rots\"][_i].shape,batch[\"noise_rots\"][_i])\n",
    "        #print(_item)\n",
    "        #np.savez(f'{data_home_dir}/data/test_data/{batch[\"data_id\"][_i]}_gt.npz', _item_gt) \n",
    "        #np.savez(f'{data_home_dir}/data/test_data/{batch[\"data_id\"][_i]}_rt.npz', _item_rt) \n",
    "        if True:\n",
    "            break\n",
    "    if True:\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "01ba95ac-cf01-4b51-8efd-2d8e757c250c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_570172/2498129417.py:5: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  encoder_weights = torch.load(cfg.model.encoder_weights_path)['state_dict']\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "/data/jhahn/slice_env/lib/python3.10/site-packages/pytorch_lightning/trainer/connectors/logger_connector/logger_connector.py:76: Starting from v1.9.0, `tensorboardX` has been removed as a dependency of the `pytorch_lightning` package, due to potential conflicts with other packages in the ML ecosystem. For this reason, `logger=True` will use `CSVLogger` as the default logger, unless the `tensorboard` or `tensorboardX` packages are found. Please `pip install lightning[extra]` or one of them to enable TensorBoard support by default\n",
      "You are using a CUDA device ('NVIDIA A100 80GB PCIe MIG 4g.40gb') that has Tensor Cores. To properly utilize them, you should set `torch.set_float32_matmul_precision('medium' | 'high')` which will trade-off precision for performance. For more details, read https://pytorch.org/docs/stable/generated/torch.set_float32_matmul_precision.html#torch.set_float32_matmul_precision\n",
      "/data/jhahn/slice_env/lib/python3.10/site-packages/pytorch_lightning/callbacks/model_checkpoint.py:654: Checkpoint directory /data/jhahn/data/shape_dataset/output/denoiser/shape_epoch10/training exists and is not empty.\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [MIG-e5a11831-23aa-537c-9ebe-5e6cce8a2bce]\n",
      "\n",
      "  | Name     | Type                | Params | Mode \n",
      "---------------------------------------------------------\n",
      "0 | denoiser | DenoiserTransformer | 57.6 M | train\n",
      "1 | encoder  | VQVAE               | 605 K  | train\n",
      "2 | cd_loss  | ChamferDistance     | 0      | train\n",
      "3 | metric   | ChamferDistance     | 0      | train\n",
      "---------------------------------------------------------\n",
      "57.6 M    Trainable params\n",
      "605 K     Non-trainable params\n",
      "58.2 M    Total params\n",
      "232.895   Total estimated model params size (MB)\n",
      "250       Modules in train mode\n",
      "0         Modules in eval mode\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "55afba38ce714584ae1913e3cb6dc5e2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Sanity Checking: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([0, 1, 2], device='cuda:0')\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/data/jhahn/slice_env/lib/python3.10/site-packages/pytorch_lightning/utilities/data.py:79: Trying to infer the `batch_size` from an ambiguous collection. The batch size we found is 3. To avoid any miscalculations, use `self.log(..., batch_size=batch_size)`.\n",
      "/data/jhahn/slice_env/lib/python3.10/site-packages/pytorch_lightning/loops/fit_loop.py:310: The number of training batches (33) is smaller than the logging interval Trainer(log_every_n_steps=50). Set a lower value for log_every_n_steps if you want to see logs for the training epoch.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "adff54a24c9249c6b5513206e51112b6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([14, 87, 81], device='cuda:0')\n",
      "tensor([44, 42, 51], device='cuda:0')\n",
      "tensor([ 5, 40, 86], device='cuda:0')\n",
      "tensor([19,  1, 79], device='cuda:0')\n",
      "tensor([ 3, 27, 37], device='cuda:0')\n",
      "tensor([62, 24, 89], device='cuda:0')\n",
      "tensor([94, 63,  6], device='cuda:0')\n",
      "tensor([84, 76,  7], device='cuda:0')\n",
      "tensor([ 2, 58, 77], device='cuda:0')\n",
      "tensor([57, 20, 90], device='cuda:0')\n",
      "tensor([21, 70, 95], device='cuda:0')\n",
      "tensor([17, 73, 11], device='cuda:0')\n",
      "tensor([32, 74, 56], device='cuda:0')\n",
      "tensor([39,  8, 26], device='cuda:0')\n",
      "tensor([97,  9, 43], device='cuda:0')\n",
      "tensor([30, 96, 83], device='cuda:0')\n",
      "tensor([75, 49,  4], device='cuda:0')\n",
      "tensor([28, 53, 29], device='cuda:0')\n",
      "tensor([38, 15, 45], device='cuda:0')\n",
      "tensor([25, 54, 59], device='cuda:0')\n",
      "tensor([91, 48, 98], device='cuda:0')\n",
      "tensor([80, 78, 41], device='cuda:0')\n",
      "tensor([33, 52, 46], device='cuda:0')\n",
      "tensor([12, 16, 22], device='cuda:0')\n",
      "tensor([72, 66, 82], device='cuda:0')\n",
      "tensor([ 0, 55, 18], device='cuda:0')\n",
      "tensor([92, 99, 61], device='cuda:0')\n",
      "tensor([85, 67, 13], device='cuda:0')\n",
      "tensor([60, 93, 31], device='cuda:0')\n",
      "tensor([50, 47, 36], device='cuda:0')\n",
      "tensor([65, 10, 71], device='cuda:0')\n",
      "tensor([69, 64, 35], device='cuda:0')\n",
      "tensor([68, 88, 34], device='cuda:0')\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3c4b520df65741cdbfca5c9497d04846",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([0, 1, 2], device='cuda:0')\n",
      "tensor([3, 4, 5], device='cuda:0')\n",
      "tensor([6, 7, 8], device='cuda:0')\n",
      "tensor([9], device='cuda:0')\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/data/jhahn/slice_env/lib/python3.10/site-packages/pytorch_lightning/utilities/data.py:79: Trying to infer the `batch_size` from an ambiguous collection. The batch size we found is 1. To avoid any miscalculations, use `self.log(..., batch_size=batch_size)`.\n",
      "`Trainer.fit` stopped: `max_epochs=1` reached.\n",
      "FIT Profiler Report\n",
      "\n",
      "----------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------\n",
      "|  Action                                                                                                                                                                    \t|  Mean duration (s)\t|  Num calls      \t|  Total time (s) \t|  Percentage %   \t|\n",
      "----------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------\n",
      "|  Total                                                                                                                                                                     \t|  -              \t|  1579           \t|  12.36          \t|  100 %          \t|\n",
      "----------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------\n",
      "|  run_training_epoch                                                                                                                                                        \t|  6.1834         \t|  1              \t|  6.1834         \t|  50.03          \t|\n",
      "|  [Strategy]SingleDeviceStrategy.validation_step                                                                                                                            \t|  0.86748        \t|  5              \t|  4.3374         \t|  35.093         \t|\n",
      "|  [Callback]ModelCheckpoint{'monitor': 'eval/part_acc', 'mode': 'max', 'every_n_train_steps': 0, 'every_n_epochs': 1, 'train_time_interval': None}.on_train_epoch_end       \t|  3.8822         \t|  1              \t|  3.8822         \t|  31.411         \t|\n",
      "|  save_checkpoint                                                                                                                                                           \t|  1.9397         \t|  2              \t|  3.8795         \t|  31.388         \t|\n",
      "|  run_training_batch                                                                                                                                                        \t|  0.088628       \t|  33             \t|  2.9247         \t|  23.663         \t|\n",
      "|  [LightningModule]Denoiser.optimizer_step                                                                                                                                  \t|  0.088345       \t|  33             \t|  2.9154         \t|  23.588         \t|\n",
      "|  [Strategy]SingleDeviceStrategy.training_step                                                                                                                              \t|  0.048849       \t|  33             \t|  1.612          \t|  13.043         \t|\n",
      "|  [Strategy]SingleDeviceStrategy.backward                                                                                                                                   \t|  0.035022       \t|  33             \t|  1.1557         \t|  9.3509         \t|\n",
      "|  [_EvaluationLoop].val_next                                                                                                                                                \t|  0.014949       \t|  5              \t|  0.074745       \t|  0.60475        \t|\n",
      "|  [Callback]TQDMProgressBar.on_train_batch_end                                                                                                                              \t|  0.0012155      \t|  33             \t|  0.040111       \t|  0.32454        \t|\n",
      "|  [_TrainingEpochLoop].train_dataloader_next                                                                                                                                \t|  0.0011156      \t|  33             \t|  0.036814       \t|  0.29786        \t|\n",
      "|  [Strategy]SingleDeviceStrategy.batch_to_device                                                                                                                            \t|  0.00056198     \t|  38             \t|  0.021355       \t|  0.17278        \t|\n",
      "|  [LightningModule]Denoiser.transfer_batch_to_device                                                                                                                        \t|  0.00052021     \t|  38             \t|  0.019768       \t|  0.15994        \t|\n",
      "|  [LightningModule]Denoiser.optimizer_zero_grad                                                                                                                             \t|  0.00048726     \t|  33             \t|  0.01608        \t|  0.1301         \t|\n",
      "|  [Callback]TQDMProgressBar.on_train_start                                                                                                                                  \t|  0.010422       \t|  1              \t|  0.010422       \t|  0.084324       \t|\n",
      "|  [Callback]TQDMProgressBar.on_validation_start                                                                                                                             \t|  0.0041276      \t|  2              \t|  0.0082553      \t|  0.066792       \t|\n",
      "|  [Callback]TQDMProgressBar.on_sanity_check_start                                                                                                                           \t|  0.0081746      \t|  1              \t|  0.0081746      \t|  0.066139       \t|\n",
      "|  [LightningModule]Denoiser.on_validation_epoch_end                                                                                                                         \t|  0.0032936      \t|  2              \t|  0.0065871      \t|  0.053296       \t|\n",
      "|  [Callback]ModelSummary.on_fit_start                                                                                                                                       \t|  0.0052473      \t|  1              \t|  0.0052473      \t|  0.042456       \t|\n",
      "|  [Callback]TQDMProgressBar.on_validation_batch_end                                                                                                                         \t|  0.0010099      \t|  5              \t|  0.0050494      \t|  0.040854       \t|\n",
      "|  [LightningModule]Denoiser.configure_optimizers                                                                                                                            \t|  0.0035466      \t|  1              \t|  0.0035466      \t|  0.028695       \t|\n",
      "|  [Callback]TQDMProgressBar.on_validation_batch_start                                                                                                                       \t|  0.00054295     \t|  5              \t|  0.0027147      \t|  0.021965       \t|\n",
      "|  [LightningModule]Denoiser.on_validation_model_eval                                                                                                                        \t|  0.0010036      \t|  2              \t|  0.0020071      \t|  0.016239       \t|\n",
      "|  [Callback]TQDMProgressBar.on_validation_end                                                                                                                               \t|  0.00088506     \t|  2              \t|  0.0017701      \t|  0.014322       \t|\n",
      "|  [LightningModule]Denoiser.on_validation_model_zero_grad                                                                                                                   \t|  0.001109       \t|  1              \t|  0.001109       \t|  0.0089731      \t|\n",
      "|  [Callback]TQDMProgressBar.on_train_epoch_start                                                                                                                            \t|  0.0010452      \t|  1              \t|  0.0010452      \t|  0.0084568      \t|\n",
      "|  [LightningModule]Denoiser.configure_gradient_clipping                                                                                                                     \t|  3.1179e-05     \t|  33             \t|  0.0010289      \t|  0.0083247      \t|\n",
      "|  [Callback]TQDMProgressBar.on_train_end                                                                                                                                    \t|  0.0009881      \t|  1              \t|  0.0009881      \t|  0.0079946      \t|\n",
      "|  [Callback]ModelCheckpoint{'monitor': 'eval/part_acc', 'mode': 'max', 'every_n_train_steps': 0, 'every_n_epochs': 1, 'train_time_interval': None}.on_train_batch_end       \t|  2.2016e-05     \t|  33             \t|  0.00072651     \t|  0.0058781      \t|\n",
      "|  [Callback]LearningRateMonitor.on_train_epoch_start                                                                                                                        \t|  0.00071294     \t|  1              \t|  0.00071294     \t|  0.0057683      \t|\n",
      "|  [Callback]ModelCheckpoint{'monitor': 'eval/part_acc', 'mode': 'max', 'every_n_train_steps': 0, 'every_n_epochs': 1, 'train_time_interval': None}.setup                    \t|  0.00021199     \t|  1              \t|  0.00021199     \t|  0.0017152      \t|\n",
      "|  [Callback]LearningRateMonitor.on_train_batch_start                                                                                                                        \t|  6.1225e-06     \t|  33             \t|  0.00020204     \t|  0.0016347      \t|\n",
      "|  [Callback]LearningRateMonitor.on_train_start                                                                                                                              \t|  0.00017645     \t|  1              \t|  0.00017645     \t|  0.0014277      \t|\n",
      "|  [Callback]TQDMProgressBar.on_train_epoch_end                                                                                                                              \t|  0.00013647     \t|  1              \t|  0.00013647     \t|  0.0011041      \t|\n",
      "|  [LightningModule]Denoiser.lr_scheduler_step                                                                                                                               \t|  0.00010179     \t|  1              \t|  0.00010179     \t|  0.00082358     \t|\n",
      "|  [Callback]LearningRateMonitor.on_after_backward                                                                                                                           \t|  2.8476e-06     \t|  33             \t|  9.397e-05      \t|  0.0007603      \t|\n",
      "|  [Callback]LearningRateMonitor.on_before_zero_grad                                                                                                                         \t|  2.8394e-06     \t|  33             \t|  9.3701e-05     \t|  0.00075813     \t|\n",
      "|  [Callback]LearningRateMonitor.on_train_batch_end                                                                                                                          \t|  2.4699e-06     \t|  33             \t|  8.1507e-05     \t|  0.00065946     \t|\n",
      "|  [Callback]ModelSummary.on_train_batch_end                                                                                                                                 \t|  2.2087e-06     \t|  33             \t|  7.2886e-05     \t|  0.00058971     \t|\n",
      "|  [Callback]LearningRateMonitor.on_before_backward                                                                                                                          \t|  2.1364e-06     \t|  33             \t|  7.0501e-05     \t|  0.00057042     \t|\n",
      "|  [LightningModule]Denoiser.on_before_batch_transfer                                                                                                                        \t|  1.6402e-06     \t|  38             \t|  6.2326e-05     \t|  0.00050427     \t|\n",
      "|  [LightningModule]Denoiser.on_after_batch_transfer                                                                                                                         \t|  1.635e-06      \t|  38             \t|  6.2131e-05     \t|  0.0005027      \t|\n",
      "|  [Callback]LearningRateMonitor.on_before_optimizer_step                                                                                                                    \t|  1.8086e-06     \t|  33             \t|  5.9684e-05     \t|  0.00048289     \t|\n",
      "|  [Callback]TQDMProgressBar.on_train_batch_start                                                                                                                            \t|  1.7938e-06     \t|  33             \t|  5.9195e-05     \t|  0.00047894     \t|\n",
      "|  [Callback]ModelCheckpoint{'monitor': 'eval/part_acc', 'mode': 'max', 'every_n_train_steps': 0, 'every_n_epochs': 1, 'train_time_interval': None}.on_validation_end        \t|  2.7441e-05     \t|  2              \t|  5.4882e-05     \t|  0.00044404     \t|\n",
      "|  [LightningModule]Denoiser.on_before_zero_grad                                                                                                                             \t|  1.463e-06      \t|  33             \t|  4.828e-05      \t|  0.00039063     \t|\n",
      "|  [LightningModule]Denoiser.on_after_backward                                                                                                                               \t|  1.3589e-06     \t|  33             \t|  4.4844e-05     \t|  0.00036283     \t|\n",
      "|  [LightningModule]Denoiser.on_train_batch_end                                                                                                                              \t|  1.3566e-06     \t|  33             \t|  4.4769e-05     \t|  0.00036222     \t|\n",
      "|  [LightningModule]Denoiser.on_before_optimizer_step                                                                                                                        \t|  1.29e-06       \t|  33             \t|  4.2571e-05     \t|  0.00034443     \t|\n",
      "|  [LightningModule]Denoiser.on_train_batch_start                                                                                                                            \t|  1.2649e-06     \t|  33             \t|  4.1742e-05     \t|  0.00033773     \t|\n",
      "|  [Callback]ModelCheckpoint{'monitor': 'eval/part_acc', 'mode': 'max', 'every_n_train_steps': 0, 'every_n_epochs': 1, 'train_time_interval': None}.on_after_backward        \t|  1.2574e-06     \t|  33             \t|  4.1494e-05     \t|  0.00033572     \t|\n",
      "|  [Callback]TQDMProgressBar.on_after_backward                                                                                                                               \t|  1.2257e-06     \t|  33             \t|  4.0447e-05     \t|  0.00032725     \t|\n",
      "|  [LightningModule]Denoiser.on_before_backward                                                                                                                              \t|  1.1917e-06     \t|  33             \t|  3.9325e-05     \t|  0.00031817     \t|\n",
      "|  [Callback]ModelSummary.on_before_zero_grad                                                                                                                                \t|  1.0925e-06     \t|  33             \t|  3.6052e-05     \t|  0.0002917      \t|\n",
      "|  [Callback]TQDMProgressBar.on_before_zero_grad                                                                                                                             \t|  1.0729e-06     \t|  33             \t|  3.5406e-05     \t|  0.00028647     \t|\n",
      "|  [Strategy]SingleDeviceStrategy.on_train_batch_start                                                                                                                       \t|  1.0716e-06     \t|  33             \t|  3.5364e-05     \t|  0.00028613     \t|\n",
      "|  [Callback]TQDMProgressBar.on_before_optimizer_step                                                                                                                        \t|  1.0677e-06     \t|  33             \t|  3.5235e-05     \t|  0.00028508     \t|\n",
      "|  [Callback]ModelSummary.on_before_backward                                                                                                                                 \t|  1.0537e-06     \t|  33             \t|  3.4773e-05     \t|  0.00028134     \t|\n",
      "|  [Callback]ModelSummary.on_before_optimizer_step                                                                                                                           \t|  1.0499e-06     \t|  33             \t|  3.4645e-05     \t|  0.00028031     \t|\n",
      "|  [Callback]TQDMProgressBar.on_before_backward                                                                                                                              \t|  1.0256e-06     \t|  33             \t|  3.3846e-05     \t|  0.00027384     \t|\n",
      "|  [Callback]ModelSummary.on_train_batch_start                                                                                                                               \t|  1.0239e-06     \t|  33             \t|  3.3787e-05     \t|  0.00027337     \t|\n",
      "|  [Callback]ModelCheckpoint{'monitor': 'eval/part_acc', 'mode': 'max', 'every_n_train_steps': 0, 'every_n_epochs': 1, 'train_time_interval': None}.on_before_optimizer_step \t|  1.0189e-06     \t|  33             \t|  3.3624e-05     \t|  0.00027205     \t|\n",
      "|  [Callback]ModelSummary.on_after_backward                                                                                                                                  \t|  1.008e-06      \t|  33             \t|  3.3265e-05     \t|  0.00026914     \t|\n",
      "|  [Callback]ModelCheckpoint{'monitor': 'eval/part_acc', 'mode': 'max', 'every_n_train_steps': 0, 'every_n_epochs': 1, 'train_time_interval': None}.on_before_zero_grad      \t|  9.7473e-07     \t|  33             \t|  3.2166e-05     \t|  0.00026025     \t|\n",
      "|  [Callback]ModelCheckpoint{'monitor': 'eval/part_acc', 'mode': 'max', 'every_n_train_steps': 0, 'every_n_epochs': 1, 'train_time_interval': None}.on_train_batch_start     \t|  9.7267e-07     \t|  33             \t|  3.2098e-05     \t|  0.0002597      \t|\n",
      "|  [Callback]ModelCheckpoint{'monitor': 'eval/part_acc', 'mode': 'max', 'every_n_train_steps': 0, 'every_n_epochs': 1, 'train_time_interval': None}.on_before_backward       \t|  9.7123e-07     \t|  33             \t|  3.2051e-05     \t|  0.00025932     \t|\n",
      "|  [Callback]LearningRateMonitor.on_validation_batch_end                                                                                                                     \t|  3.6266e-06     \t|  5              \t|  1.8133e-05     \t|  0.00014671     \t|\n",
      "|  [Callback]ModelSummary.on_train_start                                                                                                                                     \t|  1.7613e-05     \t|  1              \t|  1.7613e-05     \t|  0.00014251     \t|\n",
      "|  [Callback]ModelSummary.on_validation_batch_end                                                                                                                            \t|  2.3102e-06     \t|  5              \t|  1.1551e-05     \t|  9.3459e-05     \t|\n",
      "|  [Callback]LearningRateMonitor.on_validation_batch_start                                                                                                                   \t|  2.116e-06      \t|  5              \t|  1.058e-05      \t|  8.56e-05       \t|\n",
      "|  [Callback]LearningRateMonitor.on_validation_start                                                                                                                         \t|  4.7139e-06     \t|  2              \t|  9.4278e-06     \t|  7.6279e-05     \t|\n",
      "|  [LightningModule]Denoiser.on_train_epoch_start                                                                                                                            \t|  8.8364e-06     \t|  1              \t|  8.8364e-06     \t|  7.1494e-05     \t|\n",
      "|  [LightningModule]Denoiser.on_validation_batch_end                                                                                                                         \t|  1.5672e-06     \t|  5              \t|  7.8361e-06     \t|  6.3401e-05     \t|\n",
      "|  [Callback]ModelSummary.on_validation_start                                                                                                                                \t|  3.8822e-06     \t|  2              \t|  7.7644e-06     \t|  6.2821e-05     \t|\n",
      "|  [Callback]ModelSummary.on_validation_batch_start                                                                                                                          \t|  1.4709e-06     \t|  5              \t|  7.3547e-06     \t|  5.9506e-05     \t|\n",
      "|  [Callback]ModelSummary.on_train_epoch_start                                                                                                                               \t|  6.7716e-06     \t|  1              \t|  6.7716e-06     \t|  5.4789e-05     \t|\n",
      "|  [Callback]LearningRateMonitor.on_validation_epoch_end                                                                                                                     \t|  3.1204e-06     \t|  2              \t|  6.2408e-06     \t|  5.0493e-05     \t|\n",
      "|  [LightningModule]Denoiser.on_validation_batch_start                                                                                                                       \t|  1.2241e-06     \t|  5              \t|  6.1207e-06     \t|  4.9521e-05     \t|\n",
      "|  [Callback]ModelCheckpoint{'monitor': 'eval/part_acc', 'mode': 'max', 'every_n_train_steps': 0, 'every_n_epochs': 1, 'train_time_interval': None}.on_validation_batch_end  \t|  1.2206e-06     \t|  5              \t|  6.103e-06      \t|  4.9378e-05     \t|\n",
      "|  [Callback]LearningRateMonitor.on_train_end                                                                                                                                \t|  5.9204e-06     \t|  1              \t|  5.9204e-06     \t|  4.7901e-05     \t|\n",
      "|  [LightningModule]Denoiser.on_train_start                                                                                                                                  \t|  5.7211e-06     \t|  1              \t|  5.7211e-06     \t|  4.6289e-05     \t|\n",
      "|  [Callback]ModelCheckpoint{'monitor': 'eval/part_acc', 'mode': 'max', 'every_n_train_steps': 0, 'every_n_epochs': 1, 'train_time_interval': None}.on_validation_batch_start\t|  1.1183e-06     \t|  5              \t|  5.5917e-06     \t|  4.5241e-05     \t|\n",
      "|  [Callback]LearningRateMonitor.on_save_checkpoint                                                                                                                          \t|  2.3949e-06     \t|  2              \t|  4.7898e-06     \t|  3.8754e-05     \t|\n",
      "|  [Callback]LearningRateMonitor.on_fit_end                                                                                                                                  \t|  4.6985e-06     \t|  1              \t|  4.6985e-06     \t|  3.8015e-05     \t|\n",
      "|  [Callback]LearningRateMonitor.on_validation_end                                                                                                                           \t|  2.3143e-06     \t|  2              \t|  4.6287e-06     \t|  3.745e-05      \t|\n",
      "|  [LightningModule]Denoiser.on_validation_start                                                                                                                             \t|  2.3092e-06     \t|  2              \t|  4.6184e-06     \t|  3.7367e-05     \t|\n",
      "|  [Callback]TQDMProgressBar.setup                                                                                                                                           \t|  4.3781e-06     \t|  1              \t|  4.3781e-06     \t|  3.5423e-05     \t|\n",
      "|  [Callback]ModelSummary.on_validation_end                                                                                                                                  \t|  2.1034e-06     \t|  2              \t|  4.2068e-06     \t|  3.4037e-05     \t|\n",
      "|  [Strategy]SingleDeviceStrategy.on_validation_start                                                                                                                        \t|  2.0838e-06     \t|  2              \t|  4.1677e-06     \t|  3.372e-05      \t|\n",
      "|  [Strategy]SingleDeviceStrategy.on_train_start                                                                                                                             \t|  3.5064e-06     \t|  1              \t|  3.5064e-06     \t|  2.837e-05      \t|\n",
      "|  [Callback]ModelCheckpoint{'monitor': 'eval/part_acc', 'mode': 'max', 'every_n_train_steps': 0, 'every_n_epochs': 1, 'train_time_interval': None}.on_fit_start             \t|  3.4263e-06     \t|  1              \t|  3.4263e-06     \t|  2.7722e-05     \t|\n",
      "|  [Callback]LearningRateMonitor.on_validation_epoch_start                                                                                                                   \t|  1.6727e-06     \t|  2              \t|  3.3453e-06     \t|  2.7066e-05     \t|\n",
      "|  [LightningModule]Denoiser.configure_callbacks                                                                                                                             \t|  3.1665e-06     \t|  1              \t|  3.1665e-06     \t|  2.562e-05      \t|\n",
      "|  [Callback]TQDMProgressBar.on_sanity_check_end                                                                                                                             \t|  3.0054e-06     \t|  1              \t|  3.0054e-06     \t|  2.4316e-05     \t|\n",
      "|  [Callback]LearningRateMonitor.setup                                                                                                                                       \t|  2.9448e-06     \t|  1              \t|  2.9448e-06     \t|  2.3826e-05     \t|\n",
      "|  [Callback]LearningRateMonitor.on_sanity_check_end                                                                                                                         \t|  2.7753e-06     \t|  1              \t|  2.7753e-06     \t|  2.2455e-05     \t|\n",
      "|  [Callback]ModelCheckpoint{'monitor': 'eval/part_acc', 'mode': 'max', 'every_n_train_steps': 0, 'every_n_epochs': 1, 'train_time_interval': None}.on_train_start           \t|  2.725e-06      \t|  1              \t|  2.725e-06      \t|  2.2048e-05     \t|\n",
      "|  [Callback]ModelSummary.on_sanity_check_start                                                                                                                              \t|  2.7046e-06     \t|  1              \t|  2.7046e-06     \t|  2.1882e-05     \t|\n",
      "|  [Callback]ModelCheckpoint{'monitor': 'eval/part_acc', 'mode': 'max', 'every_n_train_steps': 0, 'every_n_epochs': 1, 'train_time_interval': None}.on_validation_start      \t|  1.2377e-06     \t|  2              \t|  2.4755e-06     \t|  2.0029e-05     \t|\n",
      "|  [LightningModule]Denoiser.teardown                                                                                                                                        \t|  2.455e-06      \t|  1              \t|  2.455e-06      \t|  1.9863e-05     \t|\n",
      "|  [Callback]LearningRateMonitor.on_fit_start                                                                                                                                \t|  2.4047e-06     \t|  1              \t|  2.4047e-06     \t|  1.9456e-05     \t|\n",
      "|  [LightningModule]Denoiser.on_validation_end                                                                                                                               \t|  1.1874e-06     \t|  2              \t|  2.3749e-06     \t|  1.9215e-05     \t|\n",
      "|  [Callback]LearningRateMonitor.on_train_epoch_end                                                                                                                          \t|  2.3441e-06     \t|  1              \t|  2.3441e-06     \t|  1.8966e-05     \t|\n",
      "|  [LightningModule]Denoiser.on_train_end                                                                                                                                    \t|  2.3134e-06     \t|  1              \t|  2.3134e-06     \t|  1.8717e-05     \t|\n",
      "|  [Callback]LearningRateMonitor.on_sanity_check_start                                                                                                                       \t|  2.2743e-06     \t|  1              \t|  2.2743e-06     \t|  1.8401e-05     \t|\n",
      "|  [Callback]ModelCheckpoint{'monitor': 'eval/part_acc', 'mode': 'max', 'every_n_train_steps': 0, 'every_n_epochs': 1, 'train_time_interval': None}.on_save_checkpoint       \t|  1.1278e-06     \t|  2              \t|  2.2557e-06     \t|  1.825e-05      \t|\n",
      "|  [Callback]TQDMProgressBar.on_validation_epoch_end                                                                                                                         \t|  1.0817e-06     \t|  2              \t|  2.1635e-06     \t|  1.7504e-05     \t|\n",
      "|  [Callback]TQDMProgressBar.on_save_checkpoint                                                                                                                              \t|  1.0626e-06     \t|  2              \t|  2.1253e-06     \t|  1.7195e-05     \t|\n",
      "|  [Callback]ModelSummary.on_train_end                                                                                                                                       \t|  1.9632e-06     \t|  1              \t|  1.9632e-06     \t|  1.5884e-05     \t|\n",
      "|  [Strategy]SingleDeviceStrategy.on_train_end                                                                                                                               \t|  1.9548e-06     \t|  1              \t|  1.9548e-06     \t|  1.5816e-05     \t|\n",
      "|  [Callback]ModelSummary.on_save_checkpoint                                                                                                                                 \t|  9.723e-07      \t|  2              \t|  1.9446e-06     \t|  1.5734e-05     \t|\n",
      "|  [Callback]LearningRateMonitor.teardown                                                                                                                                    \t|  1.9046e-06     \t|  1              \t|  1.9046e-06     \t|  1.541e-05      \t|\n",
      "|  [LightningModule]Denoiser.on_validation_epoch_start                                                                                                                       \t|  9.4203e-07     \t|  2              \t|  1.8841e-06     \t|  1.5244e-05     \t|\n",
      "|  [Callback]TQDMProgressBar.on_validation_epoch_start                                                                                                                       \t|  9.4157e-07     \t|  2              \t|  1.8831e-06     \t|  1.5236e-05     \t|\n",
      "|  [Callback]ModelCheckpoint{'monitor': 'eval/part_acc', 'mode': 'max', 'every_n_train_steps': 0, 'every_n_epochs': 1, 'train_time_interval': None}.on_validation_epoch_end  \t|  9.4157e-07     \t|  2              \t|  1.8831e-06     \t|  1.5236e-05     \t|\n",
      "|  [Callback]ModelSummary.on_validation_epoch_end                                                                                                                            \t|  9.3179e-07     \t|  2              \t|  1.8636e-06     \t|  1.5078e-05     \t|\n",
      "|  [Callback]ModelSummary.on_validation_epoch_start                                                                                                                          \t|  9.2201e-07     \t|  2              \t|  1.844e-06      \t|  1.492e-05      \t|\n",
      "|  [Callback]ModelCheckpoint{'monitor': 'eval/part_acc', 'mode': 'max', 'every_n_train_steps': 0, 'every_n_epochs': 1, 'train_time_interval': None}.on_validation_epoch_start\t|  9.0199e-07     \t|  2              \t|  1.804e-06      \t|  1.4596e-05     \t|\n",
      "|  [Callback]ModelSummary.on_train_epoch_end                                                                                                                                 \t|  1.7527e-06     \t|  1              \t|  1.7527e-06     \t|  1.4181e-05     \t|\n",
      "|  [LightningModule]Denoiser.on_fit_end                                                                                                                                      \t|  1.7527e-06     \t|  1              \t|  1.7527e-06     \t|  1.4181e-05     \t|\n",
      "|  [LightningModule]Denoiser.on_save_checkpoint                                                                                                                              \t|  8.2608e-07     \t|  2              \t|  1.6522e-06     \t|  1.3367e-05     \t|\n",
      "|  [Strategy]SingleDeviceStrategy.on_validation_end                                                                                                                          \t|  8.2189e-07     \t|  2              \t|  1.6438e-06     \t|  1.33e-05       \t|\n",
      "|  [LightningModule]Denoiser.setup                                                                                                                                           \t|  1.6131e-06     \t|  1              \t|  1.6131e-06     \t|  1.3051e-05     \t|\n",
      "|  [LightningModule]Denoiser.on_fit_start                                                                                                                                    \t|  1.6131e-06     \t|  1              \t|  1.6131e-06     \t|  1.3051e-05     \t|\n",
      "|  [Callback]TQDMProgressBar.on_fit_end                                                                                                                                      \t|  1.2917e-06     \t|  1              \t|  1.2917e-06     \t|  1.0451e-05     \t|\n",
      "|  [Callback]ModelSummary.setup                                                                                                                                              \t|  1.2228e-06     \t|  1              \t|  1.2228e-06     \t|  9.8937e-06     \t|\n",
      "|  [Callback]ModelCheckpoint{'monitor': 'eval/part_acc', 'mode': 'max', 'every_n_train_steps': 0, 'every_n_epochs': 1, 'train_time_interval': None}.on_sanity_check_start    \t|  1.2219e-06     \t|  1              \t|  1.2219e-06     \t|  9.8862e-06     \t|\n",
      "|  [Callback]TQDMProgressBar.on_fit_start                                                                                                                                    \t|  1.2023e-06     \t|  1              \t|  1.2023e-06     \t|  9.728e-06      \t|\n",
      "|  [Callback]ModelCheckpoint{'monitor': 'eval/part_acc', 'mode': 'max', 'every_n_train_steps': 0, 'every_n_epochs': 1, 'train_time_interval': None}.on_train_epoch_start     \t|  1.1623e-06     \t|  1              \t|  1.1623e-06     \t|  9.404e-06      \t|\n",
      "|  [Callback]ModelCheckpoint{'monitor': 'eval/part_acc', 'mode': 'max', 'every_n_train_steps': 0, 'every_n_epochs': 1, 'train_time_interval': None}.on_sanity_check_end      \t|  1.0915e-06     \t|  1              \t|  1.0915e-06     \t|  8.8313e-06     \t|\n",
      "|  [Callback]ModelCheckpoint{'monitor': 'eval/part_acc', 'mode': 'max', 'every_n_train_steps': 0, 'every_n_epochs': 1, 'train_time_interval': None}.on_train_end             \t|  1.072e-06      \t|  1              \t|  1.072e-06      \t|  8.673e-06      \t|\n",
      "|  [LightningModule]Denoiser.on_train_epoch_end                                                                                                                              \t|  1.0412e-06     \t|  1              \t|  1.0412e-06     \t|  8.4244e-06     \t|\n",
      "|  [Callback]TQDMProgressBar.teardown                                                                                                                                        \t|  1.0021e-06     \t|  1              \t|  1.0021e-06     \t|  8.1079e-06     \t|\n",
      "|  [Callback]ModelSummary.on_fit_end                                                                                                                                         \t|  9.8068e-07     \t|  1              \t|  9.8068e-07     \t|  7.9346e-06     \t|\n",
      "|  [Callback]ModelSummary.on_sanity_check_end                                                                                                                                \t|  9.723e-07      \t|  1              \t|  9.723e-07      \t|  7.8668e-06     \t|\n",
      "|  [Callback]ModelSummary.teardown                                                                                                                                           \t|  9.3225e-07     \t|  1              \t|  9.3225e-07     \t|  7.5428e-06     \t|\n",
      "|  [Callback]ModelCheckpoint{'monitor': 'eval/part_acc', 'mode': 'max', 'every_n_train_steps': 0, 'every_n_epochs': 1, 'train_time_interval': None}.teardown                 \t|  9.3132e-07     \t|  1              \t|  9.3132e-07     \t|  7.5352e-06     \t|\n",
      "|  [Callback]ModelCheckpoint{'monitor': 'eval/part_acc', 'mode': 'max', 'every_n_train_steps': 0, 'every_n_epochs': 1, 'train_time_interval': None}.on_fit_end               \t|  8.8196e-07     \t|  1              \t|  8.8196e-07     \t|  7.1359e-06     \t|\n",
      "----------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# initialize model\n",
    "model = hydra.utils.instantiate(cfg.model.model_name, cfg)\n",
    "\n",
    "if cfg.model.encoder_weights_path is not None:\n",
    "    encoder_weights = torch.load(cfg.model.encoder_weights_path)['state_dict']\n",
    "    model.encoder.load_state_dict({k.replace('ae.', ''): v for k, v in encoder_weights.items()})\n",
    "    # freeze the encoder\n",
    "    for param in model.encoder.parameters():\n",
    "        param.requires_grad = False\n",
    "\n",
    "# initialize logger\n",
    "#logger = hydra.utils.instantiate(cfg.logger)\n",
    "\n",
    "# initialize callbacks\n",
    "callbacks = init_callbacks(cfg)\n",
    "\n",
    "# initialize trainer\n",
    "trainer = pl.Trainer(\n",
    "    callbacks=callbacks,\n",
    "    #logger=logger,\n",
    "    **cfg.trainer\n",
    ")\n",
    "\n",
    "# check the checkpoint\n",
    "if cfg.ckpt_path is not None:\n",
    "    assert os.path.exists(cfg.ckpt_path), \"Error: Checkpoint path does not exist.\"\n",
    "\n",
    "# start training\n",
    "trainer.fit(\n",
    "    model=model, \n",
    "    train_dataloaders=train_loader,\n",
    "    val_dataloaders=val_loader,\n",
    "    ckpt_path=cfg.ckpt_path\n",
    ")\n",
    "\n",
    "\n",
    "\n",
    "#77222a952435b1b516e70facc0fd8554f280f918\n",
    "#main(cfg)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10f51a5a-941b-4b89-9d4e-66e174c5eab3",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4149b731-2b62-4b81-9bf9-ddfed28b9cf7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4eb35d84-39e3-46b0-8214-92179723f2b2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c019b673-c922-48f3-8784-f4f7d9bd7b45",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "20e7e030-cdf9-47e7-9200-8401990c0f13",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 111/111 [00:00<00:00, 397.75it/s]\n",
      "100%|██████████| 34/34 [00:00<00:00, 445.07it/s]\n"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "620ef535-8335-4ee1-8d9c-560c88bd4134",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.0023310933697341246, 0.0015830856048894128, 0.9999960299139538][-0.004443423627300274, 0.0013972501207013242, 0.9999891517804423]\n",
      "\n",
      "[-0.0004559545197791059, -0.0029019871773632686, 0.9999956852786409][-0.24204741158538035, 0.9700860169589446, -0.018605650903624166][-0.3679854355984607, 0.9271458227198749, -0.07062112007393574][-0.0011881504254301878, 0.003811472701271705, 0.9999920304554502][0.38377062836926307, -0.019864694854441884, 0.9232147630423817][0.0012962371559663572, -0.00015562117196977362, 0.99999914777528]\n",
      "\n",
      "\n",
      "[0.000529146338763008, -0.0015071868560194946, 0.9999987241951529]\n",
      "\n",
      "[-0.020661201355968672, 0.3163161190240201, 0.9484288205258791]\n",
      "\n",
      "\n",
      "[0.0017172670171577413, 0.00039634059636881275, 0.9999984469528558][5.2182471482640205e-05, 0.0001546709254816406, 0.9999999866769472][-0.0017905376519198597, 0.001005341442517636, 0.9999978916295278]\n",
      "\n",
      "\n",
      "[-0.00046062570703669974, -0.00437929463715628, 0.9999903047542207][-0.0007356788925982891, 0.000404774382868923, 0.9999996474670708][0.0009660141425714579, 0.0006509774801684812, 0.999999321522268]\n",
      "[0.016776775940853018, -0.05829995140651092, 0.9981581314877062][0.001165711872413589, -0.0003067504309856726, 0.9999992735097378]\n",
      "\n",
      "\n",
      "[0.0010617845855498656, -0.00037221633865867145, 0.9999993670340452]\n",
      "[-0.014010578446671893, 0.99988893801324, -0.0050808788949091065]\n",
      "\n",
      "[0.001491811329554606, -0.000665595504079925, 0.9999986657399008]\n",
      "[0.0010979564916027281, -0.0015857098244083157, 0.999998140006218][0.04078991170425477, 0.8248012554882347, 0.5639495296994146]\n",
      "\n",
      "[-0.0015322435650367773, 0.0016565977039421037, 0.9999974539536111][0.0032218374274953186, -0.003911236462006107, 0.9999871609140434][0.001396299990026377, 0.0003120765034712235, 0.999998976476773][-0.00015109855520524157, -0.0008074107399831527, 0.9999996626285047][0.00017307679167758087, -2.3551292298598193e-05, 0.9999999847448803]\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "[-0.23180532688661903, 0.38479005615280826, 0.8934220184844933]\n",
      "[-0.0036554817436341446, 0.31409628050772376, 0.949384097204306]\n",
      "[-0.0026057804449120133, 0.0003446198634592692, 0.9999965455667449]\n",
      "[0.000397256595071887, -0.002139206569151809, 0.9999976329884248]\n",
      "[0.0007639153288705559, 0.0004662087754931076, 0.9999995995412937][0.006133322731370479, 0.005515296846335418, 0.9999659813478505]\n",
      "[-9.135613057662335e-05, -0.00017976830196357943, 0.9999999796687075][-0.002820428067096727, 0.0033806343684920134, 0.9999903082014269][0.0016957960975079315, 0.000953112221317812, 0.9999981079245547][-0.0003947107388528422, 0.001037685588850714, 0.9999993837058357]\n",
      "\n",
      "\n",
      "[0.00108304010679386, 0.0023365972263299332, 0.9999966836632654]\n",
      "\n",
      "\n",
      "[-0.027806990177800972, 0.48686215471542166, 0.8730360895192755]\n",
      "[0.027425279836741184, 0.8323298594402707, -0.5536017152339898][0.00011311905922763445, -0.001283418362074343, 0.9999991700203488]\n",
      "\n",
      "\n",
      "[0.004845684071200814, 0.004867085046576349, 0.9999764151363929][7.757752667663711e-05, -0.0015987118089970899, 0.9999987190503192][0.0025862621634743944, -0.0010817469505175928, 0.9999960705280581][-8.77424537180499e-06, 0.001577737406287304, 0.9999987553330701]\n",
      "\n",
      "\n",
      "[0.2755085042887906, 0.9561751086133214, -0.09911723226995647][0.0007407809707199651, -0.002329236823907477, 0.9999970129452246][-0.003415896861222844, -0.0007955379556408913, 0.9999938493650822]\n",
      "\n",
      "\n",
      "[-0.0019639067814408977, -0.0007081444716150085, 0.9999978207984062][0.002020468472338712, 0.0015140143646063912, 0.9999968127287487]\n",
      "\n",
      "[0.0007999775056869109, -0.0002633793476275826, 0.9999996453335919][-3.591279946008401e-05, 0.0006080019547883433, 0.9999998145219298]\n",
      "[-0.00017296120741035946, -0.001484341227807583, 0.9999988834071468][0.00033101674378632523, 0.0022820096425137104, 0.9999973414264194][0.0016334286942129605, -0.003070582597870835, 0.9999939516983143][0.009816863938869515, -0.008685514970314638, 0.999914091815945]\n",
      "\n",
      "[-0.0017794544301024105, -0.0018790341285567723, 0.9999966513807309]\n",
      "\n",
      "\n",
      "\n",
      "[0.001444319089052168, 0.0007763751167940549, 0.9999986555911199]\n",
      "[-0.052512921804950576, 0.30885587414775106, 0.9496580658573568]\n",
      "[-0.0002018122976245753, -0.002240886839577584, 0.9999974688457809]\n",
      "[-0.027059738255225084, -0.5660908753508207, 0.8238985929166891]\n",
      "[0.18806376501521388, 0.4464548993678401, 0.8748200061262625]\n",
      "tensor(51) shape/cube/0/cube_512_256_2_2_2\n",
      "tensor(2) shape/cube/0/cube_32_16_0_1_2\n",
      "tensor(47) shape/cube/0/cube_512_256_2_1_1\n",
      "[0.002377961167387286, -0.003730377291479072, 0.9999902147450992]\n",
      "[0.00026902167079691274, -0.5211830102106068, 0.8534449000932346]\n",
      "[-0.0009495577762558772, -0.0016865105600868833, 0.9999981270093262]\n",
      "tensor(59) shape/cube/0/cube_512_256_3_1_1\n",
      "tensor(60) shape/cube/0/cube_512_256_3_1_2\n",
      "tensor(102) shape/ellipsoid/0/ellipsoid_512_128_64_64_3_1_0\n",
      "[0.0016133744320548592, 0.0038749711400344715, 0.9999911907720017]\n",
      "[-0.0003864872739987947, -0.002328268598042071, 0.9999972148925828]\n",
      "[-0.000920231219030409, -0.001970917469107558, 0.9999976343266186]\n",
      "tensor(20) shape/cube/0/cube_32_16_2_0_1\n",
      "tensor(25) shape/cube/0/cube_512_256_0_1_3\n",
      "tensor(95) shape/ellipsoid/0/ellipsoid_512_128_64_64_2_2_2\n",
      "[0.0013188244878948841, -0.0010578539781233097, 0.9999985708224443]\n",
      "[0.0035403027278557496, -0.006066782693172708, 0.9999753298978675]\n",
      "[0.0020133029798201536, -0.0037680328568803633, 0.9999908742281106]\n",
      "tensor(38) shape/cube/0/cube_512_256_1_2_1\n",
      "tensor(88) shape/ellipsoid/0/ellipsoid_512_128_64_64_1_3_3\n",
      "tensor(8) shape/cube/0/cube_32_16_0_3_2\n",
      "[-0.002230184164054306, -0.00026709720809729866, 0.9999974774656564]\n",
      "[-0.0005118962550252263, 0.0016245517621710445, 0.999998549395846]\n",
      "[1.2951676006380025e-06, -0.0013859852014617663, 0.9999990395212107]\n",
      "tensor(14) shape/cube/0/cube_32_16_1_1_2\n",
      "tensor(78) shape/ellipsoid/0/ellipsoid_512_128_64_64_1_0_2\n",
      "tensor(65) shape/cube/0/cube_512_256_3_3_1\n",
      "[0.002343203114821007, 0.0034354846619825048, 0.999991353384768]\n",
      "[0.07168915327800375, -0.3634628087585401, 0.9288463015761197]\n",
      "[1.9333728294894972e-05, -4.844326261441356e-05, 0.9999999986397285]\n",
      "tensor(13) shape/cube/0/cube_32_16_1_1_1\n",
      "tensor(69) shape/cube/0/cube_64_32_0_1_1\n",
      "tensor(7) shape/cube/0/cube_32_16_0_3_1\n",
      "[0.0007027070470318723, -0.0008172350062945973, 0.9999994191647066]\n",
      "[0.1127728027164505, -0.008415796351485254, 0.9935851595808217]\n",
      "[0.0009209608810883756, 0.0006075028586136745, 0.999999391385481]\n",
      "tensor(3) shape/cube/0/cube_32_16_0_1_3\n",
      "tensor(57) shape/cube/0/cube_512_256_3_0_2\n",
      "tensor(17) shape/cube/0/cube_32_16_1_3_1\n",
      "[0.018550707452636532, 0.030870302525691784, 0.999351237391028]\n",
      "[-0.5577809929157332, 0.03585143811350604, 0.829213505875979]\n",
      "[-0.0030729113636986764, -0.0008334538444073574, 0.9999949312723742]\n",
      "tensor(23) shape/cube/0/cube_512_256_0_1_1\n",
      "tensor(55) shape/cube/0/cube_512_256_2_3_3\n",
      "tensor(76) shape/ellipsoid/0/ellipsoid_512_128_64_64_0_3_3\n",
      "[4.51735225700552e-05, -0.0019622736980482664, 0.999998073718788]\n",
      "[-0.00019638715522693934, -0.002497385727724991, 0.9999968622433834]\n",
      "[0.0021270500462623543, 0.001022702113278205, 0.9999972148653656]\n",
      "tensor(109) shape/ellipsoid/0/ellipsoid_512_128_64_64_3_3_2\n",
      "tensor(70) shape/ellipsoid/0/ellipsoid_512_128_64_64_0_1_0\n",
      "tensor(97) shape/ellipsoid/0/ellipsoid_512_128_64_64_2_3_0\n",
      "[-0.0012181124737885554, -0.002091936159197654, 0.9999970699982611]\n",
      "[0.19608970320998872, 0.10000544984611393, 0.9754730843524566]\n",
      "[-0.0010051127461067127, 0.00024937710657773026, 0.9999994637795693]\n",
      "tensor(73) shape/ellipsoid/0/ellipsoid_512_128_64_64_0_2_2\n",
      "tensor(41) shape/cube/0/cube_512_256_1_3_1\n",
      "tensor(107) shape/ellipsoid/0/ellipsoid_512_128_64_64_3_2_3\n",
      "[-0.0002278969502997703, 0.0010263100647780947, 0.9999994473751628]\n",
      "[-0.0036968918244150526, -0.0019375334579059171, 0.9999912894395322]\n",
      "[0.0018643576669332472, 0.00016177994067527189, 0.9999982489973371]\n",
      "tensor(94) shape/ellipsoid/0/ellipsoid_512_128_64_64_2_2_0\n",
      "tensor(24) shape/cube/0/cube_512_256_0_1_2\n",
      "tensor(98) shape/ellipsoid/0/ellipsoid_512_128_64_64_2_3_2\n",
      "[0.0020298703847228053, -0.0017826864520461762, 0.9999963508209592]\n",
      "[-0.00024077142770494072, -0.002135352068033888, 0.9999976911476672]\n",
      "[0.00019822279166777866, 0.00013122454900435252, 0.9999999717439209]\n",
      "tensor(79) shape/ellipsoid/0/ellipsoid_512_128_64_64_1_0_3\n",
      "tensor(75) shape/ellipsoid/0/ellipsoid_512_128_64_64_0_3_2\n",
      "tensor(63) shape/cube/0/cube_512_256_3_2_2\n",
      "[0.0035429211211991866, 9.298746785348108e-05, 0.9999937195119076]\n",
      "\n",
      "[0.0031615987867957933, -0.0026955872971856044, 0.9999913690138703][0.5568802988995569, -0.0369791444570679, 0.8297691700543975]\n",
      "tensor(66) shape/cube/0/cube_512_256_3_3_2\n",
      "tensor(91) shape/ellipsoid/0/ellipsoid_512_128_64_64_2_1_0\n",
      "tensor(104) shape/ellipsoid/0/ellipsoid_512_128_64_64_3_1_3\n",
      "[0.00200606578501684, 0.0018908969312673224, 0.9999962000972111]\n",
      "[0.3748142339218191, -0.041271621888485675, 0.9261808372430806]\n",
      "\n",
      "[0.0012809560614364147, -0.004230614781601295, 0.9999902304773474]tensor(27) shape/cube/0/cube_512_256_0_2_2\n",
      "tensor(31) shape/cube/0/cube_512_256_0_3_3\n",
      "tensor(106) shape/ellipsoid/0/ellipsoid_512_128_64_64_3_2_2\n",
      "[0.1751072825458397, 0.3552854896671616, 0.9182100306745602]\n",
      "[-5.5664806994391885e-05, 0.001350031625611221, 0.9999990871576029]\n",
      "[0.0002783786490787495, -0.001666897814706321, 0.9999985719774819]\n",
      "tensor(58) shape/cube/0/cube_512_256_3_0_3\n",
      "tensor(6) shape/cube/0/cube_32_16_0_2_3\n",
      "tensor(44) shape/cube/0/cube_512_256_2_0_1\n",
      "[0.0012099385677657659, 0.0015048401863184575, 0.9999981357506001]\n",
      "\n",
      "[0.0004189991832912792, -0.0015214664449231222, 0.9999987547889954][-0.002490695790687604, -0.0007726215004182351, 0.9999965997394666]\n",
      "tensor(45) shape/cube/0/cube_512_256_2_0_2\n",
      "tensor(105) shape/ellipsoid/0/ellipsoid_512_128_64_64_3_2_0\n",
      "tensor(35) shape/cube/0/cube_512_256_1_1_1\n",
      "[-0.0014622777651844589, 0.0008876018217136106, 0.9999985369523016]\n",
      "[-0.00015702627024821007, 0.000800906943366962, 0.9999996669453538]\n",
      "[3.632662163939413e-05, 0.0010408479763502248, 0.9999994576577862]\n",
      "tensor(40) shape/cube/0/cube_512_256_1_2_3\n",
      "tensor(52) shape/cube/0/cube_512_256_2_2_3\n",
      "tensor(26) shape/cube/0/cube_512_256_0_2_1\n",
      "tensor(33) shape/cube/0/cube_512_256_1_0_2\n",
      "tensor(19) shape/cube/0/cube_32_16_1_3_3\n",
      "tensor(100) shape/ellipsoid/0/ellipsoid_512_128_64_64_3_0_2\n",
      "tensor(1) shape/cube/0/cube_32_16_0_1_1\n",
      "tensor(85) shape/ellipsoid/0/ellipsoid_512_128_64_64_1_2_3\n",
      "tensor(4) shape/cube/0/cube_32_16_0_2_1\n",
      "tensor(101) shape/ellipsoid/0/ellipsoid_512_128_64_64_3_0_3\n",
      "tensor(28) shape/cube/0/cube_512_256_0_2_3\n",
      "tensor(77) shape/ellipsoid/0/ellipsoid_512_128_64_64_1_0_0\n",
      "tensor(62) shape/cube/0/cube_512_256_3_2_1\n",
      "tensor(9) shape/cube/0/cube_32_16_0_3_3\n",
      "tensor(16) shape/cube/0/cube_32_16_1_2_1\n",
      "tensor(53) shape/cube/0/cube_512_256_2_3_1\n",
      "tensor(5) shape/cube/0/cube_32_16_0_2_2\n",
      "tensor(48) shape/cube/0/cube_512_256_2_1_2\n",
      "tensor(36) shape/cube/0/cube_512_256_1_1_2\n",
      "tensor(42) shape/cube/0/cube_512_256_1_3_2\n",
      "tensor(96) shape/ellipsoid/0/ellipsoid_512_128_64_64_2_2_3\n",
      "tensor(103) shape/ellipsoid/0/ellipsoid_512_128_64_64_3_1_2\n",
      "tensor(67) shape/cube/0/cube_512_256_3_3_3\n",
      "tensor(93) shape/ellipsoid/0/ellipsoid_512_128_64_64_2_1_3\n",
      "tensor(34) shape/cube/0/cube_512_256_1_0_3\n",
      "tensor(87) shape/ellipsoid/0/ellipsoid_512_128_64_64_1_3_2\n",
      "tensor(89) shape/ellipsoid/0/ellipsoid_512_128_64_64_2_0_2\n",
      "tensor(43) shape/cube/0/cube_512_256_1_3_3\n",
      "tensor(15) shape/cube/0/cube_32_16_1_1_3\n",
      "tensor(22) shape/cube/0/cube_512_256_0_0_1\n",
      "tensor(99) shape/ellipsoid/0/ellipsoid_512_128_64_64_2_3_3\n",
      "tensor(0) shape/cube/0/cube_32_16_0_0_1\n",
      "tensor(72) shape/ellipsoid/0/ellipsoid_512_128_64_64_0_1_3\n",
      "tensor(68) shape/cube/0/cube_64_32_0_0_1\n",
      "tensor(10) shape/cube/0/cube_32_16_1_0_1\n",
      "tensor(37) shape/cube/0/cube_512_256_1_1_3\n",
      "tensor(29) shape/cube/0/cube_512_256_0_3_1\n",
      "tensor(84) shape/ellipsoid/0/ellipsoid_512_128_64_64_1_2_2\n",
      "tensor(83) shape/ellipsoid/0/ellipsoid_512_128_64_64_1_2_0\n",
      "tensor(54) shape/cube/0/cube_512_256_2_3_2\n",
      "tensor(12) shape/cube/0/cube_32_16_1_0_3\n",
      "tensor(56) shape/cube/0/cube_512_256_3_0_1\n",
      "tensor(39) shape/cube/0/cube_512_256_1_2_2\n",
      "tensor(80) shape/ellipsoid/0/ellipsoid_512_128_64_64_1_1_0\n",
      "tensor(46) shape/cube/0/cube_512_256_2_0_3\n",
      "tensor(64) shape/cube/0/cube_512_256_3_2_3\n",
      "tensor(30) shape/cube/0/cube_512_256_0_3_2\n",
      "tensor(110) shape/ellipsoid/0/ellipsoid_512_128_64_64_3_3_3\n",
      "tensor(49) shape/cube/0/cube_512_256_2_1_3\n",
      "tensor(21) shape/cube/0/cube_32_16_2_0_2\n",
      "tensor(50) shape/cube/0/cube_512_256_2_2_1\n",
      "tensor(61) shape/cube/0/cube_512_256_3_1_3\n",
      "tensor(11) shape/cube/0/cube_32_16_1_0_2\n",
      "tensor(71) shape/ellipsoid/0/ellipsoid_512_128_64_64_0_1_2\n",
      "tensor(18) shape/cube/0/cube_32_16_1_3_2\n",
      "tensor(81) shape/ellipsoid/0/ellipsoid_512_128_64_64_1_1_2\n",
      "tensor(74) shape/ellipsoid/0/ellipsoid_512_128_64_64_0_2_3\n",
      "tensor(90) shape/ellipsoid/0/ellipsoid_512_128_64_64_2_0_3\n",
      "tensor(108) shape/ellipsoid/0/ellipsoid_512_128_64_64_3_3_0\n",
      "tensor(32) shape/cube/0/cube_512_256_1_0_1\n",
      "tensor(92) shape/ellipsoid/0/ellipsoid_512_128_64_64_2_1_2\n",
      "tensor(86) shape/ellipsoid/0/ellipsoid_512_128_64_64_1_3_0\n",
      "tensor(82) shape/ellipsoid/0/ellipsoid_512_128_64_64_1_1_3\n"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "afb40b7e-7043-42cb-8dd1-4b9b94c51593",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "data:\n",
      "  batch_size: 3\n",
      "  val_batch_size: 3\n",
      "  num_workers: 10\n",
      "  data_fn: shape.{}.txt\n",
      "  data_dir: /disk2/data/shape_dataset/data/pc_data/shape/train/\n",
      "  data_val_dir: /disk2/data/shape_dataset/data/pc_data/shape/val/\n",
      "  mesh_data_dir: /disk2/data/shape_dataset/data/\n",
      "  rot_range: -1\n",
      "  overfit: -1\n",
      "  data_keys:\n",
      "  - part_ids\n",
      "  num_pc_points: 1000\n",
      "  min_num_part: 2\n",
      "  max_num_part: 20\n",
      "  shuffle_parts: false\n",
      "  category: all\n",
      "ae:\n",
      "  ae_name:\n",
      "    _target_: puzzlefusion_plusplus.denoiser.model.modules.encoder.VQVAE\n",
      "  n_embeddings: 1024\n",
      "  embedding_dim: 16\n",
      "  num_point: 25\n",
      "  num_dim: 64\n",
      "  local_decode_pts: 40\n",
      "  beta: 0.25\n",
      "hydra:\n",
      "  output_subdir: null\n",
      "  run:\n",
      "    dir: .\n",
      "defaults:\n",
      "- _self_\n",
      "- encoder\n",
      "- data\n",
      "- model\n",
      "- override hydra/hydra_logging: disabled\n",
      "- override hydra/job_logging: disabled\n",
      "project_root_path: /disk2/data/shape_dataset/\n",
      "experiment_output_path: /disk2/data/shape_dataset/output/denoiser/${experiment_name}/\n",
      "ckpt_path: null\n",
      "experiment_name: shape_epoch10\n",
      "train_seed: 123\n",
      "test_seed: 123\n",
      "logger:\n",
      "  _target_: lightning.pytorch.loggers.WandbLogger\n",
      "  project: puzzlefusion_plusplus\n",
      "  name: ${experiment_name}\n",
      "  save_dir: ${experiment_output_path}/training\n",
      "trainer:\n",
      "  accelerator: gpu\n",
      "  max_epochs: 3\n",
      "  num_sanity_val_steps: 1\n",
      "  check_val_every_n_epoch: 1\n",
      "  profiler: simple\n",
      "  precision: 32\n",
      "  devices: 1\n",
      "  strategy: ddp\n",
      "checkpoint_monitor:\n",
      "  _target_: lightning.pytorch.callbacks.ModelCheckpoint\n",
      "  monitor: eval/part_acc\n",
      "  mode: max\n",
      "  save_last: true\n",
      "  save_top_k: 3\n",
      "  every_n_epochs: ${trainer.check_val_every_n_epoch}\n",
      "  filename: '{epoch}'\n",
      "  dirpath: ${experiment_output_path}/training\n",
      "model:\n",
      "  model_name:\n",
      "    _target_: puzzlefusion_plusplus.denoiser.model.denoiser.Denoiser\n",
      "  lr_scheduler:\n",
      "    _target_: torch.optim.lr_scheduler.MultiStepLR\n",
      "    milestones:\n",
      "    - 1200\n",
      "    - 1700\n",
      "    gamma: 0.5\n",
      "  encoder_weights_path: /disk2/data/shape_dataset//output/denoiser/shape_epoch10/training/last.ckpt\n",
      "  multiple_ref_parts: true\n",
      "  num_dim: 64\n",
      "  num_point: 25\n",
      "  out_channels: 7\n",
      "  std: 1\n",
      "  multires: 10\n",
      "  embed_dim: 512\n",
      "  num_layers: 6\n",
      "  num_heads: 8\n",
      "  dropout_rate: 0.1\n",
      "  DDPM_TRAIN_STEPS: 1000\n",
      "  DDPM_BETA_SCHEDULE: linear\n",
      "  timestep_spacing: leading\n",
      "  PREDICT_TYPE: epsilon\n",
      "  BETA_START: 0.0001\n",
      "  BETA_END: 0.02\n",
      "  num_inference_steps: 20\n",
      "\n"
     ]
    }
   ],
   "source": [
    "cfg.model.encoder_weights_path = cfg.experiment_output_path+'/training/last.ckpt'\n",
    "cfg.ckpt_path= None\n",
    "cfg.experiment_output_path = data_home_dir+'output/denoiser/${experiment_name}/'\n",
    "\n",
    "cfg.trainer.strategy='ddp'\n",
    "\n",
    "print(OmegaConf.to_yaml(cfg))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "16aee590-9a22-4dc2-8d19-a5a00f097623",
   "metadata": {},
   "outputs": [],
   "source": [
    "from puzzlefusion_plusplus.denoiser.dataset.dataset import build_geometry_dataloader as denoiser_dataloader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "89b72d05-03e6-417a-88bb-f37a0e6815d8",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Seed set to 123\n",
      "100%|██████████| 111/111 [00:00<00:00, 463.02it/s]\n",
      "100%|██████████| 34/34 [00:00<00:00, 562.25it/s]\n"
     ]
    }
   ],
   "source": [
    "pl.seed_everything(cfg.train_seed, workers=True)\n",
    "\n",
    "# create directories for training outputs\n",
    "os.makedirs(os.path.join(cfg.experiment_output_path, \"training\"), exist_ok=True)\n",
    "\n",
    "# initialize data\n",
    "train_loader, val_loader = denoiser_dataloader(cfg)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "a29014fa-982c-4601-aff8-80a8434b9a87",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'train_loader' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[5], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m nth_batch, batch \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28menumerate\u001b[39m(\u001b[43mtrain_loader\u001b[49m):\n\u001b[1;32m      2\u001b[0m     \u001b[38;5;28mprint\u001b[39m(nth_batch, batch[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mmesh_file_path\u001b[39m\u001b[38;5;124m'\u001b[39m], batch[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mdata_id\u001b[39m\u001b[38;5;124m'\u001b[39m])\n",
      "\u001b[0;31mNameError\u001b[0m: name 'train_loader' is not defined"
     ]
    }
   ],
   "source": [
    "for nth_batch, batch in enumerate(train_loader):\n",
    "    print(nth_batch, batch['mesh_file_path'], batch['data_id'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd3929ef-b1dc-4d9f-ad8a-ed91ca67f738",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# initialize model\n",
    "model = hydra.utils.instantiate(cfg.model.model_name, cfg)\n",
    "\n",
    "if cfg.model.encoder_weights_path is not None:\n",
    "    encoder_weights = torch.load(cfg.model.encoder_weights_path)['state_dict']\n",
    "    model.encoder.load_state_dict({k.replace('ae.', ''): v for k, v in encoder_weights.items()})\n",
    "    # freeze the encoder\n",
    "    for param in model.encoder.parameters():\n",
    "        param.requires_grad = False\n",
    "\n",
    "# initialize logger\n",
    "logger = hydra.utils.instantiate(cfg.logger)\n",
    "\n",
    "# initialize callbacks\n",
    "callbacks = init_callbacks(cfg)\n",
    "\n",
    "# initialize trainer\n",
    "trainer = pl.Trainer(\n",
    "    callbacks=callbacks,\n",
    "    logger=logger,\n",
    "    **cfg.trainer\n",
    ")\n",
    "\n",
    "# check the checkpoint\n",
    "if cfg.ckpt_path is not None:\n",
    "    assert os.path.exists(cfg.ckpt_path), \"Error: Checkpoint path does not exist.\"\n",
    "\n",
    "# start training\n",
    "trainer.fit(\n",
    "    model=model, \n",
    "    train_dataloaders=train_loader,\n",
    "    val_dataloaders=val_loader,\n",
    "    ckpt_path=cfg.ckpt_path\n",
    ")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "slice_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
