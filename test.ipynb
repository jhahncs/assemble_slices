{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "50bf9d62-cb36-4c3c-8064-ec16e68642b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import hydra\n",
    "import lightning.pytorch as pl\n",
    "import torch\n",
    "#from puzzlefusion_plusplus.auto_aggl import AutoAgglomerative\n",
    "from omegaconf import OmegaConf,open_dict\n",
    "import omegaconf\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "94e3f0c3-8916-4488-b771-cfc57a075adf",
   "metadata": {},
   "outputs": [],
   "source": [
    "cfg_auto_aggl = omegaconf.OmegaConf.load('config/auto_aggl.yaml')\n",
    "cfg_denoiser_data = omegaconf.OmegaConf.load('config/denoiser/data.yaml')\n",
    "cfg_denoiser_encode = omegaconf.OmegaConf.load('config/denoiser/encoder.yaml')\n",
    "cfg_denoiser_global_config = omegaconf.OmegaConf.load('config/denoiser/global_config.yaml')\n",
    "cfg_denoiser_model = omegaconf.OmegaConf.load('config/denoiser/model.yaml')\n",
    "\n",
    "cfg_ae_vq_vae = omegaconf.OmegaConf.load('config/ae/vq_vae.yaml')\n",
    "cfg_ae_global_config = omegaconf.OmegaConf.load('config/ae/global_config.yaml')\n",
    "cfg_ae_model = omegaconf.OmegaConf.load('config/ae/model.yaml')\n",
    "\n",
    "\n",
    "cfg = OmegaConf.merge(\n",
    "    cfg_auto_aggl,\n",
    "    {\"denoiser\": cfg_denoiser_data},\n",
    "    {\"denoiser\": cfg_denoiser_encode},\n",
    "    {\"denoiser\": cfg_denoiser_global_config},\n",
    "    {\"denoiser\": cfg_denoiser_model},\n",
    "    {\"ae\": cfg_ae_vq_vae},\n",
    "    {\"ae\": cfg_ae_global_config},\n",
    "    {\"ae\": cfg_ae_model},\n",
    "    #{\"verifier\": omegaconf.OmegaConf.load('config/verifier/global_config.yaml')},\n",
    "    #{\"verifier\": omegaconf.OmegaConf.load('config/verifier/model.yaml')},\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "c8a45e32-7536-41b0-b9b2-f1a127492c2f",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_home_dir = '/disk2/data/breaking_bad/'\n",
    "data_type_name = 'everyday'\n",
    "\n",
    "data_home_dir = '/disk2/data/shape_dataset/'\n",
    "data_type_name = 'shape'\n",
    "\n",
    "with open_dict(cfg):\n",
    "    cfg.experiment_output_path = data_home_dir+'experiment_output/'\n",
    "    cfg.denoiser.data.data_val_dir=f'{data_home_dir}data/pc_data/{data_type_name}/val/'\n",
    "    #cfg.denoiser.ckpt_path= data_home_dir+f'output/denoiser/everyday_epoch100_bs64/training/last.ckpt'\n",
    "    cfg.denoiser.ckpt_path= data_home_dir+f'output/denoiser/shape_epoch10/training/last.ckpt'\n",
    "    cfg.inference_dir= data_home_dir+'results'\n",
    "    cfg.denoiser.data.val_batch_size=1\n",
    "    #cfg.verifier.ckpt_path= '/disk2/data/breaking-bad-dataset/output/verifier/everyday_epoch100_bs64/training/last.ckpt'\n",
    "\n",
    "#print(OmegaConf.to_yaml(cfg))\n",
    "#print(cfg.experiment_output_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "9dfab6b8-7490-4f57-85f4-cb9dd550679b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Seed set to 123\n",
      "\n",
      "  0%|          | 0/34 [00:00<?, ?it/s]\u001b[A\n",
      "100%|██████████| 34/34 [00:00<00:00, 302.88it/s]\u001b[A\n"
     ]
    }
   ],
   "source": [
    "# fix the seed\n",
    "pl.seed_everything(cfg.test_seed, workers=True)\n",
    "\n",
    "# create directories for inference outputs\n",
    "inference_dir = os.path.join(cfg.experiment_output_path, \"inference\", cfg.inference_dir)\n",
    "os.makedirs(inference_dir, exist_ok=True)\n",
    "\n",
    "# initialize data\n",
    "from jahn_src.data_loader_jhahn import build_test_dataloader\n",
    "\n",
    "\n",
    "#from puzzlefusion_plusplus.denoiser.dataset.dataset import build_test_dataloader\n",
    "#cfg.denoiser.data.matching_data_path= '/disk2/data/breaking-bad-dataset/data/matching_data'\n",
    "\n",
    "test_loader = build_test_dataloader(cfg.denoiser)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "5a98a0a5-48ba-43b2-a1cc-396db1031cbd",
   "metadata": {},
   "outputs": [],
   "source": [
    "import importlib\n",
    "import jahn_src.auto_agg_jhahn\n",
    "importlib.reload(jahn_src.myutil)\n",
    "importlib.reload(jahn_src.auto_agg_jhahn)\n",
    "from jahn_src.auto_agg_jhahn import AutoAgglomerative\n",
    "\n",
    "#import importlib\n",
    "#import puzzlefusion_plusplus.auto_aggl\n",
    "#importlib.reload(puzzlefusion_plusplus.auto_aggl)\n",
    "#from puzzlefusion_plusplus.auto_aggl import AutoAgglomerative"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "9a229a62-5b76-4aa2-8f68-d2ca54b0c240",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "acc torch.Size([1]) tensor([0.0556], device='cuda:0')\n",
      "acc_per_part torch.Size([1, 20]) tensor([[False, False, False, False, False, False, False, False, False, False,\n",
      "         False, False, False,  True, False, False, False, False, False, False]],\n",
      "       device='cuda:0')\n",
      "loss_per_data torch.Size([1, 20]) tensor([[ 1.6350,  1.9793,  7.4201,  8.2897,  4.0073,  4.6137,  0.7022,  3.8346,\n",
      "          0.1000,  1.4541,  2.2568,  0.3778, 16.7177,  0.0000,  0.8669,  0.9746,\n",
      "          2.6593,  0.7483,  2.9935,  1.6588]], device='cuda:0')\n",
      "scores torch.Size([1, 190, 1]) tensor([[[0.3606],\n",
      "         [0.4661],\n",
      "         [0.4740],\n",
      "         [0.6008],\n",
      "         [0.4014],\n",
      "         [0.3109],\n",
      "         [0.8094],\n",
      "         [0.9431],\n",
      "         [0.0119],\n",
      "         [0.9150],\n",
      "         [0.3103],\n",
      "         [0.7876],\n",
      "         [0.5375],\n",
      "         [0.2941],\n",
      "         [0.7952],\n",
      "         [0.0212],\n",
      "         [0.0482],\n",
      "         [0.2591],\n",
      "         [0.4319],\n",
      "         [0.1551],\n",
      "         [0.7081],\n",
      "         [0.0260],\n",
      "         [0.3835],\n",
      "         [0.9127],\n",
      "         [0.3716],\n",
      "         [0.3552],\n",
      "         [0.0707],\n",
      "         [0.1281],\n",
      "         [0.6588],\n",
      "         [0.8857],\n",
      "         [0.8023],\n",
      "         [0.2669],\n",
      "         [0.4602],\n",
      "         [0.1158],\n",
      "         [0.1964],\n",
      "         [0.2874],\n",
      "         [0.1051],\n",
      "         [0.2557],\n",
      "         [0.6296],\n",
      "         [0.1763],\n",
      "         [0.3532],\n",
      "         [0.8194],\n",
      "         [0.7831],\n",
      "         [0.2983],\n",
      "         [0.1700],\n",
      "         [0.4573],\n",
      "         [0.5053],\n",
      "         [0.8178],\n",
      "         [0.1967],\n",
      "         [0.7756],\n",
      "         [0.9045],\n",
      "         [0.6958],\n",
      "         [0.8900],\n",
      "         [0.7445],\n",
      "         [0.5654],\n",
      "         [0.4642],\n",
      "         [0.9707],\n",
      "         [0.8627],\n",
      "         [0.9693],\n",
      "         [0.3062],\n",
      "         [0.2860],\n",
      "         [0.7123],\n",
      "         [0.8389],\n",
      "         [0.0055],\n",
      "         [0.8334],\n",
      "         [0.4756],\n",
      "         [0.7439],\n",
      "         [0.1799],\n",
      "         [0.4172],\n",
      "         [0.8903],\n",
      "         [0.7382],\n",
      "         [0.6917],\n",
      "         [0.0091],\n",
      "         [0.6199],\n",
      "         [0.8133],\n",
      "         [0.8189],\n",
      "         [0.3947],\n",
      "         [0.1198],\n",
      "         [0.3066],\n",
      "         [0.9846],\n",
      "         [0.9402],\n",
      "         [0.1524],\n",
      "         [0.4738],\n",
      "         [0.9777],\n",
      "         [0.5838],\n",
      "         [0.8293],\n",
      "         [0.9377],\n",
      "         [0.9866],\n",
      "         [0.0372],\n",
      "         [0.4030],\n",
      "         [0.2672],\n",
      "         [0.8973],\n",
      "         [0.3514],\n",
      "         [0.7056],\n",
      "         [0.3004],\n",
      "         [0.0829],\n",
      "         [0.0116],\n",
      "         [0.8676],\n",
      "         [0.7346],\n",
      "         [0.6912],\n",
      "         [0.3797],\n",
      "         [0.5855],\n",
      "         [0.9888],\n",
      "         [0.4795],\n",
      "         [0.5940],\n",
      "         [0.1858],\n",
      "         [0.4951],\n",
      "         [0.5925],\n",
      "         [0.7761],\n",
      "         [0.5542],\n",
      "         [0.0299],\n",
      "         [0.1005],\n",
      "         [0.3972],\n",
      "         [0.6365],\n",
      "         [0.7611],\n",
      "         [0.3558],\n",
      "         [0.6377],\n",
      "         [0.6524],\n",
      "         [0.5132],\n",
      "         [0.8722],\n",
      "         [0.7321],\n",
      "         [0.7931],\n",
      "         [0.3722],\n",
      "         [0.6966],\n",
      "         [0.3716],\n",
      "         [0.7097],\n",
      "         [0.6541],\n",
      "         [0.1147],\n",
      "         [0.6254],\n",
      "         [0.6401],\n",
      "         [0.3840],\n",
      "         [0.5256],\n",
      "         [0.4580],\n",
      "         [0.2037],\n",
      "         [0.3432],\n",
      "         [0.5570],\n",
      "         [0.7463],\n",
      "         [0.7266],\n",
      "         [0.0198],\n",
      "         [0.4648],\n",
      "         [0.4069],\n",
      "         [0.4919],\n",
      "         [0.2820],\n",
      "         [0.2464],\n",
      "         [0.6025],\n",
      "         [0.7089],\n",
      "         [0.2864],\n",
      "         [0.9219],\n",
      "         [0.7192],\n",
      "         [0.8498],\n",
      "         [0.3656],\n",
      "         [0.9101],\n",
      "         [0.3733],\n",
      "         [0.0850],\n",
      "         [0.4622],\n",
      "         [0.9060],\n",
      "         [0.7369],\n",
      "         [0.5934],\n",
      "         [0.3772],\n",
      "         [0.6764],\n",
      "         [0.7795],\n",
      "         [0.9987],\n",
      "         [0.6191],\n",
      "         [0.4425],\n",
      "         [0.8809],\n",
      "         [0.2292],\n",
      "         [0.7150],\n",
      "         [0.1086],\n",
      "         [0.4256],\n",
      "         [0.4561],\n",
      "         [0.4431],\n",
      "         [0.4195],\n",
      "         [0.7855],\n",
      "         [0.7899],\n",
      "         [0.3305],\n",
      "         [0.5477],\n",
      "         [0.4189],\n",
      "         [0.5108],\n",
      "         [0.8427],\n",
      "         [0.9360],\n",
      "         [0.8567],\n",
      "         [0.1050],\n",
      "         [0.5745],\n",
      "         [0.6386],\n",
      "         [0.8494],\n",
      "         [0.9423],\n",
      "         [0.4263],\n",
      "         [0.8254],\n",
      "         [0.6057],\n",
      "         [0.5854]]], device='cuda:0', dtype=torch.float64)\n",
      "================iter 1============\n",
      "['shape/cube/1/cube_512_256_2_1_0']\n",
      "tensor([[False, False, False, False, False, False, False, False, False, False,\n",
      "          True,  True, False,  True, False, False, False, False, False, False]],\n",
      "       device='cuda:0')\n",
      "acc torch.Size([1]) tensor([0.0556], device='cuda:0')\n",
      "acc_per_part torch.Size([1, 20]) tensor([[False, False, False, False, False, False, False, False, False, False,\n",
      "         False, False, False,  True, False, False, False, False, False, False]],\n",
      "       device='cuda:0')\n",
      "loss_per_data torch.Size([1, 20]) tensor([[  3.2325,   3.0373,   6.8081, 327.1787,  15.6324,  22.1621,   2.2563,\n",
      "           2.6968,   1.5864,   2.0162,   2.2568,   0.3778,   7.5158,   0.0000,\n",
      "          17.9950,   2.0828,   4.7572,   1.1927,   4.1853,   1.0865]],\n",
      "       device='cuda:0')\n",
      "scores torch.Size([1, 190, 1]) tensor([[[0.6686],\n",
      "         [0.5608],\n",
      "         [0.7462],\n",
      "         [0.3978],\n",
      "         [0.4723],\n",
      "         [0.9802],\n",
      "         [0.5033],\n",
      "         [0.6625],\n",
      "         [0.0473],\n",
      "         [0.4751],\n",
      "         [0.8289],\n",
      "         [0.9095],\n",
      "         [0.4629],\n",
      "         [0.4086],\n",
      "         [0.4380],\n",
      "         [0.2144],\n",
      "         [0.4887],\n",
      "         [0.8690],\n",
      "         [0.7686],\n",
      "         [0.1225],\n",
      "         [0.6788],\n",
      "         [0.4106],\n",
      "         [0.7877],\n",
      "         [0.7777],\n",
      "         [0.2747],\n",
      "         [0.2890],\n",
      "         [0.0035],\n",
      "         [0.1369],\n",
      "         [0.7300],\n",
      "         [0.2016],\n",
      "         [0.4253],\n",
      "         [0.1757],\n",
      "         [0.3621],\n",
      "         [0.5889],\n",
      "         [0.9663],\n",
      "         [0.8290],\n",
      "         [0.2726],\n",
      "         [0.5775],\n",
      "         [0.6429],\n",
      "         [0.2167],\n",
      "         [0.9217],\n",
      "         [0.0409],\n",
      "         [0.8371],\n",
      "         [0.0134],\n",
      "         [0.3726],\n",
      "         [0.3436],\n",
      "         [0.1318],\n",
      "         [0.7858],\n",
      "         [0.9971],\n",
      "         [0.6461],\n",
      "         [0.5913],\n",
      "         [0.9178],\n",
      "         [0.5299],\n",
      "         [0.0690],\n",
      "         [0.0362],\n",
      "         [0.0120],\n",
      "         [0.9286],\n",
      "         [0.0486],\n",
      "         [0.5971],\n",
      "         [0.3049],\n",
      "         [0.0762],\n",
      "         [0.9185],\n",
      "         [0.2143],\n",
      "         [0.2904],\n",
      "         [0.0591],\n",
      "         [0.3098],\n",
      "         [0.7248],\n",
      "         [0.4696],\n",
      "         [0.1997],\n",
      "         [0.3369],\n",
      "         [0.1412],\n",
      "         [0.7637],\n",
      "         [0.1273],\n",
      "         [0.0172],\n",
      "         [0.5943],\n",
      "         [0.1967],\n",
      "         [0.3580],\n",
      "         [0.2196],\n",
      "         [0.4691],\n",
      "         [0.7261],\n",
      "         [0.7313],\n",
      "         [0.6991],\n",
      "         [0.4289],\n",
      "         [0.4683],\n",
      "         [0.9866],\n",
      "         [0.7238],\n",
      "         [0.6744],\n",
      "         [0.3704],\n",
      "         [0.4530],\n",
      "         [0.2595],\n",
      "         [0.8561],\n",
      "         [0.4341],\n",
      "         [0.1009],\n",
      "         [0.8857],\n",
      "         [0.2341],\n",
      "         [0.8303],\n",
      "         [0.6582],\n",
      "         [0.3983],\n",
      "         [0.6424],\n",
      "         [0.1359],\n",
      "         [0.6747],\n",
      "         [0.3332],\n",
      "         [0.0112],\n",
      "         [0.4926],\n",
      "         [0.6874],\n",
      "         [0.6839],\n",
      "         [0.9651],\n",
      "         [0.2775],\n",
      "         [0.9398],\n",
      "         [0.4326],\n",
      "         [0.1967],\n",
      "         [0.0572],\n",
      "         [0.9560],\n",
      "         [0.8122],\n",
      "         [0.7471],\n",
      "         [0.4352],\n",
      "         [0.1621],\n",
      "         [0.1567],\n",
      "         [0.9801],\n",
      "         [0.7532],\n",
      "         [0.0836],\n",
      "         [0.4203],\n",
      "         [0.2224],\n",
      "         [0.7442],\n",
      "         [0.4687],\n",
      "         [0.9310],\n",
      "         [0.9724],\n",
      "         [0.7515],\n",
      "         [0.8274],\n",
      "         [0.3312],\n",
      "         [0.8162],\n",
      "         [0.3124],\n",
      "         [0.7568],\n",
      "         [0.7090],\n",
      "         [0.2133],\n",
      "         [0.4450],\n",
      "         [0.9128],\n",
      "         [0.2718],\n",
      "         [0.3638],\n",
      "         [0.7417],\n",
      "         [0.6960],\n",
      "         [0.7055],\n",
      "         [0.1085],\n",
      "         [0.2636],\n",
      "         [0.1950],\n",
      "         [0.7182],\n",
      "         [0.2456],\n",
      "         [0.0532],\n",
      "         [0.2037],\n",
      "         [0.5919],\n",
      "         [0.0083],\n",
      "         [0.7934],\n",
      "         [0.8551],\n",
      "         [0.4369],\n",
      "         [0.2047],\n",
      "         [0.3449],\n",
      "         [0.2820],\n",
      "         [0.9746],\n",
      "         [0.8542],\n",
      "         [0.0802],\n",
      "         [0.5963],\n",
      "         [0.3932],\n",
      "         [0.6690],\n",
      "         [0.5692],\n",
      "         [0.5445],\n",
      "         [0.0455],\n",
      "         [0.2194],\n",
      "         [0.1085],\n",
      "         [0.8508],\n",
      "         [0.2598],\n",
      "         [0.9402],\n",
      "         [0.7611],\n",
      "         [0.8673],\n",
      "         [0.6231],\n",
      "         [0.1889],\n",
      "         [0.0871],\n",
      "         [0.3712],\n",
      "         [0.7919],\n",
      "         [0.1483],\n",
      "         [0.6655],\n",
      "         [0.7684],\n",
      "         [0.9396],\n",
      "         [0.1361],\n",
      "         [0.1627],\n",
      "         [0.1209],\n",
      "         [0.3767],\n",
      "         [0.6294],\n",
      "         [0.6361],\n",
      "         [0.7504],\n",
      "         [0.7736]]], device='cuda:0', dtype=torch.float64)\n",
      "================iter 2============\n",
      "['shape/cube/1/cube_512_256_2_1_0']\n",
      "tensor([[False, False, False,  True, False, False, False, False,  True,  True,\n",
      "          True,  True, False,  True, False,  True, False, False, False, False]],\n",
      "       device='cuda:0')\n",
      "acc torch.Size([1]) tensor([0.0556], device='cuda:0')\n",
      "acc_per_part torch.Size([1, 20]) tensor([[False, False, False, False, False, False, False, False, False, False,\n",
      "         False, False, False,  True, False, False, False, False, False, False]],\n",
      "       device='cuda:0')\n",
      "loss_per_data torch.Size([1, 20]) tensor([[  4.6717,   5.7904,  20.1268, 327.1787,  28.3904,  39.2549,  17.8520,\n",
      "          12.9341,   1.5864,   2.0162,   2.2568,   0.3778,  12.9038,   0.0000,\n",
      "           4.6847,   2.0828,   5.4970,   7.4140,   4.0160,   7.9478]],\n",
      "       device='cuda:0')\n",
      "scores torch.Size([1, 190, 1]) tensor([[[0.9601],\n",
      "         [0.4292],\n",
      "         [0.0623],\n",
      "         [0.7516],\n",
      "         [0.3537],\n",
      "         [0.6606],\n",
      "         [0.6353],\n",
      "         [0.8987],\n",
      "         [0.3313],\n",
      "         [0.7088],\n",
      "         [0.7592],\n",
      "         [0.2426],\n",
      "         [0.7751],\n",
      "         [0.6400],\n",
      "         [0.8600],\n",
      "         [0.0262],\n",
      "         [0.5282],\n",
      "         [0.7408],\n",
      "         [0.3914],\n",
      "         [0.4009],\n",
      "         [0.1213],\n",
      "         [0.0278],\n",
      "         [0.9447],\n",
      "         [0.0079],\n",
      "         [0.3047],\n",
      "         [0.2017],\n",
      "         [0.9348],\n",
      "         [0.0478],\n",
      "         [0.9755],\n",
      "         [0.0074],\n",
      "         [0.4626],\n",
      "         [0.1439],\n",
      "         [0.4537],\n",
      "         [0.7333],\n",
      "         [0.5892],\n",
      "         [0.8064],\n",
      "         [0.0878],\n",
      "         [0.9742],\n",
      "         [0.8163],\n",
      "         [0.5896],\n",
      "         [0.1285],\n",
      "         [0.5363],\n",
      "         [0.2412],\n",
      "         [0.1086],\n",
      "         [0.5372],\n",
      "         [0.2713],\n",
      "         [0.8878],\n",
      "         [0.0240],\n",
      "         [0.2095],\n",
      "         [0.6433],\n",
      "         [0.9080],\n",
      "         [0.0043],\n",
      "         [0.6263],\n",
      "         [0.8615],\n",
      "         [0.5541],\n",
      "         [0.4375],\n",
      "         [0.7133],\n",
      "         [0.8611],\n",
      "         [0.1088],\n",
      "         [0.9984],\n",
      "         [0.4195],\n",
      "         [0.8697],\n",
      "         [0.3879],\n",
      "         [0.4358],\n",
      "         [0.0658],\n",
      "         [0.2749],\n",
      "         [0.2258],\n",
      "         [0.0873],\n",
      "         [0.5594],\n",
      "         [0.6122],\n",
      "         [0.7035],\n",
      "         [0.7570],\n",
      "         [0.6356],\n",
      "         [0.5200],\n",
      "         [0.5511],\n",
      "         [0.7776],\n",
      "         [0.0520],\n",
      "         [0.4870],\n",
      "         [0.8885],\n",
      "         [0.5259],\n",
      "         [0.4749],\n",
      "         [0.9583],\n",
      "         [0.4911],\n",
      "         [0.3784],\n",
      "         [0.7069],\n",
      "         [0.7425],\n",
      "         [0.2166],\n",
      "         [0.0697],\n",
      "         [0.7698],\n",
      "         [0.7626],\n",
      "         [0.4451],\n",
      "         [0.9044],\n",
      "         [0.9291],\n",
      "         [0.9908],\n",
      "         [0.6852],\n",
      "         [0.4047],\n",
      "         [0.2903],\n",
      "         [0.2056],\n",
      "         [0.6061],\n",
      "         [0.1860],\n",
      "         [0.0456],\n",
      "         [0.4503],\n",
      "         [0.0231],\n",
      "         [0.8413],\n",
      "         [0.4682],\n",
      "         [0.9268],\n",
      "         [0.2669],\n",
      "         [0.9814],\n",
      "         [0.3297],\n",
      "         [0.2879],\n",
      "         [0.8466],\n",
      "         [0.7403],\n",
      "         [0.4607],\n",
      "         [0.9819],\n",
      "         [0.5897],\n",
      "         [0.0427],\n",
      "         [0.7177],\n",
      "         [0.2644],\n",
      "         [0.2420],\n",
      "         [0.4087],\n",
      "         [0.4719],\n",
      "         [0.4855],\n",
      "         [0.6339],\n",
      "         [0.4808],\n",
      "         [0.0167],\n",
      "         [0.3409],\n",
      "         [0.4516],\n",
      "         [0.4140],\n",
      "         [0.5569],\n",
      "         [0.4426],\n",
      "         [0.5495],\n",
      "         [0.5017],\n",
      "         [0.7311],\n",
      "         [0.6321],\n",
      "         [0.7313],\n",
      "         [0.4465],\n",
      "         [0.5325],\n",
      "         [0.3203],\n",
      "         [0.3172],\n",
      "         [0.8552],\n",
      "         [0.5869],\n",
      "         [0.9939],\n",
      "         [0.7020],\n",
      "         [0.2879],\n",
      "         [0.3289],\n",
      "         [0.4015],\n",
      "         [0.0769],\n",
      "         [0.7442],\n",
      "         [0.3182],\n",
      "         [0.0215],\n",
      "         [0.0590],\n",
      "         [0.7044],\n",
      "         [0.6218],\n",
      "         [0.8627],\n",
      "         [0.3231],\n",
      "         [0.0930],\n",
      "         [0.6920],\n",
      "         [0.8031],\n",
      "         [0.8460],\n",
      "         [0.0010],\n",
      "         [0.1485],\n",
      "         [0.3855],\n",
      "         [0.0344],\n",
      "         [0.2185],\n",
      "         [0.4042],\n",
      "         [0.5497],\n",
      "         [0.5751],\n",
      "         [0.9672],\n",
      "         [0.5654],\n",
      "         [0.2998],\n",
      "         [0.5057],\n",
      "         [0.1960],\n",
      "         [0.8082],\n",
      "         [0.6205],\n",
      "         [0.0512],\n",
      "         [0.1883],\n",
      "         [0.1292],\n",
      "         [0.5067],\n",
      "         [0.5329],\n",
      "         [0.6474],\n",
      "         [0.0332],\n",
      "         [0.6580],\n",
      "         [0.6929],\n",
      "         [0.5297],\n",
      "         [0.4013],\n",
      "         [0.7430],\n",
      "         [0.5065],\n",
      "         [0.0788],\n",
      "         [0.4975],\n",
      "         [0.3711]]], device='cuda:0', dtype=torch.float64)\n",
      "================iter 3============\n",
      "['shape/cube/1/cube_512_256_2_1_0']\n",
      "tensor([[False,  True,  True,  True, False,  True,  True,  True,  True,  True,\n",
      "          True,  True, False,  True, False,  True,  True, False, False, False]],\n",
      "       device='cuda:0')\n",
      "acc torch.Size([1]) tensor([0.0556], device='cuda:0')\n",
      "acc_per_part torch.Size([1, 20]) tensor([[False, False, False, False, False, False, False, False, False, False,\n",
      "         False, False, False,  True, False, False, False, False, False, False]],\n",
      "       device='cuda:0')\n",
      "loss_per_data torch.Size([1, 20]) tensor([[ 15.7636,   5.7904,  20.1268, 327.1787,  31.8334,  39.2549,  17.8520,\n",
      "          12.9341,   1.5864,   2.0162,   2.2568,   0.3778,  18.3207,   0.0000,\n",
      "           3.4014,   2.0828,   5.4970,  20.3227,   2.3550,  13.0247]],\n",
      "       device='cuda:0')\n",
      "scores torch.Size([1, 190, 1]) tensor([[[1.6902e-01],\n",
      "         [8.9142e-01],\n",
      "         [8.5060e-02],\n",
      "         [1.1334e-02],\n",
      "         [6.9262e-02],\n",
      "         [9.3012e-01],\n",
      "         [7.8866e-01],\n",
      "         [5.0664e-01],\n",
      "         [5.0161e-01],\n",
      "         [4.9315e-01],\n",
      "         [2.5247e-01],\n",
      "         [4.5493e-01],\n",
      "         [1.5157e-01],\n",
      "         [1.4524e-01],\n",
      "         [2.5541e-01],\n",
      "         [8.7932e-02],\n",
      "         [7.2036e-01],\n",
      "         [2.4742e-01],\n",
      "         [3.9598e-01],\n",
      "         [8.4711e-01],\n",
      "         [5.1698e-02],\n",
      "         [8.6235e-01],\n",
      "         [6.2977e-01],\n",
      "         [9.9326e-01],\n",
      "         [4.8358e-02],\n",
      "         [5.5644e-01],\n",
      "         [9.0298e-03],\n",
      "         [3.8342e-01],\n",
      "         [8.0850e-01],\n",
      "         [9.1113e-01],\n",
      "         [3.1782e-01],\n",
      "         [6.2078e-02],\n",
      "         [2.3889e-01],\n",
      "         [1.7414e-01],\n",
      "         [8.7090e-01],\n",
      "         [6.5954e-01],\n",
      "         [2.5146e-01],\n",
      "         [2.8399e-01],\n",
      "         [2.8580e-01],\n",
      "         [8.4768e-01],\n",
      "         [6.4611e-01],\n",
      "         [2.9487e-01],\n",
      "         [4.3593e-01],\n",
      "         [6.3928e-01],\n",
      "         [5.1588e-01],\n",
      "         [1.5541e-01],\n",
      "         [2.5551e-01],\n",
      "         [9.6700e-01],\n",
      "         [7.7262e-01],\n",
      "         [8.5812e-01],\n",
      "         [4.9617e-01],\n",
      "         [5.7703e-02],\n",
      "         [6.4786e-01],\n",
      "         [2.5543e-04],\n",
      "         [9.6049e-01],\n",
      "         [1.3541e-01],\n",
      "         [3.5004e-01],\n",
      "         [3.8839e-01],\n",
      "         [4.0519e-01],\n",
      "         [3.5555e-01],\n",
      "         [9.9326e-01],\n",
      "         [7.4472e-01],\n",
      "         [4.4614e-01],\n",
      "         [9.2289e-01],\n",
      "         [5.0750e-01],\n",
      "         [5.9989e-01],\n",
      "         [4.7021e-01],\n",
      "         [3.1760e-01],\n",
      "         [8.1392e-03],\n",
      "         [6.8096e-01],\n",
      "         [2.7796e-01],\n",
      "         [6.6939e-01],\n",
      "         [6.9205e-01],\n",
      "         [2.1846e-01],\n",
      "         [1.5970e-01],\n",
      "         [7.9921e-01],\n",
      "         [2.1472e-01],\n",
      "         [7.6376e-01],\n",
      "         [5.0616e-01],\n",
      "         [8.2728e-01],\n",
      "         [5.1906e-01],\n",
      "         [8.7610e-01],\n",
      "         [6.2004e-01],\n",
      "         [7.7708e-01],\n",
      "         [3.5439e-02],\n",
      "         [3.6289e-01],\n",
      "         [7.0871e-01],\n",
      "         [4.6668e-01],\n",
      "         [2.7624e-01],\n",
      "         [9.1216e-01],\n",
      "         [3.5318e-02],\n",
      "         [5.5000e-01],\n",
      "         [8.9548e-01],\n",
      "         [5.5196e-01],\n",
      "         [6.6714e-02],\n",
      "         [4.7803e-01],\n",
      "         [4.5712e-01],\n",
      "         [4.9214e-01],\n",
      "         [7.6321e-01],\n",
      "         [6.0391e-01],\n",
      "         [2.1141e-02],\n",
      "         [3.6806e-01],\n",
      "         [6.1658e-01],\n",
      "         [3.9261e-01],\n",
      "         [1.2040e-01],\n",
      "         [2.3050e-01],\n",
      "         [1.6624e-01],\n",
      "         [3.7822e-02],\n",
      "         [2.2960e-01],\n",
      "         [2.9720e-01],\n",
      "         [3.9785e-01],\n",
      "         [3.7597e-01],\n",
      "         [7.4144e-01],\n",
      "         [3.5525e-01],\n",
      "         [3.3564e-01],\n",
      "         [1.9070e-01],\n",
      "         [1.5432e-01],\n",
      "         [4.6742e-01],\n",
      "         [5.1569e-01],\n",
      "         [4.4853e-01],\n",
      "         [3.0129e-01],\n",
      "         [1.5484e-01],\n",
      "         [9.9326e-01],\n",
      "         [6.2524e-01],\n",
      "         [6.7224e-01],\n",
      "         [7.8591e-01],\n",
      "         [7.0696e-01],\n",
      "         [1.7530e-02],\n",
      "         [6.1374e-02],\n",
      "         [2.1470e-01],\n",
      "         [9.5453e-01],\n",
      "         [8.1375e-01],\n",
      "         [5.5216e-01],\n",
      "         [8.0344e-01],\n",
      "         [8.4023e-01],\n",
      "         [3.2661e-02],\n",
      "         [5.3615e-01],\n",
      "         [3.6336e-01],\n",
      "         [2.9964e-01],\n",
      "         [6.2412e-01],\n",
      "         [1.9184e-01],\n",
      "         [3.7826e-01],\n",
      "         [8.6458e-01],\n",
      "         [6.8080e-01],\n",
      "         [1.7444e-01],\n",
      "         [6.3742e-01],\n",
      "         [2.7956e-01],\n",
      "         [2.6239e-01],\n",
      "         [5.2566e-01],\n",
      "         [8.2190e-01],\n",
      "         [9.2474e-01],\n",
      "         [9.9009e-01],\n",
      "         [3.5964e-01],\n",
      "         [2.1682e-01],\n",
      "         [3.6922e-01],\n",
      "         [9.7085e-01],\n",
      "         [6.2111e-01],\n",
      "         [4.4169e-01],\n",
      "         [3.3155e-01],\n",
      "         [9.6266e-01],\n",
      "         [6.5388e-01],\n",
      "         [6.3828e-01],\n",
      "         [5.1868e-01],\n",
      "         [3.5997e-01],\n",
      "         [2.6766e-01],\n",
      "         [8.1399e-01],\n",
      "         [7.9612e-01],\n",
      "         [8.1493e-01],\n",
      "         [2.9956e-01],\n",
      "         [3.9558e-01],\n",
      "         [1.4105e-01],\n",
      "         [5.1372e-01],\n",
      "         [1.4064e-01],\n",
      "         [6.3893e-02],\n",
      "         [8.1439e-03],\n",
      "         [1.0168e-01],\n",
      "         [5.9853e-01],\n",
      "         [1.2541e-01],\n",
      "         [6.9528e-02],\n",
      "         [7.4977e-01],\n",
      "         [8.5575e-01],\n",
      "         [8.1091e-01],\n",
      "         [9.6272e-01],\n",
      "         [3.9173e-01],\n",
      "         [9.1261e-01],\n",
      "         [8.6404e-01],\n",
      "         [2.2349e-02],\n",
      "         [3.1997e-02],\n",
      "         [6.5318e-01],\n",
      "         [1.6838e-01]]], device='cuda:0', dtype=torch.float64)\n",
      "================iter 4============\n",
      "['shape/cube/1/cube_512_256_2_1_0']\n",
      "tensor([[ True,  True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
      "          True,  True,  True,  True, False,  True,  True,  True, False, False]],\n",
      "       device='cuda:0')\n",
      "acc torch.Size([1]) tensor([0.0556], device='cuda:0')\n",
      "acc_per_part torch.Size([1, 20]) tensor([[False, False, False, False, False, False, False, False, False, False,\n",
      "         False, False, False,  True, False, False, False, False, False, False]],\n",
      "       device='cuda:0')\n",
      "loss_per_data torch.Size([1, 20]) tensor([[ 15.7636,   5.7904,  20.1268, 327.1787,  31.8334,  39.2549,  17.8520,\n",
      "          12.9341,   1.5864,   2.0162,   2.2568,   0.3778,  18.3207,   0.0000,\n",
      "          91.5570,   2.0828,   5.4970,  20.3227,   6.2375,  36.6161]],\n",
      "       device='cuda:0')\n",
      "scores torch.Size([1, 190, 1]) tensor([[[0.5752],\n",
      "         [0.3615],\n",
      "         [0.6154],\n",
      "         [0.7557],\n",
      "         [0.0253],\n",
      "         [0.8204],\n",
      "         [0.6643],\n",
      "         [0.7973],\n",
      "         [0.3091],\n",
      "         [0.8474],\n",
      "         [0.7768],\n",
      "         [0.5618],\n",
      "         [0.7063],\n",
      "         [0.1158],\n",
      "         [0.8873],\n",
      "         [0.8525],\n",
      "         [0.7632],\n",
      "         [0.9788],\n",
      "         [0.8964],\n",
      "         [0.2197],\n",
      "         [0.7794],\n",
      "         [0.1709],\n",
      "         [0.6748],\n",
      "         [0.7107],\n",
      "         [0.6499],\n",
      "         [0.6430],\n",
      "         [0.2861],\n",
      "         [0.0951],\n",
      "         [0.8880],\n",
      "         [0.7157],\n",
      "         [0.1006],\n",
      "         [0.8050],\n",
      "         [0.9258],\n",
      "         [0.6872],\n",
      "         [0.2878],\n",
      "         [0.8893],\n",
      "         [0.1685],\n",
      "         [0.3669],\n",
      "         [0.0140],\n",
      "         [0.2747],\n",
      "         [0.6684],\n",
      "         [0.6453],\n",
      "         [0.4617],\n",
      "         [0.3276],\n",
      "         [0.4825],\n",
      "         [0.2091],\n",
      "         [0.6119],\n",
      "         [0.2799],\n",
      "         [0.2224],\n",
      "         [0.3398],\n",
      "         [0.0168],\n",
      "         [0.0225],\n",
      "         [0.9085],\n",
      "         [0.6501],\n",
      "         [0.3515],\n",
      "         [0.6088],\n",
      "         [0.6236],\n",
      "         [0.6267],\n",
      "         [0.1762],\n",
      "         [0.6533],\n",
      "         [0.3557],\n",
      "         [0.2519],\n",
      "         [0.2143],\n",
      "         [0.1452],\n",
      "         [0.7723],\n",
      "         [0.7296],\n",
      "         [0.6627],\n",
      "         [0.5438],\n",
      "         [0.3406],\n",
      "         [0.0167],\n",
      "         [0.5855],\n",
      "         [0.1897],\n",
      "         [0.4271],\n",
      "         [0.4878],\n",
      "         [0.6237],\n",
      "         [0.8832],\n",
      "         [0.9534],\n",
      "         [0.6495],\n",
      "         [0.2825],\n",
      "         [0.8273],\n",
      "         [0.5606],\n",
      "         [0.2711],\n",
      "         [0.8783],\n",
      "         [0.9142],\n",
      "         [0.0058],\n",
      "         [0.3845],\n",
      "         [0.5132],\n",
      "         [0.1209],\n",
      "         [0.0988],\n",
      "         [0.7229],\n",
      "         [0.3367],\n",
      "         [0.3649],\n",
      "         [0.8275],\n",
      "         [0.0096],\n",
      "         [0.5930],\n",
      "         [0.8784],\n",
      "         [0.8827],\n",
      "         [0.7127],\n",
      "         [0.3225],\n",
      "         [0.9499],\n",
      "         [0.1995],\n",
      "         [0.6046],\n",
      "         [0.2807],\n",
      "         [0.4438],\n",
      "         [0.2563],\n",
      "         [0.9074],\n",
      "         [0.0211],\n",
      "         [0.6018],\n",
      "         [0.2667],\n",
      "         [0.3430],\n",
      "         [0.4823],\n",
      "         [0.7266],\n",
      "         [0.3519],\n",
      "         [0.7783],\n",
      "         [0.4895],\n",
      "         [0.8352],\n",
      "         [0.0555],\n",
      "         [0.6500],\n",
      "         [0.4006],\n",
      "         [0.4648],\n",
      "         [0.7848],\n",
      "         [0.3038],\n",
      "         [0.1774],\n",
      "         [0.8158],\n",
      "         [0.9570],\n",
      "         [0.7769],\n",
      "         [0.7005],\n",
      "         [0.0068],\n",
      "         [0.2500],\n",
      "         [0.9332],\n",
      "         [0.5158],\n",
      "         [0.8400],\n",
      "         [0.7583],\n",
      "         [0.1027],\n",
      "         [0.3997],\n",
      "         [0.4008],\n",
      "         [0.5159],\n",
      "         [0.2980],\n",
      "         [0.5484],\n",
      "         [0.3144],\n",
      "         [0.9710],\n",
      "         [0.8295],\n",
      "         [0.3343],\n",
      "         [0.3462],\n",
      "         [0.1446],\n",
      "         [0.2729],\n",
      "         [0.1623],\n",
      "         [0.9290],\n",
      "         [0.7029],\n",
      "         [0.5191],\n",
      "         [0.5441],\n",
      "         [0.5189],\n",
      "         [0.6436],\n",
      "         [0.8034],\n",
      "         [0.8645],\n",
      "         [0.0783],\n",
      "         [0.8452],\n",
      "         [0.5430],\n",
      "         [0.9873],\n",
      "         [0.9640],\n",
      "         [0.4315],\n",
      "         [0.6246],\n",
      "         [0.2360],\n",
      "         [0.0433],\n",
      "         [0.7666],\n",
      "         [0.3687],\n",
      "         [0.6091],\n",
      "         [0.6881],\n",
      "         [0.8775],\n",
      "         [0.8692],\n",
      "         [0.1350],\n",
      "         [0.1200],\n",
      "         [0.2268],\n",
      "         [0.6632],\n",
      "         [0.6102],\n",
      "         [0.1609],\n",
      "         [0.0773],\n",
      "         [0.4577],\n",
      "         [0.6020],\n",
      "         [0.3940],\n",
      "         [0.1990],\n",
      "         [0.5190],\n",
      "         [0.9256],\n",
      "         [0.1037],\n",
      "         [0.5986],\n",
      "         [0.2680],\n",
      "         [0.0721],\n",
      "         [0.3469],\n",
      "         [0.6434],\n",
      "         [0.9624]]], device='cuda:0', dtype=torch.float64)\n",
      "================iter 5============\n",
      "['shape/cube/1/cube_512_256_2_1_0']\n",
      "tensor([[ True,  True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
      "          True,  True,  True,  True,  True,  True,  True,  True, False, False]],\n",
      "       device='cuda:0')\n",
      "@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@\n",
      "['shape/cube/1/cube_512_256_2_2_0']\n",
      "gt_trans_torch.Size([1, 20, 3])_tensor([[[-4.2993e-02, -6.0355e-02, -1.3738e-02],\n",
      "         [-3.7126e-02, -5.3738e-02, -9.3447e-03],\n",
      "         [-2.0318e-02,  3.1883e-02, -9.4139e-03],\n",
      "         [ 6.0881e-03,  2.9512e-02, -4.6023e-03],\n",
      "         [-1.1596e-03,  3.9814e-02,  6.8711e-03],\n",
      "         [ 6.5650e-03,  4.7920e-02,  3.1338e-03],\n",
      "         [ 6.8326e-03,  5.7511e-02,  4.9761e-03],\n",
      "         [ 1.1935e-02,  6.1996e-02,  1.8248e-02],\n",
      "         [ 1.3322e-02,  7.0411e-02,  2.2929e-02],\n",
      "         [ 1.4969e-02,  8.1750e-02,  1.7043e-02],\n",
      "         [-3.7620e-02, -3.9941e-02, -2.1272e-02],\n",
      "         [-3.1767e-02, -3.2624e-02, -1.9372e-02],\n",
      "         [-2.4777e-02, -3.0347e-02, -2.4320e-03],\n",
      "         [-2.9936e-02, -1.6439e-02, -6.8484e-03],\n",
      "         [-1.4429e-02, -1.1753e-02, -9.5064e-03],\n",
      "         [-1.6646e-02, -2.0475e-03, -3.8370e-03],\n",
      "         [ 7.7716e-18,  1.1102e-18, -5.9952e-18],\n",
      "         [-1.3596e-02,  1.3610e-02,  8.9197e-03],\n",
      "         [ 0.0000e+00,  0.0000e+00,  0.0000e+00],\n",
      "         [ 0.0000e+00,  0.0000e+00,  0.0000e+00]]], device='cuda:0')\n",
      "gt_rots_torch.Size([1, 20, 4])_tensor([[[-0.0300,  0.9135,  0.1539, -0.3755],\n",
      "         [ 0.1050,  0.7853,  0.1101,  0.6001],\n",
      "         [-0.3286,  0.6156, -0.5253, -0.4869],\n",
      "         [ 0.2262,  0.1156,  0.9077,  0.3341],\n",
      "         [ 0.0336, -0.1009, -0.3447,  0.9327],\n",
      "         [-0.2099,  0.0874, -0.2830,  0.9318],\n",
      "         [ 0.4432,  0.7734, -0.4532, -0.0033],\n",
      "         [ 0.2569, -0.3079,  0.8961, -0.1902],\n",
      "         [ 0.8989,  0.3025, -0.2857,  0.1374],\n",
      "         [ 0.6379, -0.2166, -0.0468,  0.7376],\n",
      "         [-0.0653,  0.8659,  0.4727,  0.1500],\n",
      "         [-0.1032,  0.2407,  0.4049,  0.8761],\n",
      "         [ 0.4978, -0.3831,  0.2869,  0.7232],\n",
      "         [ 0.0767,  0.3081,  0.7815, -0.5371],\n",
      "         [ 0.5253,  0.5325,  0.3327,  0.5742],\n",
      "         [ 0.6574,  0.4149, -0.4941,  0.3893],\n",
      "         [ 0.0051, -0.5589, -0.2541,  0.7893],\n",
      "         [-0.1169,  0.2409, -0.3196,  0.9089],\n",
      "         [ 0.0000,  0.0000,  0.0000,  0.0000],\n",
      "         [ 0.0000,  0.0000,  0.0000,  0.0000]]], device='cuda:0')\n",
      "noisy_trans_and_rots_torch.Size([1, 20, 7])_tensor([[[-1.4903e-01,  0.0000e+00,  6.6028e-01,  2.6464e-01,  0.0000e+00,\n",
      "           0.0000e+00, -1.6931e-01],\n",
      "         [-7.9841e-01,  0.0000e+00,  1.4397e-01,  1.3014e+00,  0.0000e+00,\n",
      "           0.0000e+00, -1.9270e-01],\n",
      "         [-6.6529e-01,  0.0000e+00,  1.3297e-01,  5.8554e-01,  0.0000e+00,\n",
      "           0.0000e+00,  3.2790e-01],\n",
      "         [-2.5436e-01,  0.0000e+00,  8.9557e-01, -1.1017e+00,  0.0000e+00,\n",
      "           0.0000e+00,  9.1878e-01],\n",
      "         [-1.6383e+00,  0.0000e+00, -9.0179e-01, -1.0663e+00,  0.0000e+00,\n",
      "           0.0000e+00, -3.7920e-01],\n",
      "         [ 4.8991e-01,  0.0000e+00,  3.8243e-01,  8.8329e-02,  0.0000e+00,\n",
      "           0.0000e+00, -3.7262e-01],\n",
      "         [-4.0451e-02,  0.0000e+00, -1.5258e+00,  1.3260e-01,  0.0000e+00,\n",
      "           0.0000e+00, -4.1590e-01],\n",
      "         [-1.7745e+00,  0.0000e+00,  2.7833e-01, -1.4444e+00,  0.0000e+00,\n",
      "           0.0000e+00,  3.4482e-01],\n",
      "         [-1.7842e-01,  0.0000e+00, -1.8413e-03, -2.9698e+00,  0.0000e+00,\n",
      "           0.0000e+00, -5.4148e-01],\n",
      "         [-1.0175e+00,  0.0000e+00,  6.6467e-01,  8.7724e-01,  0.0000e+00,\n",
      "           0.0000e+00,  1.7525e-01],\n",
      "         [-1.2571e-01,  0.0000e+00,  3.8280e-01,  6.6753e-01,  0.0000e+00,\n",
      "           0.0000e+00,  6.0738e-02],\n",
      "         [-2.2717e-01,  0.0000e+00, -1.4579e-01, -4.2588e-01,  0.0000e+00,\n",
      "           0.0000e+00, -2.0324e-01],\n",
      "         [-8.7563e-01,  0.0000e+00, -3.2061e-01,  1.0602e+00,  0.0000e+00,\n",
      "           0.0000e+00, -9.2046e-01],\n",
      "         [ 2.8186e-01,  0.0000e+00, -9.1473e-01,  3.5303e-01,  0.0000e+00,\n",
      "           0.0000e+00,  9.0284e-01],\n",
      "         [-8.3552e-01,  0.0000e+00,  2.0994e+00,  3.9499e-01,  0.0000e+00,\n",
      "           0.0000e+00, -2.0176e+00],\n",
      "         [ 1.1487e+00,  0.0000e+00, -7.9792e-02, -5.6843e-01,  0.0000e+00,\n",
      "           0.0000e+00,  1.7247e+00],\n",
      "         [-6.3389e-01,  0.0000e+00, -1.8325e+00, -8.9649e-01,  0.0000e+00,\n",
      "           0.0000e+00, -4.2520e-01],\n",
      "         [ 1.4685e+00,  0.0000e+00, -2.5627e+00, -8.8812e-01,  0.0000e+00,\n",
      "           0.0000e+00,  1.2367e-01],\n",
      "         [ 1.8347e+00,  0.0000e+00,  4.8663e-01, -1.7306e+00,  0.0000e+00,\n",
      "           0.0000e+00, -6.8549e-01],\n",
      "         [ 2.5905e-01,  0.0000e+00, -7.6703e-01,  4.8841e-01,  0.0000e+00,\n",
      "           0.0000e+00,  1.2741e-01]]], device='cuda:0')\n",
      "================iter 0============\n",
      "['shape/cube/1/cube_512_256_2_2_0']\n",
      "tensor([[False, False, False, False, False, False, False, False, False, False,\n",
      "         False, False, False, False, False, False,  True, False, False, False]],\n",
      "       device='cuda:0')\n",
      "acc torch.Size([1]) tensor([0.0556], device='cuda:0')\n",
      "acc_per_part torch.Size([1, 20]) tensor([[False, False, False, False, False, False, False, False, False, False,\n",
      "         False, False, False, False, False, False,  True, False, False, False]],\n",
      "       device='cuda:0')\n",
      "loss_per_data torch.Size([1, 20]) tensor([[ 1.2079,  1.7931,  3.5042,  0.5325,  3.1925,  2.1159,  0.2525,  3.6152,\n",
      "          0.5012,  1.0967,  0.4135,  1.6988,  7.0453,  0.1698, 12.1710,  0.5481,\n",
      "          0.0000, 17.3249,  3.5066,  1.8482]], device='cuda:0')\n",
      "scores torch.Size([1, 190, 1]) tensor([[[0.6835],\n",
      "         [0.5427],\n",
      "         [0.4326],\n",
      "         [0.2880],\n",
      "         [0.0113],\n",
      "         [0.8961],\n",
      "         [0.1857],\n",
      "         [0.7984],\n",
      "         [0.1444],\n",
      "         [0.5337],\n",
      "         [0.2724],\n",
      "         [0.3440],\n",
      "         [0.6353],\n",
      "         [0.4088],\n",
      "         [0.0810],\n",
      "         [0.3651],\n",
      "         [0.3191],\n",
      "         [0.6220],\n",
      "         [0.6969],\n",
      "         [0.4202],\n",
      "         [0.7309],\n",
      "         [0.5052],\n",
      "         [0.2492],\n",
      "         [0.4499],\n",
      "         [0.5340],\n",
      "         [0.1560],\n",
      "         [0.3189],\n",
      "         [0.2052],\n",
      "         [0.5850],\n",
      "         [0.6595],\n",
      "         [0.7677],\n",
      "         [0.2351],\n",
      "         [0.2327],\n",
      "         [0.2304],\n",
      "         [0.9105],\n",
      "         [0.2645],\n",
      "         [0.1873],\n",
      "         [0.0389],\n",
      "         [0.6133],\n",
      "         [0.5408],\n",
      "         [0.1216],\n",
      "         [0.4508],\n",
      "         [0.7896],\n",
      "         [0.5198],\n",
      "         [0.6799],\n",
      "         [0.1077],\n",
      "         [0.5064],\n",
      "         [0.3383],\n",
      "         [0.5701],\n",
      "         [0.0431],\n",
      "         [0.0807],\n",
      "         [0.5404],\n",
      "         [0.2710],\n",
      "         [0.4928],\n",
      "         [0.2630],\n",
      "         [0.4604],\n",
      "         [0.0900],\n",
      "         [0.8739],\n",
      "         [0.7304],\n",
      "         [0.2188],\n",
      "         [0.5070],\n",
      "         [0.4902],\n",
      "         [0.3489],\n",
      "         [0.1767],\n",
      "         [0.0677],\n",
      "         [0.2660],\n",
      "         [0.0696],\n",
      "         [0.9956],\n",
      "         [0.1462],\n",
      "         [0.1372],\n",
      "         [0.8186],\n",
      "         [0.1147],\n",
      "         [0.2995],\n",
      "         [0.5634],\n",
      "         [0.7912],\n",
      "         [0.7470],\n",
      "         [0.3737],\n",
      "         [0.8705],\n",
      "         [0.8131],\n",
      "         [0.0400],\n",
      "         [0.9383],\n",
      "         [0.0591],\n",
      "         [0.8933],\n",
      "         [0.9192],\n",
      "         [0.6445],\n",
      "         [0.2881],\n",
      "         [0.2309],\n",
      "         [0.0497],\n",
      "         [0.0962],\n",
      "         [0.8957],\n",
      "         [0.2287],\n",
      "         [0.8214],\n",
      "         [0.4291],\n",
      "         [0.9649],\n",
      "         [0.6931],\n",
      "         [0.2782],\n",
      "         [0.3401],\n",
      "         [0.0570],\n",
      "         [0.9476],\n",
      "         [0.6004],\n",
      "         [0.9660],\n",
      "         [0.1658],\n",
      "         [0.0317],\n",
      "         [0.6058],\n",
      "         [0.9299],\n",
      "         [0.7827],\n",
      "         [0.8006],\n",
      "         [0.6963],\n",
      "         [0.4088],\n",
      "         [0.1803],\n",
      "         [0.6910],\n",
      "         [0.8707],\n",
      "         [0.5104],\n",
      "         [0.4091],\n",
      "         [0.4144],\n",
      "         [0.6351],\n",
      "         [0.9383],\n",
      "         [0.2593],\n",
      "         [0.4376],\n",
      "         [0.9760],\n",
      "         [0.0215],\n",
      "         [0.0562],\n",
      "         [0.3125],\n",
      "         [0.8833],\n",
      "         [0.4430],\n",
      "         [0.5427],\n",
      "         [0.7148],\n",
      "         [0.8741],\n",
      "         [0.8584],\n",
      "         [0.2414],\n",
      "         [0.1722],\n",
      "         [0.2053],\n",
      "         [0.0480],\n",
      "         [0.8440],\n",
      "         [0.4425],\n",
      "         [0.6004],\n",
      "         [0.2118],\n",
      "         [0.8071],\n",
      "         [0.2298],\n",
      "         [0.6702],\n",
      "         [0.9998],\n",
      "         [0.8159],\n",
      "         [0.1602],\n",
      "         [0.9773],\n",
      "         [0.0130],\n",
      "         [0.8458],\n",
      "         [0.4853],\n",
      "         [0.3486],\n",
      "         [0.2081],\n",
      "         [0.5821],\n",
      "         [0.7230],\n",
      "         [0.2109],\n",
      "         [0.6626],\n",
      "         [0.0457],\n",
      "         [0.6411],\n",
      "         [0.3471],\n",
      "         [0.3608],\n",
      "         [0.2484],\n",
      "         [0.6127],\n",
      "         [0.2877],\n",
      "         [0.6718],\n",
      "         [0.6240],\n",
      "         [0.4714],\n",
      "         [0.9693],\n",
      "         [0.7072],\n",
      "         [0.7832],\n",
      "         [0.6565],\n",
      "         [0.0930],\n",
      "         [0.7584],\n",
      "         [0.5551],\n",
      "         [0.1883],\n",
      "         [0.3724],\n",
      "         [0.7464],\n",
      "         [0.2250],\n",
      "         [0.3156],\n",
      "         [0.1436],\n",
      "         [0.4906],\n",
      "         [0.2589],\n",
      "         [0.5621],\n",
      "         [0.4532],\n",
      "         [0.3036],\n",
      "         [0.7600],\n",
      "         [0.7770],\n",
      "         [0.2877],\n",
      "         [0.9985],\n",
      "         [0.3419],\n",
      "         [0.9293],\n",
      "         [0.3447],\n",
      "         [0.1728],\n",
      "         [0.4905]]], device='cuda:0', dtype=torch.float64)\n",
      "================iter 1============\n",
      "['shape/cube/1/cube_512_256_2_2_0']\n",
      "tensor([[False, False, False, False, False, False, False, False, False, False,\n",
      "         False, False, False, False, False, False,  True,  True, False, False]],\n",
      "       device='cuda:0')\n",
      "acc torch.Size([1]) tensor([0.0556], device='cuda:0')\n",
      "acc_per_part torch.Size([1, 20]) tensor([[False, False, False, False, False, False, False, False, False, False,\n",
      "         False, False, False, False, False, False,  True, False, False, False]],\n",
      "       device='cuda:0')\n",
      "loss_per_data torch.Size([1, 20]) tensor([[ 1.5577,  1.2100,  2.2975,  6.9224,  4.5734,  1.4665,  1.5894,  5.4896,\n",
      "          0.7386,  1.1818,  0.7584,  1.6525,  7.7397,  9.7913, 19.9133, 72.4667,\n",
      "          0.0000, 17.3249, 17.0370,  1.0712]], device='cuda:0')\n",
      "scores torch.Size([1, 190, 1]) tensor([[[0.5415],\n",
      "         [0.8150],\n",
      "         [0.8341],\n",
      "         [0.2066],\n",
      "         [0.5297],\n",
      "         [0.3137],\n",
      "         [0.2455],\n",
      "         [0.9130],\n",
      "         [0.8976],\n",
      "         [0.4565],\n",
      "         [0.3580],\n",
      "         [0.0491],\n",
      "         [0.2065],\n",
      "         [0.2576],\n",
      "         [0.6429],\n",
      "         [0.2502],\n",
      "         [0.3217],\n",
      "         [0.0354],\n",
      "         [0.2766],\n",
      "         [0.1192],\n",
      "         [0.6409],\n",
      "         [0.2352],\n",
      "         [0.7248],\n",
      "         [0.4724],\n",
      "         [0.5963],\n",
      "         [0.4105],\n",
      "         [0.7914],\n",
      "         [0.6687],\n",
      "         [0.0208],\n",
      "         [0.1718],\n",
      "         [0.0250],\n",
      "         [0.9526],\n",
      "         [0.1937],\n",
      "         [0.3702],\n",
      "         [0.0744],\n",
      "         [0.5644],\n",
      "         [0.2065],\n",
      "         [0.2716],\n",
      "         [0.4406],\n",
      "         [0.2606],\n",
      "         [0.2145],\n",
      "         [0.2372],\n",
      "         [0.2539],\n",
      "         [0.2797],\n",
      "         [0.7312],\n",
      "         [0.0336],\n",
      "         [0.3547],\n",
      "         [0.0541],\n",
      "         [0.5061],\n",
      "         [0.1038],\n",
      "         [0.1714],\n",
      "         [0.0434],\n",
      "         [0.9842],\n",
      "         [0.7809],\n",
      "         [0.8432],\n",
      "         [0.7826],\n",
      "         [0.7386],\n",
      "         [0.4659],\n",
      "         [0.7039],\n",
      "         [0.6533],\n",
      "         [0.5527],\n",
      "         [0.0251],\n",
      "         [0.2430],\n",
      "         [0.6320],\n",
      "         [0.4864],\n",
      "         [0.4462],\n",
      "         [0.5662],\n",
      "         [0.5739],\n",
      "         [0.6592],\n",
      "         [0.7248],\n",
      "         [0.0539],\n",
      "         [0.7233],\n",
      "         [0.4928],\n",
      "         [0.4955],\n",
      "         [0.2338],\n",
      "         [0.6576],\n",
      "         [0.5526],\n",
      "         [0.7252],\n",
      "         [0.7726],\n",
      "         [0.6990],\n",
      "         [0.4684],\n",
      "         [0.0013],\n",
      "         [0.1964],\n",
      "         [0.3642],\n",
      "         [0.4648],\n",
      "         [0.5705],\n",
      "         [0.8765],\n",
      "         [0.1935],\n",
      "         [0.1564],\n",
      "         [0.5760],\n",
      "         [0.2409],\n",
      "         [0.5179],\n",
      "         [0.6066],\n",
      "         [0.5868],\n",
      "         [0.8779],\n",
      "         [0.2941],\n",
      "         [0.4275],\n",
      "         [0.8735],\n",
      "         [0.6770],\n",
      "         [0.4111],\n",
      "         [0.7621],\n",
      "         [0.9313],\n",
      "         [0.8251],\n",
      "         [0.9098],\n",
      "         [0.3983],\n",
      "         [0.1656],\n",
      "         [0.5224],\n",
      "         [0.8635],\n",
      "         [0.0862],\n",
      "         [0.1856],\n",
      "         [0.0265],\n",
      "         [0.0991],\n",
      "         [0.7822],\n",
      "         [0.9533],\n",
      "         [0.2447],\n",
      "         [0.6415],\n",
      "         [0.2897],\n",
      "         [0.3557],\n",
      "         [0.0449],\n",
      "         [0.1311],\n",
      "         [0.4700],\n",
      "         [0.2527],\n",
      "         [0.6645],\n",
      "         [0.7036],\n",
      "         [0.8774],\n",
      "         [0.8158],\n",
      "         [0.1546],\n",
      "         [0.9207],\n",
      "         [0.0433],\n",
      "         [0.8560],\n",
      "         [0.5720],\n",
      "         [0.0853],\n",
      "         [0.5184],\n",
      "         [0.3841],\n",
      "         [0.4860],\n",
      "         [0.6216],\n",
      "         [0.3282],\n",
      "         [0.0305],\n",
      "         [0.5713],\n",
      "         [0.7562],\n",
      "         [0.6695],\n",
      "         [0.9960],\n",
      "         [0.1834],\n",
      "         [0.7249],\n",
      "         [0.8559],\n",
      "         [0.9350],\n",
      "         [0.6115],\n",
      "         [0.5836],\n",
      "         [0.7205],\n",
      "         [0.8633],\n",
      "         [0.0770],\n",
      "         [0.6133],\n",
      "         [0.6803],\n",
      "         [0.0397],\n",
      "         [0.6981],\n",
      "         [0.4149],\n",
      "         [0.3133],\n",
      "         [0.6775],\n",
      "         [0.4669],\n",
      "         [0.6937],\n",
      "         [0.9897],\n",
      "         [0.2199],\n",
      "         [0.4936],\n",
      "         [0.1649],\n",
      "         [0.1702],\n",
      "         [0.6489],\n",
      "         [0.8158],\n",
      "         [0.5200],\n",
      "         [0.1688],\n",
      "         [0.0989],\n",
      "         [0.4304],\n",
      "         [0.0971],\n",
      "         [0.9486],\n",
      "         [0.6760],\n",
      "         [0.2453],\n",
      "         [0.5559],\n",
      "         [0.6350],\n",
      "         [0.3049],\n",
      "         [0.7645],\n",
      "         [0.9194],\n",
      "         [0.0742],\n",
      "         [0.5368],\n",
      "         [0.6875],\n",
      "         [0.0292],\n",
      "         [0.2798],\n",
      "         [0.4788],\n",
      "         [0.9120],\n",
      "         [0.0021],\n",
      "         [0.4333],\n",
      "         [0.2563]]], device='cuda:0', dtype=torch.float64)\n",
      "================iter 2============\n",
      "['shape/cube/1/cube_512_256_2_2_0']\n",
      "tensor([[False, False, False, False, False, False, False, False, False,  True,\n",
      "         False, False, False,  True, False, False,  True,  True, False, False]],\n",
      "       device='cuda:0')\n",
      "acc torch.Size([1]) tensor([0.0556], device='cuda:0')\n",
      "acc_per_part torch.Size([1, 20]) tensor([[False, False, False, False, False, False, False, False, False, False,\n",
      "         False, False, False, False, False, False,  True, False, False, False]],\n",
      "       device='cuda:0')\n",
      "loss_per_data torch.Size([1, 20]) tensor([[  0.8741,   2.5652,  12.2950,  41.8704,  46.9676,  25.9108,  19.0534,\n",
      "          18.0564,   2.8085,   1.1818,   9.5925,   7.8790,  31.4259,   9.7913,\n",
      "         101.3712, 751.8450,   0.0000,  17.3249,  21.2338,   0.7776]],\n",
      "       device='cuda:0')\n",
      "scores torch.Size([1, 190, 1]) tensor([[[0.7039],\n",
      "         [0.6145],\n",
      "         [0.4650],\n",
      "         [0.7303],\n",
      "         [0.8290],\n",
      "         [0.2319],\n",
      "         [0.3810],\n",
      "         [0.7458],\n",
      "         [0.2657],\n",
      "         [0.7628],\n",
      "         [0.8707],\n",
      "         [0.5031],\n",
      "         [0.5869],\n",
      "         [0.6307],\n",
      "         [0.2641],\n",
      "         [0.3990],\n",
      "         [0.1677],\n",
      "         [0.2278],\n",
      "         [0.9292],\n",
      "         [0.3991],\n",
      "         [0.6424],\n",
      "         [0.7790],\n",
      "         [0.8025],\n",
      "         [0.1278],\n",
      "         [0.7417],\n",
      "         [0.7268],\n",
      "         [0.5178],\n",
      "         [0.8428],\n",
      "         [0.4410],\n",
      "         [0.4182],\n",
      "         [0.3870],\n",
      "         [0.7390],\n",
      "         [0.0771],\n",
      "         [0.0924],\n",
      "         [0.4354],\n",
      "         [0.9283],\n",
      "         [0.1053],\n",
      "         [0.6843],\n",
      "         [0.7784],\n",
      "         [0.9184],\n",
      "         [0.6037],\n",
      "         [0.1232],\n",
      "         [0.2297],\n",
      "         [0.8863],\n",
      "         [0.3184],\n",
      "         [0.4723],\n",
      "         [0.4309],\n",
      "         [0.8977],\n",
      "         [0.3738],\n",
      "         [0.8422],\n",
      "         [0.1474],\n",
      "         [0.8249],\n",
      "         [0.8115],\n",
      "         [0.9880],\n",
      "         [0.1870],\n",
      "         [0.4983],\n",
      "         [0.9836],\n",
      "         [0.0908],\n",
      "         [0.5403],\n",
      "         [0.3568],\n",
      "         [0.3561],\n",
      "         [0.0224],\n",
      "         [0.7461],\n",
      "         [0.5744],\n",
      "         [0.5564],\n",
      "         [0.1388],\n",
      "         [0.2822],\n",
      "         [0.6273],\n",
      "         [0.9095],\n",
      "         [0.1867],\n",
      "         [0.1524],\n",
      "         [0.0213],\n",
      "         [0.1863],\n",
      "         [0.1254],\n",
      "         [0.1560],\n",
      "         [0.4806],\n",
      "         [0.6820],\n",
      "         [0.0440],\n",
      "         [0.9366],\n",
      "         [0.5111],\n",
      "         [0.0185],\n",
      "         [0.8462],\n",
      "         [0.1247],\n",
      "         [0.2173],\n",
      "         [0.7899],\n",
      "         [0.5978],\n",
      "         [0.8063],\n",
      "         [0.9505],\n",
      "         [0.7979],\n",
      "         [0.7927],\n",
      "         [0.6945],\n",
      "         [0.9280],\n",
      "         [0.4605],\n",
      "         [0.0043],\n",
      "         [0.2907],\n",
      "         [0.6401],\n",
      "         [0.2705],\n",
      "         [0.4742],\n",
      "         [0.0058],\n",
      "         [0.8218],\n",
      "         [0.4291],\n",
      "         [0.6747],\n",
      "         [0.1884],\n",
      "         [0.4603],\n",
      "         [0.7682],\n",
      "         [0.8869],\n",
      "         [0.2342],\n",
      "         [0.7644],\n",
      "         [0.3747],\n",
      "         [0.8518],\n",
      "         [0.9367],\n",
      "         [0.0253],\n",
      "         [0.9889],\n",
      "         [0.5955],\n",
      "         [0.9002],\n",
      "         [0.2002],\n",
      "         [0.7638],\n",
      "         [0.6864],\n",
      "         [0.0813],\n",
      "         [0.2277],\n",
      "         [0.9287],\n",
      "         [0.3574],\n",
      "         [0.2101],\n",
      "         [0.6519],\n",
      "         [0.9525],\n",
      "         [0.3694],\n",
      "         [0.6393],\n",
      "         [0.7680],\n",
      "         [0.1626],\n",
      "         [0.4640],\n",
      "         [0.0894],\n",
      "         [0.4808],\n",
      "         [0.1109],\n",
      "         [0.4577],\n",
      "         [0.8874],\n",
      "         [0.6576],\n",
      "         [0.9647],\n",
      "         [0.2931],\n",
      "         [0.5355],\n",
      "         [0.5096],\n",
      "         [0.7695],\n",
      "         [0.5562],\n",
      "         [0.5669],\n",
      "         [0.4307],\n",
      "         [0.0101],\n",
      "         [0.0072],\n",
      "         [0.2655],\n",
      "         [0.8519],\n",
      "         [0.8764],\n",
      "         [0.2132],\n",
      "         [0.5653],\n",
      "         [0.2833],\n",
      "         [0.9857],\n",
      "         [0.4841],\n",
      "         [0.1465],\n",
      "         [0.7086],\n",
      "         [0.0309],\n",
      "         [0.6116],\n",
      "         [0.0669],\n",
      "         [0.4473],\n",
      "         [0.6650],\n",
      "         [0.1607],\n",
      "         [0.7714],\n",
      "         [0.5641],\n",
      "         [0.3101],\n",
      "         [0.3016],\n",
      "         [0.5833],\n",
      "         [0.7906],\n",
      "         [0.9181],\n",
      "         [0.5018],\n",
      "         [0.3074],\n",
      "         [0.2642],\n",
      "         [0.0026],\n",
      "         [0.6359],\n",
      "         [0.9926],\n",
      "         [0.4008],\n",
      "         [0.9549],\n",
      "         [0.2629],\n",
      "         [0.3749],\n",
      "         [0.8787],\n",
      "         [0.3805],\n",
      "         [0.7261],\n",
      "         [0.3998],\n",
      "         [0.2423],\n",
      "         [0.2169],\n",
      "         [0.7913],\n",
      "         [0.0549],\n",
      "         [0.9711],\n",
      "         [0.3328],\n",
      "         [0.2950]]], device='cuda:0', dtype=torch.float64)\n",
      "================iter 3============\n",
      "['shape/cube/1/cube_512_256_2_2_0']\n",
      "tensor([[False, False, False, False,  True, False, False,  True,  True,  True,\n",
      "         False,  True, False,  True,  True, False,  True,  True, False, False]],\n",
      "       device='cuda:0')\n",
      "acc torch.Size([1]) tensor([0.0556], device='cuda:0')\n",
      "acc_per_part torch.Size([1, 20]) tensor([[False, False, False, False, False, False, False, False, False, False,\n",
      "         False, False, False, False, False, False,  True, False, False, False]],\n",
      "       device='cuda:0')\n",
      "loss_per_data torch.Size([1, 20]) tensor([[1.8954e+00, 2.8432e+00, 2.5601e+01, 7.9554e+01, 4.6968e+01, 4.4063e+01,\n",
      "         6.1137e+01, 1.8056e+01, 2.8085e+00, 1.1818e+00, 1.3988e+01, 7.8790e+00,\n",
      "         6.8784e+01, 9.7913e+00, 1.0137e+02, 5.3900e+03, 0.0000e+00, 1.7325e+01,\n",
      "         2.6286e+01, 2.2224e+00]], device='cuda:0')\n",
      "scores torch.Size([1, 190, 1]) tensor([[[3.9300e-01],\n",
      "         [6.8276e-01],\n",
      "         [4.3959e-01],\n",
      "         [1.5591e-01],\n",
      "         [4.2548e-01],\n",
      "         [7.6141e-01],\n",
      "         [5.0332e-01],\n",
      "         [7.6311e-01],\n",
      "         [2.5860e-01],\n",
      "         [7.1035e-01],\n",
      "         [9.1857e-01],\n",
      "         [7.5567e-01],\n",
      "         [4.8816e-01],\n",
      "         [4.0821e-01],\n",
      "         [9.8227e-01],\n",
      "         [7.9453e-01],\n",
      "         [5.0699e-04],\n",
      "         [9.0073e-01],\n",
      "         [3.6257e-01],\n",
      "         [9.0606e-01],\n",
      "         [9.9265e-02],\n",
      "         [6.2040e-01],\n",
      "         [5.5397e-01],\n",
      "         [2.5587e-02],\n",
      "         [1.8034e-01],\n",
      "         [9.0137e-01],\n",
      "         [8.4333e-01],\n",
      "         [9.3625e-01],\n",
      "         [4.6515e-01],\n",
      "         [4.8325e-01],\n",
      "         [9.4979e-01],\n",
      "         [8.6913e-01],\n",
      "         [2.1345e-01],\n",
      "         [4.7042e-01],\n",
      "         [5.6908e-01],\n",
      "         [1.2508e-01],\n",
      "         [9.4783e-01],\n",
      "         [1.5161e-02],\n",
      "         [5.3834e-01],\n",
      "         [2.4130e-02],\n",
      "         [8.3439e-01],\n",
      "         [5.7462e-01],\n",
      "         [9.0377e-01],\n",
      "         [2.6851e-01],\n",
      "         [7.4624e-01],\n",
      "         [6.2825e-01],\n",
      "         [7.3778e-01],\n",
      "         [7.0406e-01],\n",
      "         [3.5395e-01],\n",
      "         [3.0715e-01],\n",
      "         [7.3692e-01],\n",
      "         [7.8842e-02],\n",
      "         [9.2100e-01],\n",
      "         [1.8094e-01],\n",
      "         [4.8683e-01],\n",
      "         [8.5285e-01],\n",
      "         [1.1610e-01],\n",
      "         [9.5196e-01],\n",
      "         [6.3269e-02],\n",
      "         [2.3961e-01],\n",
      "         [2.0295e-02],\n",
      "         [7.2506e-01],\n",
      "         [2.4960e-01],\n",
      "         [7.1549e-01],\n",
      "         [8.9163e-01],\n",
      "         [6.8479e-01],\n",
      "         [3.6042e-01],\n",
      "         [9.3929e-01],\n",
      "         [5.5418e-01],\n",
      "         [3.0283e-01],\n",
      "         [7.7074e-01],\n",
      "         [3.9780e-01],\n",
      "         [2.8753e-01],\n",
      "         [8.7881e-01],\n",
      "         [2.4287e-01],\n",
      "         [2.0499e-01],\n",
      "         [5.2241e-01],\n",
      "         [4.5390e-01],\n",
      "         [6.7116e-02],\n",
      "         [2.6541e-01],\n",
      "         [8.7535e-01],\n",
      "         [2.2753e-01],\n",
      "         [6.7907e-01],\n",
      "         [2.9471e-01],\n",
      "         [5.0046e-01],\n",
      "         [8.3949e-01],\n",
      "         [6.0828e-01],\n",
      "         [9.7005e-01],\n",
      "         [8.0366e-01],\n",
      "         [2.2935e-01],\n",
      "         [7.8488e-01],\n",
      "         [1.8396e-01],\n",
      "         [5.2119e-01],\n",
      "         [2.0991e-01],\n",
      "         [5.2602e-01],\n",
      "         [5.7104e-01],\n",
      "         [7.3369e-01],\n",
      "         [2.0369e-01],\n",
      "         [8.0579e-01],\n",
      "         [1.7701e-02],\n",
      "         [4.0061e-01],\n",
      "         [5.3611e-01],\n",
      "         [1.7431e-01],\n",
      "         [4.3957e-01],\n",
      "         [5.6210e-01],\n",
      "         [7.7856e-01],\n",
      "         [1.7431e-01],\n",
      "         [9.2323e-02],\n",
      "         [3.6764e-01],\n",
      "         [5.9911e-01],\n",
      "         [9.0020e-01],\n",
      "         [2.5010e-01],\n",
      "         [1.4185e-02],\n",
      "         [8.8489e-01],\n",
      "         [1.0399e-01],\n",
      "         [5.2333e-01],\n",
      "         [2.1648e-01],\n",
      "         [2.3051e-01],\n",
      "         [3.7982e-01],\n",
      "         [9.8500e-01],\n",
      "         [5.3353e-01],\n",
      "         [3.7874e-01],\n",
      "         [8.7237e-01],\n",
      "         [8.7837e-01],\n",
      "         [7.2727e-01],\n",
      "         [7.1883e-01],\n",
      "         [1.7438e-01],\n",
      "         [4.3810e-02],\n",
      "         [5.3704e-01],\n",
      "         [1.5237e-01],\n",
      "         [5.2522e-01],\n",
      "         [2.5081e-01],\n",
      "         [2.6741e-01],\n",
      "         [1.7606e-01],\n",
      "         [7.5661e-01],\n",
      "         [9.0337e-01],\n",
      "         [1.8568e-01],\n",
      "         [5.7555e-01],\n",
      "         [5.8426e-02],\n",
      "         [7.7844e-01],\n",
      "         [9.1993e-01],\n",
      "         [9.7879e-01],\n",
      "         [6.8374e-01],\n",
      "         [7.6404e-01],\n",
      "         [9.2346e-01],\n",
      "         [7.2117e-01],\n",
      "         [2.0319e-01],\n",
      "         [9.7013e-01],\n",
      "         [4.4382e-01],\n",
      "         [1.2686e-01],\n",
      "         [9.7146e-01],\n",
      "         [5.9140e-01],\n",
      "         [6.5190e-02],\n",
      "         [6.9073e-01],\n",
      "         [5.5914e-01],\n",
      "         [2.3474e-01],\n",
      "         [7.9843e-01],\n",
      "         [1.2582e-01],\n",
      "         [9.8410e-01],\n",
      "         [2.3477e-01],\n",
      "         [2.1796e-02],\n",
      "         [2.9425e-01],\n",
      "         [1.5735e-01],\n",
      "         [7.5840e-03],\n",
      "         [5.5735e-01],\n",
      "         [4.1747e-01],\n",
      "         [6.0558e-01],\n",
      "         [7.9073e-01],\n",
      "         [7.4329e-01],\n",
      "         [1.2804e-04],\n",
      "         [8.3940e-01],\n",
      "         [6.0553e-01],\n",
      "         [9.9384e-01],\n",
      "         [8.6775e-01],\n",
      "         [9.4453e-02],\n",
      "         [3.4082e-01],\n",
      "         [1.9591e-01],\n",
      "         [7.4067e-01],\n",
      "         [1.8027e-01],\n",
      "         [9.2168e-02],\n",
      "         [2.2090e-01],\n",
      "         [3.3339e-01],\n",
      "         [1.2097e-01],\n",
      "         [1.4961e-01],\n",
      "         [8.9972e-01],\n",
      "         [3.4534e-01],\n",
      "         [9.3267e-01],\n",
      "         [4.8706e-01],\n",
      "         [8.8176e-01],\n",
      "         [7.0212e-01]]], device='cuda:0', dtype=torch.float64)\n",
      "================iter 4============\n",
      "['shape/cube/1/cube_512_256_2_2_0']\n",
      "tensor([[ True,  True,  True,  True,  True,  True, False,  True,  True,  True,\n",
      "          True,  True, False,  True,  True,  True,  True,  True, False, False]],\n",
      "       device='cuda:0')\n",
      "acc torch.Size([1]) tensor([0.0556], device='cuda:0')\n",
      "acc_per_part torch.Size([1, 20]) tensor([[False, False, False, False, False, False, False, False, False, False,\n",
      "         False, False, False, False, False, False,  True, False, False, False]],\n",
      "       device='cuda:0')\n",
      "loss_per_data torch.Size([1, 20]) tensor([[1.8954e+00, 2.8432e+00, 2.5601e+01, 7.9554e+01, 4.6968e+01, 4.4063e+01,\n",
      "         1.6701e+02, 1.8056e+01, 2.8085e+00, 1.1818e+00, 1.3988e+01, 7.8790e+00,\n",
      "         1.3945e+02, 9.7913e+00, 1.0137e+02, 5.3900e+03, 0.0000e+00, 1.7325e+01,\n",
      "         4.0913e+01, 1.4689e+01]], device='cuda:0')\n",
      "scores torch.Size([1, 190, 1]) tensor([[[0.9054],\n",
      "         [0.0055],\n",
      "         [0.3078],\n",
      "         [0.4280],\n",
      "         [0.6910],\n",
      "         [0.5022],\n",
      "         [0.3344],\n",
      "         [0.8140],\n",
      "         [0.6231],\n",
      "         [0.3750],\n",
      "         [0.3962],\n",
      "         [0.6286],\n",
      "         [0.4324],\n",
      "         [0.6565],\n",
      "         [0.2604],\n",
      "         [0.7494],\n",
      "         [0.8606],\n",
      "         [0.7325],\n",
      "         [0.6286],\n",
      "         [0.8572],\n",
      "         [0.3043],\n",
      "         [0.1634],\n",
      "         [0.5077],\n",
      "         [0.0782],\n",
      "         [0.1355],\n",
      "         [0.1608],\n",
      "         [0.7850],\n",
      "         [0.9109],\n",
      "         [0.1371],\n",
      "         [0.3913],\n",
      "         [0.1588],\n",
      "         [0.1261],\n",
      "         [0.6545],\n",
      "         [0.5156],\n",
      "         [0.6136],\n",
      "         [0.5089],\n",
      "         [0.3825],\n",
      "         [0.2743],\n",
      "         [0.9973],\n",
      "         [0.8758],\n",
      "         [0.4105],\n",
      "         [0.3162],\n",
      "         [0.1440],\n",
      "         [0.6838],\n",
      "         [0.5481],\n",
      "         [0.9677],\n",
      "         [0.9811],\n",
      "         [0.1620],\n",
      "         [0.4619],\n",
      "         [0.7572],\n",
      "         [0.8851],\n",
      "         [0.1465],\n",
      "         [0.9912],\n",
      "         [0.0777],\n",
      "         [0.8629],\n",
      "         [0.3248],\n",
      "         [0.2658],\n",
      "         [0.9108],\n",
      "         [0.1900],\n",
      "         [0.7611],\n",
      "         [0.0175],\n",
      "         [0.3361],\n",
      "         [0.2773],\n",
      "         [0.1248],\n",
      "         [0.9757],\n",
      "         [0.8380],\n",
      "         [0.8125],\n",
      "         [0.9525],\n",
      "         [0.9054],\n",
      "         [0.0188],\n",
      "         [0.6750],\n",
      "         [0.0389],\n",
      "         [0.1106],\n",
      "         [0.5306],\n",
      "         [0.5606],\n",
      "         [0.5314],\n",
      "         [0.5628],\n",
      "         [0.1258],\n",
      "         [0.4049],\n",
      "         [0.1778],\n",
      "         [0.6760],\n",
      "         [0.0639],\n",
      "         [0.1743],\n",
      "         [0.7551],\n",
      "         [0.4105],\n",
      "         [0.8438],\n",
      "         [0.8581],\n",
      "         [0.2088],\n",
      "         [0.6910],\n",
      "         [0.5875],\n",
      "         [0.8775],\n",
      "         [0.2165],\n",
      "         [0.3090],\n",
      "         [0.5854],\n",
      "         [0.4568],\n",
      "         [0.7496],\n",
      "         [0.5609],\n",
      "         [0.1845],\n",
      "         [0.0142],\n",
      "         [0.2378],\n",
      "         [0.4863],\n",
      "         [0.8268],\n",
      "         [0.5552],\n",
      "         [0.2673],\n",
      "         [0.2515],\n",
      "         [0.1237],\n",
      "         [0.7664],\n",
      "         [0.5061],\n",
      "         [0.3527],\n",
      "         [0.7271],\n",
      "         [0.9416],\n",
      "         [0.5493],\n",
      "         [0.8465],\n",
      "         [0.6628],\n",
      "         [0.2727],\n",
      "         [0.1521],\n",
      "         [0.5081],\n",
      "         [0.1275],\n",
      "         [0.8052],\n",
      "         [0.9412],\n",
      "         [0.2609],\n",
      "         [0.5777],\n",
      "         [0.2834],\n",
      "         [0.0458],\n",
      "         [0.8702],\n",
      "         [0.8078],\n",
      "         [0.9976],\n",
      "         [0.6357],\n",
      "         [0.2336],\n",
      "         [0.9149],\n",
      "         [0.7825],\n",
      "         [0.4435],\n",
      "         [0.9998],\n",
      "         [0.4618],\n",
      "         [0.6353],\n",
      "         [0.8413],\n",
      "         [0.0986],\n",
      "         [0.4195],\n",
      "         [0.0631],\n",
      "         [0.7705],\n",
      "         [0.7637],\n",
      "         [0.2854],\n",
      "         [0.7991],\n",
      "         [0.2364],\n",
      "         [0.2968],\n",
      "         [0.0981],\n",
      "         [0.9402],\n",
      "         [0.5341],\n",
      "         [0.1560],\n",
      "         [0.6135],\n",
      "         [0.8833],\n",
      "         [0.6179],\n",
      "         [0.4700],\n",
      "         [0.6655],\n",
      "         [0.3156],\n",
      "         [0.7514],\n",
      "         [0.5128],\n",
      "         [0.7610],\n",
      "         [0.5818],\n",
      "         [0.7686],\n",
      "         [0.4752],\n",
      "         [0.4201],\n",
      "         [0.7249],\n",
      "         [0.6240],\n",
      "         [0.0031],\n",
      "         [0.4081],\n",
      "         [0.0426],\n",
      "         [0.6566],\n",
      "         [0.6904],\n",
      "         [0.0692],\n",
      "         [0.6451],\n",
      "         [0.2838],\n",
      "         [0.6740],\n",
      "         [0.8642],\n",
      "         [0.9288],\n",
      "         [0.9761],\n",
      "         [0.2152],\n",
      "         [0.1896],\n",
      "         [0.6874],\n",
      "         [0.9941],\n",
      "         [0.2053],\n",
      "         [0.0145],\n",
      "         [0.9087],\n",
      "         [0.3813],\n",
      "         [0.9990],\n",
      "         [0.6311],\n",
      "         [0.4246],\n",
      "         [0.8518],\n",
      "         [0.6978],\n",
      "         [0.2509]]], device='cuda:0', dtype=torch.float64)\n",
      "================iter 5============\n",
      "['shape/cube/1/cube_512_256_2_2_0']\n",
      "tensor([[ True,  True,  True,  True,  True,  True, False,  True,  True,  True,\n",
      "          True,  True,  True,  True,  True,  True,  True,  True, False, False]],\n",
      "       device='cuda:0')\n",
      "@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@\n",
      "['shape/cube/1/cube_512_256_2_3_0']\n",
      "gt_trans_torch.Size([1, 20, 3])_tensor([[[-1.1013e-01, -3.3600e-04,  6.1093e-02],\n",
      "         [-8.9346e-02, -1.4681e-02,  4.5065e-02],\n",
      "         [-2.2109e-02, -2.0097e-06,  9.4691e-02],\n",
      "         [-1.6123e-02, -9.2562e-03,  1.0414e-01],\n",
      "         [ 7.4361e-03,  5.5753e-03,  7.9905e-02],\n",
      "         [ 2.7073e-02,  2.8487e-03,  6.5038e-02],\n",
      "         [ 4.3207e-02, -2.4036e-03,  5.5969e-02],\n",
      "         [ 6.1624e-02, -1.1876e-02,  4.3586e-02],\n",
      "         [ 7.7098e-02, -3.2132e-03,  3.4344e-02],\n",
      "         [ 9.5097e-02,  4.7722e-03,  2.1143e-02],\n",
      "         [-7.3590e-02,  3.4114e-03,  3.4531e-02],\n",
      "         [-5.4933e-02, -9.7131e-03,  2.1962e-02],\n",
      "         [-4.0322e-02,  2.0792e-03,  1.3948e-02],\n",
      "         [-3.0648e-02,  2.5636e-03,  1.5632e-02],\n",
      "         [-1.0655e-03,  4.1226e-03, -1.7234e-02],\n",
      "         [-6.3283e-18,  6.6613e-18, -2.2204e-18],\n",
      "         [-4.0059e-03, -5.6581e-03,  2.6059e-02],\n",
      "         [-1.4399e-02, -3.3284e-03,  6.2812e-02],\n",
      "         [ 0.0000e+00,  0.0000e+00,  0.0000e+00],\n",
      "         [ 0.0000e+00,  0.0000e+00,  0.0000e+00]]], device='cuda:0')\n",
      "gt_rots_torch.Size([1, 20, 4])_tensor([[[ 0.6299, -0.5815,  0.5068,  0.0909],\n",
      "         [ 0.3618, -0.5258, -0.2090,  0.7410],\n",
      "         [ 0.1550,  0.9814, -0.0965,  0.0592],\n",
      "         [-0.0905,  0.7611, -0.3939,  0.5074],\n",
      "         [ 0.4729,  0.4783,  0.0464,  0.7385],\n",
      "         [ 0.9238,  0.0262,  0.1951,  0.3283],\n",
      "         [-0.3437,  0.7592, -0.5525,  0.0147],\n",
      "         [ 0.6969,  0.0724,  0.5758,  0.4214],\n",
      "         [-0.3271,  0.7107, -0.1103,  0.6130],\n",
      "         [ 0.5656,  0.1269,  0.5701,  0.5822],\n",
      "         [ 0.9489,  0.2999,  0.0966, -0.0152],\n",
      "         [ 0.3252,  0.4124,  0.8458, -0.0942],\n",
      "         [ 0.6092, -0.4845,  0.4372,  0.4506],\n",
      "         [ 0.7851,  0.5009, -0.1939, -0.3085],\n",
      "         [-0.4251,  0.8662,  0.1291, -0.2286],\n",
      "         [ 0.7677, -0.0243, -0.3180,  0.5558],\n",
      "         [ 0.5829, -0.0876,  0.1876,  0.7858],\n",
      "         [ 0.3868, -0.4375, -0.2877,  0.7591],\n",
      "         [ 0.0000,  0.0000,  0.0000,  0.0000],\n",
      "         [ 0.0000,  0.0000,  0.0000,  0.0000]]], device='cuda:0')\n",
      "noisy_trans_and_rots_torch.Size([1, 20, 7])_tensor([[[-0.2803,  0.0000, -0.0364,  0.5522,  0.0000,  0.0000,  0.2633],\n",
      "         [ 0.3328,  0.0000, -0.6722,  1.8916,  0.0000,  0.0000, -1.0981],\n",
      "         [-0.5427,  0.0000, -0.9775, -1.1360,  0.0000,  0.0000,  2.1745],\n",
      "         [-0.0902,  0.0000, -0.7781,  2.7038,  0.0000,  0.0000, -0.2767],\n",
      "         [ 1.4966,  0.0000,  0.6651, -1.3936,  0.0000,  0.0000,  0.3698],\n",
      "         [ 0.0061,  0.0000, -0.0964, -0.3643,  0.0000,  0.0000, -1.4462],\n",
      "         [ 0.4411,  0.0000,  1.0900, -0.5674,  0.0000,  0.0000, -0.2429],\n",
      "         [-0.7655,  0.0000,  0.2776,  1.0114,  0.0000,  0.0000, -1.3268],\n",
      "         [-1.5645,  0.0000,  0.5164,  1.0686,  0.0000,  0.0000,  0.3661],\n",
      "         [ 2.5448,  0.0000,  0.0468, -0.2709,  0.0000,  0.0000, -1.8017],\n",
      "         [-0.7116,  0.0000,  1.7512,  0.4508,  0.0000,  0.0000,  0.3618],\n",
      "         [ 0.2901,  0.0000, -1.5441,  1.0428,  0.0000,  0.0000, -0.6503],\n",
      "         [-0.2697,  0.0000, -0.0710,  0.0230,  0.0000,  0.0000, -0.4297],\n",
      "         [-0.8267,  0.0000,  0.0412, -1.0592,  0.0000,  0.0000,  2.1795],\n",
      "         [ 1.2285,  0.0000,  1.0683, -0.9034,  0.0000,  0.0000, -0.3919],\n",
      "         [ 1.5327,  0.0000,  0.6229,  1.0724,  0.0000,  0.0000,  0.1634],\n",
      "         [ 0.1072,  0.0000, -0.3466, -0.9934,  0.0000,  0.0000, -3.8679],\n",
      "         [-0.8977,  0.0000,  0.0469,  2.0349,  0.0000,  0.0000, -2.3170],\n",
      "         [-0.9776,  0.0000,  0.5781, -0.7944,  0.0000,  0.0000,  0.0409],\n",
      "         [-0.5443,  0.0000,  0.1035,  0.2951,  0.0000,  0.0000, -0.2197]]],\n",
      "       device='cuda:0')\n",
      "================iter 0============\n",
      "['shape/cube/1/cube_512_256_2_3_0']\n",
      "tensor([[False, False, False, False, False, False, False, False, False, False,\n",
      "         False, False, False, False, False,  True, False, False, False, False]],\n",
      "       device='cuda:0')\n",
      "acc torch.Size([1]) tensor([0.0556], device='cuda:0')\n",
      "acc_per_part torch.Size([1, 20]) tensor([[False, False, False, False, False, False, False, False, False, False,\n",
      "         False, False, False, False, False,  True, False, False, False, False]],\n",
      "       device='cuda:0')\n",
      "loss_per_data torch.Size([1, 20]) tensor([[ 5.2605,  5.9906, 15.0535,  0.2592,  2.9451,  1.1223,  5.1239,  2.1113,\n",
      "          0.3989, 26.3091,  1.3296,  0.4371,  0.8794,  0.1121,  0.9200,  0.0000,\n",
      "          3.0853,  0.8833,  1.6882,  0.4933]], device='cuda:0')\n",
      "scores torch.Size([1, 190, 1]) tensor([[[0.7443],\n",
      "         [0.1788],\n",
      "         [0.8997],\n",
      "         [0.5486],\n",
      "         [0.3898],\n",
      "         [0.1333],\n",
      "         [0.9269],\n",
      "         [0.7945],\n",
      "         [0.3003],\n",
      "         [0.9815],\n",
      "         [0.7152],\n",
      "         [0.6034],\n",
      "         [0.2417],\n",
      "         [0.9007],\n",
      "         [0.0292],\n",
      "         [0.3946],\n",
      "         [0.2827],\n",
      "         [0.7297],\n",
      "         [0.2599],\n",
      "         [0.4399],\n",
      "         [0.7327],\n",
      "         [0.3429],\n",
      "         [0.6856],\n",
      "         [0.1755],\n",
      "         [0.2380],\n",
      "         [0.8735],\n",
      "         [0.2668],\n",
      "         [0.6176],\n",
      "         [0.4193],\n",
      "         [0.2226],\n",
      "         [0.2396],\n",
      "         [0.1835],\n",
      "         [0.7290],\n",
      "         [0.9434],\n",
      "         [0.4683],\n",
      "         [0.9683],\n",
      "         [0.9492],\n",
      "         [0.8881],\n",
      "         [0.4124],\n",
      "         [0.1054],\n",
      "         [0.7060],\n",
      "         [0.2809],\n",
      "         [0.6702],\n",
      "         [0.1479],\n",
      "         [0.4611],\n",
      "         [0.5234],\n",
      "         [0.8994],\n",
      "         [0.8815],\n",
      "         [0.7922],\n",
      "         [0.9962],\n",
      "         [0.9363],\n",
      "         [0.8106],\n",
      "         [0.0899],\n",
      "         [0.4585],\n",
      "         [0.3914],\n",
      "         [0.4987],\n",
      "         [0.6233],\n",
      "         [0.1202],\n",
      "         [0.2930],\n",
      "         [0.4105],\n",
      "         [0.5171],\n",
      "         [0.9692],\n",
      "         [0.6779],\n",
      "         [0.9626],\n",
      "         [0.2669],\n",
      "         [0.7853],\n",
      "         [0.3148],\n",
      "         [0.3333],\n",
      "         [0.9825],\n",
      "         [0.9181],\n",
      "         [0.9685],\n",
      "         [0.7311],\n",
      "         [0.3473],\n",
      "         [0.0402],\n",
      "         [0.5878],\n",
      "         [0.5063],\n",
      "         [0.5767],\n",
      "         [0.8329],\n",
      "         [0.5463],\n",
      "         [0.1770],\n",
      "         [0.4622],\n",
      "         [0.2081],\n",
      "         [0.8956],\n",
      "         [0.8150],\n",
      "         [0.6780],\n",
      "         [0.7828],\n",
      "         [0.1537],\n",
      "         [0.1466],\n",
      "         [0.1830],\n",
      "         [0.1782],\n",
      "         [0.0668],\n",
      "         [0.2749],\n",
      "         [0.7611],\n",
      "         [0.8704],\n",
      "         [0.8464],\n",
      "         [0.6803],\n",
      "         [0.5127],\n",
      "         [0.7715],\n",
      "         [0.2829],\n",
      "         [0.5769],\n",
      "         [0.6700],\n",
      "         [0.3191],\n",
      "         [0.4927],\n",
      "         [0.9211],\n",
      "         [0.7558],\n",
      "         [0.1015],\n",
      "         [0.5528],\n",
      "         [0.2962],\n",
      "         [0.5533],\n",
      "         [0.2591],\n",
      "         [0.1008],\n",
      "         [0.4861],\n",
      "         [0.2482],\n",
      "         [0.9678],\n",
      "         [0.3203],\n",
      "         [0.1099],\n",
      "         [0.7433],\n",
      "         [0.4998],\n",
      "         [0.4655],\n",
      "         [0.6481],\n",
      "         [0.0808],\n",
      "         [0.6908],\n",
      "         [0.5498],\n",
      "         [0.1506],\n",
      "         [0.6201],\n",
      "         [0.1231],\n",
      "         [0.3740],\n",
      "         [0.3678],\n",
      "         [0.6282],\n",
      "         [0.3722],\n",
      "         [0.4084],\n",
      "         [0.0435],\n",
      "         [0.7137],\n",
      "         [0.4691],\n",
      "         [0.9861],\n",
      "         [0.1486],\n",
      "         [0.2613],\n",
      "         [0.0320],\n",
      "         [0.9954],\n",
      "         [0.5857],\n",
      "         [0.4088],\n",
      "         [0.6273],\n",
      "         [0.4451],\n",
      "         [0.5579],\n",
      "         [0.1438],\n",
      "         [0.1960],\n",
      "         [0.3492],\n",
      "         [0.4179],\n",
      "         [0.6995],\n",
      "         [0.8952],\n",
      "         [0.8311],\n",
      "         [0.4860],\n",
      "         [0.4883],\n",
      "         [0.2921],\n",
      "         [0.4414],\n",
      "         [0.1565],\n",
      "         [0.0622],\n",
      "         [0.9217],\n",
      "         [0.4088],\n",
      "         [0.1505],\n",
      "         [0.0104],\n",
      "         [0.9342],\n",
      "         [0.4845],\n",
      "         [0.3401],\n",
      "         [0.3279],\n",
      "         [0.6443],\n",
      "         [0.6831],\n",
      "         [0.6763],\n",
      "         [0.7947],\n",
      "         [0.0794],\n",
      "         [0.5001],\n",
      "         [0.9198],\n",
      "         [0.6846],\n",
      "         [0.7956],\n",
      "         [0.6628],\n",
      "         [0.2942],\n",
      "         [0.7240],\n",
      "         [0.4881],\n",
      "         [0.7874],\n",
      "         [0.4806],\n",
      "         [0.8359],\n",
      "         [0.8872],\n",
      "         [0.2818],\n",
      "         [0.6024],\n",
      "         [0.8211],\n",
      "         [0.3927],\n",
      "         [0.0322],\n",
      "         [0.7896],\n",
      "         [0.0757],\n",
      "         [0.1552]]], device='cuda:0', dtype=torch.float64)\n",
      "================iter 1============\n",
      "['shape/cube/1/cube_512_256_2_3_0']\n",
      "tensor([[False, False,  True, False, False, False, False, False, False, False,\n",
      "         False,  True, False, False, False,  True, False, False, False, False]],\n",
      "       device='cuda:0')\n",
      "acc torch.Size([1]) tensor([0.0556], device='cuda:0')\n",
      "acc_per_part torch.Size([1, 20]) tensor([[False, False, False, False, False, False, False, False, False, False,\n",
      "         False, False, False, False, False,  True, False, False, False, False]],\n",
      "       device='cuda:0')\n",
      "loss_per_data torch.Size([1, 20]) tensor([[ 1.3889, 16.6760, 15.0535,  0.1802, 42.1224,  1.3345,  6.3260,  0.3265,\n",
      "          1.2645, 29.5844,  9.0097,  0.4371,  1.6146,  5.3549, 33.7195,  0.0000,\n",
      "          2.6250,  1.7955,  3.8030,  2.7817]], device='cuda:0')\n",
      "scores torch.Size([1, 190, 1]) tensor([[[0.9985],\n",
      "         [0.4935],\n",
      "         [0.6888],\n",
      "         [0.8423],\n",
      "         [0.4579],\n",
      "         [0.2697],\n",
      "         [0.6872],\n",
      "         [0.3231],\n",
      "         [0.1631],\n",
      "         [0.5822],\n",
      "         [0.9859],\n",
      "         [0.3183],\n",
      "         [0.2812],\n",
      "         [0.5518],\n",
      "         [0.0904],\n",
      "         [0.5454],\n",
      "         [0.1045],\n",
      "         [0.9578],\n",
      "         [0.3200],\n",
      "         [0.9856],\n",
      "         [0.1834],\n",
      "         [0.0819],\n",
      "         [0.3045],\n",
      "         [0.2774],\n",
      "         [0.4973],\n",
      "         [0.7363],\n",
      "         [0.3451],\n",
      "         [0.3725],\n",
      "         [0.5277],\n",
      "         [0.6616],\n",
      "         [0.7564],\n",
      "         [0.3595],\n",
      "         [0.8154],\n",
      "         [0.4119],\n",
      "         [0.1011],\n",
      "         [0.6530],\n",
      "         [0.4159],\n",
      "         [0.8094],\n",
      "         [0.5531],\n",
      "         [0.8083],\n",
      "         [0.9660],\n",
      "         [0.5565],\n",
      "         [0.8997],\n",
      "         [0.8274],\n",
      "         [0.9610],\n",
      "         [0.2784],\n",
      "         [0.9788],\n",
      "         [0.4228],\n",
      "         [0.9950],\n",
      "         [0.0235],\n",
      "         [0.5625],\n",
      "         [0.9766],\n",
      "         [0.4246],\n",
      "         [0.1051],\n",
      "         [0.9538],\n",
      "         [0.2834],\n",
      "         [0.4247],\n",
      "         [0.1597],\n",
      "         [0.4551],\n",
      "         [0.3177],\n",
      "         [0.1735],\n",
      "         [0.8802],\n",
      "         [0.7290],\n",
      "         [0.9962],\n",
      "         [0.6383],\n",
      "         [0.0791],\n",
      "         [0.7167],\n",
      "         [0.8812],\n",
      "         [0.6534],\n",
      "         [0.6513],\n",
      "         [0.6489],\n",
      "         [0.9258],\n",
      "         [0.4992],\n",
      "         [0.6591],\n",
      "         [0.9689],\n",
      "         [0.9355],\n",
      "         [0.9611],\n",
      "         [0.6877],\n",
      "         [0.7833],\n",
      "         [0.5271],\n",
      "         [0.8627],\n",
      "         [0.7025],\n",
      "         [0.8625],\n",
      "         [0.7646],\n",
      "         [0.1087],\n",
      "         [0.3016],\n",
      "         [0.3936],\n",
      "         [0.6047],\n",
      "         [0.7474],\n",
      "         [0.3231],\n",
      "         [0.4872],\n",
      "         [0.2181],\n",
      "         [0.5311],\n",
      "         [0.4618],\n",
      "         [0.8527],\n",
      "         [0.5598],\n",
      "         [0.8889],\n",
      "         [0.4305],\n",
      "         [0.8354],\n",
      "         [0.1261],\n",
      "         [0.3875],\n",
      "         [0.9191],\n",
      "         [0.8367],\n",
      "         [0.9460],\n",
      "         [0.2772],\n",
      "         [0.9405],\n",
      "         [0.4470],\n",
      "         [0.1679],\n",
      "         [0.6589],\n",
      "         [0.5169],\n",
      "         [0.8370],\n",
      "         [0.7828],\n",
      "         [0.0435],\n",
      "         [0.7746],\n",
      "         [0.7081],\n",
      "         [0.3527],\n",
      "         [0.5080],\n",
      "         [0.9842],\n",
      "         [0.9504],\n",
      "         [0.2668],\n",
      "         [0.4186],\n",
      "         [0.6168],\n",
      "         [0.3623],\n",
      "         [0.9816],\n",
      "         [0.6284],\n",
      "         [0.3119],\n",
      "         [0.7538],\n",
      "         [0.0298],\n",
      "         [0.7351],\n",
      "         [0.2137],\n",
      "         [0.1518],\n",
      "         [0.5465],\n",
      "         [0.9991],\n",
      "         [0.2198],\n",
      "         [0.5379],\n",
      "         [0.6621],\n",
      "         [0.2541],\n",
      "         [0.8944],\n",
      "         [0.6694],\n",
      "         [0.0691],\n",
      "         [0.9497],\n",
      "         [0.9880],\n",
      "         [0.0567],\n",
      "         [0.8935],\n",
      "         [0.1622],\n",
      "         [0.9456],\n",
      "         [0.0591],\n",
      "         [0.9433],\n",
      "         [0.7177],\n",
      "         [0.7401],\n",
      "         [0.0264],\n",
      "         [0.7312],\n",
      "         [0.8813],\n",
      "         [0.4857],\n",
      "         [0.6304],\n",
      "         [0.9593],\n",
      "         [0.3497],\n",
      "         [0.1298],\n",
      "         [0.3604],\n",
      "         [0.5742],\n",
      "         [0.5124],\n",
      "         [0.7728],\n",
      "         [0.2950],\n",
      "         [0.8332],\n",
      "         [0.6268],\n",
      "         [0.7811],\n",
      "         [0.1625],\n",
      "         [0.8969],\n",
      "         [0.9583],\n",
      "         [0.6315],\n",
      "         [0.7936],\n",
      "         [0.4996],\n",
      "         [0.1425],\n",
      "         [0.8994],\n",
      "         [0.1061],\n",
      "         [0.4920],\n",
      "         [0.5542],\n",
      "         [0.7920],\n",
      "         [0.0517],\n",
      "         [0.9843],\n",
      "         [0.9911],\n",
      "         [0.2863],\n",
      "         [0.9521],\n",
      "         [0.6406],\n",
      "         [0.9429],\n",
      "         [0.3625],\n",
      "         [0.5882],\n",
      "         [0.0589],\n",
      "         [0.8036],\n",
      "         [0.7967]]], device='cuda:0', dtype=torch.float64)\n",
      "================iter 2============\n",
      "['shape/cube/1/cube_512_256_2_3_0']\n",
      "tensor([[ True,  True,  True, False,  True, False,  True, False, False,  True,\n",
      "          True,  True,  True,  True,  True,  True,  True,  True, False, False]],\n",
      "       device='cuda:0')\n",
      "acc torch.Size([1]) tensor([0.0556], device='cuda:0')\n",
      "acc_per_part torch.Size([1, 20]) tensor([[False, False, False, False, False, False, False, False, False, False,\n",
      "         False, False, False, False, False,  True, False, False, False, False]],\n",
      "       device='cuda:0')\n",
      "loss_per_data torch.Size([1, 20]) tensor([[ 1.3889, 16.6760, 15.0535,  0.5266, 42.1224,  7.0374,  6.3260,  6.3625,\n",
      "         11.9861, 29.5844,  9.0097,  0.4371,  1.6146,  5.3549, 33.7195,  0.0000,\n",
      "          2.6250,  1.7955,  0.8941,  6.1908]], device='cuda:0')\n",
      "scores torch.Size([1, 190, 1]) tensor([[[0.4453],\n",
      "         [0.0647],\n",
      "         [0.2250],\n",
      "         [0.4726],\n",
      "         [0.6478],\n",
      "         [0.1529],\n",
      "         [0.9665],\n",
      "         [0.0761],\n",
      "         [0.4416],\n",
      "         [0.7009],\n",
      "         [0.2791],\n",
      "         [0.7078],\n",
      "         [0.2842],\n",
      "         [0.7113],\n",
      "         [0.8421],\n",
      "         [0.2315],\n",
      "         [0.8833],\n",
      "         [0.5516],\n",
      "         [0.3013],\n",
      "         [0.9904],\n",
      "         [0.9779],\n",
      "         [0.7924],\n",
      "         [0.6906],\n",
      "         [0.9729],\n",
      "         [0.6195],\n",
      "         [0.8398],\n",
      "         [0.0229],\n",
      "         [0.8133],\n",
      "         [0.0444],\n",
      "         [0.0495],\n",
      "         [0.8027],\n",
      "         [0.1663],\n",
      "         [0.7464],\n",
      "         [0.0089],\n",
      "         [0.6556],\n",
      "         [0.7843],\n",
      "         [0.2021],\n",
      "         [0.8564],\n",
      "         [0.8937],\n",
      "         [0.8558],\n",
      "         [0.6086],\n",
      "         [0.6029],\n",
      "         [0.4804],\n",
      "         [0.4359],\n",
      "         [0.0513],\n",
      "         [0.0048],\n",
      "         [0.5882],\n",
      "         [0.7415],\n",
      "         [0.6259],\n",
      "         [0.2942],\n",
      "         [0.9980],\n",
      "         [0.4481],\n",
      "         [0.1538],\n",
      "         [0.1926],\n",
      "         [0.5967],\n",
      "         [0.6590],\n",
      "         [0.3671],\n",
      "         [0.6745],\n",
      "         [0.6598],\n",
      "         [0.6010],\n",
      "         [0.7217],\n",
      "         [0.9452],\n",
      "         [0.3637],\n",
      "         [0.4688],\n",
      "         [0.0998],\n",
      "         [0.8845],\n",
      "         [0.6304],\n",
      "         [0.7377],\n",
      "         [0.2904],\n",
      "         [0.0722],\n",
      "         [0.3349],\n",
      "         [0.1860],\n",
      "         [0.0423],\n",
      "         [0.4070],\n",
      "         [0.9409],\n",
      "         [0.1245],\n",
      "         [0.7980],\n",
      "         [0.8763],\n",
      "         [0.5823],\n",
      "         [0.4022],\n",
      "         [0.4712],\n",
      "         [0.1198],\n",
      "         [0.9782],\n",
      "         [0.5539],\n",
      "         [0.8169],\n",
      "         [0.8473],\n",
      "         [0.2173],\n",
      "         [0.7430],\n",
      "         [0.7990],\n",
      "         [0.7743],\n",
      "         [0.5525],\n",
      "         [0.4545],\n",
      "         [0.5604],\n",
      "         [0.8698],\n",
      "         [0.0032],\n",
      "         [0.0406],\n",
      "         [0.5580],\n",
      "         [0.6938],\n",
      "         [0.5812],\n",
      "         [0.4086],\n",
      "         [0.0821],\n",
      "         [0.4952],\n",
      "         [0.9928],\n",
      "         [0.3730],\n",
      "         [0.9673],\n",
      "         [0.5154],\n",
      "         [0.4923],\n",
      "         [0.2177],\n",
      "         [0.8762],\n",
      "         [0.3082],\n",
      "         [0.2024],\n",
      "         [0.7652],\n",
      "         [0.0935],\n",
      "         [0.0109],\n",
      "         [0.5903],\n",
      "         [0.9191],\n",
      "         [0.6831],\n",
      "         [0.4672],\n",
      "         [0.5657],\n",
      "         [0.8392],\n",
      "         [0.0404],\n",
      "         [0.5786],\n",
      "         [0.9348],\n",
      "         [0.6254],\n",
      "         [0.0934],\n",
      "         [0.1677],\n",
      "         [0.4136],\n",
      "         [0.9558],\n",
      "         [0.6852],\n",
      "         [0.9831],\n",
      "         [0.4040],\n",
      "         [0.7522],\n",
      "         [0.1182],\n",
      "         [0.6866],\n",
      "         [0.9518],\n",
      "         [0.2731],\n",
      "         [0.2322],\n",
      "         [0.5293],\n",
      "         [0.6652],\n",
      "         [0.4190],\n",
      "         [0.7339],\n",
      "         [0.4429],\n",
      "         [0.2570],\n",
      "         [0.2198],\n",
      "         [0.1483],\n",
      "         [0.8540],\n",
      "         [0.8812],\n",
      "         [0.7068],\n",
      "         [0.2110],\n",
      "         [0.1701],\n",
      "         [0.7010],\n",
      "         [0.5526],\n",
      "         [0.5713],\n",
      "         [0.0552],\n",
      "         [0.3965],\n",
      "         [0.7974],\n",
      "         [0.1530],\n",
      "         [0.3507],\n",
      "         [0.1856],\n",
      "         [0.1031],\n",
      "         [0.3097],\n",
      "         [0.3925],\n",
      "         [0.6621],\n",
      "         [0.2691],\n",
      "         [0.1882],\n",
      "         [0.2494],\n",
      "         [0.2382],\n",
      "         [0.4680],\n",
      "         [0.5966],\n",
      "         [0.2331],\n",
      "         [0.0642],\n",
      "         [0.3132],\n",
      "         [0.8968],\n",
      "         [0.5714],\n",
      "         [0.5073],\n",
      "         [0.9883],\n",
      "         [0.2604],\n",
      "         [0.2066],\n",
      "         [0.3018],\n",
      "         [0.5070],\n",
      "         [0.8050],\n",
      "         [0.9262],\n",
      "         [0.7959],\n",
      "         [0.7560],\n",
      "         [0.2434],\n",
      "         [0.6368],\n",
      "         [0.6003],\n",
      "         [0.8513],\n",
      "         [0.0785],\n",
      "         [0.4938]]], device='cuda:0', dtype=torch.float64)\n",
      "================iter 3============\n",
      "['shape/cube/1/cube_512_256_2_3_0']\n",
      "tensor([[ True,  True,  True,  True,  True, False,  True,  True,  True,  True,\n",
      "          True,  True,  True,  True,  True,  True,  True,  True, False, False]],\n",
      "       device='cuda:0')\n",
      "acc torch.Size([1]) tensor([0.0556], device='cuda:0')\n",
      "acc_per_part torch.Size([1, 20]) tensor([[False, False, False, False, False, False, False, False, False, False,\n",
      "         False, False, False, False, False,  True, False, False, False, False]],\n",
      "       device='cuda:0')\n",
      "loss_per_data torch.Size([1, 20]) tensor([[ 1.3889, 16.6760, 15.0535,  0.5266, 42.1224, 14.9311,  6.3260,  6.3625,\n",
      "         11.9861, 29.5844,  9.0097,  0.4371,  1.6146,  5.3549, 33.7195,  0.0000,\n",
      "          2.6250,  1.7955,  0.1534, 12.2243]], device='cuda:0')\n",
      "scores torch.Size([1, 190, 1]) tensor([[[0.0121],\n",
      "         [0.8474],\n",
      "         [0.3103],\n",
      "         [0.7561],\n",
      "         [0.6207],\n",
      "         [0.3958],\n",
      "         [0.6185],\n",
      "         [0.3179],\n",
      "         [0.2257],\n",
      "         [0.6555],\n",
      "         [0.7899],\n",
      "         [0.5557],\n",
      "         [0.5853],\n",
      "         [0.6770],\n",
      "         [0.3242],\n",
      "         [0.1758],\n",
      "         [0.8295],\n",
      "         [0.6021],\n",
      "         [0.9603],\n",
      "         [0.7743],\n",
      "         [0.7521],\n",
      "         [0.2811],\n",
      "         [0.1930],\n",
      "         [0.1773],\n",
      "         [0.2325],\n",
      "         [0.3102],\n",
      "         [0.5124],\n",
      "         [0.7884],\n",
      "         [0.7826],\n",
      "         [0.0013],\n",
      "         [0.9045],\n",
      "         [0.7296],\n",
      "         [0.8092],\n",
      "         [0.9463],\n",
      "         [0.7682],\n",
      "         [0.3629],\n",
      "         [0.6472],\n",
      "         [0.8471],\n",
      "         [0.3420],\n",
      "         [0.7404],\n",
      "         [0.4987],\n",
      "         [0.7688],\n",
      "         [0.0771],\n",
      "         [0.0077],\n",
      "         [0.2084],\n",
      "         [0.8134],\n",
      "         [0.7802],\n",
      "         [0.1103],\n",
      "         [0.6865],\n",
      "         [0.5046],\n",
      "         [0.1168],\n",
      "         [0.3602],\n",
      "         [0.7842],\n",
      "         [0.7876],\n",
      "         [0.6163],\n",
      "         [0.7536],\n",
      "         [0.6760],\n",
      "         [0.4423],\n",
      "         [0.0112],\n",
      "         [0.5927],\n",
      "         [0.2937],\n",
      "         [0.4247],\n",
      "         [0.3815],\n",
      "         [0.2609],\n",
      "         [0.7053],\n",
      "         [0.4663],\n",
      "         [0.4035],\n",
      "         [0.3376],\n",
      "         [0.8763],\n",
      "         [0.8931],\n",
      "         [0.6704],\n",
      "         [0.9992],\n",
      "         [0.2288],\n",
      "         [0.7293],\n",
      "         [0.8455],\n",
      "         [0.2897],\n",
      "         [0.7064],\n",
      "         [0.3075],\n",
      "         [0.6615],\n",
      "         [0.6156],\n",
      "         [0.0355],\n",
      "         [0.4679],\n",
      "         [0.0625],\n",
      "         [0.5874],\n",
      "         [0.1110],\n",
      "         [0.4882],\n",
      "         [0.1976],\n",
      "         [0.3541],\n",
      "         [0.9956],\n",
      "         [0.1715],\n",
      "         [0.6500],\n",
      "         [0.7076],\n",
      "         [0.6348],\n",
      "         [0.0838],\n",
      "         [0.9190],\n",
      "         [0.0685],\n",
      "         [0.5931],\n",
      "         [0.4343],\n",
      "         [0.6528],\n",
      "         [0.2572],\n",
      "         [0.5880],\n",
      "         [0.7355],\n",
      "         [0.3102],\n",
      "         [0.7289],\n",
      "         [0.9282],\n",
      "         [0.2411],\n",
      "         [0.5739],\n",
      "         [0.6766],\n",
      "         [0.0359],\n",
      "         [0.8853],\n",
      "         [0.1969],\n",
      "         [0.3430],\n",
      "         [0.3083],\n",
      "         [0.1192],\n",
      "         [0.2361],\n",
      "         [0.7614],\n",
      "         [0.8258],\n",
      "         [0.8813],\n",
      "         [0.9309],\n",
      "         [0.4796],\n",
      "         [0.1246],\n",
      "         [0.1669],\n",
      "         [0.1369],\n",
      "         [0.6632],\n",
      "         [0.6316],\n",
      "         [0.1521],\n",
      "         [0.0287],\n",
      "         [0.0130],\n",
      "         [0.0430],\n",
      "         [0.7067],\n",
      "         [0.1297],\n",
      "         [0.8368],\n",
      "         [0.3160],\n",
      "         [0.4633],\n",
      "         [0.6234],\n",
      "         [0.5540],\n",
      "         [0.4527],\n",
      "         [0.4418],\n",
      "         [0.8101],\n",
      "         [0.8496],\n",
      "         [0.9209],\n",
      "         [0.6405],\n",
      "         [0.1940],\n",
      "         [0.2843],\n",
      "         [0.8422],\n",
      "         [0.8311],\n",
      "         [0.7843],\n",
      "         [0.8673],\n",
      "         [0.0254],\n",
      "         [0.7431],\n",
      "         [0.9300],\n",
      "         [0.3084],\n",
      "         [0.4372],\n",
      "         [0.0257],\n",
      "         [0.3138],\n",
      "         [0.5054],\n",
      "         [0.1639],\n",
      "         [0.0331],\n",
      "         [0.5072],\n",
      "         [0.4818],\n",
      "         [0.3182],\n",
      "         [0.3292],\n",
      "         [0.3586],\n",
      "         [0.2858],\n",
      "         [0.9003],\n",
      "         [0.6417],\n",
      "         [0.0801],\n",
      "         [0.1969],\n",
      "         [0.9881],\n",
      "         [0.4158],\n",
      "         [0.0579],\n",
      "         [0.7767],\n",
      "         [0.2214],\n",
      "         [0.8529],\n",
      "         [0.7138],\n",
      "         [0.4092],\n",
      "         [0.7145],\n",
      "         [0.4608],\n",
      "         [0.1450],\n",
      "         [0.9852],\n",
      "         [0.7695],\n",
      "         [0.6726],\n",
      "         [0.1497],\n",
      "         [0.0614],\n",
      "         [0.6293],\n",
      "         [0.4589],\n",
      "         [0.4223],\n",
      "         [0.2765],\n",
      "         [0.3449],\n",
      "         [0.9292]]], device='cuda:0', dtype=torch.float64)\n",
      "================iter 4============\n",
      "['shape/cube/1/cube_512_256_2_3_0']\n",
      "tensor([[ True,  True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
      "          True,  True,  True,  True,  True,  True,  True,  True, False, False]],\n",
      "       device='cuda:0')\n",
      "acc torch.Size([1]) tensor([0.0556], device='cuda:0')\n",
      "acc_per_part torch.Size([1, 20]) tensor([[False, False, False, False, False, False, False, False, False, False,\n",
      "         False, False, False, False, False,  True, False, False, False, False]],\n",
      "       device='cuda:0')\n",
      "loss_per_data torch.Size([1, 20]) tensor([[ 1.3889, 16.6760, 15.0535,  0.5266, 42.1224, 14.9311,  6.3260,  6.3625,\n",
      "         11.9861, 29.5844,  9.0097,  0.4371,  1.6146,  5.3549, 33.7195,  0.0000,\n",
      "          2.6250,  1.7955,  0.9422, 21.6103]], device='cuda:0')\n",
      "scores torch.Size([1, 190, 1]) tensor([[[0.3378],\n",
      "         [0.5455],\n",
      "         [0.0727],\n",
      "         [0.8053],\n",
      "         [0.5545],\n",
      "         [0.2933],\n",
      "         [0.8467],\n",
      "         [0.6830],\n",
      "         [0.5374],\n",
      "         [0.1492],\n",
      "         [0.3093],\n",
      "         [0.6841],\n",
      "         [0.2811],\n",
      "         [0.0371],\n",
      "         [0.1165],\n",
      "         [0.1018],\n",
      "         [0.9719],\n",
      "         [0.7001],\n",
      "         [0.7999],\n",
      "         [0.0973],\n",
      "         [0.5039],\n",
      "         [0.9320],\n",
      "         [0.5575],\n",
      "         [0.7633],\n",
      "         [0.6076],\n",
      "         [0.6078],\n",
      "         [0.7463],\n",
      "         [0.8159],\n",
      "         [0.6463],\n",
      "         [0.7467],\n",
      "         [0.8699],\n",
      "         [0.3977],\n",
      "         [0.7550],\n",
      "         [0.7417],\n",
      "         [0.3893],\n",
      "         [0.9655],\n",
      "         [0.5973],\n",
      "         [0.7741],\n",
      "         [0.8903],\n",
      "         [0.0035],\n",
      "         [0.6881],\n",
      "         [0.8668],\n",
      "         [0.1176],\n",
      "         [0.9488],\n",
      "         [0.6065],\n",
      "         [0.1608],\n",
      "         [0.9705],\n",
      "         [0.6994],\n",
      "         [0.7922],\n",
      "         [0.5002],\n",
      "         [0.5997],\n",
      "         [0.9268],\n",
      "         [0.6588],\n",
      "         [0.1757],\n",
      "         [0.4315],\n",
      "         [0.0748],\n",
      "         [0.0912],\n",
      "         [0.7877],\n",
      "         [0.8029],\n",
      "         [0.3266],\n",
      "         [0.0634],\n",
      "         [0.7479],\n",
      "         [0.7752],\n",
      "         [0.9313],\n",
      "         [0.2647],\n",
      "         [0.4085],\n",
      "         [0.8116],\n",
      "         [0.7540],\n",
      "         [0.6498],\n",
      "         [0.3630],\n",
      "         [0.9088],\n",
      "         [0.1082],\n",
      "         [0.3124],\n",
      "         [0.0014],\n",
      "         [0.5381],\n",
      "         [0.2085],\n",
      "         [0.3672],\n",
      "         [0.1674],\n",
      "         [0.5775],\n",
      "         [0.1914],\n",
      "         [0.1768],\n",
      "         [0.3688],\n",
      "         [0.2126],\n",
      "         [0.1797],\n",
      "         [0.2804],\n",
      "         [0.1733],\n",
      "         [0.1183],\n",
      "         [0.9006],\n",
      "         [0.3028],\n",
      "         [0.0779],\n",
      "         [0.4457],\n",
      "         [0.5398],\n",
      "         [0.8269],\n",
      "         [0.6895],\n",
      "         [0.2825],\n",
      "         [0.4339],\n",
      "         [0.1705],\n",
      "         [0.2375],\n",
      "         [0.2322],\n",
      "         [0.5401],\n",
      "         [0.7006],\n",
      "         [0.5448],\n",
      "         [0.9997],\n",
      "         [0.0207],\n",
      "         [0.3191],\n",
      "         [0.0129],\n",
      "         [0.0724],\n",
      "         [0.8025],\n",
      "         [0.1124],\n",
      "         [0.5633],\n",
      "         [0.2787],\n",
      "         [0.6561],\n",
      "         [0.6406],\n",
      "         [0.7822],\n",
      "         [0.9466],\n",
      "         [0.0544],\n",
      "         [0.3236],\n",
      "         [0.0066],\n",
      "         [0.6941],\n",
      "         [0.7713],\n",
      "         [0.1164],\n",
      "         [0.7034],\n",
      "         [0.1306],\n",
      "         [0.4931],\n",
      "         [0.3830],\n",
      "         [0.8693],\n",
      "         [0.3258],\n",
      "         [0.6941],\n",
      "         [0.0954],\n",
      "         [0.8852],\n",
      "         [0.0251],\n",
      "         [0.0727],\n",
      "         [0.1367],\n",
      "         [0.0488],\n",
      "         [0.9173],\n",
      "         [0.4598],\n",
      "         [0.8590],\n",
      "         [0.5232],\n",
      "         [0.2078],\n",
      "         [0.9701],\n",
      "         [0.3631],\n",
      "         [0.8940],\n",
      "         [0.0679],\n",
      "         [0.6953],\n",
      "         [0.6651],\n",
      "         [0.1755],\n",
      "         [0.1264],\n",
      "         [0.2425],\n",
      "         [0.3324],\n",
      "         [0.5015],\n",
      "         [0.0100],\n",
      "         [0.0946],\n",
      "         [0.7927],\n",
      "         [0.8387],\n",
      "         [0.1582],\n",
      "         [0.4234],\n",
      "         [0.5564],\n",
      "         [0.6448],\n",
      "         [0.6851],\n",
      "         [0.2596],\n",
      "         [0.6936],\n",
      "         [0.2499],\n",
      "         [0.5071],\n",
      "         [0.3067],\n",
      "         [0.9791],\n",
      "         [0.3261],\n",
      "         [0.1834],\n",
      "         [0.7854],\n",
      "         [0.3933],\n",
      "         [0.3734],\n",
      "         [0.3814],\n",
      "         [0.0311],\n",
      "         [0.2854],\n",
      "         [0.9913],\n",
      "         [0.3630],\n",
      "         [0.4259],\n",
      "         [0.6597],\n",
      "         [0.2721],\n",
      "         [0.9069],\n",
      "         [0.5808],\n",
      "         [0.6871],\n",
      "         [0.1101],\n",
      "         [0.8459],\n",
      "         [0.0778],\n",
      "         [0.1228],\n",
      "         [0.3414],\n",
      "         [0.0776],\n",
      "         [0.1256],\n",
      "         [0.9194],\n",
      "         [0.3542]]], device='cuda:0', dtype=torch.float64)\n",
      "================iter 5============\n",
      "['shape/cube/1/cube_512_256_2_3_0']\n",
      "tensor([[ True,  True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
      "          True,  True,  True,  True,  True,  True,  True,  True, False, False]],\n",
      "       device='cuda:0')\n",
      "@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@\n",
      "['shape/cube/1/cube_512_256_3_1_0']\n",
      "gt_trans_torch.Size([1, 20, 3])_tensor([[[-1.0257e-01, -1.8153e-01,  3.7842e-02],\n",
      "         [-8.1375e-02, -1.3202e-01,  1.8737e-02],\n",
      "         [-8.6209e-02, -2.7883e-02,  6.3743e-02],\n",
      "         [-1.0420e-01, -3.5947e-02,  7.4669e-02],\n",
      "         [-1.0929e-01, -3.0167e-02,  8.2360e-02],\n",
      "         [-1.2000e-01, -1.7051e-02,  7.5360e-02],\n",
      "         [-8.4195e-02,  3.7568e-02,  6.4947e-02],\n",
      "         [-4.5170e-02,  8.9122e-02,  6.1390e-02],\n",
      "         [-1.2633e-02,  1.4634e-01,  4.4421e-02],\n",
      "         [ 2.6355e-02,  1.9880e-01,  3.9672e-02],\n",
      "         [-3.6228e-02, -7.8504e-02,  1.8633e-02],\n",
      "         [ 3.1847e-04, -2.0039e-02,  4.7176e-03],\n",
      "         [ 0.0000e+00,  7.1054e-18, -4.4409e-18],\n",
      "         [-1.6474e-02, -1.0500e-02,  1.5757e-02],\n",
      "         [-2.8950e-02,  2.4294e-03,  7.1523e-03],\n",
      "         [-4.3928e-02, -1.2255e-02,  2.9250e-02],\n",
      "         [-6.3245e-02, -2.2973e-02,  4.1974e-02],\n",
      "         [-6.8736e-02, -1.8658e-02,  5.0941e-02],\n",
      "         [ 0.0000e+00,  0.0000e+00,  0.0000e+00],\n",
      "         [ 0.0000e+00,  0.0000e+00,  0.0000e+00]]], device='cuda:0')\n",
      "gt_rots_torch.Size([1, 20, 4])_tensor([[[-0.2010, -0.5294,  0.0415,  0.8232],\n",
      "         [-0.5202,  0.5675,  0.4696,  0.4322],\n",
      "         [ 0.6482,  0.0163,  0.7230,  0.2385],\n",
      "         [ 0.6417,  0.2840,  0.2444,  0.6692],\n",
      "         [-0.4229, -0.3596,  0.7978,  0.2353],\n",
      "         [-0.2603, -0.6498,  0.6862, -0.1980],\n",
      "         [-0.6736, -0.0423, -0.1588,  0.7206],\n",
      "         [-0.5506, -0.2226,  0.7981, -0.1020],\n",
      "         [ 0.7259,  0.6332, -0.0725, -0.2586],\n",
      "         [ 0.0135, -0.0992, -0.2902,  0.9517],\n",
      "         [-0.4409, -0.1791,  0.8226,  0.3112],\n",
      "         [ 0.5378,  0.7263, -0.4269,  0.0320],\n",
      "         [ 0.0125,  0.7738,  0.6267, -0.0912],\n",
      "         [ 0.2275,  0.7317, -0.5156,  0.3834],\n",
      "         [ 0.5724,  0.2034,  0.5697, -0.5535],\n",
      "         [-0.6555,  0.6981,  0.2375, -0.1631],\n",
      "         [ 0.0638,  0.1768,  0.9313,  0.3119],\n",
      "         [-0.5540,  0.5827, -0.5097,  0.3063],\n",
      "         [ 0.0000,  0.0000,  0.0000,  0.0000],\n",
      "         [ 0.0000,  0.0000,  0.0000,  0.0000]]], device='cuda:0')\n",
      "noisy_trans_and_rots_torch.Size([1, 20, 7])_tensor([[[ 0.2231,  0.0000,  0.9259,  0.4782,  0.0000,  0.0000,  0.9804],\n",
      "         [-0.5309,  0.0000,  0.2245, -0.0982,  0.0000,  0.0000,  0.5329],\n",
      "         [-0.2297,  0.0000,  1.0504, -0.6171,  0.0000,  0.0000,  1.1643],\n",
      "         [-0.1994,  0.0000,  0.7224,  0.3528,  0.0000,  0.0000,  0.1414],\n",
      "         [-0.4131,  0.0000,  1.1359,  0.5857,  0.0000,  0.0000, -1.3036],\n",
      "         [ 0.1035,  0.0000, -0.4057, -0.2882,  0.0000,  0.0000,  0.8088],\n",
      "         [-0.3755,  0.0000, -0.7007, -0.0550,  0.0000,  0.0000,  1.1609],\n",
      "         [-1.5798,  0.0000,  1.4137,  0.9508,  0.0000,  0.0000,  0.4011],\n",
      "         [-0.4340,  0.0000,  1.0967, -0.8089,  0.0000,  0.0000,  1.8237],\n",
      "         [ 0.2896,  0.0000,  0.2878,  1.0144,  0.0000,  0.0000, -0.0729],\n",
      "         [ 1.2488,  0.0000, -0.5899, -0.3943,  0.0000,  0.0000, -2.0700],\n",
      "         [-0.1678,  0.0000,  1.1448, -0.1910,  0.0000,  0.0000,  0.3158],\n",
      "         [ 0.4387,  0.0000, -0.1443,  0.8609,  0.0000,  0.0000, -0.3573],\n",
      "         [-0.8279,  0.0000,  0.7574, -0.7920,  0.0000,  0.0000,  0.9235],\n",
      "         [-0.8523,  0.0000, -0.1420, -0.7678,  0.0000,  0.0000,  0.7372],\n",
      "         [ 0.2541,  0.0000,  0.1317,  0.6864,  0.0000,  0.0000,  0.4475],\n",
      "         [ 1.3317,  0.0000,  0.2687, -1.3950,  0.0000,  0.0000,  0.1260],\n",
      "         [-0.2767,  0.0000, -0.0828,  1.1306,  0.0000,  0.0000, -0.8816],\n",
      "         [-0.3867,  0.0000,  0.6955, -2.1888,  0.0000,  0.0000, -1.0148],\n",
      "         [ 0.5914,  0.0000,  1.5940,  0.5782,  0.0000,  0.0000,  0.2597]]],\n",
      "       device='cuda:0')\n",
      "================iter 0============\n",
      "['shape/cube/1/cube_512_256_3_1_0']\n",
      "tensor([[False, False, False, False, False, False, False, False, False, False,\n",
      "         False, False,  True, False, False, False, False, False, False, False]],\n",
      "       device='cuda:0')\n",
      "acc torch.Size([1]) tensor([0.0556], device='cuda:0')\n",
      "acc_per_part torch.Size([1, 20]) tensor([[False, False, False, False, False, False, False, False, False, False,\n",
      "         False, False,  True, False, False, False, False, False, False, False]],\n",
      "       device='cuda:0')\n",
      "loss_per_data torch.Size([1, 20]) tensor([[4.4954, 0.8252, 1.0385, 1.4298, 1.1992, 0.5137, 5.5711, 0.1466, 3.0134,\n",
      "         0.6717, 2.5497, 0.3065, 0.0000, 1.0585, 0.4682, 3.9828, 3.1527, 1.7990,\n",
      "         1.8504, 3.1017]], device='cuda:0')\n",
      "scores torch.Size([1, 190, 1]) tensor([[[0.1199],\n",
      "         [0.9576],\n",
      "         [0.7632],\n",
      "         [0.6056],\n",
      "         [0.6894],\n",
      "         [0.9802],\n",
      "         [0.3694],\n",
      "         [0.7666],\n",
      "         [0.5033],\n",
      "         [0.0615],\n",
      "         [0.9556],\n",
      "         [0.7293],\n",
      "         [0.8028],\n",
      "         [0.3415],\n",
      "         [0.1941],\n",
      "         [0.8458],\n",
      "         [0.9255],\n",
      "         [0.2878],\n",
      "         [0.9635],\n",
      "         [0.9032],\n",
      "         [0.6080],\n",
      "         [0.0435],\n",
      "         [0.3325],\n",
      "         [0.4794],\n",
      "         [0.5983],\n",
      "         [0.0366],\n",
      "         [0.3179],\n",
      "         [0.3700],\n",
      "         [0.6663],\n",
      "         [0.6257],\n",
      "         [0.1322],\n",
      "         [0.1920],\n",
      "         [0.8282],\n",
      "         [0.3318],\n",
      "         [0.3439],\n",
      "         [0.8366],\n",
      "         [0.0662],\n",
      "         [0.8428],\n",
      "         [0.6126],\n",
      "         [0.5906],\n",
      "         [0.3284],\n",
      "         [0.8931],\n",
      "         [0.8556],\n",
      "         [0.7731],\n",
      "         [0.4106],\n",
      "         [0.6347],\n",
      "         [0.5630],\n",
      "         [0.9315],\n",
      "         [0.5047],\n",
      "         [0.9062],\n",
      "         [0.9721],\n",
      "         [0.4527],\n",
      "         [0.2330],\n",
      "         [0.2206],\n",
      "         [0.8556],\n",
      "         [0.9019],\n",
      "         [0.0540],\n",
      "         [0.7426],\n",
      "         [0.8696],\n",
      "         [0.1793],\n",
      "         [0.1586],\n",
      "         [0.7874],\n",
      "         [0.2181],\n",
      "         [0.4149],\n",
      "         [0.8551],\n",
      "         [0.5593],\n",
      "         [0.3467],\n",
      "         [0.0663],\n",
      "         [0.9727],\n",
      "         [0.8285],\n",
      "         [0.6919],\n",
      "         [0.1015],\n",
      "         [0.7224],\n",
      "         [0.9523],\n",
      "         [0.6251],\n",
      "         [0.5229],\n",
      "         [0.8378],\n",
      "         [0.1136],\n",
      "         [0.5498],\n",
      "         [0.0725],\n",
      "         [0.3434],\n",
      "         [0.8581],\n",
      "         [0.3096],\n",
      "         [0.3120],\n",
      "         [0.8324],\n",
      "         [0.3756],\n",
      "         [0.0215],\n",
      "         [0.4237],\n",
      "         [0.4835],\n",
      "         [0.5636],\n",
      "         [0.7821],\n",
      "         [0.1154],\n",
      "         [0.8100],\n",
      "         [0.9732],\n",
      "         [0.3702],\n",
      "         [0.8225],\n",
      "         [0.0526],\n",
      "         [0.8536],\n",
      "         [0.2973],\n",
      "         [0.1465],\n",
      "         [0.6174],\n",
      "         [0.2152],\n",
      "         [0.2938],\n",
      "         [0.1078],\n",
      "         [0.9486],\n",
      "         [0.9222],\n",
      "         [0.4050],\n",
      "         [0.6060],\n",
      "         [0.7669],\n",
      "         [0.1806],\n",
      "         [0.9945],\n",
      "         [0.8773],\n",
      "         [0.6045],\n",
      "         [0.7761],\n",
      "         [0.0175],\n",
      "         [0.9597],\n",
      "         [0.7500],\n",
      "         [0.3797],\n",
      "         [0.9460],\n",
      "         [0.9972],\n",
      "         [0.3150],\n",
      "         [0.5375],\n",
      "         [0.3853],\n",
      "         [0.2694],\n",
      "         [0.7225],\n",
      "         [0.1202],\n",
      "         [0.7556],\n",
      "         [0.2111],\n",
      "         [0.2162],\n",
      "         [0.6305],\n",
      "         [0.3402],\n",
      "         [0.7187],\n",
      "         [0.0267],\n",
      "         [0.5767],\n",
      "         [0.6213],\n",
      "         [0.7388],\n",
      "         [0.0061],\n",
      "         [0.4972],\n",
      "         [0.4696],\n",
      "         [0.2470],\n",
      "         [0.3144],\n",
      "         [0.9204],\n",
      "         [0.8370],\n",
      "         [0.0326],\n",
      "         [0.1808],\n",
      "         [0.4378],\n",
      "         [0.5008],\n",
      "         [0.6429],\n",
      "         [0.7557],\n",
      "         [0.9516],\n",
      "         [0.4234],\n",
      "         [0.0185],\n",
      "         [0.3589],\n",
      "         [0.6242],\n",
      "         [0.8525],\n",
      "         [0.6570],\n",
      "         [0.1434],\n",
      "         [0.3155],\n",
      "         [0.6407],\n",
      "         [0.1431],\n",
      "         [0.6962],\n",
      "         [0.6753],\n",
      "         [0.4302],\n",
      "         [0.0873],\n",
      "         [0.3398],\n",
      "         [0.4385],\n",
      "         [0.1027],\n",
      "         [0.2769],\n",
      "         [0.6167],\n",
      "         [0.6419],\n",
      "         [0.2889],\n",
      "         [0.8887],\n",
      "         [0.3412],\n",
      "         [0.0396],\n",
      "         [0.7086],\n",
      "         [0.9315],\n",
      "         [0.9485],\n",
      "         [0.7290],\n",
      "         [0.1438],\n",
      "         [0.2388],\n",
      "         [0.8022],\n",
      "         [0.3715],\n",
      "         [0.0011],\n",
      "         [0.0371],\n",
      "         [0.0754],\n",
      "         [0.8721],\n",
      "         [0.1159],\n",
      "         [0.7395],\n",
      "         [0.3016],\n",
      "         [0.1881]]], device='cuda:0', dtype=torch.float64)\n",
      "================iter 1============\n",
      "['shape/cube/1/cube_512_256_3_1_0']\n",
      "tensor([[False, False, False, False, False, False,  True, False, False, False,\n",
      "         False, False,  True, False, False, False, False, False, False, False]],\n",
      "       device='cuda:0')\n",
      "acc torch.Size([1]) tensor([0.0556], device='cuda:0')\n",
      "acc_per_part torch.Size([1, 20]) tensor([[False, False, False, False, False, False, False, False, False, False,\n",
      "         False, False,  True, False, False, False, False, False, False, False]],\n",
      "       device='cuda:0')\n",
      "loss_per_data torch.Size([1, 20]) tensor([[ 8.9206,  0.2400,  2.6429,  1.9111,  0.8255,  2.3919,  5.5711,  2.3501,\n",
      "          1.5876,  1.0719,  6.2143,  7.7962,  0.0000, 10.2234,  5.8760, 41.1490,\n",
      "         14.1230,  4.6997,  1.1482, 11.9208]], device='cuda:0')\n",
      "scores torch.Size([1, 190, 1]) tensor([[[4.3489e-02],\n",
      "         [4.9082e-01],\n",
      "         [6.1662e-01],\n",
      "         [8.0504e-02],\n",
      "         [4.3764e-01],\n",
      "         [9.6932e-01],\n",
      "         [9.5664e-01],\n",
      "         [4.3717e-01],\n",
      "         [8.2190e-01],\n",
      "         [6.4752e-01],\n",
      "         [2.4266e-01],\n",
      "         [3.7961e-01],\n",
      "         [6.3771e-01],\n",
      "         [1.3312e-01],\n",
      "         [1.9096e-01],\n",
      "         [2.5876e-01],\n",
      "         [3.3504e-01],\n",
      "         [9.0971e-01],\n",
      "         [6.1498e-01],\n",
      "         [9.2016e-02],\n",
      "         [7.6165e-01],\n",
      "         [5.2705e-01],\n",
      "         [6.9960e-01],\n",
      "         [4.0137e-01],\n",
      "         [2.4287e-01],\n",
      "         [6.7429e-01],\n",
      "         [8.7909e-01],\n",
      "         [7.6084e-01],\n",
      "         [8.8681e-02],\n",
      "         [7.7358e-01],\n",
      "         [5.0236e-01],\n",
      "         [2.9494e-01],\n",
      "         [2.8957e-01],\n",
      "         [7.9795e-01],\n",
      "         [1.7027e-01],\n",
      "         [4.7060e-01],\n",
      "         [6.7972e-01],\n",
      "         [9.5817e-01],\n",
      "         [2.0831e-01],\n",
      "         [3.0064e-01],\n",
      "         [2.8217e-01],\n",
      "         [7.5761e-01],\n",
      "         [1.0023e-01],\n",
      "         [5.2084e-01],\n",
      "         [3.8995e-01],\n",
      "         [9.4561e-01],\n",
      "         [2.0857e-01],\n",
      "         [6.8323e-01],\n",
      "         [6.6128e-01],\n",
      "         [5.1068e-01],\n",
      "         [9.3736e-01],\n",
      "         [2.3353e-01],\n",
      "         [7.8836e-01],\n",
      "         [9.8651e-02],\n",
      "         [5.4982e-01],\n",
      "         [9.0528e-02],\n",
      "         [7.9909e-02],\n",
      "         [6.2545e-03],\n",
      "         [3.4046e-01],\n",
      "         [3.2900e-01],\n",
      "         [5.4100e-01],\n",
      "         [7.2510e-01],\n",
      "         [2.5031e-01],\n",
      "         [4.9852e-01],\n",
      "         [7.4054e-01],\n",
      "         [8.9230e-01],\n",
      "         [8.6826e-01],\n",
      "         [4.0071e-01],\n",
      "         [9.0466e-01],\n",
      "         [7.9101e-01],\n",
      "         [1.8701e-01],\n",
      "         [5.7525e-01],\n",
      "         [1.1425e-01],\n",
      "         [5.9058e-01],\n",
      "         [8.5954e-01],\n",
      "         [7.1079e-01],\n",
      "         [7.1107e-01],\n",
      "         [4.5710e-01],\n",
      "         [3.0445e-01],\n",
      "         [9.5750e-01],\n",
      "         [6.2500e-01],\n",
      "         [7.0477e-02],\n",
      "         [3.6151e-01],\n",
      "         [5.5866e-01],\n",
      "         [5.2823e-03],\n",
      "         [9.5944e-02],\n",
      "         [9.4289e-01],\n",
      "         [5.0513e-01],\n",
      "         [2.3432e-01],\n",
      "         [5.0063e-04],\n",
      "         [5.5268e-01],\n",
      "         [1.1295e-01],\n",
      "         [3.6979e-01],\n",
      "         [9.8406e-01],\n",
      "         [1.0356e-04],\n",
      "         [9.0279e-01],\n",
      "         [8.6008e-01],\n",
      "         [1.8790e-01],\n",
      "         [9.7742e-01],\n",
      "         [8.2304e-01],\n",
      "         [7.9228e-03],\n",
      "         [8.6606e-01],\n",
      "         [1.2772e-01],\n",
      "         [4.9782e-01],\n",
      "         [6.5865e-02],\n",
      "         [2.6442e-01],\n",
      "         [7.9498e-01],\n",
      "         [1.2065e-02],\n",
      "         [3.3938e-01],\n",
      "         [8.3172e-02],\n",
      "         [5.1840e-01],\n",
      "         [4.6296e-01],\n",
      "         [9.5847e-01],\n",
      "         [9.5632e-01],\n",
      "         [4.7723e-01],\n",
      "         [2.2007e-01],\n",
      "         [5.9950e-01],\n",
      "         [9.3843e-01],\n",
      "         [1.2516e-01],\n",
      "         [3.3755e-01],\n",
      "         [9.5139e-01],\n",
      "         [3.2444e-01],\n",
      "         [8.7113e-01],\n",
      "         [1.6432e-01],\n",
      "         [6.7633e-01],\n",
      "         [5.7453e-02],\n",
      "         [3.3340e-01],\n",
      "         [3.7348e-01],\n",
      "         [9.8299e-02],\n",
      "         [4.0682e-01],\n",
      "         [8.0183e-01],\n",
      "         [1.3499e-01],\n",
      "         [8.3309e-01],\n",
      "         [4.3456e-01],\n",
      "         [3.4646e-01],\n",
      "         [5.4112e-02],\n",
      "         [1.6566e-01],\n",
      "         [2.0769e-01],\n",
      "         [3.3160e-01],\n",
      "         [7.3403e-01],\n",
      "         [3.2180e-01],\n",
      "         [2.1487e-01],\n",
      "         [5.4451e-01],\n",
      "         [4.6815e-01],\n",
      "         [5.6403e-01],\n",
      "         [4.0099e-01],\n",
      "         [1.5947e-01],\n",
      "         [9.4273e-01],\n",
      "         [1.9482e-02],\n",
      "         [8.8150e-01],\n",
      "         [6.4139e-01],\n",
      "         [5.1476e-01],\n",
      "         [6.5643e-01],\n",
      "         [1.7198e-02],\n",
      "         [5.7898e-02],\n",
      "         [2.8041e-01],\n",
      "         [4.0655e-01],\n",
      "         [4.9381e-01],\n",
      "         [7.5760e-01],\n",
      "         [1.6113e-01],\n",
      "         [4.0952e-01],\n",
      "         [6.6781e-01],\n",
      "         [7.4980e-01],\n",
      "         [9.8421e-01],\n",
      "         [2.2655e-01],\n",
      "         [2.8571e-01],\n",
      "         [1.7625e-01],\n",
      "         [2.4313e-01],\n",
      "         [5.5961e-01],\n",
      "         [5.1786e-01],\n",
      "         [9.2641e-02],\n",
      "         [6.9295e-01],\n",
      "         [8.9588e-02],\n",
      "         [6.6602e-01],\n",
      "         [5.8119e-01],\n",
      "         [4.7169e-01],\n",
      "         [4.9581e-01],\n",
      "         [3.1937e-01],\n",
      "         [6.9814e-03],\n",
      "         [7.6237e-01],\n",
      "         [1.3433e-01],\n",
      "         [4.7679e-01],\n",
      "         [8.3958e-01],\n",
      "         [4.2576e-01],\n",
      "         [8.3580e-01],\n",
      "         [1.9811e-01],\n",
      "         [1.7372e-01],\n",
      "         [3.5848e-01],\n",
      "         [3.9638e-02],\n",
      "         [7.7999e-02]]], device='cuda:0', dtype=torch.float64)\n",
      "================iter 2============\n",
      "['shape/cube/1/cube_512_256_3_1_0']\n",
      "tensor([[ True, False, False, False, False, False,  True, False, False, False,\n",
      "         False, False,  True, False,  True, False, False, False, False, False]],\n",
      "       device='cuda:0')\n",
      "acc torch.Size([1]) tensor([0.0556], device='cuda:0')\n",
      "acc_per_part torch.Size([1, 20]) tensor([[False, False, False, False, False, False, False, False, False, False,\n",
      "         False, False,  True, False, False, False, False, False, False, False]],\n",
      "       device='cuda:0')\n",
      "loss_per_data torch.Size([1, 20]) tensor([[  8.9206,   4.1096,  12.4376,   4.8117,   6.1802,   8.0666,   5.5711,\n",
      "           2.9389,   7.6775,   5.0161,   3.7644,  20.7406,   0.0000,  65.6266,\n",
      "           5.8760, 124.2889,  81.1026,  17.2258,  11.8978,  26.6716]],\n",
      "       device='cuda:0')\n",
      "scores torch.Size([1, 190, 1]) tensor([[[0.8690],\n",
      "         [0.2856],\n",
      "         [0.5944],\n",
      "         [0.0181],\n",
      "         [0.9275],\n",
      "         [0.1619],\n",
      "         [0.6280],\n",
      "         [0.7208],\n",
      "         [0.0786],\n",
      "         [0.8178],\n",
      "         [0.1557],\n",
      "         [0.0087],\n",
      "         [0.7584],\n",
      "         [0.2197],\n",
      "         [0.0295],\n",
      "         [0.2102],\n",
      "         [0.5878],\n",
      "         [0.1663],\n",
      "         [0.2101],\n",
      "         [0.8947],\n",
      "         [0.3393],\n",
      "         [0.0694],\n",
      "         [0.4624],\n",
      "         [0.8813],\n",
      "         [0.0886],\n",
      "         [0.2632],\n",
      "         [0.2064],\n",
      "         [0.1243],\n",
      "         [0.4618],\n",
      "         [0.9842],\n",
      "         [0.3402],\n",
      "         [0.3782],\n",
      "         [0.7439],\n",
      "         [0.1956],\n",
      "         [0.8546],\n",
      "         [0.9619],\n",
      "         [0.6766],\n",
      "         [0.4749],\n",
      "         [0.2411],\n",
      "         [0.5829],\n",
      "         [0.0071],\n",
      "         [0.7612],\n",
      "         [0.6854],\n",
      "         [0.2809],\n",
      "         [0.5989],\n",
      "         [0.8359],\n",
      "         [0.1471],\n",
      "         [0.2157],\n",
      "         [0.2136],\n",
      "         [0.4093],\n",
      "         [0.0056],\n",
      "         [0.0423],\n",
      "         [0.9597],\n",
      "         [0.1672],\n",
      "         [0.5696],\n",
      "         [0.7025],\n",
      "         [0.5467],\n",
      "         [0.1759],\n",
      "         [0.9635],\n",
      "         [0.0622],\n",
      "         [0.2681],\n",
      "         [0.2325],\n",
      "         [0.3698],\n",
      "         [0.6688],\n",
      "         [0.1914],\n",
      "         [0.7307],\n",
      "         [0.7521],\n",
      "         [0.3667],\n",
      "         [0.6592],\n",
      "         [0.3709],\n",
      "         [0.0803],\n",
      "         [0.3853],\n",
      "         [0.2776],\n",
      "         [0.0898],\n",
      "         [0.9840],\n",
      "         [0.2878],\n",
      "         [0.0346],\n",
      "         [0.0075],\n",
      "         [0.3289],\n",
      "         [0.3114],\n",
      "         [0.6076],\n",
      "         [0.6796],\n",
      "         [0.6069],\n",
      "         [0.7769],\n",
      "         [0.9577],\n",
      "         [0.2137],\n",
      "         [0.5123],\n",
      "         [0.3295],\n",
      "         [0.2057],\n",
      "         [0.9592],\n",
      "         [0.1217],\n",
      "         [0.2475],\n",
      "         [0.1825],\n",
      "         [0.2589],\n",
      "         [0.0607],\n",
      "         [0.6014],\n",
      "         [0.4741],\n",
      "         [0.6858],\n",
      "         [0.1026],\n",
      "         [0.3780],\n",
      "         [0.1352],\n",
      "         [0.5325],\n",
      "         [0.8785],\n",
      "         [0.6632],\n",
      "         [0.9401],\n",
      "         [0.1433],\n",
      "         [0.2676],\n",
      "         [0.2996],\n",
      "         [0.9886],\n",
      "         [0.3084],\n",
      "         [0.4314],\n",
      "         [0.0766],\n",
      "         [0.0435],\n",
      "         [0.5965],\n",
      "         [0.5101],\n",
      "         [0.8535],\n",
      "         [0.0216],\n",
      "         [0.6343],\n",
      "         [0.1502],\n",
      "         [0.5431],\n",
      "         [0.4131],\n",
      "         [0.4197],\n",
      "         [0.7813],\n",
      "         [0.8059],\n",
      "         [0.9350],\n",
      "         [0.8269],\n",
      "         [0.2644],\n",
      "         [0.2056],\n",
      "         [0.9838],\n",
      "         [0.0992],\n",
      "         [0.9159],\n",
      "         [0.2163],\n",
      "         [0.8504],\n",
      "         [0.6975],\n",
      "         [0.0674],\n",
      "         [0.8532],\n",
      "         [0.4931],\n",
      "         [0.0089],\n",
      "         [0.0509],\n",
      "         [0.7345],\n",
      "         [0.8774],\n",
      "         [0.6803],\n",
      "         [0.8413],\n",
      "         [0.3400],\n",
      "         [0.5902],\n",
      "         [0.6340],\n",
      "         [0.7922],\n",
      "         [0.4079],\n",
      "         [0.5281],\n",
      "         [0.1431],\n",
      "         [0.2732],\n",
      "         [0.7639],\n",
      "         [0.6530],\n",
      "         [0.3103],\n",
      "         [0.9810],\n",
      "         [0.5667],\n",
      "         [0.2696],\n",
      "         [0.0414],\n",
      "         [0.5335],\n",
      "         [0.6001],\n",
      "         [0.0231],\n",
      "         [0.5018],\n",
      "         [0.4301],\n",
      "         [0.2354],\n",
      "         [0.2867],\n",
      "         [0.8908],\n",
      "         [0.4265],\n",
      "         [0.8601],\n",
      "         [0.5007],\n",
      "         [0.9227],\n",
      "         [0.6461],\n",
      "         [0.5300],\n",
      "         [0.9406],\n",
      "         [0.4181],\n",
      "         [0.6518],\n",
      "         [0.9914],\n",
      "         [0.3100],\n",
      "         [0.1543],\n",
      "         [0.8840],\n",
      "         [0.8521],\n",
      "         [0.3176],\n",
      "         [0.0974],\n",
      "         [0.5597],\n",
      "         [0.7663],\n",
      "         [0.5622],\n",
      "         [0.1501],\n",
      "         [0.2264],\n",
      "         [0.8577],\n",
      "         [0.6268],\n",
      "         [0.1739]]], device='cuda:0', dtype=torch.float64)\n",
      "================iter 3============\n",
      "['shape/cube/1/cube_512_256_3_1_0']\n",
      "tensor([[ True,  True, False, False, False,  True,  True, False, False, False,\n",
      "         False,  True,  True,  True,  True,  True,  True, False, False, False]],\n",
      "       device='cuda:0')\n",
      "acc torch.Size([1]) tensor([0.0556], device='cuda:0')\n",
      "acc_per_part torch.Size([1, 20]) tensor([[False, False, False, False, False, False, False, False, False, False,\n",
      "         False, False,  True, False, False, False, False, False, False, False]],\n",
      "       device='cuda:0')\n",
      "loss_per_data torch.Size([1, 20]) tensor([[  8.9206,   4.1096,  12.0285,   5.7889,  27.7513,   8.0666,   5.5711,\n",
      "           6.3995,  26.1119,   8.6116,   1.3267,  20.7406,   0.0000,  65.6266,\n",
      "           5.8760, 124.2889,  81.1026,  54.9838,  30.0053,  22.3387]],\n",
      "       device='cuda:0')\n",
      "scores torch.Size([1, 190, 1]) tensor([[[0.4277],\n",
      "         [0.4269],\n",
      "         [0.7335],\n",
      "         [0.6999],\n",
      "         [0.0326],\n",
      "         [0.2834],\n",
      "         [0.7109],\n",
      "         [0.5597],\n",
      "         [0.7971],\n",
      "         [0.8112],\n",
      "         [0.8988],\n",
      "         [0.0757],\n",
      "         [0.0678],\n",
      "         [0.9644],\n",
      "         [0.4557],\n",
      "         [0.6090],\n",
      "         [0.3806],\n",
      "         [0.0531],\n",
      "         [0.1051],\n",
      "         [0.5151],\n",
      "         [0.7357],\n",
      "         [0.4995],\n",
      "         [0.7186],\n",
      "         [0.5118],\n",
      "         [0.6460],\n",
      "         [0.8415],\n",
      "         [0.2201],\n",
      "         [0.5061],\n",
      "         [0.5406],\n",
      "         [0.3712],\n",
      "         [0.3291],\n",
      "         [0.2174],\n",
      "         [0.7177],\n",
      "         [0.8624],\n",
      "         [0.2847],\n",
      "         [0.4534],\n",
      "         [0.0331],\n",
      "         [0.8161],\n",
      "         [0.1770],\n",
      "         [0.4852],\n",
      "         [0.8729],\n",
      "         [0.6245],\n",
      "         [0.2423],\n",
      "         [0.2444],\n",
      "         [0.9509],\n",
      "         [0.8330],\n",
      "         [0.8778],\n",
      "         [0.4879],\n",
      "         [0.3541],\n",
      "         [0.7411],\n",
      "         [0.7482],\n",
      "         [0.5726],\n",
      "         [0.4047],\n",
      "         [0.4598],\n",
      "         [0.0366],\n",
      "         [0.7111],\n",
      "         [0.3577],\n",
      "         [0.3670],\n",
      "         [0.6326],\n",
      "         [0.0750],\n",
      "         [0.6395],\n",
      "         [0.7589],\n",
      "         [0.0493],\n",
      "         [0.1271],\n",
      "         [0.6999],\n",
      "         [0.3634],\n",
      "         [0.0686],\n",
      "         [0.4180],\n",
      "         [0.1573],\n",
      "         [0.3924],\n",
      "         [0.7227],\n",
      "         [0.4907],\n",
      "         [0.3263],\n",
      "         [0.5478],\n",
      "         [0.1275],\n",
      "         [0.3113],\n",
      "         [0.6746],\n",
      "         [0.3893],\n",
      "         [0.2595],\n",
      "         [0.2163],\n",
      "         [0.6000],\n",
      "         [0.7931],\n",
      "         [0.9892],\n",
      "         [0.1681],\n",
      "         [0.2352],\n",
      "         [0.1487],\n",
      "         [0.5254],\n",
      "         [0.8432],\n",
      "         [0.2121],\n",
      "         [0.1910],\n",
      "         [0.8682],\n",
      "         [0.4743],\n",
      "         [0.1667],\n",
      "         [0.6944],\n",
      "         [0.1580],\n",
      "         [0.5604],\n",
      "         [0.5548],\n",
      "         [0.6187],\n",
      "         [0.0167],\n",
      "         [0.5101],\n",
      "         [0.3654],\n",
      "         [0.0795],\n",
      "         [0.6280],\n",
      "         [0.1060],\n",
      "         [0.3623],\n",
      "         [0.8100],\n",
      "         [0.0702],\n",
      "         [0.8834],\n",
      "         [0.9565],\n",
      "         [0.2502],\n",
      "         [0.2804],\n",
      "         [0.1720],\n",
      "         [0.2169],\n",
      "         [0.6735],\n",
      "         [0.1949],\n",
      "         [0.9842],\n",
      "         [0.6957],\n",
      "         [0.1889],\n",
      "         [0.8878],\n",
      "         [0.6900],\n",
      "         [0.8800],\n",
      "         [0.3492],\n",
      "         [0.7204],\n",
      "         [0.3928],\n",
      "         [0.1115],\n",
      "         [0.4181],\n",
      "         [0.9414],\n",
      "         [0.7455],\n",
      "         [0.0099],\n",
      "         [0.1122],\n",
      "         [0.9212],\n",
      "         [0.1803],\n",
      "         [0.7580],\n",
      "         [0.5955],\n",
      "         [0.4429],\n",
      "         [0.0247],\n",
      "         [0.9882],\n",
      "         [0.8373],\n",
      "         [0.7295],\n",
      "         [0.8767],\n",
      "         [0.6955],\n",
      "         [0.2930],\n",
      "         [0.5035],\n",
      "         [0.7620],\n",
      "         [0.5620],\n",
      "         [0.9380],\n",
      "         [0.5252],\n",
      "         [0.8096],\n",
      "         [0.7185],\n",
      "         [0.5205],\n",
      "         [0.8245],\n",
      "         [0.8039],\n",
      "         [0.0858],\n",
      "         [0.3815],\n",
      "         [0.0760],\n",
      "         [0.1508],\n",
      "         [0.5617],\n",
      "         [0.6660],\n",
      "         [0.1395],\n",
      "         [0.9222],\n",
      "         [0.0697],\n",
      "         [0.9798],\n",
      "         [0.8754],\n",
      "         [0.2787],\n",
      "         [0.7743],\n",
      "         [0.9192],\n",
      "         [0.4894],\n",
      "         [0.3166],\n",
      "         [0.4087],\n",
      "         [0.3314],\n",
      "         [0.3565],\n",
      "         [0.9267],\n",
      "         [0.8185],\n",
      "         [0.8554],\n",
      "         [0.8337],\n",
      "         [0.4731],\n",
      "         [0.6666],\n",
      "         [0.1625],\n",
      "         [0.3960],\n",
      "         [0.0634],\n",
      "         [0.5479],\n",
      "         [0.1844],\n",
      "         [0.4147],\n",
      "         [0.4624],\n",
      "         [0.3853],\n",
      "         [0.7429],\n",
      "         [0.6190],\n",
      "         [0.3181],\n",
      "         [0.1030],\n",
      "         [0.2822]]], device='cuda:0', dtype=torch.float64)\n",
      "================iter 4============\n",
      "['shape/cube/1/cube_512_256_3_1_0']\n",
      "tensor([[ True,  True, False, False, False,  True,  True,  True,  True,  True,\n",
      "          True,  True,  True,  True,  True,  True,  True,  True, False, False]],\n",
      "       device='cuda:0')\n",
      "acc torch.Size([1]) tensor([0.0556], device='cuda:0')\n",
      "acc_per_part torch.Size([1, 20]) tensor([[False, False, False, False, False, False, False, False, False, False,\n",
      "         False, False,  True, False, False, False, False, False, False, False]],\n",
      "       device='cuda:0')\n",
      "loss_per_data torch.Size([1, 20]) tensor([[  8.9206,   4.1096,  50.7294,  14.3770,  50.2127,   8.0666,   5.5711,\n",
      "           6.3995,  26.1119,   8.6116,   1.3267,  20.7406,   0.0000,  65.6266,\n",
      "           5.8760, 124.2889,  81.1026,  54.9838,  46.5602,  15.8446]],\n",
      "       device='cuda:0')\n",
      "scores torch.Size([1, 190, 1]) tensor([[[0.0665],\n",
      "         [0.6456],\n",
      "         [0.8124],\n",
      "         [0.3617],\n",
      "         [0.0470],\n",
      "         [0.5321],\n",
      "         [0.4269],\n",
      "         [0.4235],\n",
      "         [0.7426],\n",
      "         [0.9522],\n",
      "         [0.8765],\n",
      "         [0.1961],\n",
      "         [0.5539],\n",
      "         [0.1692],\n",
      "         [0.7741],\n",
      "         [0.2317],\n",
      "         [0.0438],\n",
      "         [0.0660],\n",
      "         [0.4630],\n",
      "         [0.8275],\n",
      "         [0.3101],\n",
      "         [0.5361],\n",
      "         [0.9416],\n",
      "         [0.4245],\n",
      "         [0.8036],\n",
      "         [0.0066],\n",
      "         [0.5603],\n",
      "         [0.5890],\n",
      "         [0.5498],\n",
      "         [0.5456],\n",
      "         [0.4955],\n",
      "         [0.1883],\n",
      "         [0.9012],\n",
      "         [0.8578],\n",
      "         [0.9713],\n",
      "         [0.0125],\n",
      "         [0.3173],\n",
      "         [0.3044],\n",
      "         [0.3892],\n",
      "         [0.7934],\n",
      "         [0.2767],\n",
      "         [0.7189],\n",
      "         [0.1219],\n",
      "         [0.3581],\n",
      "         [0.0019],\n",
      "         [0.1031],\n",
      "         [0.2710],\n",
      "         [0.6662],\n",
      "         [0.3376],\n",
      "         [0.8718],\n",
      "         [0.7547],\n",
      "         [0.8627],\n",
      "         [0.6461],\n",
      "         [0.3624],\n",
      "         [0.3164],\n",
      "         [0.5519],\n",
      "         [0.7110],\n",
      "         [0.7664],\n",
      "         [0.9897],\n",
      "         [0.4386],\n",
      "         [0.7990],\n",
      "         [0.7901],\n",
      "         [0.7852],\n",
      "         [0.2828],\n",
      "         [0.3972],\n",
      "         [0.6265],\n",
      "         [0.2702],\n",
      "         [0.0696],\n",
      "         [0.2076],\n",
      "         [0.9839],\n",
      "         [0.5143],\n",
      "         [0.5063],\n",
      "         [0.1459],\n",
      "         [0.7560],\n",
      "         [0.8376],\n",
      "         [0.3209],\n",
      "         [0.6410],\n",
      "         [0.9840],\n",
      "         [0.7547],\n",
      "         [0.7860],\n",
      "         [0.8237],\n",
      "         [0.0530],\n",
      "         [0.7360],\n",
      "         [0.7334],\n",
      "         [0.7862],\n",
      "         [0.5130],\n",
      "         [0.1895],\n",
      "         [0.4611],\n",
      "         [0.3404],\n",
      "         [0.9072],\n",
      "         [0.0491],\n",
      "         [0.2540],\n",
      "         [0.7643],\n",
      "         [0.5930],\n",
      "         [0.0433],\n",
      "         [0.1099],\n",
      "         [0.0416],\n",
      "         [0.9720],\n",
      "         [0.2238],\n",
      "         [0.0430],\n",
      "         [0.2286],\n",
      "         [0.5732],\n",
      "         [0.3934],\n",
      "         [0.4929],\n",
      "         [0.5978],\n",
      "         [0.8503],\n",
      "         [0.5892],\n",
      "         [0.2508],\n",
      "         [0.0941],\n",
      "         [0.4072],\n",
      "         [0.2879],\n",
      "         [0.0245],\n",
      "         [0.4183],\n",
      "         [0.4507],\n",
      "         [0.7186],\n",
      "         [0.0368],\n",
      "         [0.1336],\n",
      "         [0.3521],\n",
      "         [0.7250],\n",
      "         [0.7520],\n",
      "         [0.8151],\n",
      "         [0.2134],\n",
      "         [0.8993],\n",
      "         [0.6457],\n",
      "         [0.3915],\n",
      "         [0.0041],\n",
      "         [0.1688],\n",
      "         [0.5802],\n",
      "         [0.7716],\n",
      "         [0.5990],\n",
      "         [0.5698],\n",
      "         [0.0970],\n",
      "         [0.4676],\n",
      "         [0.7390],\n",
      "         [0.0078],\n",
      "         [0.7634],\n",
      "         [0.2277],\n",
      "         [0.9098],\n",
      "         [0.1322],\n",
      "         [0.6598],\n",
      "         [0.1933],\n",
      "         [0.0038],\n",
      "         [0.7953],\n",
      "         [0.2896],\n",
      "         [0.6142],\n",
      "         [0.6726],\n",
      "         [0.1768],\n",
      "         [0.0109],\n",
      "         [0.0860],\n",
      "         [0.1334],\n",
      "         [0.8351],\n",
      "         [0.3218],\n",
      "         [0.9683],\n",
      "         [0.8812],\n",
      "         [0.3294],\n",
      "         [0.9844],\n",
      "         [0.1414],\n",
      "         [0.8174],\n",
      "         [0.3712],\n",
      "         [0.3503],\n",
      "         [0.9394],\n",
      "         [0.3906],\n",
      "         [0.0329],\n",
      "         [0.6867],\n",
      "         [0.7114],\n",
      "         [0.1032],\n",
      "         [0.0096],\n",
      "         [0.1518],\n",
      "         [0.7803],\n",
      "         [0.4851],\n",
      "         [0.3192],\n",
      "         [0.8943],\n",
      "         [0.8383],\n",
      "         [0.2331],\n",
      "         [0.5726],\n",
      "         [0.3842],\n",
      "         [0.1691],\n",
      "         [0.4313],\n",
      "         [0.8494],\n",
      "         [0.6215],\n",
      "         [0.1411],\n",
      "         [0.0745],\n",
      "         [0.0204],\n",
      "         [0.5988],\n",
      "         [0.9702],\n",
      "         [0.0547],\n",
      "         [0.5478],\n",
      "         [0.9916],\n",
      "         [0.5376],\n",
      "         [0.3293]]], device='cuda:0', dtype=torch.float64)\n",
      "================iter 5============\n",
      "['shape/cube/1/cube_512_256_3_1_0']\n",
      "tensor([[ True,  True, False,  True,  True,  True,  True,  True,  True,  True,\n",
      "          True,  True,  True,  True,  True,  True,  True,  True, False, False]],\n",
      "       device='cuda:0')\n",
      "@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@\n",
      "['shape/cube/1/cube_512_256_3_2_0']\n",
      "gt_trans_torch.Size([1, 20, 3])_tensor([[[-1.1181e-01,  1.9252e-02, -6.5224e-02],\n",
      "         [-8.0953e-02,  2.1494e-02, -6.3515e-02],\n",
      "         [-5.3877e-02, -5.9538e-02, -7.4113e-02],\n",
      "         [-6.3955e-02, -7.1411e-02, -5.6710e-02],\n",
      "         [-2.7328e-02, -6.5815e-02, -4.3930e-02],\n",
      "         [-7.0345e-03, -6.6741e-02, -3.3795e-02],\n",
      "         [ 1.5889e-02, -6.9463e-02, -4.5859e-02],\n",
      "         [ 2.3157e-02, -7.2783e-02, -1.4317e-02],\n",
      "         [ 5.1358e-02, -7.2574e-02, -1.8349e-02],\n",
      "         [ 6.5274e-02, -7.5361e-02, -2.1137e-03],\n",
      "         [-6.4998e-02,  1.7188e-02, -6.7680e-02],\n",
      "         [-4.8726e-02,  1.5099e-02, -5.2301e-02],\n",
      "         [-2.9385e-02,  1.4002e-02, -4.0555e-02],\n",
      "         [-7.6464e-03,  1.3639e-02, -2.9520e-02],\n",
      "         [ 1.0712e-03,  7.9689e-03, -2.3138e-02],\n",
      "         [ 3.5527e-18,  2.2204e-18,  6.2172e-18],\n",
      "         [-9.1689e-03, -1.8074e-02, -3.8937e-02],\n",
      "         [-4.5154e-02, -4.3621e-02, -5.1547e-02],\n",
      "         [ 0.0000e+00,  0.0000e+00,  0.0000e+00],\n",
      "         [ 0.0000e+00,  0.0000e+00,  0.0000e+00]]], device='cuda:0')\n",
      "gt_rots_torch.Size([1, 20, 4])_tensor([[[ 0.0977,  0.5300,  0.7306,  0.4192],\n",
      "         [ 0.5823,  0.6251,  0.5198, -0.0055],\n",
      "         [ 0.7479,  0.0360,  0.2343, -0.6201],\n",
      "         [-0.1266, -0.3895,  0.5667,  0.7149],\n",
      "         [ 0.3676,  0.7981, -0.4128,  0.2397],\n",
      "         [ 0.8999,  0.3897,  0.1865,  0.0599],\n",
      "         [ 0.4894,  0.8269,  0.0523,  0.2719],\n",
      "         [-0.0607,  0.1317, -0.3581,  0.9224],\n",
      "         [-0.3651, -0.2001, -0.3741,  0.8287],\n",
      "         [-0.4545,  0.5886, -0.4850,  0.4602],\n",
      "         [ 0.1566,  0.7807, -0.5151,  0.3173],\n",
      "         [-0.0530,  0.2589,  0.8375, -0.4783],\n",
      "         [ 0.3109,  0.4717, -0.2388,  0.7898],\n",
      "         [ 0.7558, -0.0692, -0.1874,  0.6236],\n",
      "         [ 0.4631,  0.2350,  0.2617,  0.8135],\n",
      "         [-0.4722, -0.4145,  0.7635,  0.1491],\n",
      "         [ 0.5378,  0.5101,  0.6278, -0.2375],\n",
      "         [-0.6149,  0.1239,  0.7727, -0.0979],\n",
      "         [ 0.0000,  0.0000,  0.0000,  0.0000],\n",
      "         [ 0.0000,  0.0000,  0.0000,  0.0000]]], device='cuda:0')\n",
      "noisy_trans_and_rots_torch.Size([1, 20, 7])_tensor([[[ 1.1486,  0.0000,  0.7492,  0.2615,  0.0000,  0.0000,  0.7297],\n",
      "         [-1.0195,  0.0000, -2.2701, -0.6250,  0.0000,  0.0000, -0.7246],\n",
      "         [ 0.1654,  0.0000,  1.4774, -0.7715,  0.0000,  0.0000,  0.7887],\n",
      "         [-1.5557,  0.0000, -1.2032, -1.2458,  0.0000,  0.0000, -1.0884],\n",
      "         [ 0.6824,  0.0000, -0.6095, -0.8318,  0.0000,  0.0000,  1.3623],\n",
      "         [ 1.1390,  0.0000,  0.1047,  0.9291,  0.0000,  0.0000,  1.7137],\n",
      "         [ 1.1292,  0.0000,  0.5859,  0.7247,  0.0000,  0.0000, -0.4255],\n",
      "         [-0.8519,  0.0000, -0.3035,  0.4951,  0.0000,  0.0000, -0.6580],\n",
      "         [-0.3121,  0.0000,  0.8463,  0.6126,  0.0000,  0.0000, -0.0767],\n",
      "         [-0.9149,  0.0000,  0.2187,  2.0555,  0.0000,  0.0000, -0.1527],\n",
      "         [-0.3887,  0.0000,  0.6686,  1.1039,  0.0000,  0.0000,  0.5348],\n",
      "         [-0.5115,  0.0000,  0.4906, -0.8208,  0.0000,  0.0000,  0.1833],\n",
      "         [-0.9389,  0.0000, -0.6160, -0.7836,  0.0000,  0.0000,  0.0808],\n",
      "         [-0.2537,  0.0000, -0.2378, -0.0304,  0.0000,  0.0000,  0.1326],\n",
      "         [-0.3388,  0.0000, -0.0857, -0.4223,  0.0000,  0.0000,  1.3428],\n",
      "         [-0.2393,  0.0000,  0.0511, -0.0030,  0.0000,  0.0000, -1.3741],\n",
      "         [ 0.2763,  0.0000,  2.1595, -1.2333,  0.0000,  0.0000,  0.9500],\n",
      "         [ 0.2757,  0.0000,  1.1274,  0.1253,  0.0000,  0.0000, -0.6485],\n",
      "         [-1.1587,  0.0000,  0.5633,  0.6426,  0.0000,  0.0000,  0.4873],\n",
      "         [-2.4493,  0.0000,  2.0070, -0.8397,  0.0000,  0.0000,  1.0726]]],\n",
      "       device='cuda:0')\n",
      "================iter 0============\n",
      "['shape/cube/1/cube_512_256_3_2_0']\n",
      "tensor([[False, False, False, False, False, False, False, False, False, False,\n",
      "         False, False, False, False, False,  True, False, False, False, False]],\n",
      "       device='cuda:0')\n",
      "acc torch.Size([1]) tensor([0.0556], device='cuda:0')\n",
      "acc_per_part torch.Size([1, 20]) tensor([[False, False, False, False, False, False, False, False, False, False,\n",
      "         False, False, False, False, False,  True, False, False, False, False]],\n",
      "       device='cuda:0')\n",
      "loss_per_data torch.Size([1, 20]) tensor([[ 4.7024,  5.5498,  1.6666,  1.0020,  5.2808,  0.7566,  1.8549,  2.4687,\n",
      "          0.4334,  0.6955,  0.8068,  1.2230,  1.3458,  0.6547,  0.3337,  0.0000,\n",
      "          8.1561, 15.2735,  0.2328,  9.3804]], device='cuda:0')\n",
      "scores torch.Size([1, 190, 1]) tensor([[[0.3256],\n",
      "         [0.9619],\n",
      "         [0.0693],\n",
      "         [0.0766],\n",
      "         [0.6971],\n",
      "         [0.5469],\n",
      "         [0.8039],\n",
      "         [0.5130],\n",
      "         [0.8958],\n",
      "         [0.8040],\n",
      "         [0.6088],\n",
      "         [0.3732],\n",
      "         [0.0874],\n",
      "         [0.3640],\n",
      "         [0.2197],\n",
      "         [0.5288],\n",
      "         [0.4667],\n",
      "         [0.5219],\n",
      "         [0.4886],\n",
      "         [0.8072],\n",
      "         [0.2349],\n",
      "         [0.0700],\n",
      "         [0.2001],\n",
      "         [0.4729],\n",
      "         [0.2645],\n",
      "         [0.2004],\n",
      "         [0.6049],\n",
      "         [0.4090],\n",
      "         [0.3160],\n",
      "         [0.7789],\n",
      "         [0.7299],\n",
      "         [0.2302],\n",
      "         [0.1401],\n",
      "         [0.1874],\n",
      "         [0.9758],\n",
      "         [0.6159],\n",
      "         [0.6852],\n",
      "         [0.4174],\n",
      "         [0.8453],\n",
      "         [0.1150],\n",
      "         [0.4862],\n",
      "         [0.3711],\n",
      "         [0.6465],\n",
      "         [0.9721],\n",
      "         [0.1023],\n",
      "         [0.7804],\n",
      "         [0.5683],\n",
      "         [0.9145],\n",
      "         [0.4374],\n",
      "         [0.1238],\n",
      "         [0.3494],\n",
      "         [0.0555],\n",
      "         [0.8882],\n",
      "         [0.8631],\n",
      "         [0.3094],\n",
      "         [0.5774],\n",
      "         [0.1536],\n",
      "         [0.2604],\n",
      "         [0.2267],\n",
      "         [0.4171],\n",
      "         [0.7784],\n",
      "         [0.3966],\n",
      "         [0.5735],\n",
      "         [0.9813],\n",
      "         [0.5482],\n",
      "         [0.8875],\n",
      "         [0.0685],\n",
      "         [0.7450],\n",
      "         [0.6350],\n",
      "         [0.8445],\n",
      "         [0.1192],\n",
      "         [0.6982],\n",
      "         [0.7214],\n",
      "         [0.5998],\n",
      "         [0.6593],\n",
      "         [0.9003],\n",
      "         [0.8417],\n",
      "         [0.6406],\n",
      "         [0.7994],\n",
      "         [0.3763],\n",
      "         [0.2412],\n",
      "         [0.5976],\n",
      "         [0.1135],\n",
      "         [0.1572],\n",
      "         [0.7959],\n",
      "         [0.8443],\n",
      "         [0.9465],\n",
      "         [0.8448],\n",
      "         [0.7044],\n",
      "         [0.9831],\n",
      "         [0.7977],\n",
      "         [0.6747],\n",
      "         [0.5498],\n",
      "         [0.8124],\n",
      "         [0.9432],\n",
      "         [0.4496],\n",
      "         [0.9847],\n",
      "         [0.2980],\n",
      "         [0.6346],\n",
      "         [0.1509],\n",
      "         [0.6859],\n",
      "         [0.7330],\n",
      "         [0.4216],\n",
      "         [0.7165],\n",
      "         [0.0140],\n",
      "         [0.0291],\n",
      "         [0.4101],\n",
      "         [0.9067],\n",
      "         [0.8341],\n",
      "         [0.5130],\n",
      "         [0.6593],\n",
      "         [0.4052],\n",
      "         [0.8268],\n",
      "         [0.5997],\n",
      "         [0.7721],\n",
      "         [0.0308],\n",
      "         [0.6118],\n",
      "         [0.1343],\n",
      "         [0.1781],\n",
      "         [0.2147],\n",
      "         [0.6561],\n",
      "         [0.0915],\n",
      "         [0.0268],\n",
      "         [0.3450],\n",
      "         [0.3138],\n",
      "         [0.7556],\n",
      "         [0.0177],\n",
      "         [0.2689],\n",
      "         [0.6737],\n",
      "         [0.4871],\n",
      "         [0.0910],\n",
      "         [0.6174],\n",
      "         [0.4408],\n",
      "         [0.0166],\n",
      "         [0.8643],\n",
      "         [0.9453],\n",
      "         [0.7133],\n",
      "         [0.0438],\n",
      "         [0.8956],\n",
      "         [0.7811],\n",
      "         [0.5943],\n",
      "         [0.8825],\n",
      "         [0.5143],\n",
      "         [0.7811],\n",
      "         [0.0571],\n",
      "         [0.8960],\n",
      "         [0.2952],\n",
      "         [0.5026],\n",
      "         [0.2474],\n",
      "         [0.5853],\n",
      "         [0.9687],\n",
      "         [0.2112],\n",
      "         [0.0050],\n",
      "         [0.3751],\n",
      "         [0.3974],\n",
      "         [0.9056],\n",
      "         [0.2852],\n",
      "         [0.9884],\n",
      "         [0.8587],\n",
      "         [0.0042],\n",
      "         [0.9405],\n",
      "         [0.7568],\n",
      "         [0.7254],\n",
      "         [0.6623],\n",
      "         [0.2170],\n",
      "         [0.2483],\n",
      "         [0.9039],\n",
      "         [0.2351],\n",
      "         [0.4685],\n",
      "         [0.5867],\n",
      "         [0.9242],\n",
      "         [0.2809],\n",
      "         [0.8398],\n",
      "         [0.5656],\n",
      "         [0.4768],\n",
      "         [0.6120],\n",
      "         [0.4588],\n",
      "         [0.0651],\n",
      "         [0.1702],\n",
      "         [0.5609],\n",
      "         [0.8124],\n",
      "         [0.4427],\n",
      "         [0.7814],\n",
      "         [0.3980],\n",
      "         [0.6499],\n",
      "         [0.4858],\n",
      "         [0.4422],\n",
      "         [0.8127],\n",
      "         [0.2024],\n",
      "         [0.5073]]], device='cuda:0', dtype=torch.float64)\n",
      "================iter 1============\n",
      "['shape/cube/1/cube_512_256_3_2_0']\n",
      "tensor([[False, False, False, False, False,  True,  True, False, False, False,\n",
      "         False,  True, False,  True, False,  True, False, False, False, False]],\n",
      "       device='cuda:0')\n",
      "acc torch.Size([1]) tensor([0.0556], device='cuda:0')\n",
      "acc_per_part torch.Size([1, 20]) tensor([[False, False, False, False, False, False, False, False, False, False,\n",
      "         False, False, False, False, False,  True, False, False, False, False]],\n",
      "       device='cuda:0')\n",
      "loss_per_data torch.Size([1, 20]) tensor([[ 0.7907,  0.4148,  9.9285, 11.0581,  2.5078,  0.7566,  1.8549,  3.9331,\n",
      "          0.6606,  3.2693, 16.8397,  1.2230,  1.2582,  0.6547,  2.0743,  0.0000,\n",
      "         38.9258, 52.6279,  0.9023,  5.5314]], device='cuda:0')\n",
      "scores torch.Size([1, 190, 1]) tensor([[[0.5598],\n",
      "         [0.4992],\n",
      "         [0.1446],\n",
      "         [0.3748],\n",
      "         [0.2349],\n",
      "         [0.6551],\n",
      "         [0.0334],\n",
      "         [0.5052],\n",
      "         [0.8631],\n",
      "         [0.1636],\n",
      "         [0.9439],\n",
      "         [0.0097],\n",
      "         [0.9350],\n",
      "         [0.7772],\n",
      "         [0.9240],\n",
      "         [0.1729],\n",
      "         [0.9907],\n",
      "         [0.1934],\n",
      "         [0.2990],\n",
      "         [0.6105],\n",
      "         [0.5349],\n",
      "         [0.3217],\n",
      "         [0.1641],\n",
      "         [0.5591],\n",
      "         [0.8619],\n",
      "         [0.8705],\n",
      "         [0.8959],\n",
      "         [0.9367],\n",
      "         [0.1238],\n",
      "         [0.0623],\n",
      "         [0.4244],\n",
      "         [0.8766],\n",
      "         [0.2087],\n",
      "         [0.8746],\n",
      "         [0.7372],\n",
      "         [0.8955],\n",
      "         [0.8949],\n",
      "         [0.8627],\n",
      "         [0.4439],\n",
      "         [0.0127],\n",
      "         [0.6659],\n",
      "         [0.3509],\n",
      "         [0.0372],\n",
      "         [0.5647],\n",
      "         [0.6623],\n",
      "         [0.3628],\n",
      "         [0.8621],\n",
      "         [0.1653],\n",
      "         [0.3135],\n",
      "         [0.8789],\n",
      "         [0.2730],\n",
      "         [0.3577],\n",
      "         [0.4821],\n",
      "         [0.5636],\n",
      "         [0.1576],\n",
      "         [0.7209],\n",
      "         [0.9857],\n",
      "         [0.4177],\n",
      "         [0.8010],\n",
      "         [0.7353],\n",
      "         [0.0153],\n",
      "         [0.5334],\n",
      "         [0.3219],\n",
      "         [0.7773],\n",
      "         [0.4993],\n",
      "         [0.5817],\n",
      "         [0.3876],\n",
      "         [0.7452],\n",
      "         [0.2184],\n",
      "         [0.7953],\n",
      "         [0.3435],\n",
      "         [0.5125],\n",
      "         [0.7290],\n",
      "         [0.0674],\n",
      "         [0.8880],\n",
      "         [0.0659],\n",
      "         [0.3871],\n",
      "         [0.7661],\n",
      "         [0.8886],\n",
      "         [0.5066],\n",
      "         [0.2657],\n",
      "         [0.8075],\n",
      "         [0.0899],\n",
      "         [0.3503],\n",
      "         [0.5968],\n",
      "         [0.7161],\n",
      "         [0.0144],\n",
      "         [0.3179],\n",
      "         [0.3958],\n",
      "         [0.1777],\n",
      "         [0.5778],\n",
      "         [0.5652],\n",
      "         [0.2954],\n",
      "         [0.1894],\n",
      "         [0.1660],\n",
      "         [0.2419],\n",
      "         [0.2028],\n",
      "         [0.0916],\n",
      "         [0.7197],\n",
      "         [0.4144],\n",
      "         [0.1912],\n",
      "         [0.2288],\n",
      "         [0.0787],\n",
      "         [0.9289],\n",
      "         [0.2846],\n",
      "         [0.8206],\n",
      "         [0.3912],\n",
      "         [0.7065],\n",
      "         [0.2792],\n",
      "         [0.6224],\n",
      "         [0.4895],\n",
      "         [0.6348],\n",
      "         [0.1473],\n",
      "         [0.9458],\n",
      "         [0.7103],\n",
      "         [0.5327],\n",
      "         [0.4133],\n",
      "         [0.2200],\n",
      "         [0.8642],\n",
      "         [0.7211],\n",
      "         [0.7431],\n",
      "         [0.0228],\n",
      "         [0.1554],\n",
      "         [0.8988],\n",
      "         [0.9296],\n",
      "         [0.2548],\n",
      "         [0.6352],\n",
      "         [0.3645],\n",
      "         [0.5635],\n",
      "         [0.7426],\n",
      "         [0.9801],\n",
      "         [0.9946],\n",
      "         [0.9650],\n",
      "         [0.8279],\n",
      "         [0.2660],\n",
      "         [0.5423],\n",
      "         [0.2446],\n",
      "         [0.7374],\n",
      "         [0.2264],\n",
      "         [0.3487],\n",
      "         [0.4050],\n",
      "         [0.4071],\n",
      "         [0.1214],\n",
      "         [0.8828],\n",
      "         [0.4422],\n",
      "         [0.9604],\n",
      "         [0.0099],\n",
      "         [0.3584],\n",
      "         [0.9383],\n",
      "         [0.1096],\n",
      "         [0.1826],\n",
      "         [0.3509],\n",
      "         [0.6317],\n",
      "         [0.5938],\n",
      "         [0.9862],\n",
      "         [0.7868],\n",
      "         [0.3944],\n",
      "         [0.9384],\n",
      "         [0.3494],\n",
      "         [0.8861],\n",
      "         [0.9869],\n",
      "         [0.9149],\n",
      "         [0.2988],\n",
      "         [0.5803],\n",
      "         [0.7705],\n",
      "         [0.6086],\n",
      "         [0.1564],\n",
      "         [0.1907],\n",
      "         [0.9545],\n",
      "         [0.1859],\n",
      "         [0.7615],\n",
      "         [0.8883],\n",
      "         [0.1621],\n",
      "         [0.0293],\n",
      "         [0.3370],\n",
      "         [0.8930],\n",
      "         [0.2987],\n",
      "         [0.2187],\n",
      "         [0.5441],\n",
      "         [0.3435],\n",
      "         [0.7962],\n",
      "         [0.4060],\n",
      "         [0.8310],\n",
      "         [0.2787],\n",
      "         [0.6584],\n",
      "         [0.9469],\n",
      "         [0.2227],\n",
      "         [0.1814],\n",
      "         [0.6714],\n",
      "         [0.5926]]], device='cuda:0', dtype=torch.float64)\n",
      "================iter 2============\n",
      "['shape/cube/1/cube_512_256_3_2_0']\n",
      "tensor([[ True, False, False,  True, False,  True,  True, False,  True, False,\n",
      "          True,  True,  True,  True, False,  True, False, False, False, False]],\n",
      "       device='cuda:0')\n",
      "acc torch.Size([1]) tensor([0.0556], device='cuda:0')\n",
      "acc_per_part torch.Size([1, 20]) tensor([[False, False, False, False, False, False, False, False, False, False,\n",
      "         False, False, False, False, False,  True, False, False, False, False]],\n",
      "       device='cuda:0')\n",
      "loss_per_data torch.Size([1, 20]) tensor([[  0.7907,   2.3145,   7.1922,  11.0581,   3.2056,   0.7566,   1.8549,\n",
      "           6.0636,   0.6606,   0.9647,  16.8397,   1.2230,   1.2582,   0.6547,\n",
      "          10.0815,   0.0000,  69.4219, 108.1684,   2.4190,   0.3315]],\n",
      "       device='cuda:0')\n",
      "scores torch.Size([1, 190, 1]) tensor([[[0.7744],\n",
      "         [0.7444],\n",
      "         [0.6801],\n",
      "         [0.5383],\n",
      "         [0.5559],\n",
      "         [0.7530],\n",
      "         [0.7306],\n",
      "         [0.5946],\n",
      "         [0.8068],\n",
      "         [0.6275],\n",
      "         [0.2573],\n",
      "         [0.2718],\n",
      "         [0.6102],\n",
      "         [0.9720],\n",
      "         [0.8203],\n",
      "         [0.1244],\n",
      "         [0.1353],\n",
      "         [0.9783],\n",
      "         [0.9230],\n",
      "         [0.7358],\n",
      "         [0.7868],\n",
      "         [0.7209],\n",
      "         [0.7449],\n",
      "         [0.8413],\n",
      "         [0.3606],\n",
      "         [0.0074],\n",
      "         [0.0885],\n",
      "         [0.5216],\n",
      "         [0.7264],\n",
      "         [0.0965],\n",
      "         [0.4170],\n",
      "         [0.4349],\n",
      "         [0.2226],\n",
      "         [0.2843],\n",
      "         [0.2689],\n",
      "         [0.8038],\n",
      "         [0.0882],\n",
      "         [0.0343],\n",
      "         [0.2652],\n",
      "         [0.8782],\n",
      "         [0.0066],\n",
      "         [0.6072],\n",
      "         [0.7660],\n",
      "         [0.8453],\n",
      "         [0.1984],\n",
      "         [0.5672],\n",
      "         [0.2634],\n",
      "         [0.8010],\n",
      "         [0.0413],\n",
      "         [0.5986],\n",
      "         [0.3521],\n",
      "         [0.0243],\n",
      "         [0.0258],\n",
      "         [0.3440],\n",
      "         [0.0948],\n",
      "         [0.3532],\n",
      "         [0.7513],\n",
      "         [0.6124],\n",
      "         [0.1568],\n",
      "         [0.9595],\n",
      "         [0.9261],\n",
      "         [0.3608],\n",
      "         [0.5425],\n",
      "         [0.6257],\n",
      "         [0.5064],\n",
      "         [0.0778],\n",
      "         [0.4592],\n",
      "         [0.4078],\n",
      "         [0.1570],\n",
      "         [0.8980],\n",
      "         [0.5425],\n",
      "         [0.8203],\n",
      "         [0.2206],\n",
      "         [0.4648],\n",
      "         [0.4105],\n",
      "         [0.4293],\n",
      "         [0.3521],\n",
      "         [0.0202],\n",
      "         [0.3641],\n",
      "         [0.5257],\n",
      "         [0.4017],\n",
      "         [0.2025],\n",
      "         [0.0311],\n",
      "         [0.8846],\n",
      "         [0.2572],\n",
      "         [0.6750],\n",
      "         [0.3848],\n",
      "         [0.4404],\n",
      "         [0.0258],\n",
      "         [0.9298],\n",
      "         [0.9145],\n",
      "         [0.8934],\n",
      "         [0.3767],\n",
      "         [0.9774],\n",
      "         [0.0473],\n",
      "         [0.7977],\n",
      "         [0.8061],\n",
      "         [0.6122],\n",
      "         [0.6904],\n",
      "         [0.4282],\n",
      "         [0.7318],\n",
      "         [0.8513],\n",
      "         [0.8709],\n",
      "         [0.4981],\n",
      "         [0.9229],\n",
      "         [0.6362],\n",
      "         [0.0994],\n",
      "         [0.3154],\n",
      "         [0.1691],\n",
      "         [0.8277],\n",
      "         [0.9979],\n",
      "         [0.1538],\n",
      "         [0.4787],\n",
      "         [0.6361],\n",
      "         [0.5005],\n",
      "         [0.1198],\n",
      "         [0.9682],\n",
      "         [0.0776],\n",
      "         [0.3821],\n",
      "         [0.7512],\n",
      "         [0.6542],\n",
      "         [0.3007],\n",
      "         [0.9150],\n",
      "         [0.2510],\n",
      "         [0.7454],\n",
      "         [0.1906],\n",
      "         [0.3756],\n",
      "         [0.4936],\n",
      "         [0.8477],\n",
      "         [0.2347],\n",
      "         [0.0608],\n",
      "         [0.7091],\n",
      "         [0.7216],\n",
      "         [0.6235],\n",
      "         [0.3498],\n",
      "         [0.6052],\n",
      "         [0.4909],\n",
      "         [0.6211],\n",
      "         [0.0142],\n",
      "         [0.3988],\n",
      "         [0.1038],\n",
      "         [0.6392],\n",
      "         [0.0015],\n",
      "         [0.2146],\n",
      "         [0.5564],\n",
      "         [0.6579],\n",
      "         [0.9263],\n",
      "         [0.4446],\n",
      "         [0.4745],\n",
      "         [0.9117],\n",
      "         [0.5902],\n",
      "         [0.4965],\n",
      "         [0.9949],\n",
      "         [0.0111],\n",
      "         [0.9364],\n",
      "         [0.6376],\n",
      "         [0.8334],\n",
      "         [0.7363],\n",
      "         [0.5611],\n",
      "         [0.0626],\n",
      "         [0.0746],\n",
      "         [0.9675],\n",
      "         [0.6930],\n",
      "         [0.1547],\n",
      "         [0.7797],\n",
      "         [0.2468],\n",
      "         [0.1580],\n",
      "         [0.1638],\n",
      "         [0.9831],\n",
      "         [0.7714],\n",
      "         [0.7410],\n",
      "         [0.0571],\n",
      "         [0.7870],\n",
      "         [0.0668],\n",
      "         [0.5384],\n",
      "         [0.0441],\n",
      "         [0.7420],\n",
      "         [0.0237],\n",
      "         [0.1845],\n",
      "         [0.3232],\n",
      "         [0.6926],\n",
      "         [0.3310],\n",
      "         [0.6429],\n",
      "         [0.0942],\n",
      "         [0.3016],\n",
      "         [0.3131],\n",
      "         [0.9114],\n",
      "         [0.2786],\n",
      "         [0.3554],\n",
      "         [0.9034]]], device='cuda:0', dtype=torch.float64)\n",
      "================iter 3============\n",
      "['shape/cube/1/cube_512_256_3_2_0']\n",
      "tensor([[ True, False, False,  True, False,  True,  True,  True,  True,  True,\n",
      "          True,  True,  True,  True,  True,  True, False, False, False, False]],\n",
      "       device='cuda:0')\n",
      "acc torch.Size([1]) tensor([0.0556], device='cuda:0')\n",
      "acc_per_part torch.Size([1, 20]) tensor([[False, False, False, False, False, False, False, False, False, False,\n",
      "         False, False, False, False, False,  True, False, False, False, False]],\n",
      "       device='cuda:0')\n",
      "loss_per_data torch.Size([1, 20]) tensor([[  0.7907,   5.9492,  24.2505,  11.0581,   6.9359,   0.7566,   1.8549,\n",
      "           6.0636,   0.6606,   0.9647,  16.8397,   1.2230,   1.2582,   0.6547,\n",
      "          10.0815,   0.0000, 154.1619, 250.8703,   3.5152,   0.7793]],\n",
      "       device='cuda:0')\n",
      "scores torch.Size([1, 190, 1]) tensor([[[0.9271],\n",
      "         [0.7573],\n",
      "         [0.5537],\n",
      "         [0.4311],\n",
      "         [0.8998],\n",
      "         [0.5788],\n",
      "         [0.5176],\n",
      "         [0.5339],\n",
      "         [0.1331],\n",
      "         [0.2538],\n",
      "         [0.9480],\n",
      "         [0.4964],\n",
      "         [0.7963],\n",
      "         [0.3418],\n",
      "         [0.9309],\n",
      "         [0.5398],\n",
      "         [0.9433],\n",
      "         [0.2855],\n",
      "         [0.1217],\n",
      "         [0.6081],\n",
      "         [0.8845],\n",
      "         [0.3545],\n",
      "         [0.5786],\n",
      "         [0.3173],\n",
      "         [0.3410],\n",
      "         [0.9282],\n",
      "         [0.6824],\n",
      "         [0.1701],\n",
      "         [0.5400],\n",
      "         [0.4399],\n",
      "         [0.4924],\n",
      "         [0.0834],\n",
      "         [0.8979],\n",
      "         [0.8693],\n",
      "         [0.0612],\n",
      "         [0.2336],\n",
      "         [0.7884],\n",
      "         [0.3868],\n",
      "         [0.3875],\n",
      "         [0.7674],\n",
      "         [0.1912],\n",
      "         [0.5702],\n",
      "         [0.7091],\n",
      "         [0.5885],\n",
      "         [0.3750],\n",
      "         [0.4297],\n",
      "         [0.1950],\n",
      "         [0.5109],\n",
      "         [0.6574],\n",
      "         [0.5929],\n",
      "         [0.3192],\n",
      "         [0.8831],\n",
      "         [0.1319],\n",
      "         [0.1480],\n",
      "         [0.1444],\n",
      "         [0.7754],\n",
      "         [0.5275],\n",
      "         [0.3743],\n",
      "         [0.3660],\n",
      "         [0.1427],\n",
      "         [0.3983],\n",
      "         [0.3257],\n",
      "         [0.3776],\n",
      "         [0.9299],\n",
      "         [0.6315],\n",
      "         [0.3474],\n",
      "         [0.8120],\n",
      "         [0.7017],\n",
      "         [0.1175],\n",
      "         [0.8468],\n",
      "         [0.6956],\n",
      "         [0.5211],\n",
      "         [0.2566],\n",
      "         [0.2017],\n",
      "         [0.2143],\n",
      "         [0.2188],\n",
      "         [0.0463],\n",
      "         [0.7129],\n",
      "         [0.9357],\n",
      "         [0.9728],\n",
      "         [0.4059],\n",
      "         [0.5764],\n",
      "         [0.6789],\n",
      "         [0.5465],\n",
      "         [0.5007],\n",
      "         [0.0829],\n",
      "         [0.5547],\n",
      "         [0.7746],\n",
      "         [0.4021],\n",
      "         [0.9601],\n",
      "         [0.9996],\n",
      "         [0.2462],\n",
      "         [0.1463],\n",
      "         [0.8218],\n",
      "         [0.7354],\n",
      "         [0.7160],\n",
      "         [0.0169],\n",
      "         [0.5089],\n",
      "         [0.3519],\n",
      "         [0.7508],\n",
      "         [0.5242],\n",
      "         [0.7268],\n",
      "         [0.9601],\n",
      "         [0.6938],\n",
      "         [0.4103],\n",
      "         [0.7943],\n",
      "         [0.0274],\n",
      "         [0.4337],\n",
      "         [0.9555],\n",
      "         [0.2360],\n",
      "         [0.4102],\n",
      "         [0.5741],\n",
      "         [0.7761],\n",
      "         [0.9559],\n",
      "         [0.8648],\n",
      "         [0.3209],\n",
      "         [0.1387],\n",
      "         [0.7456],\n",
      "         [0.8292],\n",
      "         [0.9958],\n",
      "         [0.9920],\n",
      "         [0.1215],\n",
      "         [0.0302],\n",
      "         [0.5103],\n",
      "         [0.0249],\n",
      "         [0.1954],\n",
      "         [0.3575],\n",
      "         [0.5727],\n",
      "         [0.2420],\n",
      "         [0.8638],\n",
      "         [0.7877],\n",
      "         [0.2741],\n",
      "         [0.6607],\n",
      "         [0.4172],\n",
      "         [0.8336],\n",
      "         [0.2016],\n",
      "         [0.9394],\n",
      "         [0.9998],\n",
      "         [0.1640],\n",
      "         [0.3496],\n",
      "         [0.0334],\n",
      "         [0.9266],\n",
      "         [0.4577],\n",
      "         [0.8219],\n",
      "         [0.0204],\n",
      "         [0.2073],\n",
      "         [0.9360],\n",
      "         [0.4216],\n",
      "         [0.9240],\n",
      "         [0.6655],\n",
      "         [0.6109],\n",
      "         [0.5585],\n",
      "         [0.1174],\n",
      "         [0.8218],\n",
      "         [0.4561],\n",
      "         [0.5586],\n",
      "         [0.6313],\n",
      "         [0.1460],\n",
      "         [0.6004],\n",
      "         [0.8847],\n",
      "         [0.2796],\n",
      "         [0.6296],\n",
      "         [0.9067],\n",
      "         [0.7089],\n",
      "         [0.6677],\n",
      "         [0.1661],\n",
      "         [0.2489],\n",
      "         [0.2780],\n",
      "         [0.0143],\n",
      "         [0.1885],\n",
      "         [0.5430],\n",
      "         [0.4296],\n",
      "         [0.2047],\n",
      "         [0.0153],\n",
      "         [0.1692],\n",
      "         [0.8960],\n",
      "         [0.8571],\n",
      "         [0.9040],\n",
      "         [0.8516],\n",
      "         [0.7599],\n",
      "         [0.3695],\n",
      "         [0.6907],\n",
      "         [0.5413],\n",
      "         [0.4715],\n",
      "         [0.6396],\n",
      "         [0.4043],\n",
      "         [0.3281],\n",
      "         [0.7058],\n",
      "         [0.4506],\n",
      "         [0.6058]]], device='cuda:0', dtype=torch.float64)\n",
      "================iter 4============\n",
      "['shape/cube/1/cube_512_256_3_2_0']\n",
      "tensor([[ True,  True, False,  True,  True,  True,  True,  True,  True,  True,\n",
      "          True,  True,  True,  True,  True,  True,  True,  True, False, False]],\n",
      "       device='cuda:0')\n",
      "acc torch.Size([1]) tensor([0.0556], device='cuda:0')\n",
      "acc_per_part torch.Size([1, 20]) tensor([[False, False, False, False, False, False, False, False, False, False,\n",
      "         False, False, False, False, False,  True, False, False, False, False]],\n",
      "       device='cuda:0')\n",
      "loss_per_data torch.Size([1, 20]) tensor([[  0.7907,   5.9492, 100.0785,  11.0581,   6.9359,   0.7566,   1.8549,\n",
      "           6.0636,   0.6606,   0.9647,  16.8397,   1.2230,   1.2582,   0.6547,\n",
      "          10.0815,   0.0000, 154.1619, 250.8703,  42.1623,   3.6431]],\n",
      "       device='cuda:0')\n",
      "scores torch.Size([1, 190, 1]) tensor([[[0.5849],\n",
      "         [0.5703],\n",
      "         [0.9099],\n",
      "         [0.3649],\n",
      "         [0.8842],\n",
      "         [0.7567],\n",
      "         [0.0811],\n",
      "         [0.0912],\n",
      "         [0.8880],\n",
      "         [0.8509],\n",
      "         [0.5790],\n",
      "         [0.4059],\n",
      "         [0.0038],\n",
      "         [0.7732],\n",
      "         [0.5877],\n",
      "         [0.6448],\n",
      "         [0.8874],\n",
      "         [0.4869],\n",
      "         [0.9253],\n",
      "         [0.8404],\n",
      "         [0.9282],\n",
      "         [0.2986],\n",
      "         [0.0654],\n",
      "         [0.2833],\n",
      "         [0.8319],\n",
      "         [0.7073],\n",
      "         [0.6174],\n",
      "         [0.9834],\n",
      "         [0.0728],\n",
      "         [0.5772],\n",
      "         [0.6075],\n",
      "         [0.9137],\n",
      "         [0.8524],\n",
      "         [0.0822],\n",
      "         [0.3570],\n",
      "         [0.7324],\n",
      "         [0.9104],\n",
      "         [0.0697],\n",
      "         [0.5151],\n",
      "         [0.5558],\n",
      "         [0.2919],\n",
      "         [0.6874],\n",
      "         [0.3578],\n",
      "         [0.4384],\n",
      "         [0.9431],\n",
      "         [0.9161],\n",
      "         [0.2736],\n",
      "         [0.6643],\n",
      "         [0.2339],\n",
      "         [0.3408],\n",
      "         [0.5244],\n",
      "         [0.9015],\n",
      "         [0.3720],\n",
      "         [0.8629],\n",
      "         [0.0237],\n",
      "         [0.5410],\n",
      "         [0.3574],\n",
      "         [0.4657],\n",
      "         [0.4438],\n",
      "         [0.0352],\n",
      "         [0.7748],\n",
      "         [0.0942],\n",
      "         [0.8714],\n",
      "         [0.6760],\n",
      "         [0.6409],\n",
      "         [0.1686],\n",
      "         [0.0800],\n",
      "         [0.5450],\n",
      "         [0.2545],\n",
      "         [0.3675],\n",
      "         [0.6912],\n",
      "         [0.7233],\n",
      "         [0.8668],\n",
      "         [0.1761],\n",
      "         [0.3292],\n",
      "         [0.7460],\n",
      "         [0.0718],\n",
      "         [0.2340],\n",
      "         [0.0982],\n",
      "         [0.3718],\n",
      "         [0.7547],\n",
      "         [0.8661],\n",
      "         [0.9981],\n",
      "         [0.3536],\n",
      "         [0.0823],\n",
      "         [0.8174],\n",
      "         [0.9416],\n",
      "         [0.3646],\n",
      "         [0.1566],\n",
      "         [0.9529],\n",
      "         [0.9659],\n",
      "         [0.2831],\n",
      "         [0.0523],\n",
      "         [0.3422],\n",
      "         [0.6476],\n",
      "         [0.2896],\n",
      "         [0.3631],\n",
      "         [0.1841],\n",
      "         [0.6675],\n",
      "         [0.7105],\n",
      "         [0.1799],\n",
      "         [0.0409],\n",
      "         [0.1231],\n",
      "         [0.1624],\n",
      "         [0.8643],\n",
      "         [0.8407],\n",
      "         [0.7117],\n",
      "         [0.4990],\n",
      "         [0.2666],\n",
      "         [0.5779],\n",
      "         [0.7036],\n",
      "         [0.9802],\n",
      "         [0.1544],\n",
      "         [0.4329],\n",
      "         [0.2349],\n",
      "         [0.7757],\n",
      "         [0.2477],\n",
      "         [0.4982],\n",
      "         [0.6073],\n",
      "         [0.3272],\n",
      "         [0.7110],\n",
      "         [0.2253],\n",
      "         [0.6648],\n",
      "         [0.4299],\n",
      "         [0.5380],\n",
      "         [0.2570],\n",
      "         [0.0227],\n",
      "         [0.8946],\n",
      "         [0.0332],\n",
      "         [0.2701],\n",
      "         [0.0729],\n",
      "         [0.2622],\n",
      "         [0.5710],\n",
      "         [0.2610],\n",
      "         [0.4368],\n",
      "         [0.5006],\n",
      "         [0.7887],\n",
      "         [0.0713],\n",
      "         [0.2711],\n",
      "         [0.7480],\n",
      "         [0.8054],\n",
      "         [0.3229],\n",
      "         [0.7088],\n",
      "         [0.8564],\n",
      "         [0.6264],\n",
      "         [0.7088],\n",
      "         [0.0618],\n",
      "         [0.1451],\n",
      "         [0.1350],\n",
      "         [0.3861],\n",
      "         [0.1563],\n",
      "         [0.9483],\n",
      "         [0.2021],\n",
      "         [0.2291],\n",
      "         [0.7196],\n",
      "         [0.8347],\n",
      "         [0.8410],\n",
      "         [0.1737],\n",
      "         [0.1103],\n",
      "         [0.7353],\n",
      "         [0.6583],\n",
      "         [0.0899],\n",
      "         [0.9213],\n",
      "         [0.7150],\n",
      "         [0.8194],\n",
      "         [0.0528],\n",
      "         [0.6820],\n",
      "         [0.1511],\n",
      "         [0.3652],\n",
      "         [0.8273],\n",
      "         [0.6295],\n",
      "         [0.1369],\n",
      "         [0.4441],\n",
      "         [0.6068],\n",
      "         [0.3002],\n",
      "         [0.1542],\n",
      "         [0.1746],\n",
      "         [0.7585],\n",
      "         [0.1122],\n",
      "         [0.8236],\n",
      "         [0.3815],\n",
      "         [0.1096],\n",
      "         [0.3322],\n",
      "         [0.2107],\n",
      "         [0.2106],\n",
      "         [0.6409],\n",
      "         [0.3110],\n",
      "         [0.4172],\n",
      "         [0.7449],\n",
      "         [0.0572]]], device='cuda:0', dtype=torch.float64)\n",
      "================iter 5============\n",
      "['shape/cube/1/cube_512_256_3_2_0']\n",
      "tensor([[ True,  True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
      "          True,  True,  True,  True,  True,  True,  True,  True, False, False]],\n",
      "       device='cuda:0')\n",
      "@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@\n",
      "['shape/cube/1/cube_512_256_3_3_0']\n",
      "gt_trans_torch.Size([1, 20, 3])_tensor([[[-4.5757e-02, -5.6619e-02,  1.2717e-02],\n",
      "         [-4.8081e-02, -4.1320e-02,  1.2175e-02],\n",
      "         [ 1.7352e-02,  4.7644e-03, -1.6452e-02],\n",
      "         [ 2.3909e-02,  1.3903e-02, -7.9266e-03],\n",
      "         [ 2.0702e-02,  3.1784e-02, -1.2645e-03],\n",
      "         [ 2.5239e-02,  3.7490e-02, -1.1784e-02],\n",
      "         [ 2.7080e-02,  4.6767e-02, -1.8460e-02],\n",
      "         [ 3.7706e-02,  4.9950e-02, -1.7702e-02],\n",
      "         [ 5.4242e-02,  4.5814e-02, -2.2822e-02],\n",
      "         [ 5.5126e-02,  5.8429e-02, -2.0336e-02],\n",
      "         [-3.5494e-02, -4.1685e-02,  7.5387e-03],\n",
      "         [-2.3174e-02, -3.9104e-02,  1.2264e-02],\n",
      "         [-3.2538e-02, -1.9929e-02,  2.7527e-03],\n",
      "         [-2.2142e-02, -1.4775e-02,  1.0709e-02],\n",
      "         [-1.6268e-02, -1.1004e-02, -1.8462e-03],\n",
      "         [ 2.1382e-03, -1.1909e-02,  1.0085e-02],\n",
      "         [-3.5527e-18, -8.8818e-18,  4.8850e-18],\n",
      "         [ 5.3719e-03,  9.2624e-03,  4.9989e-03],\n",
      "         [ 0.0000e+00,  0.0000e+00,  0.0000e+00],\n",
      "         [ 0.0000e+00,  0.0000e+00,  0.0000e+00]]], device='cuda:0')\n",
      "gt_rots_torch.Size([1, 20, 4])_tensor([[[ 0.8023,  0.4171, -0.2099,  0.3718],\n",
      "         [-0.5508,  0.0894,  0.8073,  0.1920],\n",
      "         [-0.1055,  0.4907,  0.6993,  0.5089],\n",
      "         [-0.5644,  0.7127,  0.1657, -0.3823],\n",
      "         [ 0.2757,  0.7867,  0.3885,  0.3927],\n",
      "         [ 0.8700,  0.3655, -0.2668,  0.1956],\n",
      "         [ 0.7772,  0.2956, -0.5258, -0.1792],\n",
      "         [ 0.3018,  0.7247,  0.3770,  0.4915],\n",
      "         [-0.6135, -0.2383,  0.7509,  0.0536],\n",
      "         [-0.1156,  0.7231,  0.5494,  0.4025],\n",
      "         [ 0.6695,  0.5790,  0.1812,  0.4286],\n",
      "         [ 0.6628,  0.7456,  0.0355,  0.0594],\n",
      "         [-0.5696,  0.8148,  0.1061, -0.0184],\n",
      "         [ 0.2892,  0.1512,  0.8146, -0.4795],\n",
      "         [ 0.7157,  0.5222, -0.2999,  0.3538],\n",
      "         [ 0.8161,  0.3752, -0.3464,  0.2706],\n",
      "         [ 0.1235,  0.7271,  0.5643,  0.3711],\n",
      "         [-0.5286,  0.4356, -0.3340,  0.6475],\n",
      "         [ 0.0000,  0.0000,  0.0000,  0.0000],\n",
      "         [ 0.0000,  0.0000,  0.0000,  0.0000]]], device='cuda:0')\n",
      "noisy_trans_and_rots_torch.Size([1, 20, 7])_tensor([[[-1.6820,  0.0000, -0.0630,  1.2521,  0.0000,  0.0000, -0.6504],\n",
      "         [ 0.0592,  0.0000, -0.0652, -0.6331,  0.0000,  0.0000, -0.0126],\n",
      "         [ 1.0051,  0.0000, -0.2364,  1.4326,  0.0000,  0.0000, -1.0811],\n",
      "         [-0.2260,  0.0000,  0.2587,  0.9646,  0.0000,  0.0000,  1.1894],\n",
      "         [ 1.2238,  0.0000,  0.4554, -1.5826,  0.0000,  0.0000,  1.1490],\n",
      "         [ 1.8406,  0.0000,  0.2483, -0.3351,  0.0000,  0.0000, -1.2407],\n",
      "         [ 0.4641,  0.0000, -0.1138, -1.5210,  0.0000,  0.0000,  0.1220],\n",
      "         [-0.8896,  0.0000,  0.6270, -0.4291,  0.0000,  0.0000,  1.1848],\n",
      "         [-0.5261,  0.0000,  0.2715,  0.4777,  0.0000,  0.0000, -1.3798],\n",
      "         [ 0.2856,  0.0000,  2.4711,  2.1786,  0.0000,  0.0000, -2.4213],\n",
      "         [ 1.3327,  0.0000, -1.2665,  1.4553,  0.0000,  0.0000,  1.0663],\n",
      "         [ 1.0786,  0.0000,  0.8260, -0.4184,  0.0000,  0.0000,  1.0378],\n",
      "         [-1.7871,  0.0000, -0.5256, -1.6395,  0.0000,  0.0000, -0.1283],\n",
      "         [ 0.9266,  0.0000, -2.1313,  1.3407,  0.0000,  0.0000,  2.4422],\n",
      "         [ 2.3397,  0.0000, -1.5657, -1.1622,  0.0000,  0.0000,  1.2225],\n",
      "         [-1.3925,  0.0000, -0.5867,  0.5440,  0.0000,  0.0000,  0.1118],\n",
      "         [ 0.6498,  0.0000, -1.2249, -0.6677,  0.0000,  0.0000,  2.0295],\n",
      "         [ 0.2937,  0.0000,  1.0061,  0.0969,  0.0000,  0.0000,  1.1600],\n",
      "         [-0.0188,  0.0000, -1.0856,  1.9396,  0.0000,  0.0000, -1.5887],\n",
      "         [ 0.0718,  0.0000,  1.8119,  1.9900,  0.0000,  0.0000, -0.7515]]],\n",
      "       device='cuda:0')\n",
      "================iter 0============\n",
      "['shape/cube/1/cube_512_256_3_3_0']\n",
      "tensor([[False, False, False, False, False, False, False, False, False, False,\n",
      "         False, False, False, False, False, False,  True, False, False, False]],\n",
      "       device='cuda:0')\n",
      "acc torch.Size([1]) tensor([0.0556], device='cuda:0')\n",
      "acc_per_part torch.Size([1, 20]) tensor([[False, False, False, False, False, False, False, False, False, False,\n",
      "         False, False, False, False, False, False,  True, False, False, False]],\n",
      "       device='cuda:0')\n",
      "loss_per_data torch.Size([1, 20]) tensor([[ 0.1699,  0.2883,  1.4254,  0.7983,  1.5169,  5.0429,  0.6413,  1.1320,\n",
      "          1.2233, 16.4655,  1.1540,  4.9203,  7.4972, 12.7757, 16.2016,  1.3288,\n",
      "          0.0000,  3.1412,  5.5855,  7.7732]], device='cuda:0')\n",
      "scores torch.Size([1, 190, 1]) tensor([[[0.7437],\n",
      "         [0.3889],\n",
      "         [0.8446],\n",
      "         [0.4480],\n",
      "         [0.3559],\n",
      "         [0.8897],\n",
      "         [0.0813],\n",
      "         [0.7920],\n",
      "         [0.5145],\n",
      "         [0.9405],\n",
      "         [0.0639],\n",
      "         [0.2800],\n",
      "         [0.0112],\n",
      "         [0.3731],\n",
      "         [0.3606],\n",
      "         [0.9113],\n",
      "         [0.4949],\n",
      "         [0.8804],\n",
      "         [0.0933],\n",
      "         [0.8173],\n",
      "         [0.1091],\n",
      "         [0.7257],\n",
      "         [0.9569],\n",
      "         [0.6604],\n",
      "         [0.6593],\n",
      "         [0.9160],\n",
      "         [0.4241],\n",
      "         [0.6024],\n",
      "         [0.4862],\n",
      "         [0.9830],\n",
      "         [0.2674],\n",
      "         [0.3814],\n",
      "         [0.0178],\n",
      "         [0.2000],\n",
      "         [0.0139],\n",
      "         [0.0385],\n",
      "         [0.0090],\n",
      "         [0.1287],\n",
      "         [0.5762],\n",
      "         [0.1409],\n",
      "         [0.9316],\n",
      "         [0.8067],\n",
      "         [0.1923],\n",
      "         [0.8466],\n",
      "         [0.9193],\n",
      "         [0.7753],\n",
      "         [0.0080],\n",
      "         [0.3017],\n",
      "         [0.5952],\n",
      "         [0.8040],\n",
      "         [0.1031],\n",
      "         [0.9655],\n",
      "         [0.0983],\n",
      "         [0.1195],\n",
      "         [0.0619],\n",
      "         [0.3947],\n",
      "         [0.6688],\n",
      "         [0.7344],\n",
      "         [0.6955],\n",
      "         [0.1668],\n",
      "         [0.3168],\n",
      "         [0.8246],\n",
      "         [0.8090],\n",
      "         [0.3529],\n",
      "         [0.7277],\n",
      "         [0.5840],\n",
      "         [0.6391],\n",
      "         [0.4050],\n",
      "         [0.3684],\n",
      "         [0.4270],\n",
      "         [0.6409],\n",
      "         [0.5837],\n",
      "         [0.6657],\n",
      "         [0.6920],\n",
      "         [0.9746],\n",
      "         [0.3745],\n",
      "         [0.7432],\n",
      "         [0.7410],\n",
      "         [0.7925],\n",
      "         [0.2205],\n",
      "         [0.5228],\n",
      "         [0.2020],\n",
      "         [0.8335],\n",
      "         [0.8464],\n",
      "         [0.2391],\n",
      "         [0.1592],\n",
      "         [0.8047],\n",
      "         [0.0630],\n",
      "         [0.2804],\n",
      "         [0.7037],\n",
      "         [0.5203],\n",
      "         [0.1942],\n",
      "         [0.3134],\n",
      "         [0.5282],\n",
      "         [0.6258],\n",
      "         [0.5238],\n",
      "         [0.1997],\n",
      "         [0.5571],\n",
      "         [0.0321],\n",
      "         [0.0226],\n",
      "         [0.3000],\n",
      "         [0.8464],\n",
      "         [0.9666],\n",
      "         [0.5047],\n",
      "         [0.8733],\n",
      "         [0.7545],\n",
      "         [0.2071],\n",
      "         [0.6475],\n",
      "         [0.3746],\n",
      "         [0.8926],\n",
      "         [0.1170],\n",
      "         [0.2554],\n",
      "         [0.5992],\n",
      "         [0.7760],\n",
      "         [0.0243],\n",
      "         [0.0363],\n",
      "         [0.8175],\n",
      "         [0.4550],\n",
      "         [0.3529],\n",
      "         [0.1127],\n",
      "         [0.8865],\n",
      "         [0.4528],\n",
      "         [0.8299],\n",
      "         [0.2416],\n",
      "         [0.3755],\n",
      "         [0.2487],\n",
      "         [0.0946],\n",
      "         [0.5712],\n",
      "         [0.6173],\n",
      "         [0.7994],\n",
      "         [0.3152],\n",
      "         [0.3752],\n",
      "         [0.8983],\n",
      "         [0.3028],\n",
      "         [0.9332],\n",
      "         [0.7328],\n",
      "         [0.4732],\n",
      "         [0.0771],\n",
      "         [0.4841],\n",
      "         [0.2017],\n",
      "         [0.9467],\n",
      "         [0.6802],\n",
      "         [0.7943],\n",
      "         [0.3332],\n",
      "         [0.7766],\n",
      "         [0.2322],\n",
      "         [0.5053],\n",
      "         [0.2311],\n",
      "         [0.6332],\n",
      "         [0.3907],\n",
      "         [0.2206],\n",
      "         [0.2130],\n",
      "         [0.3504],\n",
      "         [0.2982],\n",
      "         [0.9273],\n",
      "         [0.2382],\n",
      "         [0.5663],\n",
      "         [0.5474],\n",
      "         [0.0546],\n",
      "         [0.4816],\n",
      "         [0.6504],\n",
      "         [0.3232],\n",
      "         [0.4392],\n",
      "         [0.0859],\n",
      "         [0.7026],\n",
      "         [0.2008],\n",
      "         [0.3211],\n",
      "         [0.6571],\n",
      "         [0.0409],\n",
      "         [0.9379],\n",
      "         [0.4574],\n",
      "         [0.1938],\n",
      "         [0.4237],\n",
      "         [0.6800],\n",
      "         [0.9688],\n",
      "         [0.7497],\n",
      "         [0.6509],\n",
      "         [0.2517],\n",
      "         [0.9017],\n",
      "         [0.9474],\n",
      "         [0.1503],\n",
      "         [0.3759],\n",
      "         [0.1630],\n",
      "         [0.8616],\n",
      "         [0.9856],\n",
      "         [0.3139],\n",
      "         [0.1962],\n",
      "         [0.3759],\n",
      "         [0.0864],\n",
      "         [0.4169]]], device='cuda:0', dtype=torch.float64)\n",
      "================iter 1============\n",
      "['shape/cube/1/cube_512_256_3_3_0']\n",
      "tensor([[ True, False, False, False, False, False, False, False, False, False,\n",
      "         False, False, False, False, False, False,  True,  True, False, False]],\n",
      "       device='cuda:0')\n",
      "acc torch.Size([1]) tensor([0.0556], device='cuda:0')\n",
      "acc_per_part torch.Size([1, 20]) tensor([[False, False, False, False, False, False, False, False, False, False,\n",
      "         False, False, False, False, False, False,  True, False, False, False]],\n",
      "       device='cuda:0')\n",
      "loss_per_data torch.Size([1, 20]) tensor([[ 0.1699,  0.5134,  1.3626,  4.0925,  7.0439, 20.5725,  4.6548,  0.5020,\n",
      "          1.1670, 10.3164,  0.6918,  5.1158, 31.2803, 60.4831,  8.4820, 72.6532,\n",
      "          0.0000,  3.1412,  6.7784, 21.3680]], device='cuda:0')\n",
      "scores torch.Size([1, 190, 1]) tensor([[[7.6946e-01],\n",
      "         [8.4229e-01],\n",
      "         [3.9538e-01],\n",
      "         [1.4371e-01],\n",
      "         [6.4334e-01],\n",
      "         [8.7379e-01],\n",
      "         [1.8934e-01],\n",
      "         [1.6748e-01],\n",
      "         [8.2657e-01],\n",
      "         [3.6578e-01],\n",
      "         [3.3671e-01],\n",
      "         [9.4273e-02],\n",
      "         [2.2302e-01],\n",
      "         [7.7211e-02],\n",
      "         [7.5726e-01],\n",
      "         [7.8068e-02],\n",
      "         [4.1795e-01],\n",
      "         [8.7682e-01],\n",
      "         [5.3619e-01],\n",
      "         [1.1153e-03],\n",
      "         [2.8754e-02],\n",
      "         [9.5647e-02],\n",
      "         [6.2228e-01],\n",
      "         [9.7498e-01],\n",
      "         [1.4101e-01],\n",
      "         [5.3629e-01],\n",
      "         [9.7265e-01],\n",
      "         [3.8593e-01],\n",
      "         [7.5839e-01],\n",
      "         [6.6269e-01],\n",
      "         [6.3147e-01],\n",
      "         [9.2158e-02],\n",
      "         [7.9228e-02],\n",
      "         [5.0971e-01],\n",
      "         [8.5070e-01],\n",
      "         [9.2325e-01],\n",
      "         [1.6770e-01],\n",
      "         [2.0495e-01],\n",
      "         [1.6070e-01],\n",
      "         [8.5121e-01],\n",
      "         [3.7188e-01],\n",
      "         [5.6294e-01],\n",
      "         [6.1367e-01],\n",
      "         [8.9202e-01],\n",
      "         [2.5396e-01],\n",
      "         [3.4503e-01],\n",
      "         [9.2369e-01],\n",
      "         [4.2845e-01],\n",
      "         [2.6175e-01],\n",
      "         [4.3487e-01],\n",
      "         [3.0524e-01],\n",
      "         [8.9112e-01],\n",
      "         [1.9790e-01],\n",
      "         [9.1753e-01],\n",
      "         [7.4899e-01],\n",
      "         [2.2654e-01],\n",
      "         [3.6212e-01],\n",
      "         [4.0156e-01],\n",
      "         [4.6820e-01],\n",
      "         [8.0439e-01],\n",
      "         [8.6641e-02],\n",
      "         [3.3501e-01],\n",
      "         [1.1900e-01],\n",
      "         [4.6287e-01],\n",
      "         [3.4441e-01],\n",
      "         [5.3362e-01],\n",
      "         [2.0437e-01],\n",
      "         [8.4459e-01],\n",
      "         [7.2651e-01],\n",
      "         [3.1121e-02],\n",
      "         [4.1166e-01],\n",
      "         [4.2925e-02],\n",
      "         [3.8202e-01],\n",
      "         [2.5809e-01],\n",
      "         [1.5274e-01],\n",
      "         [3.1791e-01],\n",
      "         [1.3807e-01],\n",
      "         [8.4949e-01],\n",
      "         [1.2143e-01],\n",
      "         [5.9899e-01],\n",
      "         [2.0455e-01],\n",
      "         [1.0653e-03],\n",
      "         [5.9084e-01],\n",
      "         [4.5261e-01],\n",
      "         [8.2582e-02],\n",
      "         [7.2848e-01],\n",
      "         [4.1797e-02],\n",
      "         [4.6185e-01],\n",
      "         [8.4825e-01],\n",
      "         [7.4097e-02],\n",
      "         [1.9217e-01],\n",
      "         [5.3486e-01],\n",
      "         [2.2099e-01],\n",
      "         [7.3013e-01],\n",
      "         [8.2236e-01],\n",
      "         [7.0149e-01],\n",
      "         [5.1514e-01],\n",
      "         [9.5569e-01],\n",
      "         [4.1054e-01],\n",
      "         [6.4921e-01],\n",
      "         [7.0045e-04],\n",
      "         [4.1943e-01],\n",
      "         [5.9147e-01],\n",
      "         [1.8219e-01],\n",
      "         [6.5437e-01],\n",
      "         [9.8773e-01],\n",
      "         [8.0701e-01],\n",
      "         [4.4157e-01],\n",
      "         [7.7595e-01],\n",
      "         [6.6264e-01],\n",
      "         [8.4716e-01],\n",
      "         [2.6096e-01],\n",
      "         [1.5213e-01],\n",
      "         [9.7545e-01],\n",
      "         [3.0799e-01],\n",
      "         [6.8933e-01],\n",
      "         [5.6027e-01],\n",
      "         [5.5994e-01],\n",
      "         [4.0783e-01],\n",
      "         [5.4201e-01],\n",
      "         [6.0724e-01],\n",
      "         [7.9032e-01],\n",
      "         [2.6629e-01],\n",
      "         [5.2934e-01],\n",
      "         [2.6705e-01],\n",
      "         [1.4666e-01],\n",
      "         [6.7992e-01],\n",
      "         [5.0985e-01],\n",
      "         [7.7848e-01],\n",
      "         [7.1129e-02],\n",
      "         [7.6958e-01],\n",
      "         [3.0388e-02],\n",
      "         [3.6437e-02],\n",
      "         [1.7721e-01],\n",
      "         [6.0049e-01],\n",
      "         [3.2463e-02],\n",
      "         [9.5267e-01],\n",
      "         [6.1582e-02],\n",
      "         [3.8412e-01],\n",
      "         [8.8816e-01],\n",
      "         [1.9022e-01],\n",
      "         [9.3254e-01],\n",
      "         [6.3866e-01],\n",
      "         [4.2987e-01],\n",
      "         [3.7641e-01],\n",
      "         [3.3164e-01],\n",
      "         [1.5745e-01],\n",
      "         [2.3312e-01],\n",
      "         [6.7909e-01],\n",
      "         [5.1019e-01],\n",
      "         [5.2114e-01],\n",
      "         [7.0146e-01],\n",
      "         [1.0022e-01],\n",
      "         [1.2756e-01],\n",
      "         [3.3958e-01],\n",
      "         [1.7239e-01],\n",
      "         [3.2220e-01],\n",
      "         [3.5468e-01],\n",
      "         [5.4432e-01],\n",
      "         [5.6105e-01],\n",
      "         [1.6562e-01],\n",
      "         [6.4527e-01],\n",
      "         [1.5187e-01],\n",
      "         [6.0746e-01],\n",
      "         [6.7698e-01],\n",
      "         [5.0328e-01],\n",
      "         [6.8113e-01],\n",
      "         [3.2643e-01],\n",
      "         [8.1456e-01],\n",
      "         [2.8798e-01],\n",
      "         [6.3173e-02],\n",
      "         [2.2960e-01],\n",
      "         [1.3163e-01],\n",
      "         [6.3972e-02],\n",
      "         [1.3129e-01],\n",
      "         [1.1342e-01],\n",
      "         [7.6393e-02],\n",
      "         [9.0414e-01],\n",
      "         [3.8298e-01],\n",
      "         [5.8957e-01],\n",
      "         [9.3767e-01],\n",
      "         [4.2029e-01],\n",
      "         [4.4744e-01],\n",
      "         [3.9208e-01],\n",
      "         [8.5660e-01],\n",
      "         [5.7006e-01],\n",
      "         [4.4668e-01],\n",
      "         [1.3055e-01],\n",
      "         [9.5883e-01],\n",
      "         [6.9862e-01]]], device='cuda:0', dtype=torch.float64)\n",
      "================iter 2============\n",
      "['shape/cube/1/cube_512_256_3_3_0']\n",
      "tensor([[ True, False, False, False, False, False, False, False, False,  True,\n",
      "         False, False, False, False,  True,  True,  True,  True, False, False]],\n",
      "       device='cuda:0')\n",
      "acc torch.Size([1]) tensor([0.0556], device='cuda:0')\n",
      "acc_per_part torch.Size([1, 20]) tensor([[False, False, False, False, False, False, False, False, False, False,\n",
      "         False, False, False, False, False, False,  True, False, False, False]],\n",
      "       device='cuda:0')\n",
      "loss_per_data torch.Size([1, 20]) tensor([[1.6988e-01, 1.3430e+00, 6.6122e+00, 6.0095e+00, 1.7469e+01, 2.2608e+01,\n",
      "         2.6497e+01, 2.6958e+00, 1.5026e+01, 1.0316e+01, 9.7772e+00, 4.2698e+00,\n",
      "         8.1699e+02, 4.2444e+02, 8.4820e+00, 7.2653e+01, 0.0000e+00, 3.1412e+00,\n",
      "         1.5624e+01, 6.8850e+01]], device='cuda:0')\n",
      "scores torch.Size([1, 190, 1]) tensor([[[8.8941e-01],\n",
      "         [5.6754e-01],\n",
      "         [2.6976e-01],\n",
      "         [1.3376e-01],\n",
      "         [1.2950e-01],\n",
      "         [4.1850e-01],\n",
      "         [1.5977e-01],\n",
      "         [6.7891e-01],\n",
      "         [2.0526e-01],\n",
      "         [8.9434e-01],\n",
      "         [5.6514e-01],\n",
      "         [7.6823e-01],\n",
      "         [4.1419e-01],\n",
      "         [7.8387e-01],\n",
      "         [2.8496e-01],\n",
      "         [3.3266e-01],\n",
      "         [9.3706e-01],\n",
      "         [8.0595e-01],\n",
      "         [4.7618e-01],\n",
      "         [3.1719e-01],\n",
      "         [4.2171e-02],\n",
      "         [3.1126e-01],\n",
      "         [8.8009e-01],\n",
      "         [1.6342e-01],\n",
      "         [3.7772e-01],\n",
      "         [9.4641e-01],\n",
      "         [9.6665e-01],\n",
      "         [1.7180e-01],\n",
      "         [6.7875e-02],\n",
      "         [4.9765e-01],\n",
      "         [6.2521e-01],\n",
      "         [4.5204e-01],\n",
      "         [9.3493e-01],\n",
      "         [8.8622e-01],\n",
      "         [2.0476e-01],\n",
      "         [6.1335e-01],\n",
      "         [6.8850e-01],\n",
      "         [5.6953e-02],\n",
      "         [7.0723e-02],\n",
      "         [9.1798e-01],\n",
      "         [8.1107e-01],\n",
      "         [8.9380e-01],\n",
      "         [7.7356e-01],\n",
      "         [7.3490e-02],\n",
      "         [9.8529e-01],\n",
      "         [5.0428e-01],\n",
      "         [3.6025e-01],\n",
      "         [4.4682e-01],\n",
      "         [3.7901e-01],\n",
      "         [6.9455e-01],\n",
      "         [6.4140e-01],\n",
      "         [2.4835e-01],\n",
      "         [4.1144e-02],\n",
      "         [1.0183e-01],\n",
      "         [5.3782e-01],\n",
      "         [1.9289e-01],\n",
      "         [2.8353e-01],\n",
      "         [6.0533e-01],\n",
      "         [6.5481e-01],\n",
      "         [9.7273e-01],\n",
      "         [5.4479e-01],\n",
      "         [7.6873e-01],\n",
      "         [9.2634e-01],\n",
      "         [9.7946e-01],\n",
      "         [2.0589e-01],\n",
      "         [2.4509e-01],\n",
      "         [2.2463e-01],\n",
      "         [7.5508e-01],\n",
      "         [9.2772e-01],\n",
      "         [5.6203e-01],\n",
      "         [8.3260e-01],\n",
      "         [6.0633e-01],\n",
      "         [7.5120e-01],\n",
      "         [8.5181e-01],\n",
      "         [4.0319e-01],\n",
      "         [8.6045e-01],\n",
      "         [6.4790e-01],\n",
      "         [8.4582e-02],\n",
      "         [4.2039e-01],\n",
      "         [3.3259e-01],\n",
      "         [7.2352e-01],\n",
      "         [6.2428e-01],\n",
      "         [9.6203e-01],\n",
      "         [7.0492e-02],\n",
      "         [4.4991e-01],\n",
      "         [9.0582e-01],\n",
      "         [4.7877e-01],\n",
      "         [1.5064e-01],\n",
      "         [1.7683e-01],\n",
      "         [6.0666e-01],\n",
      "         [2.7667e-01],\n",
      "         [5.2758e-01],\n",
      "         [6.7025e-01],\n",
      "         [8.8925e-01],\n",
      "         [3.7166e-01],\n",
      "         [6.4986e-01],\n",
      "         [1.7618e-01],\n",
      "         [6.9417e-01],\n",
      "         [1.3066e-02],\n",
      "         [6.4767e-01],\n",
      "         [6.7077e-01],\n",
      "         [7.7451e-01],\n",
      "         [2.9134e-01],\n",
      "         [7.1240e-01],\n",
      "         [1.1590e-01],\n",
      "         [8.2200e-01],\n",
      "         [6.4200e-01],\n",
      "         [1.0272e-01],\n",
      "         [6.6042e-01],\n",
      "         [4.9594e-01],\n",
      "         [2.1298e-01],\n",
      "         [6.6431e-02],\n",
      "         [3.4608e-02],\n",
      "         [2.2921e-01],\n",
      "         [3.3067e-01],\n",
      "         [5.3086e-02],\n",
      "         [3.3923e-02],\n",
      "         [2.3191e-01],\n",
      "         [3.4803e-02],\n",
      "         [5.5462e-01],\n",
      "         [9.5494e-01],\n",
      "         [9.3548e-01],\n",
      "         [1.4683e-03],\n",
      "         [7.7534e-01],\n",
      "         [5.4723e-01],\n",
      "         [2.4033e-01],\n",
      "         [9.8623e-01],\n",
      "         [4.8361e-01],\n",
      "         [8.1416e-01],\n",
      "         [5.0218e-01],\n",
      "         [1.3966e-01],\n",
      "         [8.7941e-01],\n",
      "         [7.4512e-01],\n",
      "         [8.2132e-01],\n",
      "         [4.3698e-01],\n",
      "         [7.9106e-01],\n",
      "         [3.8421e-01],\n",
      "         [8.8439e-01],\n",
      "         [7.2883e-01],\n",
      "         [7.4237e-01],\n",
      "         [2.5123e-01],\n",
      "         [8.2205e-01],\n",
      "         [2.3495e-01],\n",
      "         [3.0338e-01],\n",
      "         [8.0649e-01],\n",
      "         [2.9190e-01],\n",
      "         [4.9228e-01],\n",
      "         [9.2162e-01],\n",
      "         [3.6529e-02],\n",
      "         [2.9008e-01],\n",
      "         [4.9816e-01],\n",
      "         [5.8922e-01],\n",
      "         [9.3147e-01],\n",
      "         [9.1255e-01],\n",
      "         [4.3638e-01],\n",
      "         [9.7333e-01],\n",
      "         [8.9808e-01],\n",
      "         [1.9797e-01],\n",
      "         [8.8530e-02],\n",
      "         [9.6479e-01],\n",
      "         [7.5913e-01],\n",
      "         [8.8452e-01],\n",
      "         [2.9584e-01],\n",
      "         [5.1223e-01],\n",
      "         [9.7867e-01],\n",
      "         [4.7516e-01],\n",
      "         [2.2555e-01],\n",
      "         [7.2532e-01],\n",
      "         [6.5067e-02],\n",
      "         [8.3096e-01],\n",
      "         [7.3263e-01],\n",
      "         [2.9385e-01],\n",
      "         [9.4857e-01],\n",
      "         [8.7497e-04],\n",
      "         [2.5645e-01],\n",
      "         [6.8635e-01],\n",
      "         [3.3851e-01],\n",
      "         [2.1383e-01],\n",
      "         [9.9602e-01],\n",
      "         [7.7322e-01],\n",
      "         [2.2216e-01],\n",
      "         [1.0618e-01],\n",
      "         [7.5719e-02],\n",
      "         [8.8912e-01],\n",
      "         [4.7137e-01],\n",
      "         [8.2868e-01],\n",
      "         [3.5901e-01],\n",
      "         [2.2857e-01],\n",
      "         [3.8063e-01],\n",
      "         [5.1931e-03]]], device='cuda:0', dtype=torch.float64)\n",
      "================iter 3============\n",
      "['shape/cube/1/cube_512_256_3_3_0']\n",
      "tensor([[ True,  True, False,  True,  True, False, False,  True, False,  True,\n",
      "         False,  True,  True,  True,  True,  True,  True,  True, False, False]],\n",
      "       device='cuda:0')\n",
      "acc torch.Size([1]) tensor([0.0556], device='cuda:0')\n",
      "acc_per_part torch.Size([1, 20]) tensor([[False, False, False, False, False, False, False, False, False, False,\n",
      "         False, False, False, False, False, False,  True, False, False, False]],\n",
      "       device='cuda:0')\n",
      "loss_per_data torch.Size([1, 20]) tensor([[1.6988e-01, 1.3430e+00, 1.5475e+01, 6.0095e+00, 1.7469e+01, 4.8376e+01,\n",
      "         8.0679e+01, 2.6958e+00, 3.1591e+01, 1.0316e+01, 1.8685e+01, 4.2698e+00,\n",
      "         8.1699e+02, 4.2444e+02, 8.4820e+00, 7.2653e+01, 0.0000e+00, 3.1412e+00,\n",
      "         2.7917e+01, 1.4779e+02]], device='cuda:0')\n",
      "scores torch.Size([1, 190, 1]) tensor([[[0.1437],\n",
      "         [0.7406],\n",
      "         [0.5020],\n",
      "         [0.5508],\n",
      "         [0.2877],\n",
      "         [0.0179],\n",
      "         [0.8639],\n",
      "         [0.4518],\n",
      "         [0.7890],\n",
      "         [0.5497],\n",
      "         [0.2180],\n",
      "         [0.2260],\n",
      "         [0.0623],\n",
      "         [0.8437],\n",
      "         [0.8952],\n",
      "         [0.1169],\n",
      "         [0.0513],\n",
      "         [0.2833],\n",
      "         [0.2788],\n",
      "         [0.7297],\n",
      "         [0.2984],\n",
      "         [0.0426],\n",
      "         [0.7521],\n",
      "         [0.2951],\n",
      "         [0.5692],\n",
      "         [0.5258],\n",
      "         [0.1958],\n",
      "         [0.8776],\n",
      "         [0.3888],\n",
      "         [0.7203],\n",
      "         [0.7986],\n",
      "         [0.4337],\n",
      "         [0.6529],\n",
      "         [0.3777],\n",
      "         [0.1336],\n",
      "         [0.6343],\n",
      "         [0.7950],\n",
      "         [0.3779],\n",
      "         [0.5602],\n",
      "         [0.9708],\n",
      "         [0.6884],\n",
      "         [0.9129],\n",
      "         [0.5454],\n",
      "         [0.3123],\n",
      "         [0.1168],\n",
      "         [0.2221],\n",
      "         [0.5930],\n",
      "         [0.2365],\n",
      "         [0.1284],\n",
      "         [0.7950],\n",
      "         [0.4315],\n",
      "         [0.0937],\n",
      "         [0.7260],\n",
      "         [0.5330],\n",
      "         [0.4996],\n",
      "         [0.7055],\n",
      "         [0.6791],\n",
      "         [0.6898],\n",
      "         [0.7584],\n",
      "         [0.6170],\n",
      "         [0.3179],\n",
      "         [0.7548],\n",
      "         [0.9319],\n",
      "         [0.2301],\n",
      "         [0.8676],\n",
      "         [0.6746],\n",
      "         [0.0205],\n",
      "         [0.5899],\n",
      "         [0.2149],\n",
      "         [0.1929],\n",
      "         [0.9271],\n",
      "         [0.1960],\n",
      "         [0.3178],\n",
      "         [0.7774],\n",
      "         [0.0979],\n",
      "         [0.7973],\n",
      "         [0.7445],\n",
      "         [0.2173],\n",
      "         [0.4070],\n",
      "         [0.7592],\n",
      "         [0.9705],\n",
      "         [0.1604],\n",
      "         [0.6344],\n",
      "         [0.5000],\n",
      "         [0.0097],\n",
      "         [0.0336],\n",
      "         [0.4027],\n",
      "         [0.8183],\n",
      "         [0.8730],\n",
      "         [0.0667],\n",
      "         [0.3212],\n",
      "         [0.7891],\n",
      "         [0.3959],\n",
      "         [0.2946],\n",
      "         [0.9822],\n",
      "         [0.0371],\n",
      "         [0.9898],\n",
      "         [0.9642],\n",
      "         [0.7165],\n",
      "         [0.0373],\n",
      "         [0.9847],\n",
      "         [0.7828],\n",
      "         [0.1490],\n",
      "         [0.5800],\n",
      "         [0.2546],\n",
      "         [0.8674],\n",
      "         [0.7360],\n",
      "         [0.5856],\n",
      "         [0.9078],\n",
      "         [0.0642],\n",
      "         [0.5406],\n",
      "         [0.1049],\n",
      "         [0.8897],\n",
      "         [0.5943],\n",
      "         [0.0395],\n",
      "         [0.1028],\n",
      "         [0.3800],\n",
      "         [0.3188],\n",
      "         [0.3655],\n",
      "         [0.6813],\n",
      "         [0.1734],\n",
      "         [0.0650],\n",
      "         [0.0567],\n",
      "         [0.6503],\n",
      "         [0.2472],\n",
      "         [0.4425],\n",
      "         [0.4193],\n",
      "         [0.1747],\n",
      "         [0.6392],\n",
      "         [0.3111],\n",
      "         [0.1758],\n",
      "         [0.8313],\n",
      "         [0.4673],\n",
      "         [0.6098],\n",
      "         [0.3588],\n",
      "         [0.3581],\n",
      "         [0.6244],\n",
      "         [0.1512],\n",
      "         [0.7243],\n",
      "         [0.8597],\n",
      "         [0.6372],\n",
      "         [0.2995],\n",
      "         [0.4056],\n",
      "         [0.2940],\n",
      "         [0.5094],\n",
      "         [0.5618],\n",
      "         [0.6975],\n",
      "         [0.3777],\n",
      "         [0.8026],\n",
      "         [0.0815],\n",
      "         [0.6755],\n",
      "         [0.6930],\n",
      "         [0.1501],\n",
      "         [0.1637],\n",
      "         [0.6205],\n",
      "         [0.2415],\n",
      "         [0.8126],\n",
      "         [0.7738],\n",
      "         [0.0571],\n",
      "         [0.3168],\n",
      "         [0.9551],\n",
      "         [0.1315],\n",
      "         [0.6738],\n",
      "         [0.2736],\n",
      "         [0.7727],\n",
      "         [0.2918],\n",
      "         [0.1190],\n",
      "         [0.8155],\n",
      "         [0.6581],\n",
      "         [0.6527],\n",
      "         [0.9357],\n",
      "         [0.7530],\n",
      "         [0.4682],\n",
      "         [0.8533],\n",
      "         [0.8428],\n",
      "         [0.0274],\n",
      "         [0.9158],\n",
      "         [0.8801],\n",
      "         [0.0772],\n",
      "         [0.9604],\n",
      "         [0.9273],\n",
      "         [0.6999],\n",
      "         [0.5497],\n",
      "         [0.1563],\n",
      "         [0.6969],\n",
      "         [0.9688],\n",
      "         [0.8712],\n",
      "         [0.8350],\n",
      "         [0.0773],\n",
      "         [0.2399]]], device='cuda:0', dtype=torch.float64)\n",
      "================iter 4============\n",
      "['shape/cube/1/cube_512_256_3_3_0']\n",
      "tensor([[ True,  True,  True,  True,  True,  True,  True,  True, False,  True,\n",
      "         False,  True,  True,  True,  True,  True,  True,  True, False, False]],\n",
      "       device='cuda:0')\n",
      "acc torch.Size([1]) tensor([0.0556], device='cuda:0')\n",
      "acc_per_part torch.Size([1, 20]) tensor([[False, False, False, False, False, False, False, False, False, False,\n",
      "         False, False, False, False, False, False,  True, False, False, False]],\n",
      "       device='cuda:0')\n",
      "loss_per_data torch.Size([1, 20]) tensor([[1.6988e-01, 1.3430e+00, 1.5475e+01, 6.0095e+00, 1.7469e+01, 4.8376e+01,\n",
      "         8.0679e+01, 2.6958e+00, 7.6279e+01, 1.0316e+01, 2.8941e+01, 4.2698e+00,\n",
      "         8.1699e+02, 4.2444e+02, 8.4820e+00, 7.2653e+01, 0.0000e+00, 3.1412e+00,\n",
      "         3.1496e+01, 2.8869e+02]], device='cuda:0')\n",
      "scores torch.Size([1, 190, 1]) tensor([[[0.8381],\n",
      "         [0.9264],\n",
      "         [0.0379],\n",
      "         [0.1065],\n",
      "         [0.3217],\n",
      "         [0.1805],\n",
      "         [0.4409],\n",
      "         [0.4885],\n",
      "         [0.6835],\n",
      "         [0.5021],\n",
      "         [0.0445],\n",
      "         [0.0585],\n",
      "         [0.9460],\n",
      "         [0.6395],\n",
      "         [0.8345],\n",
      "         [0.1035],\n",
      "         [0.9023],\n",
      "         [0.3336],\n",
      "         [0.1521],\n",
      "         [0.6231],\n",
      "         [0.3841],\n",
      "         [0.4847],\n",
      "         [0.6946],\n",
      "         [0.9371],\n",
      "         [0.7807],\n",
      "         [0.3167],\n",
      "         [0.9371],\n",
      "         [0.6908],\n",
      "         [0.5079],\n",
      "         [0.6988],\n",
      "         [0.7875],\n",
      "         [0.8252],\n",
      "         [0.6333],\n",
      "         [0.6682],\n",
      "         [0.6043],\n",
      "         [0.4150],\n",
      "         [0.9159],\n",
      "         [0.3454],\n",
      "         [0.2837],\n",
      "         [0.4967],\n",
      "         [0.0750],\n",
      "         [0.0207],\n",
      "         [0.3050],\n",
      "         [0.1595],\n",
      "         [0.3247],\n",
      "         [0.7868],\n",
      "         [0.0457],\n",
      "         [0.9652],\n",
      "         [0.3938],\n",
      "         [0.2177],\n",
      "         [0.9095],\n",
      "         [0.2947],\n",
      "         [0.5060],\n",
      "         [0.6883],\n",
      "         [0.9657],\n",
      "         [0.2061],\n",
      "         [0.3902],\n",
      "         [0.5870],\n",
      "         [0.4127],\n",
      "         [0.1667],\n",
      "         [0.4858],\n",
      "         [0.9122],\n",
      "         [0.3436],\n",
      "         [0.0247],\n",
      "         [0.3898],\n",
      "         [0.4568],\n",
      "         [0.2097],\n",
      "         [0.3524],\n",
      "         [0.1685],\n",
      "         [0.2119],\n",
      "         [0.8787],\n",
      "         [0.6593],\n",
      "         [0.8165],\n",
      "         [0.7820],\n",
      "         [0.7187],\n",
      "         [0.2906],\n",
      "         [0.6223],\n",
      "         [0.7245],\n",
      "         [0.0074],\n",
      "         [0.3446],\n",
      "         [0.8076],\n",
      "         [0.3448],\n",
      "         [0.7791],\n",
      "         [0.4554],\n",
      "         [0.5559],\n",
      "         [0.5431],\n",
      "         [0.7127],\n",
      "         [0.0078],\n",
      "         [0.5153],\n",
      "         [0.5083],\n",
      "         [0.4176],\n",
      "         [0.5340],\n",
      "         [0.2518],\n",
      "         [0.6248],\n",
      "         [0.9074],\n",
      "         [0.9973],\n",
      "         [0.5338],\n",
      "         [0.1180],\n",
      "         [0.0190],\n",
      "         [0.0929],\n",
      "         [0.3539],\n",
      "         [0.4523],\n",
      "         [0.4584],\n",
      "         [0.4433],\n",
      "         [0.1536],\n",
      "         [0.0357],\n",
      "         [0.7566],\n",
      "         [0.1258],\n",
      "         [0.6077],\n",
      "         [0.2276],\n",
      "         [0.9560],\n",
      "         [0.5325],\n",
      "         [0.2652],\n",
      "         [0.9508],\n",
      "         [0.8543],\n",
      "         [0.3323],\n",
      "         [0.3404],\n",
      "         [0.3551],\n",
      "         [0.1439],\n",
      "         [0.5287],\n",
      "         [0.2009],\n",
      "         [0.8312],\n",
      "         [0.0719],\n",
      "         [0.3105],\n",
      "         [0.8643],\n",
      "         [0.1503],\n",
      "         [0.9590],\n",
      "         [0.4129],\n",
      "         [0.5277],\n",
      "         [0.8714],\n",
      "         [0.4240],\n",
      "         [0.6350],\n",
      "         [0.9835],\n",
      "         [0.3636],\n",
      "         [0.9346],\n",
      "         [0.0100],\n",
      "         [0.4518],\n",
      "         [0.4140],\n",
      "         [0.5816],\n",
      "         [0.2275],\n",
      "         [0.4533],\n",
      "         [0.7878],\n",
      "         [0.8761],\n",
      "         [0.0015],\n",
      "         [0.5036],\n",
      "         [0.1580],\n",
      "         [0.6296],\n",
      "         [0.9507],\n",
      "         [0.0223],\n",
      "         [0.1536],\n",
      "         [0.2058],\n",
      "         [0.2222],\n",
      "         [0.5039],\n",
      "         [0.2130],\n",
      "         [0.3351],\n",
      "         [0.6019],\n",
      "         [0.9518],\n",
      "         [0.8347],\n",
      "         [0.9157],\n",
      "         [0.7044],\n",
      "         [0.3050],\n",
      "         [0.0592],\n",
      "         [0.0297],\n",
      "         [0.7988],\n",
      "         [0.5134],\n",
      "         [0.0484],\n",
      "         [0.3785],\n",
      "         [0.5116],\n",
      "         [0.3032],\n",
      "         [0.1504],\n",
      "         [0.6010],\n",
      "         [0.7888],\n",
      "         [0.3507],\n",
      "         [0.3380],\n",
      "         [0.3014],\n",
      "         [0.4371],\n",
      "         [0.5797],\n",
      "         [0.6593],\n",
      "         [0.9014],\n",
      "         [0.3001],\n",
      "         [0.7753],\n",
      "         [0.9065],\n",
      "         [0.8274],\n",
      "         [0.9326],\n",
      "         [0.5616],\n",
      "         [0.1886],\n",
      "         [0.3110],\n",
      "         [0.9703],\n",
      "         [0.8495],\n",
      "         [0.8613]]], device='cuda:0', dtype=torch.float64)\n",
      "================iter 5============\n",
      "['shape/cube/1/cube_512_256_3_3_0']\n",
      "tensor([[ True,  True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
      "          True,  True,  True,  True,  True,  True,  True,  True, False, False]],\n",
      "       device='cuda:0')\n",
      "@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@\n",
      "['shape/cube/1/cube_64_32_0_1_0']\n",
      "gt_trans_torch.Size([1, 20, 3])_tensor([[[ 1.2434e-17,  5.4401e-18, -4.4409e-18],\n",
      "         [-2.3646e-02, -6.1164e-02, -1.0838e-02],\n",
      "         [-3.9168e-01, -4.8644e-01, -4.8638e-02],\n",
      "         [-4.1563e-01, -5.4622e-01, -5.1231e-02],\n",
      "         [-4.6095e-01, -5.9077e-01, -4.9144e-02],\n",
      "         [-5.1146e-01, -6.3180e-01, -4.9191e-02],\n",
      "         [-5.4297e-01, -6.8557e-01, -5.2391e-02],\n",
      "         [-5.8056e-01, -7.3511e-01, -5.5703e-02],\n",
      "         [-7.1888e-02, -1.0374e-01,  2.6947e-03],\n",
      "         [-1.0786e-01, -1.5374e-01, -2.2087e-02],\n",
      "         [-1.4545e-01, -2.0409e-01, -1.7987e-02],\n",
      "         [-1.9478e-01, -2.4645e-01, -1.0494e-02],\n",
      "         [-2.2611e-01, -2.9987e-01, -2.4896e-02],\n",
      "         [-2.6013e-01, -3.5054e-01, -3.1144e-02],\n",
      "         [-2.9988e-01, -3.9877e-01, -3.1292e-02],\n",
      "         [-3.4373e-01, -4.4450e-01, -3.6210e-02],\n",
      "         [ 0.0000e+00,  0.0000e+00,  0.0000e+00],\n",
      "         [ 0.0000e+00,  0.0000e+00,  0.0000e+00],\n",
      "         [ 0.0000e+00,  0.0000e+00,  0.0000e+00],\n",
      "         [ 0.0000e+00,  0.0000e+00,  0.0000e+00]]], device='cuda:0')\n",
      "gt_rots_torch.Size([1, 20, 4])_tensor([[[-0.0930, -0.0215,  0.5051,  0.8577],\n",
      "         [ 0.7830,  0.4795, -0.2111, -0.3352],\n",
      "         [ 0.2856,  0.8758, -0.1833,  0.3434],\n",
      "         [ 0.6362, -0.5483,  0.5425,  0.0192],\n",
      "         [-0.3771,  0.7351, -0.3032, -0.4749],\n",
      "         [-0.2801,  0.4070,  0.8674,  0.0591],\n",
      "         [ 0.1830,  0.4704,  0.6216,  0.5990],\n",
      "         [-0.2453,  0.6066,  0.6818, -0.3271],\n",
      "         [ 0.8836, -0.0822, -0.0875,  0.4526],\n",
      "         [ 0.1931, -0.1304,  0.6915,  0.6838],\n",
      "         [-0.4456,  0.3121,  0.7082, -0.4500],\n",
      "         [ 0.2345, -0.3975,  0.8226, -0.3321],\n",
      "         [-0.6230,  0.1853,  0.6438, -0.4039],\n",
      "         [ 0.8819, -0.2266,  0.4091,  0.0600],\n",
      "         [ 0.9397, -0.1274, -0.2337,  0.2147],\n",
      "         [-0.0334, -0.5190,  0.8419, -0.1437],\n",
      "         [ 0.0000,  0.0000,  0.0000,  0.0000],\n",
      "         [ 0.0000,  0.0000,  0.0000,  0.0000],\n",
      "         [ 0.0000,  0.0000,  0.0000,  0.0000],\n",
      "         [ 0.0000,  0.0000,  0.0000,  0.0000]]], device='cuda:0')\n",
      "noisy_trans_and_rots_torch.Size([1, 20, 7])_tensor([[[ 0.8636,  0.0000,  0.1918, -0.3068,  0.0000,  0.0000,  0.6603],\n",
      "         [ 1.6132,  0.0000,  0.8812,  1.9716,  0.0000,  0.0000, -0.8975],\n",
      "         [-0.0321,  0.0000,  0.2308,  0.2796,  0.0000,  0.0000,  0.2940],\n",
      "         [-0.3896,  0.0000,  0.0558,  0.6474,  0.0000,  0.0000, -0.8311],\n",
      "         [-1.0042,  0.0000, -0.5094, -0.0041,  0.0000,  0.0000, -1.3790],\n",
      "         [-0.0611,  0.0000,  0.5080, -0.6679,  0.0000,  0.0000, -1.0562],\n",
      "         [ 0.1600,  0.0000, -1.3053, -0.2903,  0.0000,  0.0000,  0.1227],\n",
      "         [ 0.7242,  0.0000,  0.6134, -1.5972,  0.0000,  0.0000,  0.5130],\n",
      "         [-0.8460,  0.0000,  0.9402,  0.0145,  0.0000,  0.0000,  1.2374],\n",
      "         [ 1.1904,  0.0000,  1.7304,  0.3149,  0.0000,  0.0000,  0.4413],\n",
      "         [-0.4143,  0.0000, -1.3566, -0.4753,  0.0000,  0.0000, -0.5082],\n",
      "         [-0.7480,  0.0000, -0.8201,  0.3008,  0.0000,  0.0000, -0.3561],\n",
      "         [ 0.8315,  0.0000,  1.8847,  0.8534,  0.0000,  0.0000, -0.6363],\n",
      "         [-0.8269,  0.0000,  0.1732,  2.0397,  0.0000,  0.0000, -0.9432],\n",
      "         [ 0.9220,  0.0000, -2.8888, -1.0454,  0.0000,  0.0000,  1.1441],\n",
      "         [ 0.8228,  0.0000, -0.9583,  0.2842,  0.0000,  0.0000, -1.6308],\n",
      "         [-0.7529,  0.0000,  0.4036, -1.6160,  0.0000,  0.0000,  0.5061],\n",
      "         [-0.7041,  0.0000,  1.1498,  0.1037,  0.0000,  0.0000, -0.4276],\n",
      "         [ 0.9548,  0.0000,  2.6045,  1.8676,  0.0000,  0.0000,  0.3580],\n",
      "         [ 1.6258,  0.0000, -0.6286, -0.0047,  0.0000,  0.0000,  0.8426]]],\n",
      "       device='cuda:0')\n",
      "================iter 0============\n",
      "['shape/cube/1/cube_64_32_0_1_0']\n",
      "tensor([[ True, False, False, False, False, False, False, False, False, False,\n",
      "         False, False, False, False, False, False, False, False, False, False]],\n",
      "       device='cuda:0')\n",
      "acc torch.Size([1]) tensor([0.0625], device='cuda:0')\n",
      "acc_per_part torch.Size([1, 20]) tensor([[ True, False, False, False, False, False, False, False, False, False,\n",
      "         False, False, False, False, False, False, False, False, False, False]],\n",
      "       device='cuda:0')\n",
      "loss_per_data torch.Size([1, 20]) tensor([[ 0.0000,  9.8803,  1.9774, 10.7501,  1.5779,  3.1064,  8.3503,  7.3385,\n",
      "          1.1700,  9.5505,  1.7172,  1.3906,  9.5848,  2.5044, 29.5595,  3.5195,\n",
      "          2.7831,  1.5778, 28.4319,  1.6943]], device='cuda:0')\n",
      "scores torch.Size([1, 190, 1]) tensor([[[0.1846],\n",
      "         [0.9756],\n",
      "         [0.3112],\n",
      "         [0.5373],\n",
      "         [0.2488],\n",
      "         [0.3777],\n",
      "         [0.9741],\n",
      "         [0.6618],\n",
      "         [0.8745],\n",
      "         [0.2690],\n",
      "         [0.7910],\n",
      "         [0.1257],\n",
      "         [0.0891],\n",
      "         [0.5064],\n",
      "         [0.3437],\n",
      "         [0.8316],\n",
      "         [0.8198],\n",
      "         [0.5033],\n",
      "         [0.3540],\n",
      "         [0.6763],\n",
      "         [0.5580],\n",
      "         [0.0318],\n",
      "         [0.5244],\n",
      "         [0.9767],\n",
      "         [0.3547],\n",
      "         [0.9048],\n",
      "         [0.3833],\n",
      "         [0.6615],\n",
      "         [0.2244],\n",
      "         [0.8605],\n",
      "         [0.6149],\n",
      "         [0.9684],\n",
      "         [0.9283],\n",
      "         [0.0771],\n",
      "         [0.5534],\n",
      "         [0.2862],\n",
      "         [0.8329],\n",
      "         [0.6022],\n",
      "         [0.6967],\n",
      "         [0.9302],\n",
      "         [0.1674],\n",
      "         [0.1545],\n",
      "         [0.0733],\n",
      "         [0.1896],\n",
      "         [0.3258],\n",
      "         [0.1120],\n",
      "         [0.3459],\n",
      "         [0.6414],\n",
      "         [0.5700],\n",
      "         [0.5131],\n",
      "         [0.1228],\n",
      "         [0.6889],\n",
      "         [0.4031],\n",
      "         [0.2376],\n",
      "         [0.8342],\n",
      "         [0.7472],\n",
      "         [0.3820],\n",
      "         [0.9650],\n",
      "         [0.1812],\n",
      "         [0.7392],\n",
      "         [0.7097],\n",
      "         [0.8650],\n",
      "         [0.0734],\n",
      "         [0.1778],\n",
      "         [0.1715],\n",
      "         [0.2404],\n",
      "         [0.8419],\n",
      "         [0.7033],\n",
      "         [0.6086],\n",
      "         [0.8613],\n",
      "         [0.6399],\n",
      "         [0.0028],\n",
      "         [0.5802],\n",
      "         [0.6195],\n",
      "         [0.6494],\n",
      "         [0.9223],\n",
      "         [0.6854],\n",
      "         [0.5632],\n",
      "         [0.7882],\n",
      "         [0.7458],\n",
      "         [0.1288],\n",
      "         [0.7932],\n",
      "         [0.6881],\n",
      "         [0.8669],\n",
      "         [0.0876],\n",
      "         [0.8894],\n",
      "         [0.9551],\n",
      "         [0.3054],\n",
      "         [0.7333],\n",
      "         [0.5378],\n",
      "         [0.1527],\n",
      "         [0.5227],\n",
      "         [0.2798],\n",
      "         [0.5817],\n",
      "         [0.4255],\n",
      "         [0.3759],\n",
      "         [0.1809],\n",
      "         [0.5911],\n",
      "         [0.7074],\n",
      "         [0.7142],\n",
      "         [0.2521],\n",
      "         [0.9180],\n",
      "         [0.3912],\n",
      "         [0.7595],\n",
      "         [0.7519],\n",
      "         [0.8230],\n",
      "         [0.9544],\n",
      "         [0.8910],\n",
      "         [0.1699],\n",
      "         [0.0705],\n",
      "         [0.1247],\n",
      "         [0.1161],\n",
      "         [0.2393],\n",
      "         [0.9585],\n",
      "         [0.5685],\n",
      "         [0.0824],\n",
      "         [0.8167],\n",
      "         [0.5536],\n",
      "         [0.7105],\n",
      "         [0.3748],\n",
      "         [0.1847],\n",
      "         [0.2047],\n",
      "         [0.8304],\n",
      "         [0.5573],\n",
      "         [0.6388],\n",
      "         [0.1191],\n",
      "         [0.6037],\n",
      "         [0.1338],\n",
      "         [0.0947],\n",
      "         [0.7499],\n",
      "         [0.8917],\n",
      "         [0.2511],\n",
      "         [0.7808],\n",
      "         [0.4125],\n",
      "         [0.1670],\n",
      "         [0.5772],\n",
      "         [0.3799],\n",
      "         [0.4908],\n",
      "         [0.3875],\n",
      "         [0.8263],\n",
      "         [0.1101],\n",
      "         [0.3219],\n",
      "         [0.4953],\n",
      "         [0.9885],\n",
      "         [0.2060],\n",
      "         [0.2206],\n",
      "         [0.1809],\n",
      "         [0.4351],\n",
      "         [0.1807],\n",
      "         [0.7776],\n",
      "         [0.5168],\n",
      "         [0.0857],\n",
      "         [0.5287],\n",
      "         [0.3586],\n",
      "         [0.6154],\n",
      "         [0.0415],\n",
      "         [0.0821],\n",
      "         [0.8036],\n",
      "         [0.7850],\n",
      "         [0.3197],\n",
      "         [0.1496],\n",
      "         [0.8567],\n",
      "         [0.8961],\n",
      "         [0.8472],\n",
      "         [0.6382],\n",
      "         [0.5683],\n",
      "         [0.6303],\n",
      "         [0.1203],\n",
      "         [0.3922],\n",
      "         [0.6892],\n",
      "         [0.0823],\n",
      "         [0.9747],\n",
      "         [0.2554],\n",
      "         [0.2151],\n",
      "         [0.9332],\n",
      "         [0.0275],\n",
      "         [0.4848],\n",
      "         [0.0443],\n",
      "         [0.7479],\n",
      "         [0.1498],\n",
      "         [0.6197],\n",
      "         [0.8981],\n",
      "         [0.9896],\n",
      "         [0.9461],\n",
      "         [0.2363],\n",
      "         [0.5384],\n",
      "         [0.7939],\n",
      "         [0.2119],\n",
      "         [0.2238],\n",
      "         [0.5864]]], device='cuda:0', dtype=torch.float64)\n",
      "================iter 1============\n",
      "['shape/cube/1/cube_64_32_0_1_0']\n",
      "tensor([[ True, False,  True, False, False, False, False,  True, False, False,\n",
      "         False, False, False, False, False, False, False, False, False, False]],\n",
      "       device='cuda:0')\n",
      "acc torch.Size([1]) tensor([0.0625], device='cuda:0')\n",
      "acc_per_part torch.Size([1, 20]) tensor([[ True, False, False, False, False, False, False, False, False, False,\n",
      "         False, False, False, False, False, False, False, False, False, False]],\n",
      "       device='cuda:0')\n",
      "loss_per_data torch.Size([1, 20]) tensor([[  0.0000,   3.0067,   1.9774,  25.7890,   3.9679,   3.1207,   8.1718,\n",
      "           7.3385, 109.0576,  10.0335,   1.5124,   1.8340,   4.5357,   1.8625,\n",
      "          12.9727,   1.3152,   0.5722,  21.7144,  35.3569,   2.4400]],\n",
      "       device='cuda:0')\n",
      "scores torch.Size([1, 190, 1]) tensor([[[0.6685],\n",
      "         [0.0367],\n",
      "         [0.9917],\n",
      "         [0.7697],\n",
      "         [0.4533],\n",
      "         [0.0793],\n",
      "         [0.8173],\n",
      "         [0.6329],\n",
      "         [0.5339],\n",
      "         [0.1978],\n",
      "         [0.3944],\n",
      "         [0.4035],\n",
      "         [0.8755],\n",
      "         [0.1889],\n",
      "         [0.6745],\n",
      "         [0.4844],\n",
      "         [0.9972],\n",
      "         [0.1448],\n",
      "         [0.2279],\n",
      "         [0.5832],\n",
      "         [0.7518],\n",
      "         [0.3847],\n",
      "         [0.4842],\n",
      "         [0.6634],\n",
      "         [0.4674],\n",
      "         [0.5398],\n",
      "         [0.7658],\n",
      "         [0.6185],\n",
      "         [0.3086],\n",
      "         [0.8325],\n",
      "         [0.5464],\n",
      "         [0.3921],\n",
      "         [0.2775],\n",
      "         [0.3024],\n",
      "         [0.8492],\n",
      "         [0.7891],\n",
      "         [0.5106],\n",
      "         [0.4690],\n",
      "         [0.9421],\n",
      "         [0.9953],\n",
      "         [0.4000],\n",
      "         [0.7727],\n",
      "         [0.6426],\n",
      "         [0.4609],\n",
      "         [0.7354],\n",
      "         [0.4111],\n",
      "         [0.9518],\n",
      "         [0.4251],\n",
      "         [0.4533],\n",
      "         [0.0139],\n",
      "         [0.4627],\n",
      "         [0.5719],\n",
      "         [0.0980],\n",
      "         [0.3276],\n",
      "         [0.9765],\n",
      "         [0.9127],\n",
      "         [0.6046],\n",
      "         [0.5600],\n",
      "         [0.6538],\n",
      "         [0.2500],\n",
      "         [0.8150],\n",
      "         [0.6537],\n",
      "         [0.0420],\n",
      "         [0.8785],\n",
      "         [0.9142],\n",
      "         [0.1106],\n",
      "         [0.4854],\n",
      "         [0.0423],\n",
      "         [0.4726],\n",
      "         [0.0494],\n",
      "         [0.1780],\n",
      "         [0.0125],\n",
      "         [0.7067],\n",
      "         [0.5810],\n",
      "         [0.0548],\n",
      "         [0.7266],\n",
      "         [0.6329],\n",
      "         [0.2565],\n",
      "         [0.9794],\n",
      "         [0.6362],\n",
      "         [0.5363],\n",
      "         [0.7576],\n",
      "         [0.8293],\n",
      "         [0.4510],\n",
      "         [0.2164],\n",
      "         [0.3973],\n",
      "         [0.2299],\n",
      "         [0.1164],\n",
      "         [0.4090],\n",
      "         [0.8484],\n",
      "         [0.7123],\n",
      "         [0.6674],\n",
      "         [0.1005],\n",
      "         [0.4068],\n",
      "         [0.9347],\n",
      "         [0.4849],\n",
      "         [0.3636],\n",
      "         [0.5341],\n",
      "         [0.4748],\n",
      "         [0.8685],\n",
      "         [0.6062],\n",
      "         [0.0085],\n",
      "         [0.1439],\n",
      "         [0.8271],\n",
      "         [0.9630],\n",
      "         [0.2654],\n",
      "         [0.2022],\n",
      "         [0.2476],\n",
      "         [0.0680],\n",
      "         [0.6592],\n",
      "         [0.8687],\n",
      "         [0.5967],\n",
      "         [0.5094],\n",
      "         [0.6166],\n",
      "         [0.3829],\n",
      "         [0.8213],\n",
      "         [0.9906],\n",
      "         [0.7582],\n",
      "         [0.2254],\n",
      "         [0.6360],\n",
      "         [0.8620],\n",
      "         [0.1174],\n",
      "         [0.1067],\n",
      "         [0.5111],\n",
      "         [0.6658],\n",
      "         [0.3690],\n",
      "         [0.2001],\n",
      "         [0.4651],\n",
      "         [0.4593],\n",
      "         [0.1916],\n",
      "         [0.8507],\n",
      "         [0.9474],\n",
      "         [0.6223],\n",
      "         [0.6291],\n",
      "         [0.4876],\n",
      "         [0.4828],\n",
      "         [0.3379],\n",
      "         [0.3238],\n",
      "         [0.6878],\n",
      "         [0.1608],\n",
      "         [0.5723],\n",
      "         [0.5296],\n",
      "         [0.2005],\n",
      "         [0.4108],\n",
      "         [0.2418],\n",
      "         [0.4550],\n",
      "         [0.6611],\n",
      "         [0.0947],\n",
      "         [0.9818],\n",
      "         [0.1008],\n",
      "         [0.0688],\n",
      "         [0.9525],\n",
      "         [0.8097],\n",
      "         [0.2874],\n",
      "         [0.5986],\n",
      "         [0.1227],\n",
      "         [0.4387],\n",
      "         [0.6822],\n",
      "         [0.3214],\n",
      "         [0.9809],\n",
      "         [0.5310],\n",
      "         [0.5873],\n",
      "         [0.4369],\n",
      "         [0.4210],\n",
      "         [0.8908],\n",
      "         [0.4723],\n",
      "         [0.2191],\n",
      "         [0.0308],\n",
      "         [0.8853],\n",
      "         [0.0721],\n",
      "         [0.6156],\n",
      "         [0.0089],\n",
      "         [0.1376],\n",
      "         [0.2556],\n",
      "         [0.0392],\n",
      "         [0.2882],\n",
      "         [0.0898],\n",
      "         [0.1883],\n",
      "         [0.1006],\n",
      "         [0.7500],\n",
      "         [0.2563],\n",
      "         [0.6428],\n",
      "         [0.9819],\n",
      "         [0.2568],\n",
      "         [0.0383],\n",
      "         [0.0280],\n",
      "         [0.2375],\n",
      "         [0.6133],\n",
      "         [0.8902],\n",
      "         [0.1089]]], device='cuda:0', dtype=torch.float64)\n",
      "================iter 2============\n",
      "['shape/cube/1/cube_64_32_0_1_0']\n",
      "tensor([[ True, False,  True,  True,  True,  True, False,  True, False, False,\n",
      "         False, False,  True, False, False, False, False, False, False, False]],\n",
      "       device='cuda:0')\n",
      "acc torch.Size([1]) tensor([0.0625], device='cuda:0')\n",
      "acc_per_part torch.Size([1, 20]) tensor([[ True, False, False, False, False, False, False, False, False, False,\n",
      "         False, False, False, False, False, False, False, False, False, False]],\n",
      "       device='cuda:0')\n",
      "loss_per_data torch.Size([1, 20]) tensor([[0.0000e+00, 5.9266e+00, 1.9774e+00, 2.5789e+01, 3.9679e+00, 3.1207e+00,\n",
      "         2.8002e+01, 7.3385e+00, 1.2070e+03, 2.0858e+01, 8.8174e+00, 1.1355e+00,\n",
      "         4.5357e+00, 3.2366e+00, 4.0230e+01, 2.7813e+00, 3.5926e-01, 4.2677e+01,\n",
      "         9.1894e+01, 1.4244e+00]], device='cuda:0')\n",
      "scores torch.Size([1, 190, 1]) tensor([[[6.5502e-01],\n",
      "         [2.5894e-01],\n",
      "         [9.9818e-01],\n",
      "         [3.5512e-01],\n",
      "         [6.0872e-01],\n",
      "         [1.2317e-01],\n",
      "         [7.1315e-01],\n",
      "         [8.9323e-01],\n",
      "         [2.3415e-01],\n",
      "         [9.4461e-01],\n",
      "         [5.0918e-01],\n",
      "         [3.4808e-01],\n",
      "         [5.5974e-01],\n",
      "         [5.7633e-01],\n",
      "         [1.3527e-01],\n",
      "         [6.8117e-01],\n",
      "         [6.5300e-01],\n",
      "         [8.0529e-01],\n",
      "         [6.4024e-01],\n",
      "         [5.1612e-01],\n",
      "         [5.8279e-01],\n",
      "         [9.6379e-01],\n",
      "         [5.0119e-01],\n",
      "         [5.1495e-01],\n",
      "         [9.2259e-01],\n",
      "         [5.3233e-01],\n",
      "         [8.8116e-01],\n",
      "         [1.7295e-01],\n",
      "         [3.6179e-01],\n",
      "         [3.0361e-01],\n",
      "         [7.2760e-01],\n",
      "         [8.5499e-01],\n",
      "         [3.6183e-01],\n",
      "         [4.1219e-01],\n",
      "         [1.1252e-01],\n",
      "         [4.6697e-02],\n",
      "         [5.1388e-01],\n",
      "         [6.3327e-01],\n",
      "         [2.0889e-01],\n",
      "         [4.5190e-01],\n",
      "         [1.6530e-02],\n",
      "         [1.1903e-01],\n",
      "         [6.1683e-01],\n",
      "         [7.8944e-01],\n",
      "         [5.3917e-01],\n",
      "         [7.6395e-01],\n",
      "         [7.0644e-01],\n",
      "         [1.8498e-01],\n",
      "         [5.7852e-01],\n",
      "         [1.2322e-01],\n",
      "         [8.9000e-01],\n",
      "         [4.9423e-01],\n",
      "         [4.5282e-01],\n",
      "         [2.1472e-01],\n",
      "         [4.9706e-01],\n",
      "         [6.6688e-01],\n",
      "         [5.0644e-01],\n",
      "         [2.4566e-01],\n",
      "         [6.4072e-02],\n",
      "         [8.1536e-01],\n",
      "         [7.9911e-02],\n",
      "         [3.0566e-02],\n",
      "         [4.7351e-01],\n",
      "         [6.1306e-01],\n",
      "         [8.8391e-01],\n",
      "         [6.4280e-01],\n",
      "         [5.7542e-01],\n",
      "         [6.3568e-01],\n",
      "         [9.5751e-01],\n",
      "         [8.7471e-01],\n",
      "         [5.6771e-01],\n",
      "         [5.9953e-01],\n",
      "         [6.9285e-01],\n",
      "         [7.4738e-01],\n",
      "         [8.0885e-01],\n",
      "         [4.4760e-01],\n",
      "         [7.5311e-01],\n",
      "         [3.4796e-01],\n",
      "         [8.6436e-01],\n",
      "         [4.4993e-01],\n",
      "         [9.3856e-01],\n",
      "         [5.0478e-01],\n",
      "         [7.4530e-02],\n",
      "         [2.1746e-01],\n",
      "         [4.2659e-01],\n",
      "         [7.8972e-01],\n",
      "         [5.7804e-02],\n",
      "         [2.5632e-01],\n",
      "         [6.9471e-01],\n",
      "         [5.5778e-01],\n",
      "         [1.1185e-01],\n",
      "         [3.6076e-01],\n",
      "         [8.4707e-02],\n",
      "         [5.8379e-01],\n",
      "         [2.7052e-01],\n",
      "         [5.7421e-01],\n",
      "         [4.2932e-03],\n",
      "         [5.7347e-01],\n",
      "         [9.0213e-01],\n",
      "         [7.7370e-01],\n",
      "         [8.4012e-01],\n",
      "         [2.5114e-01],\n",
      "         [9.2686e-01],\n",
      "         [1.6523e-03],\n",
      "         [5.0049e-01],\n",
      "         [1.7571e-01],\n",
      "         [6.3301e-01],\n",
      "         [8.9901e-01],\n",
      "         [6.3187e-01],\n",
      "         [8.9534e-01],\n",
      "         [2.7289e-01],\n",
      "         [3.2585e-01],\n",
      "         [8.0302e-01],\n",
      "         [5.5383e-01],\n",
      "         [5.4318e-01],\n",
      "         [5.9244e-01],\n",
      "         [1.2918e-01],\n",
      "         [1.1751e-01],\n",
      "         [1.8998e-01],\n",
      "         [7.7238e-01],\n",
      "         [6.4333e-01],\n",
      "         [8.6760e-02],\n",
      "         [6.0972e-01],\n",
      "         [4.9483e-01],\n",
      "         [9.2916e-01],\n",
      "         [8.5191e-01],\n",
      "         [2.9500e-01],\n",
      "         [6.5341e-01],\n",
      "         [3.5099e-01],\n",
      "         [6.1998e-01],\n",
      "         [1.9353e-01],\n",
      "         [3.9589e-01],\n",
      "         [1.7433e-01],\n",
      "         [1.0595e-01],\n",
      "         [3.9991e-01],\n",
      "         [6.9189e-01],\n",
      "         [4.8643e-01],\n",
      "         [8.5058e-01],\n",
      "         [3.5410e-02],\n",
      "         [9.9894e-01],\n",
      "         [5.2818e-01],\n",
      "         [7.4441e-02],\n",
      "         [9.7698e-01],\n",
      "         [6.0256e-01],\n",
      "         [6.2077e-01],\n",
      "         [3.0021e-01],\n",
      "         [6.9760e-01],\n",
      "         [3.2584e-01],\n",
      "         [4.3249e-01],\n",
      "         [9.5382e-01],\n",
      "         [8.8052e-01],\n",
      "         [7.0462e-01],\n",
      "         [1.4654e-01],\n",
      "         [4.5429e-01],\n",
      "         [2.8695e-01],\n",
      "         [4.9810e-01],\n",
      "         [3.4169e-01],\n",
      "         [3.4553e-02],\n",
      "         [8.2318e-01],\n",
      "         [8.6113e-01],\n",
      "         [2.2155e-01],\n",
      "         [1.0673e-04],\n",
      "         [6.2585e-01],\n",
      "         [1.9630e-01],\n",
      "         [7.6509e-01],\n",
      "         [4.6931e-01],\n",
      "         [3.6439e-01],\n",
      "         [7.6413e-01],\n",
      "         [2.2636e-01],\n",
      "         [3.3820e-02],\n",
      "         [5.6270e-01],\n",
      "         [8.5810e-01],\n",
      "         [5.9695e-01],\n",
      "         [5.6863e-01],\n",
      "         [3.7806e-01],\n",
      "         [5.4415e-01],\n",
      "         [3.8327e-01],\n",
      "         [7.5120e-01],\n",
      "         [6.8307e-01],\n",
      "         [5.6349e-01],\n",
      "         [6.1953e-01],\n",
      "         [8.0827e-01],\n",
      "         [3.7468e-01],\n",
      "         [1.6126e-01],\n",
      "         [5.7694e-01],\n",
      "         [6.6918e-01],\n",
      "         [4.6600e-02],\n",
      "         [2.1845e-01],\n",
      "         [2.6630e-02],\n",
      "         [2.5215e-01]]], device='cuda:0', dtype=torch.float64)\n",
      "================iter 3============\n",
      "['shape/cube/1/cube_64_32_0_1_0']\n",
      "tensor([[ True,  True,  True,  True,  True,  True, False,  True, False, False,\n",
      "          True, False,  True, False, False,  True, False, False, False, False]],\n",
      "       device='cuda:0')\n",
      "acc torch.Size([1]) tensor([0.0625], device='cuda:0')\n",
      "acc_per_part torch.Size([1, 20]) tensor([[ True, False, False, False, False, False, False, False, False, False,\n",
      "         False, False, False, False, False, False, False, False, False, False]],\n",
      "       device='cuda:0')\n",
      "loss_per_data torch.Size([1, 20]) tensor([[0.0000e+00, 5.9266e+00, 1.9774e+00, 2.5789e+01, 3.9679e+00, 3.1207e+00,\n",
      "         6.3689e+01, 7.3385e+00, 1.3016e+03, 4.7973e+01, 8.8174e+00, 7.1657e+00,\n",
      "         4.5357e+00, 1.2686e+01, 5.0767e+01, 2.7813e+00, 4.7304e+00, 5.5157e+01,\n",
      "         1.2214e+02, 6.2966e-01]], device='cuda:0')\n",
      "scores torch.Size([1, 190, 1]) tensor([[[0.9693],\n",
      "         [0.1215],\n",
      "         [0.7804],\n",
      "         [0.0213],\n",
      "         [0.3866],\n",
      "         [0.8368],\n",
      "         [0.8399],\n",
      "         [0.2802],\n",
      "         [0.0162],\n",
      "         [0.9083],\n",
      "         [0.0355],\n",
      "         [0.3735],\n",
      "         [0.4375],\n",
      "         [0.4944],\n",
      "         [0.6789],\n",
      "         [0.7837],\n",
      "         [0.7799],\n",
      "         [0.9683],\n",
      "         [0.3806],\n",
      "         [0.3908],\n",
      "         [0.4594],\n",
      "         [0.5300],\n",
      "         [0.6133],\n",
      "         [0.3770],\n",
      "         [0.0032],\n",
      "         [0.6498],\n",
      "         [0.0201],\n",
      "         [0.1439],\n",
      "         [0.1447],\n",
      "         [0.6808],\n",
      "         [0.9736],\n",
      "         [0.2969],\n",
      "         [0.7223],\n",
      "         [0.6592],\n",
      "         [0.4414],\n",
      "         [0.3233],\n",
      "         [0.4057],\n",
      "         [0.3317],\n",
      "         [0.6091],\n",
      "         [0.1750],\n",
      "         [0.8095],\n",
      "         [0.8511],\n",
      "         [0.3103],\n",
      "         [0.4491],\n",
      "         [0.8245],\n",
      "         [0.9678],\n",
      "         [0.9197],\n",
      "         [0.0145],\n",
      "         [0.1311],\n",
      "         [0.2273],\n",
      "         [0.9353],\n",
      "         [0.6958],\n",
      "         [0.8653],\n",
      "         [0.9741],\n",
      "         [0.8243],\n",
      "         [0.1093],\n",
      "         [0.2116],\n",
      "         [0.7560],\n",
      "         [0.0720],\n",
      "         [0.4693],\n",
      "         [0.9911],\n",
      "         [0.6583],\n",
      "         [0.3281],\n",
      "         [0.0644],\n",
      "         [0.8171],\n",
      "         [0.0862],\n",
      "         [0.3461],\n",
      "         [0.0097],\n",
      "         [0.4909],\n",
      "         [0.3101],\n",
      "         [0.9733],\n",
      "         [0.8378],\n",
      "         [0.4831],\n",
      "         [0.6210],\n",
      "         [0.3506],\n",
      "         [0.8453],\n",
      "         [0.3850],\n",
      "         [0.5451],\n",
      "         [0.8585],\n",
      "         [0.8282],\n",
      "         [0.1434],\n",
      "         [0.3090],\n",
      "         [0.4132],\n",
      "         [0.1745],\n",
      "         [0.8817],\n",
      "         [0.6698],\n",
      "         [0.9016],\n",
      "         [0.8363],\n",
      "         [0.2556],\n",
      "         [0.1959],\n",
      "         [0.5286],\n",
      "         [0.9869],\n",
      "         [0.7157],\n",
      "         [0.3540],\n",
      "         [0.2251],\n",
      "         [0.0990],\n",
      "         [0.3424],\n",
      "         [0.9230],\n",
      "         [0.5445],\n",
      "         [0.1703],\n",
      "         [0.4457],\n",
      "         [0.9217],\n",
      "         [0.3076],\n",
      "         [0.9116],\n",
      "         [0.0118],\n",
      "         [0.6251],\n",
      "         [0.2150],\n",
      "         [0.3575],\n",
      "         [0.2568],\n",
      "         [0.2135],\n",
      "         [0.1072],\n",
      "         [0.1547],\n",
      "         [0.6369],\n",
      "         [0.7714],\n",
      "         [0.8781],\n",
      "         [0.2922],\n",
      "         [0.2622],\n",
      "         [0.2941],\n",
      "         [0.0380],\n",
      "         [0.2680],\n",
      "         [0.1420],\n",
      "         [0.3520],\n",
      "         [0.7335],\n",
      "         [0.8691],\n",
      "         [0.6182],\n",
      "         [0.3406],\n",
      "         [0.7940],\n",
      "         [0.7501],\n",
      "         [0.7723],\n",
      "         [0.9471],\n",
      "         [0.7227],\n",
      "         [0.0365],\n",
      "         [0.0823],\n",
      "         [0.1811],\n",
      "         [0.7308],\n",
      "         [0.2102],\n",
      "         [0.5984],\n",
      "         [0.4166],\n",
      "         [0.2887],\n",
      "         [0.2881],\n",
      "         [0.5365],\n",
      "         [0.0218],\n",
      "         [0.8414],\n",
      "         [0.3058],\n",
      "         [0.0641],\n",
      "         [0.8126],\n",
      "         [0.0258],\n",
      "         [0.2376],\n",
      "         [0.0754],\n",
      "         [0.2166],\n",
      "         [0.3096],\n",
      "         [0.1930],\n",
      "         [0.6060],\n",
      "         [0.9657],\n",
      "         [0.7690],\n",
      "         [0.6463],\n",
      "         [0.5023],\n",
      "         [0.5436],\n",
      "         [0.3255],\n",
      "         [0.2202],\n",
      "         [0.3100],\n",
      "         [0.2171],\n",
      "         [0.8501],\n",
      "         [0.1041],\n",
      "         [0.9228],\n",
      "         [0.1498],\n",
      "         [0.6768],\n",
      "         [0.8335],\n",
      "         [0.8645],\n",
      "         [0.3023],\n",
      "         [0.1330],\n",
      "         [0.6764],\n",
      "         [0.7453],\n",
      "         [0.3337],\n",
      "         [0.5292],\n",
      "         [0.0230],\n",
      "         [0.0608],\n",
      "         [0.2555],\n",
      "         [0.5477],\n",
      "         [0.1301],\n",
      "         [0.1945],\n",
      "         [0.7103],\n",
      "         [0.7684],\n",
      "         [0.7445],\n",
      "         [0.4629],\n",
      "         [0.4975],\n",
      "         [0.9686],\n",
      "         [0.8886],\n",
      "         [0.7314],\n",
      "         [0.1331]]], device='cuda:0', dtype=torch.float64)\n",
      "================iter 4============\n",
      "['shape/cube/1/cube_64_32_0_1_0']\n",
      "tensor([[ True,  True,  True,  True,  True,  True, False,  True, False, False,\n",
      "          True,  True,  True,  True, False,  True, False, False, False, False]],\n",
      "       device='cuda:0')\n",
      "acc torch.Size([1]) tensor([0.0625], device='cuda:0')\n",
      "acc_per_part torch.Size([1, 20]) tensor([[ True, False, False, False, False, False, False, False, False, False,\n",
      "         False, False, False, False, False, False, False, False, False, False]],\n",
      "       device='cuda:0')\n",
      "loss_per_data torch.Size([1, 20]) tensor([[0.0000e+00, 5.9266e+00, 1.9774e+00, 2.5789e+01, 3.9679e+00, 3.1207e+00,\n",
      "         1.1364e+02, 7.3385e+00, 4.3340e+03, 1.5228e+02, 8.8174e+00, 7.1657e+00,\n",
      "         4.5357e+00, 1.2686e+01, 1.6913e+02, 2.7813e+00, 4.9925e+00, 8.9067e+01,\n",
      "         2.2650e+02, 9.2340e+00]], device='cuda:0')\n",
      "scores torch.Size([1, 190, 1]) tensor([[[0.8541],\n",
      "         [0.1449],\n",
      "         [0.5348],\n",
      "         [0.8823],\n",
      "         [0.4189],\n",
      "         [0.5236],\n",
      "         [0.1908],\n",
      "         [0.8579],\n",
      "         [0.6943],\n",
      "         [0.9134],\n",
      "         [0.5136],\n",
      "         [0.2140],\n",
      "         [0.6074],\n",
      "         [0.2801],\n",
      "         [0.5638],\n",
      "         [0.5325],\n",
      "         [0.5643],\n",
      "         [0.3666],\n",
      "         [0.6680],\n",
      "         [0.4458],\n",
      "         [0.8708],\n",
      "         [0.5256],\n",
      "         [0.9170],\n",
      "         [0.4450],\n",
      "         [0.2997],\n",
      "         [0.0902],\n",
      "         [0.3286],\n",
      "         [0.8787],\n",
      "         [0.1211],\n",
      "         [0.6407],\n",
      "         [0.6419],\n",
      "         [0.0439],\n",
      "         [0.0554],\n",
      "         [0.3147],\n",
      "         [0.1788],\n",
      "         [0.9515],\n",
      "         [0.4978],\n",
      "         [0.8130],\n",
      "         [0.0021],\n",
      "         [0.7262],\n",
      "         [0.9317],\n",
      "         [0.4843],\n",
      "         [0.7952],\n",
      "         [0.4492],\n",
      "         [0.7121],\n",
      "         [0.5024],\n",
      "         [0.2251],\n",
      "         [0.3841],\n",
      "         [0.1059],\n",
      "         [0.7004],\n",
      "         [0.2764],\n",
      "         [0.4324],\n",
      "         [0.1111],\n",
      "         [0.1557],\n",
      "         [0.2402],\n",
      "         [0.1799],\n",
      "         [0.1843],\n",
      "         [0.7211],\n",
      "         [0.4489],\n",
      "         [0.7765],\n",
      "         [0.4607],\n",
      "         [0.7015],\n",
      "         [0.5661],\n",
      "         [0.9423],\n",
      "         [0.9551],\n",
      "         [0.3697],\n",
      "         [0.3730],\n",
      "         [0.9179],\n",
      "         [0.0316],\n",
      "         [0.4106],\n",
      "         [0.9406],\n",
      "         [0.6548],\n",
      "         [0.6514],\n",
      "         [0.3193],\n",
      "         [0.3740],\n",
      "         [0.7245],\n",
      "         [0.5762],\n",
      "         [0.6355],\n",
      "         [0.7370],\n",
      "         [0.8527],\n",
      "         [0.9486],\n",
      "         [0.5282],\n",
      "         [0.9488],\n",
      "         [0.2515],\n",
      "         [0.8342],\n",
      "         [0.4326],\n",
      "         [0.0948],\n",
      "         [0.6646],\n",
      "         [0.8948],\n",
      "         [0.0057],\n",
      "         [0.7647],\n",
      "         [0.3894],\n",
      "         [0.9116],\n",
      "         [0.5077],\n",
      "         [0.6757],\n",
      "         [0.2863],\n",
      "         [0.3879],\n",
      "         [0.2724],\n",
      "         [0.0956],\n",
      "         [0.9091],\n",
      "         [0.2178],\n",
      "         [0.1494],\n",
      "         [0.1910],\n",
      "         [0.3502],\n",
      "         [0.8963],\n",
      "         [0.2622],\n",
      "         [0.5381],\n",
      "         [0.1325],\n",
      "         [0.1540],\n",
      "         [0.9367],\n",
      "         [0.6699],\n",
      "         [0.2603],\n",
      "         [0.6390],\n",
      "         [0.5964],\n",
      "         [0.1275],\n",
      "         [0.8684],\n",
      "         [0.7418],\n",
      "         [0.5505],\n",
      "         [0.7004],\n",
      "         [0.8710],\n",
      "         [0.6879],\n",
      "         [0.5576],\n",
      "         [0.6412],\n",
      "         [0.8307],\n",
      "         [0.9003],\n",
      "         [0.5641],\n",
      "         [0.0699],\n",
      "         [0.7068],\n",
      "         [0.8465],\n",
      "         [0.6915],\n",
      "         [0.1119],\n",
      "         [0.8939],\n",
      "         [0.0126],\n",
      "         [0.0584],\n",
      "         [0.6986],\n",
      "         [0.7414],\n",
      "         [0.3172],\n",
      "         [0.1606],\n",
      "         [0.0713],\n",
      "         [0.3144],\n",
      "         [0.3647],\n",
      "         [0.6085],\n",
      "         [0.2653],\n",
      "         [0.2413],\n",
      "         [0.6959],\n",
      "         [0.8009],\n",
      "         [0.1478],\n",
      "         [0.9872],\n",
      "         [0.3415],\n",
      "         [0.7420],\n",
      "         [0.5311],\n",
      "         [0.7772],\n",
      "         [0.4472],\n",
      "         [0.8388],\n",
      "         [0.9520],\n",
      "         [0.8313],\n",
      "         [0.1217],\n",
      "         [0.6053],\n",
      "         [0.4770],\n",
      "         [0.2795],\n",
      "         [0.3364],\n",
      "         [0.1372],\n",
      "         [0.8776],\n",
      "         [0.4358],\n",
      "         [0.3293],\n",
      "         [0.8003],\n",
      "         [0.9909],\n",
      "         [0.6427],\n",
      "         [0.3429],\n",
      "         [0.3580],\n",
      "         [0.9788],\n",
      "         [0.8240],\n",
      "         [0.1883],\n",
      "         [0.5622],\n",
      "         [0.0672],\n",
      "         [0.4428],\n",
      "         [0.3734],\n",
      "         [0.9724],\n",
      "         [0.7917],\n",
      "         [0.7186],\n",
      "         [0.8037],\n",
      "         [0.3406],\n",
      "         [0.6755],\n",
      "         [0.6690],\n",
      "         [0.1231],\n",
      "         [0.5581],\n",
      "         [0.4926],\n",
      "         [0.5148],\n",
      "         [0.5347],\n",
      "         [0.7083]]], device='cuda:0', dtype=torch.float64)\n",
      "================iter 5============\n",
      "['shape/cube/1/cube_64_32_0_1_0']\n",
      "tensor([[ True,  True,  True,  True,  True,  True,  True,  True, False, False,\n",
      "          True,  True,  True,  True,  True,  True, False, False, False, False]],\n",
      "       device='cuda:0')\n",
      "@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@\n",
      "['shape/cube/1/fractured_0']\n",
      "gt_trans_torch.Size([1, 20, 3])_tensor([[[ 1.7764e-18,  8.8818e-18,  2.8866e-18],\n",
      "         [ 5.0575e-02,  2.6203e-02, -3.8275e-02],\n",
      "         [ 3.2651e-02,  5.5376e-02, -2.6534e-02],\n",
      "         [-7.4584e-03,  2.7585e-02, -4.2647e-02],\n",
      "         [ 1.4504e-02,  3.8474e-02, -7.2641e-02],\n",
      "         [-7.3179e-03,  4.2428e-02, -7.7231e-02],\n",
      "         [ 5.2268e-03,  6.2657e-02, -9.4158e-02],\n",
      "         [-3.0274e-02,  7.7017e-02, -8.0792e-02],\n",
      "         [-2.6026e-02,  7.6302e-02, -1.0772e-01],\n",
      "         [-3.7514e-02,  8.5781e-02, -1.1527e-01],\n",
      "         [ 0.0000e+00,  0.0000e+00,  0.0000e+00],\n",
      "         [ 0.0000e+00,  0.0000e+00,  0.0000e+00],\n",
      "         [ 0.0000e+00,  0.0000e+00,  0.0000e+00],\n",
      "         [ 0.0000e+00,  0.0000e+00,  0.0000e+00],\n",
      "         [ 0.0000e+00,  0.0000e+00,  0.0000e+00],\n",
      "         [ 0.0000e+00,  0.0000e+00,  0.0000e+00],\n",
      "         [ 0.0000e+00,  0.0000e+00,  0.0000e+00],\n",
      "         [ 0.0000e+00,  0.0000e+00,  0.0000e+00],\n",
      "         [ 0.0000e+00,  0.0000e+00,  0.0000e+00],\n",
      "         [ 0.0000e+00,  0.0000e+00,  0.0000e+00]]], device='cuda:0')\n",
      "gt_rots_torch.Size([1, 20, 4])_tensor([[[-9.6883e-02,  4.3761e-04,  4.2062e-01,  9.0205e-01],\n",
      "         [-5.3438e-01,  1.6221e-01, -2.1355e-01,  8.0157e-01],\n",
      "         [-1.0498e-01,  9.6949e-01,  5.4769e-02,  2.1464e-01],\n",
      "         [ 5.6223e-02,  3.9279e-01,  6.7577e-01, -6.2120e-01],\n",
      "         [ 2.9915e-01, -4.5659e-01, -3.2886e-01,  7.7064e-01],\n",
      "         [-1.3279e-01, -8.7021e-02,  7.5075e-01,  6.4123e-01],\n",
      "         [-3.0296e-01,  7.6492e-01, -2.8603e-01,  4.9122e-01],\n",
      "         [-1.3859e-01, -3.8491e-01,  8.4494e-01, -3.4455e-01],\n",
      "         [ 1.4130e-01,  1.2828e-02,  3.7615e-01,  9.1563e-01],\n",
      "         [ 8.3665e-01,  2.6887e-01, -4.4411e-01, -1.7464e-01],\n",
      "         [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00],\n",
      "         [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00],\n",
      "         [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00],\n",
      "         [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00],\n",
      "         [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00],\n",
      "         [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00],\n",
      "         [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00],\n",
      "         [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00],\n",
      "         [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00],\n",
      "         [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00]]],\n",
      "       device='cuda:0')\n",
      "noisy_trans_and_rots_torch.Size([1, 20, 7])_tensor([[[-1.2066e+00,  0.0000e+00,  6.5174e-01,  9.4095e-01,  0.0000e+00,\n",
      "           0.0000e+00,  8.7023e-01],\n",
      "         [-9.0929e-02,  0.0000e+00,  2.1336e-01,  3.6043e-01,  0.0000e+00,\n",
      "           0.0000e+00,  1.9268e-02],\n",
      "         [ 1.7464e+00,  0.0000e+00, -5.7125e-01,  2.0148e+00,  0.0000e+00,\n",
      "           0.0000e+00, -1.0588e+00],\n",
      "         [-6.4456e-02,  0.0000e+00, -1.0866e+00, -3.8683e-01,  0.0000e+00,\n",
      "           0.0000e+00, -1.1790e+00],\n",
      "         [ 4.7299e-01,  0.0000e+00, -1.8018e-01, -1.4398e+00,  0.0000e+00,\n",
      "           0.0000e+00, -1.0189e+00],\n",
      "         [-1.5234e+00,  0.0000e+00, -1.5912e-02,  5.6041e-01,  0.0000e+00,\n",
      "           0.0000e+00,  1.7127e+00],\n",
      "         [ 1.5898e-01,  0.0000e+00, -1.9758e+00,  4.8134e-01,  0.0000e+00,\n",
      "           0.0000e+00, -2.0408e-01],\n",
      "         [-4.6810e-01,  0.0000e+00, -7.0402e-01,  1.1057e+00,  0.0000e+00,\n",
      "           0.0000e+00,  1.0157e+00],\n",
      "         [ 9.1992e-01,  0.0000e+00,  6.6527e-01,  1.2907e+00,  0.0000e+00,\n",
      "           0.0000e+00,  2.0782e-01],\n",
      "         [ 3.6980e-01,  0.0000e+00, -7.7249e-02,  1.4794e+00,  0.0000e+00,\n",
      "           0.0000e+00, -8.0976e-01],\n",
      "         [-1.3876e+00,  0.0000e+00, -2.6137e+00, -1.0035e+00,  0.0000e+00,\n",
      "           0.0000e+00,  1.6344e+00],\n",
      "         [-1.3561e+00,  0.0000e+00, -5.6596e-01,  7.6654e-01,  0.0000e+00,\n",
      "           0.0000e+00, -1.4632e+00],\n",
      "         [ 1.2834e+00,  0.0000e+00,  6.7086e-01, -4.7667e-01,  0.0000e+00,\n",
      "           0.0000e+00, -1.5501e-03],\n",
      "         [-5.5706e-01,  0.0000e+00, -5.0344e-01, -1.2848e+00,  0.0000e+00,\n",
      "           0.0000e+00, -1.8943e+00],\n",
      "         [ 1.0433e+00,  0.0000e+00, -7.1799e-01, -1.3124e+00,  0.0000e+00,\n",
      "           0.0000e+00, -1.0361e+00],\n",
      "         [ 1.5057e+00,  0.0000e+00,  1.1272e+00, -5.0570e-01,  0.0000e+00,\n",
      "           0.0000e+00, -1.9077e-01],\n",
      "         [ 1.5983e-01,  0.0000e+00,  2.1697e+00,  1.0520e+00,  0.0000e+00,\n",
      "           0.0000e+00,  9.0264e-01],\n",
      "         [ 1.0845e+00,  0.0000e+00,  5.9113e-02,  1.1355e+00,  0.0000e+00,\n",
      "           0.0000e+00, -8.9530e-01],\n",
      "         [ 7.3032e-01,  0.0000e+00,  6.9540e-01,  8.7560e-01,  0.0000e+00,\n",
      "           0.0000e+00,  1.7178e-01],\n",
      "         [ 5.3205e-01,  0.0000e+00,  6.5538e-01, -2.3509e+00,  0.0000e+00,\n",
      "           0.0000e+00, -1.2113e+00]]], device='cuda:0')\n",
      "================iter 0============\n",
      "['shape/cube/1/fractured_0']\n",
      "tensor([[ True, False, False, False, False, False, False, False, False, False,\n",
      "         False, False, False, False, False, False, False, False, False, False]],\n",
      "       device='cuda:0')\n",
      "acc torch.Size([1]) tensor([0.1000], device='cuda:0')\n",
      "acc_per_part torch.Size([1, 20]) tensor([[ True, False, False, False, False, False, False, False, False, False,\n",
      "         False, False, False, False, False, False, False, False, False, False]],\n",
      "       device='cuda:0')\n",
      "loss_per_data torch.Size([1, 20]) tensor([[ 0.0000,  7.3289,  0.5703,  3.0585,  3.3088, 21.8867,  5.4514,  1.3687,\n",
      "          1.7660,  3.6554, 18.3449,  1.0675,  1.5372,  1.4367,  1.1950,  2.1924,\n",
      "          3.9371,  4.9915,  1.8443,  1.3991]], device='cuda:0')\n",
      "scores torch.Size([1, 190, 1]) tensor([[[0.6007],\n",
      "         [0.0782],\n",
      "         [0.9469],\n",
      "         [0.6279],\n",
      "         [0.6804],\n",
      "         [0.3079],\n",
      "         [0.1531],\n",
      "         [0.8449],\n",
      "         [0.3031],\n",
      "         [0.5313],\n",
      "         [0.6643],\n",
      "         [0.2322],\n",
      "         [0.9800],\n",
      "         [0.5913],\n",
      "         [0.4962],\n",
      "         [0.7523],\n",
      "         [0.4908],\n",
      "         [0.4629],\n",
      "         [0.6221],\n",
      "         [0.7667],\n",
      "         [0.8606],\n",
      "         [0.4263],\n",
      "         [0.6568],\n",
      "         [0.7667],\n",
      "         [0.2677],\n",
      "         [0.5141],\n",
      "         [0.7238],\n",
      "         [0.9555],\n",
      "         [0.3761],\n",
      "         [0.8495],\n",
      "         [0.9469],\n",
      "         [0.2079],\n",
      "         [0.0503],\n",
      "         [0.5828],\n",
      "         [0.8201],\n",
      "         [0.1016],\n",
      "         [0.5313],\n",
      "         [0.0972],\n",
      "         [0.4195],\n",
      "         [0.9099],\n",
      "         [0.5478],\n",
      "         [0.4966],\n",
      "         [0.5363],\n",
      "         [0.9013],\n",
      "         [0.8853],\n",
      "         [0.2850],\n",
      "         [0.5050],\n",
      "         [0.8473],\n",
      "         [0.3912],\n",
      "         [0.7027],\n",
      "         [0.3478],\n",
      "         [0.9814],\n",
      "         [0.2952],\n",
      "         [0.5109],\n",
      "         [0.1403],\n",
      "         [0.7891],\n",
      "         [0.8744],\n",
      "         [0.6080],\n",
      "         [0.9262],\n",
      "         [0.5483],\n",
      "         [0.9802],\n",
      "         [0.6743],\n",
      "         [0.3918],\n",
      "         [0.7270],\n",
      "         [0.4162],\n",
      "         [0.2167],\n",
      "         [0.3409],\n",
      "         [0.6443],\n",
      "         [0.3831],\n",
      "         [0.2026],\n",
      "         [0.0959],\n",
      "         [0.6870],\n",
      "         [0.1923],\n",
      "         [0.0165],\n",
      "         [0.9622],\n",
      "         [0.8036],\n",
      "         [0.8876],\n",
      "         [0.3243],\n",
      "         [0.6702],\n",
      "         [0.1119],\n",
      "         [0.2118],\n",
      "         [0.8413],\n",
      "         [0.8403],\n",
      "         [0.9317],\n",
      "         [0.6222],\n",
      "         [0.3535],\n",
      "         [0.4282],\n",
      "         [0.5232],\n",
      "         [0.1101],\n",
      "         [0.1029],\n",
      "         [0.2968],\n",
      "         [0.5567],\n",
      "         [0.9768],\n",
      "         [0.8465],\n",
      "         [0.0274],\n",
      "         [0.7885],\n",
      "         [0.8321],\n",
      "         [0.9369],\n",
      "         [0.1697],\n",
      "         [0.2988],\n",
      "         [0.9858],\n",
      "         [0.0813],\n",
      "         [0.0258],\n",
      "         [0.6985],\n",
      "         [0.4230],\n",
      "         [0.2896],\n",
      "         [0.9501],\n",
      "         [0.2000],\n",
      "         [0.3992],\n",
      "         [0.6549],\n",
      "         [0.2566],\n",
      "         [0.6297],\n",
      "         [0.1881],\n",
      "         [0.5274],\n",
      "         [0.8589],\n",
      "         [0.5148],\n",
      "         [0.7945],\n",
      "         [0.4940],\n",
      "         [0.2637],\n",
      "         [0.5215],\n",
      "         [0.4909],\n",
      "         [0.4481],\n",
      "         [0.2748],\n",
      "         [0.7782],\n",
      "         [0.7171],\n",
      "         [0.3162],\n",
      "         [0.9665],\n",
      "         [0.6078],\n",
      "         [0.4354],\n",
      "         [0.1138],\n",
      "         [0.3014],\n",
      "         [0.8568],\n",
      "         [0.9006],\n",
      "         [0.4683],\n",
      "         [0.5813],\n",
      "         [0.2250],\n",
      "         [0.1986],\n",
      "         [0.0175],\n",
      "         [0.7419],\n",
      "         [0.6939],\n",
      "         [0.3848],\n",
      "         [0.3666],\n",
      "         [0.6448],\n",
      "         [0.1129],\n",
      "         [0.3913],\n",
      "         [0.9354],\n",
      "         [0.5882],\n",
      "         [0.7550],\n",
      "         [0.3725],\n",
      "         [0.6449],\n",
      "         [0.0696],\n",
      "         [0.9423],\n",
      "         [0.0131],\n",
      "         [0.2823],\n",
      "         [0.4154],\n",
      "         [0.6438],\n",
      "         [0.7639],\n",
      "         [0.1715],\n",
      "         [0.0868],\n",
      "         [0.6715],\n",
      "         [0.2292],\n",
      "         [0.9949],\n",
      "         [0.7858],\n",
      "         [0.4451],\n",
      "         [0.0542],\n",
      "         [0.7022],\n",
      "         [0.8104],\n",
      "         [0.4791],\n",
      "         [0.2605],\n",
      "         [0.0730],\n",
      "         [0.6514],\n",
      "         [0.0046],\n",
      "         [0.9914],\n",
      "         [0.2505],\n",
      "         [0.4675],\n",
      "         [0.5679],\n",
      "         [0.5635],\n",
      "         [0.6714],\n",
      "         [0.8314],\n",
      "         [0.0094],\n",
      "         [0.3012],\n",
      "         [0.9120],\n",
      "         [0.5964],\n",
      "         [0.1177],\n",
      "         [0.6546],\n",
      "         [0.5643],\n",
      "         [0.6673],\n",
      "         [0.5879],\n",
      "         [0.1858],\n",
      "         [0.5210]]], device='cuda:0', dtype=torch.float64)\n",
      "================iter 1============\n",
      "['shape/cube/1/fractured_0']\n",
      "tensor([[ True, False, False,  True, False, False, False, False, False, False,\n",
      "         False, False, False, False, False, False, False, False, False, False]],\n",
      "       device='cuda:0')\n",
      "acc torch.Size([1]) tensor([0.1000], device='cuda:0')\n",
      "acc_per_part torch.Size([1, 20]) tensor([[ True, False, False, False, False, False, False, False, False, False,\n",
      "         False, False, False, False, False, False, False, False, False, False]],\n",
      "       device='cuda:0')\n",
      "loss_per_data torch.Size([1, 20]) tensor([[0.0000e+00, 1.5088e+02, 1.2599e+01, 3.0585e+00, 6.8451e+01, 6.2601e+02,\n",
      "         2.8807e+02, 7.2920e+01, 1.8209e+02, 1.1861e+02, 2.6422e+01, 1.6242e+00,\n",
      "         6.3024e-01, 1.4588e-01, 4.6767e-02, 1.2096e+00, 5.0946e-01, 1.8245e+00,\n",
      "         1.1812e+00, 3.4209e+00]], device='cuda:0')\n",
      "scores torch.Size([1, 190, 1]) tensor([[[0.9063],\n",
      "         [0.5717],\n",
      "         [0.1761],\n",
      "         [0.6579],\n",
      "         [0.6359],\n",
      "         [0.6808],\n",
      "         [0.0730],\n",
      "         [0.4952],\n",
      "         [0.2761],\n",
      "         [0.6187],\n",
      "         [0.1367],\n",
      "         [0.1217],\n",
      "         [0.3002],\n",
      "         [0.9930],\n",
      "         [0.1729],\n",
      "         [0.8454],\n",
      "         [0.9029],\n",
      "         [0.0929],\n",
      "         [0.9932],\n",
      "         [0.1351],\n",
      "         [0.9187],\n",
      "         [0.8566],\n",
      "         [0.9355],\n",
      "         [0.0982],\n",
      "         [0.6474],\n",
      "         [0.7239],\n",
      "         [0.7062],\n",
      "         [0.9529],\n",
      "         [0.0609],\n",
      "         [0.7394],\n",
      "         [0.8943],\n",
      "         [0.2192],\n",
      "         [0.8122],\n",
      "         [0.0788],\n",
      "         [0.6640],\n",
      "         [0.6918],\n",
      "         [0.0504],\n",
      "         [0.8790],\n",
      "         [0.0695],\n",
      "         [0.7297],\n",
      "         [0.3348],\n",
      "         [0.1102],\n",
      "         [0.6941],\n",
      "         [0.9223],\n",
      "         [0.8184],\n",
      "         [0.2726],\n",
      "         [0.3744],\n",
      "         [0.5328],\n",
      "         [0.5860],\n",
      "         [0.5683],\n",
      "         [0.3165],\n",
      "         [0.6677],\n",
      "         [0.0794],\n",
      "         [0.3434],\n",
      "         [0.5183],\n",
      "         [0.4875],\n",
      "         [0.9095],\n",
      "         [0.4129],\n",
      "         [0.6680],\n",
      "         [0.2241],\n",
      "         [0.4852],\n",
      "         [0.8283],\n",
      "         [0.8141],\n",
      "         [0.0076],\n",
      "         [0.3403],\n",
      "         [0.8102],\n",
      "         [0.5042],\n",
      "         [0.8172],\n",
      "         [0.3896],\n",
      "         [0.5196],\n",
      "         [0.3772],\n",
      "         [0.7914],\n",
      "         [0.3821],\n",
      "         [0.6084],\n",
      "         [0.9357],\n",
      "         [0.2985],\n",
      "         [0.3165],\n",
      "         [0.8932],\n",
      "         [0.6179],\n",
      "         [0.4541],\n",
      "         [0.4024],\n",
      "         [0.3438],\n",
      "         [0.3236],\n",
      "         [0.2528],\n",
      "         [0.7424],\n",
      "         [0.5547],\n",
      "         [0.3502],\n",
      "         [0.3081],\n",
      "         [0.3369],\n",
      "         [0.4686],\n",
      "         [0.8733],\n",
      "         [0.1983],\n",
      "         [0.2674],\n",
      "         [0.2075],\n",
      "         [0.7428],\n",
      "         [0.5747],\n",
      "         [0.5505],\n",
      "         [0.3382],\n",
      "         [0.9701],\n",
      "         [0.2026],\n",
      "         [0.8425],\n",
      "         [0.9639],\n",
      "         [0.4803],\n",
      "         [0.4446],\n",
      "         [0.5577],\n",
      "         [0.1312],\n",
      "         [0.7135],\n",
      "         [0.6202],\n",
      "         [0.0143],\n",
      "         [0.0541],\n",
      "         [0.9388],\n",
      "         [0.7423],\n",
      "         [0.9182],\n",
      "         [0.6625],\n",
      "         [0.1685],\n",
      "         [0.1712],\n",
      "         [0.9161],\n",
      "         [0.3687],\n",
      "         [0.5217],\n",
      "         [0.3896],\n",
      "         [0.9694],\n",
      "         [0.2745],\n",
      "         [0.3661],\n",
      "         [0.3442],\n",
      "         [0.4444],\n",
      "         [0.7378],\n",
      "         [0.3084],\n",
      "         [0.0093],\n",
      "         [0.3896],\n",
      "         [0.6773],\n",
      "         [0.9334],\n",
      "         [0.4729],\n",
      "         [0.1137],\n",
      "         [0.0013],\n",
      "         [0.7396],\n",
      "         [0.0871],\n",
      "         [0.3918],\n",
      "         [0.3737],\n",
      "         [0.2733],\n",
      "         [0.1921],\n",
      "         [0.3163],\n",
      "         [0.9810],\n",
      "         [0.5930],\n",
      "         [0.1182],\n",
      "         [0.0735],\n",
      "         [0.6850],\n",
      "         [0.6000],\n",
      "         [0.3732],\n",
      "         [0.5160],\n",
      "         [0.1180],\n",
      "         [0.4084],\n",
      "         [0.0283],\n",
      "         [0.7491],\n",
      "         [0.4385],\n",
      "         [0.4269],\n",
      "         [0.4852],\n",
      "         [0.0441],\n",
      "         [0.8997],\n",
      "         [0.4813],\n",
      "         [0.7647],\n",
      "         [0.8841],\n",
      "         [0.5209],\n",
      "         [0.2500],\n",
      "         [0.5361],\n",
      "         [0.4851],\n",
      "         [0.0558],\n",
      "         [0.0853],\n",
      "         [0.5236],\n",
      "         [0.8189],\n",
      "         [0.8380],\n",
      "         [0.8163],\n",
      "         [0.0232],\n",
      "         [0.0124],\n",
      "         [0.4222],\n",
      "         [0.2326],\n",
      "         [0.9020],\n",
      "         [0.6234],\n",
      "         [0.2670],\n",
      "         [0.7348],\n",
      "         [0.5527],\n",
      "         [0.3915],\n",
      "         [0.1348],\n",
      "         [0.3910],\n",
      "         [0.9218],\n",
      "         [0.3119],\n",
      "         [0.3075],\n",
      "         [0.4838],\n",
      "         [0.3765],\n",
      "         [0.3578],\n",
      "         [0.2512]]], device='cuda:0', dtype=torch.float64)\n",
      "================iter 2============\n",
      "['shape/cube/1/fractured_0']\n",
      "tensor([[ True,  True, False,  True, False, False,  True, False, False, False,\n",
      "         False, False, False, False, False, False, False, False, False, False]],\n",
      "       device='cuda:0')\n",
      "acc torch.Size([1]) tensor([0.1000], device='cuda:0')\n",
      "acc_per_part torch.Size([1, 20]) tensor([[ True, False, False, False, False, False, False, False, False, False,\n",
      "         False, False, False, False, False, False, False, False, False, False]],\n",
      "       device='cuda:0')\n",
      "loss_per_data torch.Size([1, 20]) tensor([[0.0000e+00, 1.5088e+02, 4.6492e+01, 3.0585e+00, 3.2970e+02, 2.4882e+03,\n",
      "         2.8807e+02, 5.8099e+02, 9.9819e+02, 2.4047e+02, 8.4288e+01, 7.6887e+00,\n",
      "         2.4684e+00, 4.9432e+00, 1.5059e-01, 2.3526e+00, 3.7200e-01, 5.0599e-01,\n",
      "         7.3754e+00, 1.8213e+00]], device='cuda:0')\n",
      "scores torch.Size([1, 190, 1]) tensor([[[0.1048],\n",
      "         [0.9110],\n",
      "         [0.3668],\n",
      "         [0.4160],\n",
      "         [0.5377],\n",
      "         [0.2478],\n",
      "         [0.1477],\n",
      "         [0.1294],\n",
      "         [0.2090],\n",
      "         [0.3323],\n",
      "         [0.2198],\n",
      "         [0.0712],\n",
      "         [0.6401],\n",
      "         [0.8589],\n",
      "         [0.1476],\n",
      "         [0.9919],\n",
      "         [0.5829],\n",
      "         [0.5950],\n",
      "         [0.3329],\n",
      "         [0.8906],\n",
      "         [0.9739],\n",
      "         [0.5981],\n",
      "         [0.0128],\n",
      "         [0.4114],\n",
      "         [0.7569],\n",
      "         [0.0696],\n",
      "         [0.8288],\n",
      "         [0.8148],\n",
      "         [0.5493],\n",
      "         [0.7531],\n",
      "         [0.3311],\n",
      "         [0.1867],\n",
      "         [0.0780],\n",
      "         [0.5982],\n",
      "         [0.4500],\n",
      "         [0.9124],\n",
      "         [0.3056],\n",
      "         [0.1007],\n",
      "         [0.9593],\n",
      "         [0.5350],\n",
      "         [0.4131],\n",
      "         [0.6215],\n",
      "         [0.1553],\n",
      "         [0.7223],\n",
      "         [0.0274],\n",
      "         [0.1410],\n",
      "         [0.3805],\n",
      "         [0.4670],\n",
      "         [0.9863],\n",
      "         [0.7878],\n",
      "         [0.7596],\n",
      "         [0.2100],\n",
      "         [0.3657],\n",
      "         [0.7751],\n",
      "         [0.7796],\n",
      "         [0.7942],\n",
      "         [0.3729],\n",
      "         [0.6179],\n",
      "         [0.9472],\n",
      "         [0.9198],\n",
      "         [0.2577],\n",
      "         [0.8190],\n",
      "         [0.9885],\n",
      "         [0.3739],\n",
      "         [0.3571],\n",
      "         [0.5631],\n",
      "         [0.3153],\n",
      "         [0.7684],\n",
      "         [0.9034],\n",
      "         [0.1346],\n",
      "         [0.6350],\n",
      "         [0.2548],\n",
      "         [0.1757],\n",
      "         [0.2194],\n",
      "         [0.4104],\n",
      "         [0.3068],\n",
      "         [0.8145],\n",
      "         [0.1448],\n",
      "         [0.8860],\n",
      "         [0.3534],\n",
      "         [0.9618],\n",
      "         [0.8116],\n",
      "         [0.3368],\n",
      "         [0.1887],\n",
      "         [0.1661],\n",
      "         [0.9819],\n",
      "         [0.4041],\n",
      "         [0.3232],\n",
      "         [0.3189],\n",
      "         [0.6834],\n",
      "         [0.8622],\n",
      "         [0.4353],\n",
      "         [0.0064],\n",
      "         [0.5484],\n",
      "         [0.6470],\n",
      "         [0.3058],\n",
      "         [0.5036],\n",
      "         [0.5563],\n",
      "         [0.8184],\n",
      "         [0.8425],\n",
      "         [0.4800],\n",
      "         [0.0348],\n",
      "         [0.6718],\n",
      "         [0.6656],\n",
      "         [0.9610],\n",
      "         [0.1182],\n",
      "         [0.2823],\n",
      "         [0.7133],\n",
      "         [0.4614],\n",
      "         [0.6016],\n",
      "         [0.3875],\n",
      "         [0.1865],\n",
      "         [0.7418],\n",
      "         [0.0948],\n",
      "         [0.0469],\n",
      "         [0.7698],\n",
      "         [0.6353],\n",
      "         [0.4656],\n",
      "         [0.4525],\n",
      "         [0.4323],\n",
      "         [0.2378],\n",
      "         [0.1284],\n",
      "         [0.7246],\n",
      "         [0.3926],\n",
      "         [0.5931],\n",
      "         [0.3000],\n",
      "         [0.1217],\n",
      "         [0.1117],\n",
      "         [0.1937],\n",
      "         [0.4170],\n",
      "         [0.2998],\n",
      "         [0.7130],\n",
      "         [0.9557],\n",
      "         [0.2387],\n",
      "         [0.2939],\n",
      "         [0.6345],\n",
      "         [0.8507],\n",
      "         [0.3442],\n",
      "         [0.0421],\n",
      "         [0.5880],\n",
      "         [0.8538],\n",
      "         [0.0909],\n",
      "         [0.2048],\n",
      "         [0.7125],\n",
      "         [0.3655],\n",
      "         [0.1194],\n",
      "         [0.6859],\n",
      "         [0.1421],\n",
      "         [0.2719],\n",
      "         [0.8952],\n",
      "         [0.2978],\n",
      "         [0.1323],\n",
      "         [0.9202],\n",
      "         [0.4252],\n",
      "         [0.2933],\n",
      "         [0.8483],\n",
      "         [0.3963],\n",
      "         [0.7764],\n",
      "         [0.6020],\n",
      "         [0.7023],\n",
      "         [0.3129],\n",
      "         [0.1110],\n",
      "         [0.7489],\n",
      "         [0.7359],\n",
      "         [0.2977],\n",
      "         [0.2028],\n",
      "         [0.4122],\n",
      "         [0.9782],\n",
      "         [0.4877],\n",
      "         [0.8106],\n",
      "         [0.0388],\n",
      "         [0.8398],\n",
      "         [0.4567],\n",
      "         [0.2419],\n",
      "         [0.9394],\n",
      "         [0.1644],\n",
      "         [0.9533],\n",
      "         [0.9483],\n",
      "         [0.9855],\n",
      "         [0.8825],\n",
      "         [0.8151],\n",
      "         [0.4857],\n",
      "         [0.6637],\n",
      "         [0.3539],\n",
      "         [0.0793],\n",
      "         [0.2276],\n",
      "         [0.1939],\n",
      "         [0.6998],\n",
      "         [0.7569],\n",
      "         [0.6609]]], device='cuda:0', dtype=torch.float64)\n",
      "================iter 3============\n",
      "['shape/cube/1/fractured_0']\n",
      "tensor([[ True,  True,  True,  True, False,  True,  True, False,  True,  True,\n",
      "         False, False, False, False, False, False, False, False, False, False]],\n",
      "       device='cuda:0')\n",
      "acc torch.Size([1]) tensor([0.1000], device='cuda:0')\n",
      "acc_per_part torch.Size([1, 20]) tensor([[ True, False, False, False, False, False, False, False, False, False,\n",
      "         False, False, False, False, False, False, False, False, False, False]],\n",
      "       device='cuda:0')\n",
      "loss_per_data torch.Size([1, 20]) tensor([[0.0000e+00, 1.5088e+02, 4.6492e+01, 3.0585e+00, 1.0563e+03, 2.4882e+03,\n",
      "         2.8807e+02, 1.5000e+03, 9.9819e+02, 2.4047e+02, 2.4311e+02, 2.6138e+01,\n",
      "         1.7323e+01, 5.6028e+00, 3.9256e-01, 5.2438e+00, 9.1121e-01, 1.6994e+00,\n",
      "         2.0136e+00, 6.3262e-01]], device='cuda:0')\n",
      "scores torch.Size([1, 190, 1]) tensor([[[0.4033],\n",
      "         [0.9202],\n",
      "         [0.1089],\n",
      "         [0.4412],\n",
      "         [0.0673],\n",
      "         [0.0832],\n",
      "         [0.3934],\n",
      "         [0.1689],\n",
      "         [0.7344],\n",
      "         [0.9441],\n",
      "         [0.7172],\n",
      "         [0.4083],\n",
      "         [0.7634],\n",
      "         [0.8182],\n",
      "         [0.0772],\n",
      "         [0.5786],\n",
      "         [0.8313],\n",
      "         [0.0620],\n",
      "         [0.3688],\n",
      "         [0.3751],\n",
      "         [0.8094],\n",
      "         [0.6727],\n",
      "         [0.1921],\n",
      "         [0.1635],\n",
      "         [0.3587],\n",
      "         [0.7058],\n",
      "         [0.1901],\n",
      "         [0.6287],\n",
      "         [0.0842],\n",
      "         [0.1886],\n",
      "         [0.9206],\n",
      "         [0.8291],\n",
      "         [0.8074],\n",
      "         [0.9767],\n",
      "         [0.4154],\n",
      "         [0.2422],\n",
      "         [0.9686],\n",
      "         [0.5365],\n",
      "         [0.2267],\n",
      "         [0.1187],\n",
      "         [0.6001],\n",
      "         [0.5266],\n",
      "         [0.9405],\n",
      "         [0.2787],\n",
      "         [0.4607],\n",
      "         [0.4336],\n",
      "         [0.4414],\n",
      "         [0.3039],\n",
      "         [0.4768],\n",
      "         [0.0627],\n",
      "         [0.0186],\n",
      "         [0.6876],\n",
      "         [0.3685],\n",
      "         [0.6842],\n",
      "         [0.9345],\n",
      "         [0.9979],\n",
      "         [0.6886],\n",
      "         [0.6030],\n",
      "         [0.7885],\n",
      "         [0.4927],\n",
      "         [0.7174],\n",
      "         [0.4475],\n",
      "         [0.6045],\n",
      "         [0.7442],\n",
      "         [0.1354],\n",
      "         [0.2565],\n",
      "         [0.8484],\n",
      "         [0.8919],\n",
      "         [0.6445],\n",
      "         [0.8146],\n",
      "         [0.0752],\n",
      "         [0.6783],\n",
      "         [0.7487],\n",
      "         [0.3980],\n",
      "         [0.3160],\n",
      "         [0.2874],\n",
      "         [0.6600],\n",
      "         [0.2339],\n",
      "         [0.5972],\n",
      "         [0.0671],\n",
      "         [0.1785],\n",
      "         [0.5848],\n",
      "         [0.0372],\n",
      "         [0.3369],\n",
      "         [0.3978],\n",
      "         [0.2293],\n",
      "         [0.0145],\n",
      "         [0.5780],\n",
      "         [0.7318],\n",
      "         [0.4169],\n",
      "         [0.9808],\n",
      "         [0.3897],\n",
      "         [0.5634],\n",
      "         [0.8772],\n",
      "         [0.4961],\n",
      "         [0.1719],\n",
      "         [0.6192],\n",
      "         [0.8489],\n",
      "         [0.9663],\n",
      "         [0.5776],\n",
      "         [0.1311],\n",
      "         [0.5364],\n",
      "         [0.6568],\n",
      "         [0.3746],\n",
      "         [0.4611],\n",
      "         [0.9198],\n",
      "         [0.8138],\n",
      "         [0.8629],\n",
      "         [0.3363],\n",
      "         [0.5942],\n",
      "         [0.6633],\n",
      "         [0.0751],\n",
      "         [0.5262],\n",
      "         [0.5805],\n",
      "         [0.3489],\n",
      "         [0.5306],\n",
      "         [0.1089],\n",
      "         [0.1595],\n",
      "         [0.2151],\n",
      "         [0.0937],\n",
      "         [0.4793],\n",
      "         [0.5690],\n",
      "         [0.6928],\n",
      "         [0.3555],\n",
      "         [0.0192],\n",
      "         [0.0078],\n",
      "         [0.0951],\n",
      "         [0.9408],\n",
      "         [0.2154],\n",
      "         [0.6474],\n",
      "         [0.8226],\n",
      "         [0.4936],\n",
      "         [0.0387],\n",
      "         [0.9122],\n",
      "         [0.5572],\n",
      "         [0.7780],\n",
      "         [0.4315],\n",
      "         [0.1059],\n",
      "         [0.2171],\n",
      "         [0.0445],\n",
      "         [0.5078],\n",
      "         [0.3820],\n",
      "         [0.8168],\n",
      "         [0.4084],\n",
      "         [0.5353],\n",
      "         [0.9015],\n",
      "         [0.7921],\n",
      "         [0.8669],\n",
      "         [0.3805],\n",
      "         [0.0643],\n",
      "         [0.2402],\n",
      "         [0.1998],\n",
      "         [0.0456],\n",
      "         [0.2887],\n",
      "         [0.9284],\n",
      "         [0.8955],\n",
      "         [0.3001],\n",
      "         [0.0062],\n",
      "         [0.1445],\n",
      "         [0.3226],\n",
      "         [0.0298],\n",
      "         [0.4716],\n",
      "         [0.6959],\n",
      "         [0.0301],\n",
      "         [0.7099],\n",
      "         [0.1688],\n",
      "         [0.5066],\n",
      "         [0.5098],\n",
      "         [0.5835],\n",
      "         [0.5383],\n",
      "         [0.1289],\n",
      "         [0.3367],\n",
      "         [0.5160],\n",
      "         [0.1030],\n",
      "         [0.3092],\n",
      "         [0.8879],\n",
      "         [0.1591],\n",
      "         [0.0524],\n",
      "         [0.4338],\n",
      "         [0.7692],\n",
      "         [0.4202],\n",
      "         [0.4923],\n",
      "         [0.9598],\n",
      "         [0.5215],\n",
      "         [0.2402],\n",
      "         [0.0326],\n",
      "         [0.8333],\n",
      "         [0.4375],\n",
      "         [0.6199],\n",
      "         [0.4964]]], device='cuda:0', dtype=torch.float64)\n",
      "================iter 4============\n",
      "['shape/cube/1/fractured_0']\n",
      "tensor([[ True,  True,  True,  True,  True,  True,  True, False,  True,  True,\n",
      "         False, False, False, False, False, False, False, False, False, False]],\n",
      "       device='cuda:0')\n",
      "acc torch.Size([1]) tensor([0.1000], device='cuda:0')\n",
      "acc_per_part torch.Size([1, 20]) tensor([[ True, False, False, False, False, False, False, False, False, False,\n",
      "         False, False, False, False, False, False, False, False, False, False]],\n",
      "       device='cuda:0')\n",
      "loss_per_data torch.Size([1, 20]) tensor([[0.0000e+00, 1.5088e+02, 4.6492e+01, 3.0585e+00, 1.0563e+03, 2.4882e+03,\n",
      "         2.8807e+02, 6.6049e+03, 9.9819e+02, 2.4047e+02, 9.2034e+02, 6.0501e+01,\n",
      "         6.1836e+01, 2.0160e+01, 4.0905e+00, 2.6131e+01, 3.6720e+00, 1.0141e+01,\n",
      "         7.3247e+00, 2.2265e+00]], device='cuda:0')\n",
      "scores torch.Size([1, 190, 1]) tensor([[[0.9204],\n",
      "         [0.4037],\n",
      "         [0.0187],\n",
      "         [0.3562],\n",
      "         [0.7933],\n",
      "         [0.8571],\n",
      "         [0.3602],\n",
      "         [0.9644],\n",
      "         [0.8175],\n",
      "         [0.9984],\n",
      "         [0.1681],\n",
      "         [0.4735],\n",
      "         [0.0017],\n",
      "         [0.7611],\n",
      "         [0.9070],\n",
      "         [0.5340],\n",
      "         [0.8474],\n",
      "         [0.5618],\n",
      "         [0.2407],\n",
      "         [0.9406],\n",
      "         [0.4922],\n",
      "         [0.9214],\n",
      "         [0.0644],\n",
      "         [0.3193],\n",
      "         [0.8813],\n",
      "         [0.4544],\n",
      "         [0.2261],\n",
      "         [0.2860],\n",
      "         [0.4932],\n",
      "         [0.5713],\n",
      "         [0.8667],\n",
      "         [0.7918],\n",
      "         [0.8183],\n",
      "         [0.2146],\n",
      "         [0.6009],\n",
      "         [0.1174],\n",
      "         [0.2660],\n",
      "         [0.1501],\n",
      "         [0.3397],\n",
      "         [0.5575],\n",
      "         [0.2349],\n",
      "         [0.9123],\n",
      "         [0.1954],\n",
      "         [0.5087],\n",
      "         [0.1404],\n",
      "         [0.1278],\n",
      "         [0.9239],\n",
      "         [0.1281],\n",
      "         [0.3856],\n",
      "         [0.0982],\n",
      "         [0.2576],\n",
      "         [0.6487],\n",
      "         [0.9534],\n",
      "         [0.7777],\n",
      "         [0.5704],\n",
      "         [0.3661],\n",
      "         [0.8062],\n",
      "         [0.6774],\n",
      "         [0.6336],\n",
      "         [0.1053],\n",
      "         [0.5043],\n",
      "         [0.6345],\n",
      "         [0.8313],\n",
      "         [0.6187],\n",
      "         [0.2552],\n",
      "         [0.2225],\n",
      "         [0.3383],\n",
      "         [0.4769],\n",
      "         [0.2426],\n",
      "         [0.8755],\n",
      "         [0.0407],\n",
      "         [0.8978],\n",
      "         [0.2096],\n",
      "         [0.9242],\n",
      "         [0.2656],\n",
      "         [0.3981],\n",
      "         [0.8740],\n",
      "         [0.1200],\n",
      "         [0.5588],\n",
      "         [0.4259],\n",
      "         [0.2854],\n",
      "         [0.9863],\n",
      "         [0.6915],\n",
      "         [0.8054],\n",
      "         [0.5636],\n",
      "         [0.1119],\n",
      "         [0.4300],\n",
      "         [0.5583],\n",
      "         [0.3225],\n",
      "         [0.4373],\n",
      "         [0.3451],\n",
      "         [0.7116],\n",
      "         [0.4308],\n",
      "         [0.0342],\n",
      "         [0.5049],\n",
      "         [0.6725],\n",
      "         [0.3007],\n",
      "         [0.9764],\n",
      "         [0.4711],\n",
      "         [0.7390],\n",
      "         [0.9968],\n",
      "         [0.0395],\n",
      "         [0.1535],\n",
      "         [0.8637],\n",
      "         [0.9421],\n",
      "         [0.7466],\n",
      "         [0.1200],\n",
      "         [0.1408],\n",
      "         [0.3119],\n",
      "         [0.3509],\n",
      "         [0.2315],\n",
      "         [0.0611],\n",
      "         [0.0116],\n",
      "         [0.4617],\n",
      "         [0.0214],\n",
      "         [0.7564],\n",
      "         [0.2777],\n",
      "         [0.7490],\n",
      "         [0.6807],\n",
      "         [0.8836],\n",
      "         [0.2424],\n",
      "         [0.5046],\n",
      "         [0.5818],\n",
      "         [0.4863],\n",
      "         [0.9992],\n",
      "         [0.2418],\n",
      "         [0.6345],\n",
      "         [0.5644],\n",
      "         [0.5304],\n",
      "         [0.2749],\n",
      "         [0.6685],\n",
      "         [0.9643],\n",
      "         [0.4614],\n",
      "         [0.7789],\n",
      "         [0.4266],\n",
      "         [0.8494],\n",
      "         [0.8984],\n",
      "         [0.7231],\n",
      "         [0.5768],\n",
      "         [0.4357],\n",
      "         [0.2650],\n",
      "         [0.2388],\n",
      "         [0.3838],\n",
      "         [0.8664],\n",
      "         [0.0806],\n",
      "         [0.8265],\n",
      "         [0.5281],\n",
      "         [0.7294],\n",
      "         [0.4165],\n",
      "         [0.5193],\n",
      "         [0.5349],\n",
      "         [0.6970],\n",
      "         [0.5482],\n",
      "         [0.0388],\n",
      "         [0.8054],\n",
      "         [0.3435],\n",
      "         [0.1699],\n",
      "         [0.2066],\n",
      "         [0.3048],\n",
      "         [0.5325],\n",
      "         [0.9056],\n",
      "         [0.4305],\n",
      "         [0.6632],\n",
      "         [0.0902],\n",
      "         [0.9473],\n",
      "         [0.9795],\n",
      "         [0.9421],\n",
      "         [0.3336],\n",
      "         [0.9195],\n",
      "         [0.5148],\n",
      "         [0.6133],\n",
      "         [0.3217],\n",
      "         [0.0363],\n",
      "         [0.8880],\n",
      "         [0.6267],\n",
      "         [0.1197],\n",
      "         [0.3393],\n",
      "         [0.7701],\n",
      "         [0.6546],\n",
      "         [0.5169],\n",
      "         [0.1223],\n",
      "         [0.3975],\n",
      "         [0.5896],\n",
      "         [0.2057],\n",
      "         [0.9697],\n",
      "         [0.9839],\n",
      "         [0.8381],\n",
      "         [0.0237],\n",
      "         [0.9354],\n",
      "         [0.5905]]], device='cuda:0', dtype=torch.float64)\n",
      "================iter 5============\n",
      "['shape/cube/1/fractured_0']\n",
      "tensor([[ True,  True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
      "         False, False, False, False, False, False, False, False, False, False]],\n",
      "       device='cuda:0')\n",
      "@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@\n",
      "['shape/cube/2/cube_with_cone_20_pieces']\n",
      "gt_trans_torch.Size([1, 20, 3])_tensor([[[-1.4211e-17,  1.3323e-17, -6.6613e-18],\n",
      "         [ 2.8956e-02,  1.4308e-02, -4.1213e-03],\n",
      "         [ 4.5969e-02,  4.7148e-02, -7.5021e-03],\n",
      "         [ 7.8195e-02,  5.7227e-02, -2.4357e-03],\n",
      "         [ 1.0371e-01,  7.3942e-02, -1.9097e-02],\n",
      "         [ 1.3349e-01,  8.4615e-02, -2.7467e-02],\n",
      "         [ 1.6416e-01,  9.6789e-02, -2.0099e-02],\n",
      "         [ 1.9105e-01,  1.1463e-01, -1.0727e-02],\n",
      "         [ 2.2324e-01,  1.1900e-01, -2.7813e-02],\n",
      "         [ 2.3370e-01,  1.6450e-01, -3.9133e-02],\n",
      "         [ 2.6916e-01,  1.6374e-01, -3.9969e-02],\n",
      "         [ 3.0191e-01,  1.7257e-01, -4.8418e-02],\n",
      "         [ 3.2455e-01,  1.9856e-01, -3.8189e-02],\n",
      "         [ 3.5396e-01,  2.0844e-01, -4.8003e-02],\n",
      "         [ 3.8738e-01,  2.1522e-01, -4.6135e-02],\n",
      "         [ 4.0970e-01,  2.3789e-01, -5.7255e-02],\n",
      "         [ 4.3771e-01,  2.5076e-01, -5.7663e-02],\n",
      "         [ 4.6788e-01,  2.5771e-01, -7.5612e-02],\n",
      "         [ 4.8835e-01,  2.9116e-01, -6.2825e-02],\n",
      "         [ 5.1885e-01,  2.9678e-01, -7.9117e-02]]], device='cuda:0')\n",
      "gt_rots_torch.Size([1, 20, 4])_tensor([[[-0.2652,  0.7609,  0.3776,  0.4561],\n",
      "         [ 0.6865, -0.0976, -0.6802, -0.2377],\n",
      "         [-0.2883, -0.4170, -0.5100,  0.6949],\n",
      "         [ 0.4053,  0.8040, -0.3230, -0.2917],\n",
      "         [-0.3161, -0.3225,  0.8597,  0.2387],\n",
      "         [ 0.9006,  0.2954, -0.3172, -0.0336],\n",
      "         [ 0.6819, -0.0791, -0.5484, -0.4775],\n",
      "         [-0.4944,  0.2472, -0.3487,  0.7569],\n",
      "         [-0.4702,  0.8432, -0.1425,  0.2184],\n",
      "         [ 0.3951,  0.2246,  0.1658,  0.8752],\n",
      "         [-0.3291,  0.0335, -0.3468,  0.8777],\n",
      "         [ 0.4042,  0.7763, -0.0854, -0.4761],\n",
      "         [ 0.1634, -0.0193,  0.7246, -0.6692],\n",
      "         [ 0.6132, -0.4606, -0.3520, -0.5366],\n",
      "         [ 0.6582,  0.7516,  0.0098,  0.0430],\n",
      "         [ 0.8284, -0.1754,  0.3292, -0.4179],\n",
      "         [ 0.7241, -0.5622,  0.3985, -0.0282],\n",
      "         [-0.0022,  0.3290,  0.8127, -0.4808],\n",
      "         [ 0.3385,  0.8678,  0.2599, -0.2545],\n",
      "         [-0.5015,  0.2785, -0.4370,  0.6928]]], device='cuda:0')\n",
      "noisy_trans_and_rots_torch.Size([1, 20, 7])_tensor([[[-0.3732,  0.0000,  0.4147,  0.6064,  0.0000,  0.0000, -2.3248],\n",
      "         [ 1.9576,  0.0000,  0.5742,  0.0984,  0.0000,  0.0000,  0.3357],\n",
      "         [-0.3684,  0.0000, -0.7518,  0.5231,  0.0000,  0.0000,  1.1356],\n",
      "         [-0.2777,  0.0000, -0.2113, -0.8993,  0.0000,  0.0000, -0.1893],\n",
      "         [ 1.3616,  0.0000, -0.3420,  0.9452,  0.0000,  0.0000,  0.3306],\n",
      "         [-1.4298,  0.0000, -1.0900,  0.3234,  0.0000,  0.0000,  1.3439],\n",
      "         [-0.4143,  0.0000,  1.1904, -1.8391,  0.0000,  0.0000, -0.2929],\n",
      "         [ 0.0058,  0.0000,  1.2263,  0.0684,  0.0000,  0.0000,  0.6652],\n",
      "         [-1.9785,  0.0000,  0.0651, -1.3914,  0.0000,  0.0000, -0.2105],\n",
      "         [-0.6856,  0.0000,  0.3837,  0.0563,  0.0000,  0.0000,  0.4016],\n",
      "         [ 2.0720,  0.0000,  1.6926,  0.8316,  0.0000,  0.0000, -0.3976],\n",
      "         [-0.4527,  0.0000, -0.1948,  0.4081,  0.0000,  0.0000, -1.7647],\n",
      "         [ 0.2905,  0.0000,  0.3358,  1.7920,  0.0000,  0.0000, -0.3507],\n",
      "         [ 1.1710,  0.0000, -1.2182,  0.8812,  0.0000,  0.0000,  0.2922],\n",
      "         [ 0.3390,  0.0000, -0.6306, -0.7595,  0.0000,  0.0000,  0.9900],\n",
      "         [ 3.5944,  0.0000, -1.2930,  1.7291,  0.0000,  0.0000,  2.1232],\n",
      "         [-0.0317,  0.0000, -0.3659, -0.3298,  0.0000,  0.0000,  0.1590],\n",
      "         [ 0.4228,  0.0000,  1.6123,  0.2062,  0.0000,  0.0000,  0.7061],\n",
      "         [ 1.1986,  0.0000, -0.4001,  1.7880,  0.0000,  0.0000, -0.2700],\n",
      "         [ 0.3199,  0.0000,  0.0456, -0.0114,  0.0000,  0.0000, -1.2083]]],\n",
      "       device='cuda:0')\n",
      "================iter 0============\n",
      "['shape/cube/2/cube_with_cone_20_pieces']\n",
      "tensor([[ True, False, False, False, False, False, False, False, False, False,\n",
      "         False, False, False, False, False, False, False, False, False, False]],\n",
      "       device='cuda:0')\n",
      "acc torch.Size([1]) tensor([0.0500], device='cuda:0')\n",
      "acc_per_part torch.Size([1, 20]) tensor([[ True, False, False, False, False, False, False, False, False, False,\n",
      "         False, False, False, False, False, False, False, False, False, False]],\n",
      "       device='cuda:0')\n",
      "loss_per_data torch.Size([1, 20]) tensor([[ 0.0000,  0.9526,  1.2947,  0.5275,  0.3740,  0.8275,  1.5542,  3.7768,\n",
      "          0.3078,  2.1277,  6.1137,  1.5837,  3.8131,  0.1220,  2.6764, 34.6891,\n",
      "          0.1710,  1.0440, 10.7867,  0.9304]], device='cuda:0')\n",
      "scores torch.Size([1, 190, 1]) tensor([[[7.5480e-01],\n",
      "         [1.4241e-01],\n",
      "         [4.6182e-02],\n",
      "         [9.6796e-01],\n",
      "         [7.2837e-01],\n",
      "         [5.9216e-01],\n",
      "         [4.9666e-01],\n",
      "         [2.3604e-01],\n",
      "         [4.7760e-01],\n",
      "         [3.1249e-01],\n",
      "         [5.1737e-01],\n",
      "         [7.9212e-01],\n",
      "         [1.6401e-01],\n",
      "         [8.9455e-01],\n",
      "         [4.1467e-01],\n",
      "         [6.0659e-01],\n",
      "         [9.4522e-01],\n",
      "         [2.6030e-01],\n",
      "         [2.4445e-01],\n",
      "         [1.4982e-01],\n",
      "         [1.3405e-01],\n",
      "         [1.4697e-01],\n",
      "         [6.6076e-01],\n",
      "         [8.9387e-01],\n",
      "         [9.8734e-01],\n",
      "         [2.6113e-01],\n",
      "         [7.1651e-01],\n",
      "         [2.6930e-01],\n",
      "         [7.1467e-01],\n",
      "         [4.2179e-02],\n",
      "         [6.2006e-01],\n",
      "         [7.0956e-01],\n",
      "         [9.2273e-01],\n",
      "         [9.5142e-01],\n",
      "         [2.0323e-01],\n",
      "         [3.9913e-01],\n",
      "         [1.3568e-01],\n",
      "         [3.3827e-01],\n",
      "         [7.0895e-04],\n",
      "         [7.2351e-01],\n",
      "         [5.9468e-01],\n",
      "         [3.8176e-01],\n",
      "         [9.0295e-02],\n",
      "         [8.4429e-01],\n",
      "         [5.0323e-01],\n",
      "         [8.0728e-01],\n",
      "         [7.1273e-01],\n",
      "         [5.1418e-02],\n",
      "         [5.5171e-01],\n",
      "         [4.0664e-01],\n",
      "         [3.9552e-01],\n",
      "         [4.3503e-01],\n",
      "         [8.6169e-01],\n",
      "         [2.2660e-01],\n",
      "         [7.2038e-01],\n",
      "         [3.4651e-02],\n",
      "         [5.8771e-02],\n",
      "         [5.3900e-01],\n",
      "         [7.0076e-01],\n",
      "         [5.5596e-01],\n",
      "         [1.5734e-02],\n",
      "         [9.0259e-01],\n",
      "         [5.0807e-02],\n",
      "         [7.6371e-01],\n",
      "         [1.7284e-01],\n",
      "         [6.7313e-01],\n",
      "         [7.7970e-01],\n",
      "         [1.8358e-01],\n",
      "         [2.9007e-03],\n",
      "         [4.0464e-01],\n",
      "         [3.0920e-01],\n",
      "         [9.7391e-01],\n",
      "         [1.2382e-01],\n",
      "         [4.9306e-01],\n",
      "         [3.8732e-01],\n",
      "         [5.5083e-01],\n",
      "         [4.2973e-01],\n",
      "         [7.9927e-01],\n",
      "         [5.4693e-01],\n",
      "         [3.0614e-01],\n",
      "         [5.8141e-01],\n",
      "         [4.8208e-01],\n",
      "         [8.1682e-01],\n",
      "         [1.5732e-01],\n",
      "         [4.1367e-01],\n",
      "         [3.1480e-01],\n",
      "         [6.8921e-01],\n",
      "         [2.7554e-01],\n",
      "         [9.3736e-01],\n",
      "         [5.0464e-02],\n",
      "         [1.6866e-01],\n",
      "         [8.3877e-02],\n",
      "         [4.3960e-01],\n",
      "         [5.5006e-01],\n",
      "         [5.0861e-01],\n",
      "         [6.2750e-01],\n",
      "         [8.2985e-01],\n",
      "         [4.5491e-01],\n",
      "         [2.9161e-01],\n",
      "         [7.2151e-01],\n",
      "         [3.4800e-01],\n",
      "         [2.8028e-01],\n",
      "         [4.7390e-01],\n",
      "         [8.2799e-01],\n",
      "         [2.5612e-01],\n",
      "         [2.3486e-01],\n",
      "         [7.7714e-01],\n",
      "         [1.4062e-01],\n",
      "         [7.5971e-01],\n",
      "         [2.2605e-01],\n",
      "         [8.4794e-01],\n",
      "         [5.0037e-01],\n",
      "         [7.7001e-01],\n",
      "         [5.9227e-01],\n",
      "         [6.2907e-01],\n",
      "         [4.8442e-01],\n",
      "         [1.4784e-01],\n",
      "         [6.4564e-01],\n",
      "         [1.5275e-01],\n",
      "         [3.1267e-01],\n",
      "         [9.3119e-01],\n",
      "         [7.2875e-01],\n",
      "         [2.5453e-01],\n",
      "         [7.1718e-01],\n",
      "         [5.5490e-01],\n",
      "         [2.6280e-01],\n",
      "         [8.0243e-01],\n",
      "         [2.6071e-01],\n",
      "         [3.5640e-01],\n",
      "         [3.9111e-01],\n",
      "         [2.1631e-01],\n",
      "         [7.1904e-02],\n",
      "         [4.6075e-01],\n",
      "         [3.5164e-01],\n",
      "         [6.5659e-01],\n",
      "         [5.4604e-02],\n",
      "         [3.9756e-01],\n",
      "         [4.2950e-01],\n",
      "         [3.4432e-01],\n",
      "         [4.8407e-01],\n",
      "         [4.2368e-01],\n",
      "         [1.3829e-01],\n",
      "         [3.5428e-01],\n",
      "         [2.0962e-01],\n",
      "         [4.3571e-02],\n",
      "         [2.1683e-01],\n",
      "         [8.5818e-01],\n",
      "         [3.5034e-02],\n",
      "         [1.5613e-01],\n",
      "         [7.7915e-01],\n",
      "         [3.5069e-01],\n",
      "         [4.9232e-01],\n",
      "         [5.6616e-01],\n",
      "         [2.9879e-01],\n",
      "         [5.3846e-01],\n",
      "         [8.6999e-01],\n",
      "         [1.7029e-01],\n",
      "         [1.8132e-02],\n",
      "         [8.1857e-01],\n",
      "         [5.8311e-01],\n",
      "         [1.2265e-01],\n",
      "         [1.9437e-01],\n",
      "         [6.7637e-01],\n",
      "         [7.0533e-01],\n",
      "         [7.2294e-01],\n",
      "         [6.5680e-01],\n",
      "         [2.6786e-01],\n",
      "         [8.2701e-01],\n",
      "         [6.0013e-01],\n",
      "         [3.6243e-02],\n",
      "         [8.9326e-02],\n",
      "         [9.0137e-01],\n",
      "         [6.7637e-01],\n",
      "         [8.7661e-01],\n",
      "         [6.8690e-01],\n",
      "         [3.1362e-02],\n",
      "         [9.2217e-01],\n",
      "         [6.9425e-01],\n",
      "         [7.2155e-01],\n",
      "         [3.2910e-01],\n",
      "         [4.3315e-01],\n",
      "         [2.8384e-01],\n",
      "         [1.2446e-01],\n",
      "         [3.3226e-02],\n",
      "         [5.7794e-01],\n",
      "         [9.7655e-01],\n",
      "         [3.7105e-01],\n",
      "         [9.7335e-01],\n",
      "         [4.7400e-01],\n",
      "         [1.1271e-02]]], device='cuda:0', dtype=torch.float64)\n",
      "================iter 1============\n",
      "['shape/cube/2/cube_with_cone_20_pieces']\n",
      "tensor([[ True, False, False, False,  True, False, False, False, False, False,\n",
      "         False, False, False, False, False, False, False,  True, False, False]],\n",
      "       device='cuda:0')\n",
      "acc torch.Size([1]) tensor([0.0500], device='cuda:0')\n",
      "acc_per_part torch.Size([1, 20]) tensor([[ True, False, False, False, False, False, False, False, False, False,\n",
      "         False, False, False, False, False, False, False, False, False, False]],\n",
      "       device='cuda:0')\n",
      "loss_per_data torch.Size([1, 20]) tensor([[  0.0000,   3.0697,   0.8010,   3.2992,   0.3740,  18.3597,   3.0915,\n",
      "           7.6684,  28.8329,  14.0803,   0.3150,   0.4325,   0.6937,  10.6001,\n",
      "          21.7765,  55.1973, 225.4051,   1.0440,  16.6986,   4.4189]],\n",
      "       device='cuda:0')\n",
      "scores torch.Size([1, 190, 1]) tensor([[[0.9741],\n",
      "         [0.7902],\n",
      "         [0.3407],\n",
      "         [0.6014],\n",
      "         [0.9804],\n",
      "         [0.1821],\n",
      "         [0.6051],\n",
      "         [0.8226],\n",
      "         [0.5090],\n",
      "         [0.3845],\n",
      "         [0.3025],\n",
      "         [0.7131],\n",
      "         [0.0021],\n",
      "         [0.7255],\n",
      "         [0.4332],\n",
      "         [0.8831],\n",
      "         [0.3707],\n",
      "         [0.4781],\n",
      "         [0.7310],\n",
      "         [0.6496],\n",
      "         [0.3363],\n",
      "         [0.8494],\n",
      "         [0.8671],\n",
      "         [0.1672],\n",
      "         [0.6630],\n",
      "         [0.9306],\n",
      "         [0.8926],\n",
      "         [0.0088],\n",
      "         [0.3672],\n",
      "         [0.3947],\n",
      "         [0.9834],\n",
      "         [0.5943],\n",
      "         [0.4282],\n",
      "         [0.9539],\n",
      "         [0.9826],\n",
      "         [0.1937],\n",
      "         [0.4545],\n",
      "         [0.8967],\n",
      "         [0.8095],\n",
      "         [0.1667],\n",
      "         [0.0927],\n",
      "         [0.6356],\n",
      "         [0.2715],\n",
      "         [0.5037],\n",
      "         [0.6635],\n",
      "         [0.7426],\n",
      "         [0.5724],\n",
      "         [0.0534],\n",
      "         [0.5235],\n",
      "         [0.6719],\n",
      "         [0.2189],\n",
      "         [0.9441],\n",
      "         [0.8061],\n",
      "         [0.1382],\n",
      "         [0.5022],\n",
      "         [0.0226],\n",
      "         [0.6367],\n",
      "         [0.1193],\n",
      "         [0.1844],\n",
      "         [0.1752],\n",
      "         [0.4024],\n",
      "         [0.4178],\n",
      "         [0.9121],\n",
      "         [0.9895],\n",
      "         [0.3456],\n",
      "         [0.3398],\n",
      "         [0.5755],\n",
      "         [0.0865],\n",
      "         [0.1000],\n",
      "         [0.0576],\n",
      "         [0.5063],\n",
      "         [0.3719],\n",
      "         [0.1474],\n",
      "         [0.5691],\n",
      "         [0.3725],\n",
      "         [0.4079],\n",
      "         [0.2950],\n",
      "         [0.2884],\n",
      "         [0.8679],\n",
      "         [0.7038],\n",
      "         [0.4000],\n",
      "         [0.5175],\n",
      "         [0.9935],\n",
      "         [0.9749],\n",
      "         [0.4225],\n",
      "         [0.1604],\n",
      "         [0.7442],\n",
      "         [0.9777],\n",
      "         [0.5998],\n",
      "         [0.9729],\n",
      "         [0.2708],\n",
      "         [0.4159],\n",
      "         [0.9470],\n",
      "         [0.7112],\n",
      "         [0.1555],\n",
      "         [0.5663],\n",
      "         [0.4498],\n",
      "         [0.0276],\n",
      "         [0.1760],\n",
      "         [0.2894],\n",
      "         [0.2522],\n",
      "         [0.2999],\n",
      "         [0.9620],\n",
      "         [0.5598],\n",
      "         [0.2176],\n",
      "         [0.0688],\n",
      "         [0.5734],\n",
      "         [0.9479],\n",
      "         [0.5843],\n",
      "         [0.6430],\n",
      "         [0.7745],\n",
      "         [0.4431],\n",
      "         [0.3160],\n",
      "         [0.3739],\n",
      "         [0.2295],\n",
      "         [0.4102],\n",
      "         [0.7063],\n",
      "         [0.7479],\n",
      "         [0.1410],\n",
      "         [0.9171],\n",
      "         [0.1141],\n",
      "         [0.0212],\n",
      "         [0.7094],\n",
      "         [0.8286],\n",
      "         [0.8367],\n",
      "         [0.6409],\n",
      "         [0.2844],\n",
      "         [0.2783],\n",
      "         [0.6477],\n",
      "         [0.4201],\n",
      "         [0.8988],\n",
      "         [0.1011],\n",
      "         [0.0294],\n",
      "         [0.0971],\n",
      "         [0.3634],\n",
      "         [0.6257],\n",
      "         [0.1438],\n",
      "         [0.5327],\n",
      "         [0.0573],\n",
      "         [0.0099],\n",
      "         [0.3555],\n",
      "         [0.3956],\n",
      "         [0.7138],\n",
      "         [0.1814],\n",
      "         [0.3719],\n",
      "         [0.3386],\n",
      "         [0.4147],\n",
      "         [0.7385],\n",
      "         [0.7779],\n",
      "         [0.7447],\n",
      "         [0.5692],\n",
      "         [0.5287],\n",
      "         [0.4712],\n",
      "         [0.6194],\n",
      "         [0.1146],\n",
      "         [0.4143],\n",
      "         [0.8142],\n",
      "         [0.5002],\n",
      "         [0.8617],\n",
      "         [0.3999],\n",
      "         [0.2532],\n",
      "         [0.2819],\n",
      "         [0.2832],\n",
      "         [0.5316],\n",
      "         [0.2123],\n",
      "         [0.9115],\n",
      "         [0.4087],\n",
      "         [0.4097],\n",
      "         [0.9101],\n",
      "         [0.7577],\n",
      "         [0.7371],\n",
      "         [0.5940],\n",
      "         [0.8655],\n",
      "         [0.0937],\n",
      "         [0.3725],\n",
      "         [0.0356],\n",
      "         [0.4077],\n",
      "         [0.8213],\n",
      "         [0.3888],\n",
      "         [0.0623],\n",
      "         [0.9766],\n",
      "         [0.1795],\n",
      "         [0.6933],\n",
      "         [0.8200],\n",
      "         [0.0383],\n",
      "         [0.5145],\n",
      "         [0.1035],\n",
      "         [0.3257],\n",
      "         [0.9102],\n",
      "         [0.7926]]], device='cuda:0', dtype=torch.float64)\n",
      "================iter 2============\n",
      "['shape/cube/2/cube_with_cone_20_pieces']\n",
      "tensor([[ True,  True,  True, False,  True,  True, False, False, False, False,\n",
      "         False, False, False, False, False, False, False,  True,  True,  True]],\n",
      "       device='cuda:0')\n",
      "acc torch.Size([1]) tensor([0.0500], device='cuda:0')\n",
      "acc_per_part torch.Size([1, 20]) tensor([[ True, False, False, False, False, False, False, False, False, False,\n",
      "         False, False, False, False, False, False, False, False, False, False]],\n",
      "       device='cuda:0')\n",
      "loss_per_data torch.Size([1, 20]) tensor([[0.0000e+00, 3.0697e+00, 8.0103e-01, 4.6409e+00, 3.7403e-01, 1.8360e+01,\n",
      "         1.9474e+01, 5.1718e+01, 9.0948e+01, 1.4896e+02, 1.8213e+00, 2.5670e+01,\n",
      "         8.6298e+00, 3.5629e+01, 7.5914e+01, 1.0703e+02, 1.3100e+03, 1.0440e+00,\n",
      "         1.6699e+01, 4.4189e+00]], device='cuda:0')\n",
      "scores torch.Size([1, 190, 1]) tensor([[[0.7986],\n",
      "         [0.6448],\n",
      "         [0.3524],\n",
      "         [0.8332],\n",
      "         [0.5166],\n",
      "         [0.4149],\n",
      "         [0.8014],\n",
      "         [0.2665],\n",
      "         [0.5029],\n",
      "         [0.2607],\n",
      "         [0.2988],\n",
      "         [0.2058],\n",
      "         [0.2200],\n",
      "         [0.5448],\n",
      "         [0.3922],\n",
      "         [0.8057],\n",
      "         [0.3585],\n",
      "         [0.5913],\n",
      "         [0.0264],\n",
      "         [0.0679],\n",
      "         [0.5512],\n",
      "         [0.1431],\n",
      "         [0.5169],\n",
      "         [0.2192],\n",
      "         [0.0355],\n",
      "         [0.0037],\n",
      "         [0.1691],\n",
      "         [0.6423],\n",
      "         [0.6673],\n",
      "         [0.7841],\n",
      "         [0.4737],\n",
      "         [0.1479],\n",
      "         [0.8700],\n",
      "         [0.9451],\n",
      "         [0.3580],\n",
      "         [0.4349],\n",
      "         [0.5439],\n",
      "         [0.9509],\n",
      "         [0.9736],\n",
      "         [0.8868],\n",
      "         [0.4410],\n",
      "         [0.3707],\n",
      "         [0.2851],\n",
      "         [0.1215],\n",
      "         [0.9373],\n",
      "         [0.4461],\n",
      "         [0.0871],\n",
      "         [0.1154],\n",
      "         [0.8989],\n",
      "         [0.5671],\n",
      "         [0.6012],\n",
      "         [0.8367],\n",
      "         [0.4317],\n",
      "         [0.3761],\n",
      "         [0.4479],\n",
      "         [0.6293],\n",
      "         [0.0540],\n",
      "         [0.2158],\n",
      "         [0.6989],\n",
      "         [0.4715],\n",
      "         [0.8534],\n",
      "         [0.9358],\n",
      "         [0.3856],\n",
      "         [0.2477],\n",
      "         [0.3705],\n",
      "         [0.4384],\n",
      "         [0.6787],\n",
      "         [0.2190],\n",
      "         [0.2806],\n",
      "         [0.7603],\n",
      "         [0.1675],\n",
      "         [0.4641],\n",
      "         [0.4198],\n",
      "         [0.8406],\n",
      "         [0.5086],\n",
      "         [0.0341],\n",
      "         [0.5416],\n",
      "         [0.9660],\n",
      "         [0.1892],\n",
      "         [0.7644],\n",
      "         [0.9880],\n",
      "         [0.0238],\n",
      "         [0.3884],\n",
      "         [0.9745],\n",
      "         [0.8684],\n",
      "         [0.1147],\n",
      "         [0.5024],\n",
      "         [0.1682],\n",
      "         [0.5243],\n",
      "         [0.0635],\n",
      "         [0.5441],\n",
      "         [0.3736],\n",
      "         [0.3118],\n",
      "         [0.6907],\n",
      "         [0.0069],\n",
      "         [0.4398],\n",
      "         [0.3170],\n",
      "         [0.3101],\n",
      "         [0.6395],\n",
      "         [0.7138],\n",
      "         [0.0060],\n",
      "         [0.8020],\n",
      "         [0.8458],\n",
      "         [0.6478],\n",
      "         [0.9541],\n",
      "         [0.6706],\n",
      "         [0.2329],\n",
      "         [0.8049],\n",
      "         [0.1525],\n",
      "         [0.5968],\n",
      "         [0.3218],\n",
      "         [0.9898],\n",
      "         [0.8708],\n",
      "         [0.9506],\n",
      "         [0.0572],\n",
      "         [0.7028],\n",
      "         [0.1475],\n",
      "         [0.1319],\n",
      "         [0.4204],\n",
      "         [0.6243],\n",
      "         [0.9653],\n",
      "         [0.4625],\n",
      "         [0.4653],\n",
      "         [0.8542],\n",
      "         [0.4940],\n",
      "         [0.7367],\n",
      "         [0.5284],\n",
      "         [0.7581],\n",
      "         [0.7341],\n",
      "         [0.1712],\n",
      "         [0.4342],\n",
      "         [0.1951],\n",
      "         [0.5890],\n",
      "         [0.7061],\n",
      "         [0.0870],\n",
      "         [0.9489],\n",
      "         [0.1902],\n",
      "         [0.1383],\n",
      "         [0.2611],\n",
      "         [0.0537],\n",
      "         [0.6797],\n",
      "         [0.3078],\n",
      "         [0.4266],\n",
      "         [0.3873],\n",
      "         [0.1537],\n",
      "         [0.0715],\n",
      "         [0.6106],\n",
      "         [0.7351],\n",
      "         [0.2282],\n",
      "         [0.7126],\n",
      "         [0.0440],\n",
      "         [0.0822],\n",
      "         [0.2725],\n",
      "         [0.6585],\n",
      "         [0.3424],\n",
      "         [0.9595],\n",
      "         [0.0392],\n",
      "         [0.2839],\n",
      "         [0.9977],\n",
      "         [0.3541],\n",
      "         [0.3730],\n",
      "         [0.4269],\n",
      "         [0.0396],\n",
      "         [0.0306],\n",
      "         [0.4254],\n",
      "         [0.4815],\n",
      "         [0.2308],\n",
      "         [0.7981],\n",
      "         [0.5586],\n",
      "         [0.9557],\n",
      "         [0.5195],\n",
      "         [0.0919],\n",
      "         [0.9552],\n",
      "         [0.1803],\n",
      "         [0.1188],\n",
      "         [0.0770],\n",
      "         [0.7867],\n",
      "         [0.2125],\n",
      "         [0.9041],\n",
      "         [0.3907],\n",
      "         [0.5226],\n",
      "         [0.9734],\n",
      "         [0.4908],\n",
      "         [0.1800],\n",
      "         [0.1491],\n",
      "         [0.3469],\n",
      "         [0.0643],\n",
      "         [0.1737],\n",
      "         [0.1973],\n",
      "         [0.3549]]], device='cuda:0', dtype=torch.float64)\n",
      "================iter 3============\n",
      "['shape/cube/2/cube_with_cone_20_pieces']\n",
      "tensor([[ True,  True,  True,  True,  True,  True,  True, False, False, False,\n",
      "          True, False,  True,  True,  True,  True,  True,  True,  True,  True]],\n",
      "       device='cuda:0')\n",
      "acc torch.Size([1]) tensor([0.0500], device='cuda:0')\n",
      "acc_per_part torch.Size([1, 20]) tensor([[ True, False, False, False, False, False, False, False, False, False,\n",
      "         False, False, False, False, False, False, False, False, False, False]],\n",
      "       device='cuda:0')\n",
      "loss_per_data torch.Size([1, 20]) tensor([[0.0000e+00, 3.0697e+00, 8.0103e-01, 4.6409e+00, 3.7403e-01, 1.8360e+01,\n",
      "         1.9474e+01, 1.3287e+02, 4.8176e+02, 4.0099e+02, 1.8213e+00, 1.1814e+02,\n",
      "         8.6298e+00, 3.5629e+01, 7.5914e+01, 1.0703e+02, 1.3100e+03, 1.0440e+00,\n",
      "         1.6699e+01, 4.4189e+00]], device='cuda:0')\n",
      "scores torch.Size([1, 190, 1]) tensor([[[0.5436],\n",
      "         [0.8145],\n",
      "         [0.9161],\n",
      "         [0.1567],\n",
      "         [0.4487],\n",
      "         [0.4399],\n",
      "         [0.2831],\n",
      "         [0.1808],\n",
      "         [0.5893],\n",
      "         [0.3311],\n",
      "         [0.2966],\n",
      "         [0.8208],\n",
      "         [0.4606],\n",
      "         [0.9428],\n",
      "         [0.3674],\n",
      "         [0.9902],\n",
      "         [0.0352],\n",
      "         [0.6053],\n",
      "         [0.0412],\n",
      "         [0.8408],\n",
      "         [0.2880],\n",
      "         [0.2449],\n",
      "         [0.0561],\n",
      "         [0.5695],\n",
      "         [0.5480],\n",
      "         [0.9899],\n",
      "         [0.2478],\n",
      "         [0.3259],\n",
      "         [0.2505],\n",
      "         [0.3160],\n",
      "         [0.8200],\n",
      "         [0.3057],\n",
      "         [0.5229],\n",
      "         [0.8169],\n",
      "         [0.5466],\n",
      "         [0.9988],\n",
      "         [0.9567],\n",
      "         [0.6785],\n",
      "         [0.0432],\n",
      "         [0.9256],\n",
      "         [0.0341],\n",
      "         [0.3425],\n",
      "         [0.7110],\n",
      "         [0.4211],\n",
      "         [0.6387],\n",
      "         [0.3984],\n",
      "         [0.2314],\n",
      "         [0.5089],\n",
      "         [0.8553],\n",
      "         [0.9699],\n",
      "         [0.9416],\n",
      "         [0.3943],\n",
      "         [0.1474],\n",
      "         [0.5125],\n",
      "         [0.6023],\n",
      "         [0.5498],\n",
      "         [0.8781],\n",
      "         [0.6871],\n",
      "         [0.1274],\n",
      "         [0.6930],\n",
      "         [0.6172],\n",
      "         [0.2654],\n",
      "         [0.1212],\n",
      "         [0.3693],\n",
      "         [0.4301],\n",
      "         [0.0437],\n",
      "         [0.5018],\n",
      "         [0.4800],\n",
      "         [0.5949],\n",
      "         [0.1375],\n",
      "         [0.7242],\n",
      "         [0.9577],\n",
      "         [0.5508],\n",
      "         [0.9414],\n",
      "         [0.3413],\n",
      "         [0.2198],\n",
      "         [0.5622],\n",
      "         [0.4137],\n",
      "         [0.5500],\n",
      "         [0.1293],\n",
      "         [0.1693],\n",
      "         [0.9860],\n",
      "         [0.5397],\n",
      "         [0.2270],\n",
      "         [0.1128],\n",
      "         [0.1033],\n",
      "         [0.9573],\n",
      "         [0.2589],\n",
      "         [0.2200],\n",
      "         [0.1491],\n",
      "         [0.6137],\n",
      "         [0.7139],\n",
      "         [0.9090],\n",
      "         [0.1983],\n",
      "         [0.3559],\n",
      "         [0.0389],\n",
      "         [0.7501],\n",
      "         [0.1874],\n",
      "         [0.6752],\n",
      "         [0.1835],\n",
      "         [0.4928],\n",
      "         [0.4030],\n",
      "         [0.2609],\n",
      "         [0.0997],\n",
      "         [0.4827],\n",
      "         [0.3462],\n",
      "         [0.8746],\n",
      "         [0.8228],\n",
      "         [0.5695],\n",
      "         [0.1925],\n",
      "         [0.2484],\n",
      "         [0.6373],\n",
      "         [0.1737],\n",
      "         [0.5948],\n",
      "         [0.2413],\n",
      "         [0.4182],\n",
      "         [0.5267],\n",
      "         [0.5011],\n",
      "         [0.7564],\n",
      "         [0.7490],\n",
      "         [0.8522],\n",
      "         [0.5644],\n",
      "         [0.9117],\n",
      "         [0.7200],\n",
      "         [0.0251],\n",
      "         [0.4280],\n",
      "         [0.1241],\n",
      "         [0.8124],\n",
      "         [0.6198],\n",
      "         [0.1914],\n",
      "         [0.6912],\n",
      "         [0.5143],\n",
      "         [0.7359],\n",
      "         [0.1520],\n",
      "         [0.6427],\n",
      "         [0.8877],\n",
      "         [0.2455],\n",
      "         [0.0258],\n",
      "         [0.9598],\n",
      "         [0.7795],\n",
      "         [0.1143],\n",
      "         [0.4736],\n",
      "         [0.0328],\n",
      "         [0.4864],\n",
      "         [0.7606],\n",
      "         [0.4942],\n",
      "         [0.6342],\n",
      "         [0.4616],\n",
      "         [0.9858],\n",
      "         [0.9200],\n",
      "         [0.3618],\n",
      "         [0.4545],\n",
      "         [0.5779],\n",
      "         [0.9649],\n",
      "         [0.6820],\n",
      "         [0.3417],\n",
      "         [0.9238],\n",
      "         [0.3948],\n",
      "         [0.6749],\n",
      "         [0.6657],\n",
      "         [0.2290],\n",
      "         [0.3859],\n",
      "         [0.9279],\n",
      "         [0.6018],\n",
      "         [0.6817],\n",
      "         [0.5248],\n",
      "         [0.4305],\n",
      "         [0.2464],\n",
      "         [0.1696],\n",
      "         [0.3567],\n",
      "         [0.2098],\n",
      "         [0.4797],\n",
      "         [0.5025],\n",
      "         [0.4048],\n",
      "         [0.6411],\n",
      "         [0.7114],\n",
      "         [0.7589],\n",
      "         [0.1357],\n",
      "         [0.8796],\n",
      "         [0.7648],\n",
      "         [0.2225],\n",
      "         [0.4231],\n",
      "         [0.9186],\n",
      "         [0.8376],\n",
      "         [0.9951],\n",
      "         [0.5276],\n",
      "         [0.9774],\n",
      "         [0.0870],\n",
      "         [0.6248],\n",
      "         [0.3517]]], device='cuda:0', dtype=torch.float64)\n",
      "================iter 4============\n",
      "['shape/cube/2/cube_with_cone_20_pieces']\n",
      "tensor([[True, True, True, True, True, True, True, True, True, True, True, True,\n",
      "         True, True, True, True, True, True, True, True]], device='cuda:0')\n",
      "acc torch.Size([1]) tensor([0.0500], device='cuda:0')\n",
      "acc_per_part torch.Size([1, 20]) tensor([[ True, False, False, False, False, False, False, False, False, False,\n",
      "         False, False, False, False, False, False, False, False, False, False]],\n",
      "       device='cuda:0')\n",
      "loss_per_data torch.Size([1, 20]) tensor([[0.0000e+00, 3.0697e+00, 8.0103e-01, 4.6409e+00, 3.7403e-01, 1.8360e+01,\n",
      "         1.9474e+01, 1.3287e+02, 4.8176e+02, 4.0099e+02, 1.8213e+00, 1.1814e+02,\n",
      "         8.6298e+00, 3.5629e+01, 7.5914e+01, 1.0703e+02, 1.3100e+03, 1.0440e+00,\n",
      "         1.6699e+01, 4.4189e+00]], device='cuda:0')\n",
      "scores torch.Size([1, 190, 1]) tensor([[[0.5047],\n",
      "         [0.1920],\n",
      "         [0.8930],\n",
      "         [0.9174],\n",
      "         [0.5085],\n",
      "         [0.0640],\n",
      "         [0.6172],\n",
      "         [0.8189],\n",
      "         [0.6411],\n",
      "         [0.2814],\n",
      "         [0.0819],\n",
      "         [0.1452],\n",
      "         [0.0388],\n",
      "         [0.3587],\n",
      "         [0.0497],\n",
      "         [0.4584],\n",
      "         [0.9106],\n",
      "         [0.6178],\n",
      "         [0.2795],\n",
      "         [0.7404],\n",
      "         [0.9141],\n",
      "         [0.3276],\n",
      "         [0.7927],\n",
      "         [0.9457],\n",
      "         [0.6681],\n",
      "         [0.7875],\n",
      "         [0.3688],\n",
      "         [0.2151],\n",
      "         [0.9971],\n",
      "         [0.2443],\n",
      "         [0.8371],\n",
      "         [0.7211],\n",
      "         [0.5048],\n",
      "         [0.1338],\n",
      "         [0.2064],\n",
      "         [0.6999],\n",
      "         [0.7228],\n",
      "         [0.0808],\n",
      "         [0.4696],\n",
      "         [0.0051],\n",
      "         [0.0023],\n",
      "         [0.2696],\n",
      "         [0.1942],\n",
      "         [0.0378],\n",
      "         [0.1780],\n",
      "         [0.0548],\n",
      "         [0.7216],\n",
      "         [0.3979],\n",
      "         [0.4761],\n",
      "         [0.7371],\n",
      "         [0.1427],\n",
      "         [0.9747],\n",
      "         [0.3879],\n",
      "         [0.8461],\n",
      "         [0.5967],\n",
      "         [0.7940],\n",
      "         [0.1212],\n",
      "         [0.1507],\n",
      "         [0.9815],\n",
      "         [0.6165],\n",
      "         [0.8457],\n",
      "         [0.7853],\n",
      "         [0.0546],\n",
      "         [0.6281],\n",
      "         [0.7238],\n",
      "         [0.4568],\n",
      "         [0.1894],\n",
      "         [0.2964],\n",
      "         [0.7014],\n",
      "         [0.7563],\n",
      "         [0.3315],\n",
      "         [0.9492],\n",
      "         [0.9674],\n",
      "         [0.2155],\n",
      "         [0.0214],\n",
      "         [0.7762],\n",
      "         [0.9447],\n",
      "         [0.6075],\n",
      "         [0.6031],\n",
      "         [0.2621],\n",
      "         [0.8426],\n",
      "         [0.8002],\n",
      "         [0.3848],\n",
      "         [0.8551],\n",
      "         [0.2056],\n",
      "         [0.1082],\n",
      "         [0.4369],\n",
      "         [0.1832],\n",
      "         [0.8322],\n",
      "         [0.6727],\n",
      "         [0.8171],\n",
      "         [0.4618],\n",
      "         [0.8929],\n",
      "         [0.2275],\n",
      "         [0.1895],\n",
      "         [0.9177],\n",
      "         [0.2283],\n",
      "         [0.7178],\n",
      "         [0.8115],\n",
      "         [0.4433],\n",
      "         [0.3692],\n",
      "         [0.9543],\n",
      "         [0.1501],\n",
      "         [0.1204],\n",
      "         [0.9987],\n",
      "         [0.3138],\n",
      "         [0.0865],\n",
      "         [0.8727],\n",
      "         [0.8041],\n",
      "         [0.3520],\n",
      "         [0.9456],\n",
      "         [0.2107],\n",
      "         [0.8942],\n",
      "         [0.2023],\n",
      "         [0.0075],\n",
      "         [0.6266],\n",
      "         [0.2575],\n",
      "         [0.8534],\n",
      "         [0.2824],\n",
      "         [0.2162],\n",
      "         [0.8528],\n",
      "         [0.4939],\n",
      "         [0.7645],\n",
      "         [0.5653],\n",
      "         [0.1291],\n",
      "         [0.8134],\n",
      "         [0.0109],\n",
      "         [0.2102],\n",
      "         [0.0969],\n",
      "         [0.7284],\n",
      "         [0.9459],\n",
      "         [0.6604],\n",
      "         [0.1328],\n",
      "         [0.5775],\n",
      "         [0.8345],\n",
      "         [0.8310],\n",
      "         [0.8053],\n",
      "         [0.0590],\n",
      "         [0.2718],\n",
      "         [0.0510],\n",
      "         [0.7682],\n",
      "         [0.6222],\n",
      "         [0.4058],\n",
      "         [0.8959],\n",
      "         [0.8614],\n",
      "         [0.2739],\n",
      "         [0.1753],\n",
      "         [0.3910],\n",
      "         [0.4033],\n",
      "         [0.7527],\n",
      "         [0.2857],\n",
      "         [0.3142],\n",
      "         [0.8810],\n",
      "         [0.3153],\n",
      "         [0.5216],\n",
      "         [0.8797],\n",
      "         [0.2087],\n",
      "         [0.6820],\n",
      "         [0.0872],\n",
      "         [0.2301],\n",
      "         [0.4073],\n",
      "         [0.0225],\n",
      "         [0.9373],\n",
      "         [0.9046],\n",
      "         [0.8348],\n",
      "         [0.2508],\n",
      "         [0.9748],\n",
      "         [0.2484],\n",
      "         [0.2665],\n",
      "         [0.4649],\n",
      "         [0.6623],\n",
      "         [0.1543],\n",
      "         [0.5980],\n",
      "         [0.2154],\n",
      "         [0.5077],\n",
      "         [0.5845],\n",
      "         [0.9125],\n",
      "         [0.5314],\n",
      "         [0.6196],\n",
      "         [0.9495],\n",
      "         [0.3580],\n",
      "         [0.2329],\n",
      "         [0.2333],\n",
      "         [0.2793],\n",
      "         [0.1841],\n",
      "         [0.6625],\n",
      "         [0.9512],\n",
      "         [0.6988],\n",
      "         [0.5240],\n",
      "         [0.3651]]], device='cuda:0', dtype=torch.float64)\n",
      "================iter 5============\n",
      "['shape/cube/2/cube_with_cone_20_pieces']\n",
      "tensor([[True, True, True, True, True, True, True, True, True, True, True, True,\n",
      "         True, True, True, True, True, True, True, True]], device='cuda:0')\n",
      "@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@\n",
      "['shape/ellipsoid/1/ellipsoid_512_128_64_64_0_0_1']\n",
      "gt_trans_torch.Size([1, 20, 3])_tensor([[[-1.1086e-01,  3.7831e-02,  4.5426e-02],\n",
      "         [-9.7644e-02,  3.3967e-02,  3.8254e-02],\n",
      "         [ 2.4120e-02, -1.2522e-02, -1.6408e-02],\n",
      "         [ 3.4528e-02, -8.1185e-03, -3.6454e-02],\n",
      "         [ 4.5728e-02, -1.2286e-02, -4.7813e-02],\n",
      "         [ 6.9604e-02, -2.8044e-02, -2.4855e-02],\n",
      "         [ 7.8366e-02, -3.0125e-02, -4.3520e-02],\n",
      "         [ 9.2528e-02, -2.8089e-02, -5.3526e-02],\n",
      "         [ 1.0447e-01, -3.8855e-02, -5.7816e-02],\n",
      "         [ 1.1626e-01, -3.8509e-02, -7.1534e-02],\n",
      "         [-8.1064e-02,  3.3108e-02,  3.4448e-02],\n",
      "         [-6.8945e-02,  4.7991e-02,  1.0940e-02],\n",
      "         [-5.6229e-02,  1.7179e-02,  2.2284e-02],\n",
      "         [-3.9996e-02,  1.2556e-02,  2.1112e-02],\n",
      "         [-2.9135e-02,  4.6236e-03,  1.1581e-02],\n",
      "         [-1.9822e-02,  1.5303e-02, -1.4248e-02],\n",
      "         [ 3.0809e-18,  3.1086e-18, -2.8866e-18],\n",
      "         [ 6.9985e-03, -9.5608e-03, -1.6182e-02],\n",
      "         [ 0.0000e+00,  0.0000e+00,  0.0000e+00],\n",
      "         [ 0.0000e+00,  0.0000e+00,  0.0000e+00]]], device='cuda:0')\n",
      "gt_rots_torch.Size([1, 20, 4])_tensor([[[ 0.2828, -0.0318,  0.9554,  0.0792],\n",
      "         [-0.0170,  0.7567,  0.5221,  0.3931],\n",
      "         [ 0.8931, -0.2946, -0.1459, -0.3070],\n",
      "         [ 0.8109,  0.2653,  0.4686, -0.2291],\n",
      "         [ 0.8658,  0.0889, -0.0240, -0.4918],\n",
      "         [ 0.3469,  0.4200, -0.5863,  0.5996],\n",
      "         [ 0.0633,  0.0633,  0.8865, -0.4540],\n",
      "         [ 0.6416,  0.5163, -0.1923, -0.5336],\n",
      "         [-0.3040,  0.0473,  0.9511,  0.0280],\n",
      "         [-0.5871,  0.4234,  0.6118,  0.3190],\n",
      "         [-0.3609,  0.6589,  0.2347,  0.6169],\n",
      "         [ 0.8200, -0.2711, -0.1190,  0.4899],\n",
      "         [ 0.1776, -0.5197,  0.7988, -0.2457],\n",
      "         [ 0.2605, -0.0238,  0.0660,  0.9629],\n",
      "         [-0.0202,  0.7679,  0.4012,  0.4989],\n",
      "         [ 0.0523,  0.6842,  0.6167, -0.3857],\n",
      "         [ 0.9256, -0.3737, -0.0339, -0.0490],\n",
      "         [-0.0741,  0.4034,  0.9032,  0.1265],\n",
      "         [ 0.0000,  0.0000,  0.0000,  0.0000],\n",
      "         [ 0.0000,  0.0000,  0.0000,  0.0000]]], device='cuda:0')\n",
      "noisy_trans_and_rots_torch.Size([1, 20, 7])_tensor([[[-0.5880,  0.0000,  0.5958, -0.1634,  0.0000,  0.0000,  0.6717],\n",
      "         [ 1.9561,  0.0000,  0.5520,  1.2931,  0.0000,  0.0000, -0.9021],\n",
      "         [ 0.0516,  0.0000, -0.3321,  0.6947,  0.0000,  0.0000,  1.3900],\n",
      "         [ 0.6625,  0.0000, -0.4535,  0.1604,  0.0000,  0.0000, -1.0426],\n",
      "         [-0.0675,  0.0000,  1.2949,  0.2524,  0.0000,  0.0000, -2.2134],\n",
      "         [ 0.5327,  0.0000,  0.5522, -1.2107,  0.0000,  0.0000,  1.1781],\n",
      "         [-0.9514,  0.0000, -1.7219, -0.2567,  0.0000,  0.0000, -0.1718],\n",
      "         [ 0.1238,  0.0000, -0.2843, -1.3312,  0.0000,  0.0000,  0.2690],\n",
      "         [-0.0166,  0.0000,  1.4676,  0.8509,  0.0000,  0.0000,  1.0048],\n",
      "         [ 0.7275,  0.0000, -2.2317, -0.5400,  0.0000,  0.0000, -0.6162],\n",
      "         [ 2.0765,  0.0000, -1.0147, -0.4673,  0.0000,  0.0000, -1.0007],\n",
      "         [-0.5518,  0.0000,  0.0909,  1.5773,  0.0000,  0.0000, -0.0276],\n",
      "         [-1.7222,  0.0000,  0.8240,  1.4414,  0.0000,  0.0000, -0.5199],\n",
      "         [ 0.8027,  0.0000,  0.8824, -0.7676,  0.0000,  0.0000,  0.2668],\n",
      "         [-2.7649,  0.0000, -0.0241, -1.1488,  0.0000,  0.0000, -0.5396],\n",
      "         [ 0.0100,  0.0000,  0.0523,  0.4985,  0.0000,  0.0000, -0.7111],\n",
      "         [ 0.3043,  0.0000,  0.6227, -0.7926,  0.0000,  0.0000,  0.5477],\n",
      "         [ 2.1547,  0.0000, -0.8518, -1.9560,  0.0000,  0.0000, -0.8652],\n",
      "         [-0.9201,  0.0000, -1.8107,  0.2139,  0.0000,  0.0000, -0.3365],\n",
      "         [ 0.5083,  0.0000, -0.8709,  0.1199,  0.0000,  0.0000,  0.4672]]],\n",
      "       device='cuda:0')\n",
      "================iter 0============\n",
      "['shape/ellipsoid/1/ellipsoid_512_128_64_64_0_0_1']\n",
      "tensor([[False, False, False, False, False, False, False, False, False, False,\n",
      "         False, False, False, False, False, False,  True, False, False, False]],\n",
      "       device='cuda:0')\n",
      "acc torch.Size([1]) tensor([0.0556], device='cuda:0')\n",
      "acc_per_part torch.Size([1, 20]) tensor([[False, False, False, False, False, False, False, False, False, False,\n",
      "         False, False, False, False, False, False,  True, False, False, False]],\n",
      "       device='cuda:0')\n",
      "loss_per_data torch.Size([1, 20]) tensor([[ 0.8689,  5.2823,  2.3110,  1.0632,  2.5361,  0.7355,  4.0870,  3.9491,\n",
      "          6.0776, 16.2774,  2.2720,  2.1473,  1.7973,  0.9963,  3.4686,  6.9024,\n",
      "          0.0000, 12.9246,  9.5666,  1.8090]], device='cuda:0')\n",
      "scores torch.Size([1, 190, 1]) tensor([[[0.4763],\n",
      "         [0.3694],\n",
      "         [0.4211],\n",
      "         [0.8002],\n",
      "         [0.9731],\n",
      "         [0.4129],\n",
      "         [0.0275],\n",
      "         [0.5428],\n",
      "         [0.5270],\n",
      "         [0.9402],\n",
      "         [0.8658],\n",
      "         [0.6419],\n",
      "         [0.0720],\n",
      "         [0.8578],\n",
      "         [0.5336],\n",
      "         [0.7564],\n",
      "         [0.4186],\n",
      "         [0.3388],\n",
      "         [0.2431],\n",
      "         [0.0191],\n",
      "         [0.2321],\n",
      "         [0.9362],\n",
      "         [0.8200],\n",
      "         [0.5724],\n",
      "         [0.5150],\n",
      "         [0.7612],\n",
      "         [0.0414],\n",
      "         [0.3417],\n",
      "         [0.4193],\n",
      "         [0.5265],\n",
      "         [0.0687],\n",
      "         [0.6026],\n",
      "         [0.3317],\n",
      "         [0.8688],\n",
      "         [0.1620],\n",
      "         [0.0860],\n",
      "         [0.9229],\n",
      "         [0.1056],\n",
      "         [0.4446],\n",
      "         [0.1994],\n",
      "         [0.7478],\n",
      "         [0.1729],\n",
      "         [0.3938],\n",
      "         [0.9888],\n",
      "         [0.4627],\n",
      "         [0.1784],\n",
      "         [0.2030],\n",
      "         [0.6278],\n",
      "         [0.5264],\n",
      "         [0.5499],\n",
      "         [0.3056],\n",
      "         [0.6599],\n",
      "         [0.0524],\n",
      "         [0.5685],\n",
      "         [0.4335],\n",
      "         [0.0749],\n",
      "         [0.6385],\n",
      "         [0.4273],\n",
      "         [0.5438],\n",
      "         [0.9402],\n",
      "         [0.0978],\n",
      "         [0.6278],\n",
      "         [0.5793],\n",
      "         [0.7242],\n",
      "         [0.8051],\n",
      "         [0.0261],\n",
      "         [0.6139],\n",
      "         [0.8481],\n",
      "         [0.8131],\n",
      "         [0.8133],\n",
      "         [0.5042],\n",
      "         [0.5498],\n",
      "         [0.4799],\n",
      "         [0.7674],\n",
      "         [0.0033],\n",
      "         [0.2628],\n",
      "         [0.2020],\n",
      "         [0.4346],\n",
      "         [0.9940],\n",
      "         [0.6286],\n",
      "         [0.4397],\n",
      "         [0.9233],\n",
      "         [0.3435],\n",
      "         [0.4855],\n",
      "         [0.3075],\n",
      "         [0.7503],\n",
      "         [0.8412],\n",
      "         [0.9537],\n",
      "         [0.8418],\n",
      "         [0.9920],\n",
      "         [0.9321],\n",
      "         [0.5407],\n",
      "         [0.1733],\n",
      "         [0.2579],\n",
      "         [0.2518],\n",
      "         [0.0091],\n",
      "         [0.8234],\n",
      "         [0.1052],\n",
      "         [0.5734],\n",
      "         [0.7174],\n",
      "         [0.4179],\n",
      "         [0.5002],\n",
      "         [0.3467],\n",
      "         [0.3373],\n",
      "         [0.2519],\n",
      "         [0.7789],\n",
      "         [0.6712],\n",
      "         [0.1220],\n",
      "         [0.7655],\n",
      "         [0.1520],\n",
      "         [0.9831],\n",
      "         [0.5961],\n",
      "         [0.5811],\n",
      "         [0.4652],\n",
      "         [0.0039],\n",
      "         [0.6624],\n",
      "         [0.7594],\n",
      "         [0.5687],\n",
      "         [0.6316],\n",
      "         [0.6241],\n",
      "         [0.1073],\n",
      "         [0.6984],\n",
      "         [0.2970],\n",
      "         [0.4929],\n",
      "         [0.7885],\n",
      "         [0.7645],\n",
      "         [0.9232],\n",
      "         [0.9139],\n",
      "         [0.5396],\n",
      "         [0.5166],\n",
      "         [0.8396],\n",
      "         [0.5987],\n",
      "         [0.2074],\n",
      "         [0.9043],\n",
      "         [0.8882],\n",
      "         [0.3793],\n",
      "         [0.3838],\n",
      "         [0.1362],\n",
      "         [0.9945],\n",
      "         [0.2663],\n",
      "         [0.0808],\n",
      "         [0.2718],\n",
      "         [0.4890],\n",
      "         [0.8568],\n",
      "         [0.5446],\n",
      "         [0.5447],\n",
      "         [0.4767],\n",
      "         [0.3359],\n",
      "         [0.9960],\n",
      "         [0.1019],\n",
      "         [0.6014],\n",
      "         [0.7069],\n",
      "         [0.5969],\n",
      "         [0.3893],\n",
      "         [0.5260],\n",
      "         [0.0853],\n",
      "         [0.5142],\n",
      "         [0.9633],\n",
      "         [0.3716],\n",
      "         [0.3064],\n",
      "         [0.0252],\n",
      "         [0.6106],\n",
      "         [0.7514],\n",
      "         [0.1358],\n",
      "         [0.4299],\n",
      "         [0.7024],\n",
      "         [0.5214],\n",
      "         [0.6850],\n",
      "         [0.5198],\n",
      "         [0.0183],\n",
      "         [0.9169],\n",
      "         [0.2886],\n",
      "         [0.7764],\n",
      "         [0.9607],\n",
      "         [0.8364],\n",
      "         [0.3655],\n",
      "         [0.7813],\n",
      "         [0.2437],\n",
      "         [0.0364],\n",
      "         [0.2431],\n",
      "         [0.8063],\n",
      "         [0.1136],\n",
      "         [0.5108],\n",
      "         [0.3908],\n",
      "         [0.2569],\n",
      "         [0.5807],\n",
      "         [0.0473],\n",
      "         [0.0200],\n",
      "         [0.5957],\n",
      "         [0.0093]]], device='cuda:0', dtype=torch.float64)\n",
      "================iter 1============\n",
      "['shape/ellipsoid/1/ellipsoid_512_128_64_64_0_0_1']\n",
      "tensor([[False, False, False, False,  True, False, False, False, False, False,\n",
      "         False, False, False, False, False, False,  True, False, False, False]],\n",
      "       device='cuda:0')\n",
      "acc torch.Size([1]) tensor([0.0556], device='cuda:0')\n",
      "acc_per_part torch.Size([1, 20]) tensor([[False, False, False, False, False, False, False, False, False, False,\n",
      "         False, False, False, False, False, False,  True, False, False, False]],\n",
      "       device='cuda:0')\n",
      "loss_per_data torch.Size([1, 20]) tensor([[ 0.6140,  0.8104,  0.6731,  1.4350,  2.5361,  1.9496,  5.7667,  4.7523,\n",
      "          9.3118,  8.3803,  0.5745,  1.3560,  2.4036,  3.0730,  0.3858,  4.7819,\n",
      "          0.0000, 31.4359, 27.2844,  8.4231]], device='cuda:0')\n",
      "scores torch.Size([1, 190, 1]) tensor([[[0.5625],\n",
      "         [0.0250],\n",
      "         [0.6861],\n",
      "         [0.0653],\n",
      "         [0.4566],\n",
      "         [0.3766],\n",
      "         [0.9267],\n",
      "         [0.9100],\n",
      "         [0.6151],\n",
      "         [0.0560],\n",
      "         [0.2168],\n",
      "         [0.3681],\n",
      "         [0.2378],\n",
      "         [0.7375],\n",
      "         [0.9277],\n",
      "         [0.2528],\n",
      "         [0.1376],\n",
      "         [0.7960],\n",
      "         [0.6993],\n",
      "         [0.5118],\n",
      "         [0.5027],\n",
      "         [0.8716],\n",
      "         [0.2144],\n",
      "         [0.7861],\n",
      "         [0.5322],\n",
      "         [0.0367],\n",
      "         [0.9347],\n",
      "         [0.3141],\n",
      "         [0.2177],\n",
      "         [0.2359],\n",
      "         [0.2692],\n",
      "         [0.5845],\n",
      "         [0.4559],\n",
      "         [0.1221],\n",
      "         [0.8490],\n",
      "         [0.4502],\n",
      "         [0.8532],\n",
      "         [0.6999],\n",
      "         [0.7613],\n",
      "         [0.5461],\n",
      "         [0.1361],\n",
      "         [0.2771],\n",
      "         [0.4830],\n",
      "         [0.5280],\n",
      "         [0.3551],\n",
      "         [0.3183],\n",
      "         [0.5324],\n",
      "         [0.1994],\n",
      "         [0.6638],\n",
      "         [0.4740],\n",
      "         [0.8586],\n",
      "         [0.2912],\n",
      "         [0.7319],\n",
      "         [0.7374],\n",
      "         [0.6483],\n",
      "         [0.8683],\n",
      "         [0.9346],\n",
      "         [0.1426],\n",
      "         [0.7880],\n",
      "         [0.7090],\n",
      "         [0.7562],\n",
      "         [0.6943],\n",
      "         [0.4388],\n",
      "         [0.4420],\n",
      "         [0.6822],\n",
      "         [0.9446],\n",
      "         [0.1735],\n",
      "         [0.4273],\n",
      "         [0.6040],\n",
      "         [0.9669],\n",
      "         [0.6568],\n",
      "         [0.3248],\n",
      "         [0.2861],\n",
      "         [0.6296],\n",
      "         [0.9788],\n",
      "         [0.8312],\n",
      "         [0.9576],\n",
      "         [0.4334],\n",
      "         [0.4940],\n",
      "         [0.5996],\n",
      "         [0.4258],\n",
      "         [0.8919],\n",
      "         [0.6429],\n",
      "         [0.1003],\n",
      "         [0.4423],\n",
      "         [0.2697],\n",
      "         [0.2302],\n",
      "         [0.2260],\n",
      "         [0.4116],\n",
      "         [0.2077],\n",
      "         [0.1124],\n",
      "         [0.6485],\n",
      "         [0.4215],\n",
      "         [0.3772],\n",
      "         [0.8472],\n",
      "         [0.8550],\n",
      "         [0.4635],\n",
      "         [0.4605],\n",
      "         [0.9645],\n",
      "         [0.8207],\n",
      "         [0.4502],\n",
      "         [0.4115],\n",
      "         [0.9875],\n",
      "         [0.8164],\n",
      "         [0.5723],\n",
      "         [0.6321],\n",
      "         [0.5485],\n",
      "         [0.2656],\n",
      "         [0.0387],\n",
      "         [0.9172],\n",
      "         [0.8114],\n",
      "         [0.8926],\n",
      "         [0.3058],\n",
      "         [0.5367],\n",
      "         [0.5755],\n",
      "         [0.5321],\n",
      "         [0.0561],\n",
      "         [0.7375],\n",
      "         [0.4994],\n",
      "         [0.8172],\n",
      "         [0.5811],\n",
      "         [0.0757],\n",
      "         [0.5845],\n",
      "         [0.4214],\n",
      "         [0.5038],\n",
      "         [0.8451],\n",
      "         [0.3974],\n",
      "         [0.6415],\n",
      "         [0.8198],\n",
      "         [0.5345],\n",
      "         [0.6725],\n",
      "         [0.4913],\n",
      "         [0.8631],\n",
      "         [0.4108],\n",
      "         [0.7962],\n",
      "         [0.0040],\n",
      "         [0.1662],\n",
      "         [0.3776],\n",
      "         [0.9926],\n",
      "         [0.1545],\n",
      "         [0.0029],\n",
      "         [0.6606],\n",
      "         [0.9900],\n",
      "         [0.4877],\n",
      "         [0.7753],\n",
      "         [0.7866],\n",
      "         [0.5218],\n",
      "         [0.7807],\n",
      "         [0.4148],\n",
      "         [0.6175],\n",
      "         [0.0366],\n",
      "         [0.2355],\n",
      "         [0.3997],\n",
      "         [0.0789],\n",
      "         [0.3562],\n",
      "         [0.7437],\n",
      "         [0.6736],\n",
      "         [0.5436],\n",
      "         [0.2682],\n",
      "         [0.3003],\n",
      "         [0.6547],\n",
      "         [0.7681],\n",
      "         [0.8719],\n",
      "         [0.0391],\n",
      "         [0.4142],\n",
      "         [0.7249],\n",
      "         [0.0388],\n",
      "         [0.7895],\n",
      "         [0.9459],\n",
      "         [0.7483],\n",
      "         [0.9176],\n",
      "         [0.5811],\n",
      "         [0.1069],\n",
      "         [0.7220],\n",
      "         [0.7148],\n",
      "         [0.8454],\n",
      "         [0.8969],\n",
      "         [0.9516],\n",
      "         [0.2638],\n",
      "         [0.4273],\n",
      "         [0.9833],\n",
      "         [0.7060],\n",
      "         [0.6012],\n",
      "         [0.8908],\n",
      "         [0.5063],\n",
      "         [0.8313],\n",
      "         [0.7979],\n",
      "         [0.9113],\n",
      "         [0.7530],\n",
      "         [0.4111]]], device='cuda:0', dtype=torch.float64)\n",
      "================iter 2============\n",
      "['shape/ellipsoid/1/ellipsoid_512_128_64_64_0_0_1']\n",
      "tensor([[False, False, False, False,  True, False, False, False, False,  True,\n",
      "         False,  True, False, False, False,  True,  True, False, False, False]],\n",
      "       device='cuda:0')\n",
      "acc torch.Size([1]) tensor([0.0556], device='cuda:0')\n",
      "acc_per_part torch.Size([1, 20]) tensor([[False, False, False, False, False, False, False, False, False, False,\n",
      "         False, False, False, False, False, False,  True, False, False, False]],\n",
      "       device='cuda:0')\n",
      "loss_per_data torch.Size([1, 20]) tensor([[ 6.5960,  2.2917,  9.9805,  1.1838,  2.5361,  2.1658,  5.0964,  6.2606,\n",
      "          1.8378,  8.3803,  1.9493,  1.3560,  7.9590,  5.9929,  0.5379,  4.7819,\n",
      "          0.0000, 62.7091, 35.8775, 29.0410]], device='cuda:0')\n",
      "scores torch.Size([1, 190, 1]) tensor([[[0.1471],\n",
      "         [0.8285],\n",
      "         [0.8846],\n",
      "         [0.8781],\n",
      "         [0.0103],\n",
      "         [0.8162],\n",
      "         [0.9225],\n",
      "         [0.2891],\n",
      "         [0.8332],\n",
      "         [0.7904],\n",
      "         [0.0166],\n",
      "         [0.1771],\n",
      "         [0.3691],\n",
      "         [0.8048],\n",
      "         [0.9392],\n",
      "         [0.9313],\n",
      "         [0.1724],\n",
      "         [0.7496],\n",
      "         [0.4903],\n",
      "         [0.5215],\n",
      "         [0.8989],\n",
      "         [0.9896],\n",
      "         [0.0886],\n",
      "         [0.2628],\n",
      "         [0.4792],\n",
      "         [0.0013],\n",
      "         [0.6752],\n",
      "         [0.6049],\n",
      "         [0.3716],\n",
      "         [0.8107],\n",
      "         [0.2234],\n",
      "         [0.3198],\n",
      "         [0.1949],\n",
      "         [0.9423],\n",
      "         [0.8761],\n",
      "         [0.3408],\n",
      "         [0.0850],\n",
      "         [0.8257],\n",
      "         [0.8531],\n",
      "         [0.2964],\n",
      "         [0.9543],\n",
      "         [0.0606],\n",
      "         [0.9951],\n",
      "         [0.8328],\n",
      "         [0.8502],\n",
      "         [0.7621],\n",
      "         [0.1127],\n",
      "         [0.3566],\n",
      "         [0.4416],\n",
      "         [0.0658],\n",
      "         [0.3678],\n",
      "         [0.2126],\n",
      "         [0.5263],\n",
      "         [0.7671],\n",
      "         [0.2575],\n",
      "         [0.4475],\n",
      "         [0.4932],\n",
      "         [0.8845],\n",
      "         [0.8418],\n",
      "         [0.3140],\n",
      "         [0.5866],\n",
      "         [0.5426],\n",
      "         [0.0377],\n",
      "         [0.3038],\n",
      "         [0.2896],\n",
      "         [0.7778],\n",
      "         [0.6311],\n",
      "         [0.9255],\n",
      "         [0.5587],\n",
      "         [0.9774],\n",
      "         [0.8201],\n",
      "         [0.5874],\n",
      "         [0.2996],\n",
      "         [0.2338],\n",
      "         [0.3371],\n",
      "         [0.8176],\n",
      "         [0.0050],\n",
      "         [0.8074],\n",
      "         [0.3071],\n",
      "         [0.6390],\n",
      "         [0.4463],\n",
      "         [0.0556],\n",
      "         [0.1860],\n",
      "         [0.3992],\n",
      "         [0.3174],\n",
      "         [0.0086],\n",
      "         [0.6021],\n",
      "         [0.2501],\n",
      "         [0.8684],\n",
      "         [0.8949],\n",
      "         [0.3596],\n",
      "         [0.1309],\n",
      "         [0.6272],\n",
      "         [0.4342],\n",
      "         [0.1392],\n",
      "         [0.1060],\n",
      "         [0.0910],\n",
      "         [0.6997],\n",
      "         [0.6970],\n",
      "         [0.6126],\n",
      "         [0.2351],\n",
      "         [0.0541],\n",
      "         [0.3146],\n",
      "         [0.3845],\n",
      "         [0.2798],\n",
      "         [0.4121],\n",
      "         [0.8385],\n",
      "         [0.6424],\n",
      "         [0.1306],\n",
      "         [0.5496],\n",
      "         [0.2795],\n",
      "         [0.8634],\n",
      "         [0.9712],\n",
      "         [0.4877],\n",
      "         [0.1839],\n",
      "         [0.8606],\n",
      "         [0.8847],\n",
      "         [0.7933],\n",
      "         [0.4198],\n",
      "         [0.8141],\n",
      "         [0.3281],\n",
      "         [0.2809],\n",
      "         [0.3061],\n",
      "         [0.4917],\n",
      "         [0.1395],\n",
      "         [0.8512],\n",
      "         [0.6726],\n",
      "         [0.5798],\n",
      "         [0.7033],\n",
      "         [0.1874],\n",
      "         [0.8584],\n",
      "         [0.2167],\n",
      "         [0.7316],\n",
      "         [0.4168],\n",
      "         [0.4377],\n",
      "         [0.9443],\n",
      "         [0.5766],\n",
      "         [0.4339],\n",
      "         [0.8781],\n",
      "         [0.6020],\n",
      "         [0.9087],\n",
      "         [0.2716],\n",
      "         [0.9615],\n",
      "         [0.3930],\n",
      "         [0.5462],\n",
      "         [0.1959],\n",
      "         [0.6836],\n",
      "         [0.7527],\n",
      "         [0.2763],\n",
      "         [0.7278],\n",
      "         [0.1492],\n",
      "         [0.5698],\n",
      "         [0.6425],\n",
      "         [0.1814],\n",
      "         [0.7910],\n",
      "         [0.7422],\n",
      "         [0.2026],\n",
      "         [0.6908],\n",
      "         [0.1567],\n",
      "         [0.9998],\n",
      "         [0.7599],\n",
      "         [0.2232],\n",
      "         [0.6712],\n",
      "         [0.9746],\n",
      "         [0.4247],\n",
      "         [0.9772],\n",
      "         [0.4992],\n",
      "         [0.5156],\n",
      "         [0.5166],\n",
      "         [0.1534],\n",
      "         [0.4333],\n",
      "         [0.4071],\n",
      "         [0.9352],\n",
      "         [0.3492],\n",
      "         [0.9298],\n",
      "         [0.2711],\n",
      "         [0.8501],\n",
      "         [0.2323],\n",
      "         [0.1433],\n",
      "         [0.9844],\n",
      "         [0.8711],\n",
      "         [0.5261],\n",
      "         [0.0903],\n",
      "         [0.3060],\n",
      "         [0.1291],\n",
      "         [0.3828],\n",
      "         [0.1529],\n",
      "         [0.7175],\n",
      "         [0.7859],\n",
      "         [0.2209]]], device='cuda:0', dtype=torch.float64)\n",
      "================iter 3============\n",
      "['shape/ellipsoid/1/ellipsoid_512_128_64_64_0_0_1']\n",
      "tensor([[ True,  True, False, False,  True, False, False, False, False,  True,\n",
      "          True,  True,  True, False, False,  True,  True,  True, False, False]],\n",
      "       device='cuda:0')\n",
      "acc torch.Size([1]) tensor([0.0556], device='cuda:0')\n",
      "acc_per_part torch.Size([1, 20]) tensor([[False, False, False, False, False, False, False, False, False, False,\n",
      "         False, False, False, False, False, False,  True, False, False, False]],\n",
      "       device='cuda:0')\n",
      "loss_per_data torch.Size([1, 20]) tensor([[ 6.5960,  2.2917, 14.8492,  3.2307,  2.5361,  2.1171, 20.3653, 16.6858,\n",
      "          7.4945,  8.3803,  1.9493,  1.3560,  7.9590,  9.2579,  1.1723,  4.7819,\n",
      "          0.0000, 62.7091, 40.8466, 78.5570]], device='cuda:0')\n",
      "scores torch.Size([1, 190, 1]) tensor([[[0.4307],\n",
      "         [0.6765],\n",
      "         [0.3856],\n",
      "         [0.4063],\n",
      "         [0.8083],\n",
      "         [0.8086],\n",
      "         [0.8500],\n",
      "         [0.6211],\n",
      "         [0.4126],\n",
      "         [0.0435],\n",
      "         [0.7615],\n",
      "         [0.9779],\n",
      "         [0.1510],\n",
      "         [0.8808],\n",
      "         [0.9075],\n",
      "         [0.4795],\n",
      "         [0.2098],\n",
      "         [0.2649],\n",
      "         [0.8143],\n",
      "         [0.6184],\n",
      "         [0.5228],\n",
      "         [0.5297],\n",
      "         [0.6838],\n",
      "         [0.3854],\n",
      "         [0.8086],\n",
      "         [0.2857],\n",
      "         [0.2502],\n",
      "         [0.6374],\n",
      "         [0.0076],\n",
      "         [0.0641],\n",
      "         [0.3397],\n",
      "         [0.8954],\n",
      "         [0.7953],\n",
      "         [0.8347],\n",
      "         [0.7022],\n",
      "         [0.0444],\n",
      "         [0.5707],\n",
      "         [0.9066],\n",
      "         [0.0945],\n",
      "         [0.4635],\n",
      "         [0.5615],\n",
      "         [0.3491],\n",
      "         [0.4881],\n",
      "         [0.7959],\n",
      "         [0.9970],\n",
      "         [0.3895],\n",
      "         [0.8293],\n",
      "         [0.7261],\n",
      "         [0.3275],\n",
      "         [0.4604],\n",
      "         [0.9035],\n",
      "         [0.5598],\n",
      "         [0.6503],\n",
      "         [0.5132],\n",
      "         [0.0825],\n",
      "         [0.9675],\n",
      "         [0.1374],\n",
      "         [0.5089],\n",
      "         [0.6823],\n",
      "         [0.8799],\n",
      "         [0.8981],\n",
      "         [0.3695],\n",
      "         [0.8509],\n",
      "         [0.4877],\n",
      "         [0.5135],\n",
      "         [0.0599],\n",
      "         [0.1502],\n",
      "         [0.4987],\n",
      "         [0.9162],\n",
      "         [0.0667],\n",
      "         [0.0102],\n",
      "         [0.6120],\n",
      "         [0.7616],\n",
      "         [0.2568],\n",
      "         [0.5050],\n",
      "         [0.9929],\n",
      "         [0.9516],\n",
      "         [0.7962],\n",
      "         [0.3048],\n",
      "         [0.0041],\n",
      "         [0.6593],\n",
      "         [0.6708],\n",
      "         [0.6341],\n",
      "         [0.1555],\n",
      "         [0.8423],\n",
      "         [0.2077],\n",
      "         [0.1913],\n",
      "         [0.1558],\n",
      "         [0.6973],\n",
      "         [0.2100],\n",
      "         [0.6837],\n",
      "         [0.4870],\n",
      "         [0.3361],\n",
      "         [0.1456],\n",
      "         [0.4008],\n",
      "         [0.3865],\n",
      "         [0.7782],\n",
      "         [0.7620],\n",
      "         [0.8375],\n",
      "         [0.8977],\n",
      "         [0.5226],\n",
      "         [0.3373],\n",
      "         [0.5019],\n",
      "         [0.1375],\n",
      "         [0.7186],\n",
      "         [0.7615],\n",
      "         [0.9039],\n",
      "         [0.4376],\n",
      "         [0.0905],\n",
      "         [0.3660],\n",
      "         [0.6037],\n",
      "         [0.8617],\n",
      "         [0.8359],\n",
      "         [0.9453],\n",
      "         [0.9927],\n",
      "         [0.0746],\n",
      "         [0.6703],\n",
      "         [0.4003],\n",
      "         [0.6077],\n",
      "         [0.1540],\n",
      "         [0.7341],\n",
      "         [0.1439],\n",
      "         [0.6562],\n",
      "         [0.3777],\n",
      "         [0.6215],\n",
      "         [0.0638],\n",
      "         [0.7824],\n",
      "         [0.0076],\n",
      "         [0.9726],\n",
      "         [0.3932],\n",
      "         [0.2179],\n",
      "         [0.6594],\n",
      "         [0.6558],\n",
      "         [0.4037],\n",
      "         [0.3989],\n",
      "         [0.7223],\n",
      "         [0.9284],\n",
      "         [0.1670],\n",
      "         [0.6836],\n",
      "         [0.3672],\n",
      "         [0.2932],\n",
      "         [0.6560],\n",
      "         [0.9644],\n",
      "         [0.7985],\n",
      "         [0.6313],\n",
      "         [0.3836],\n",
      "         [0.1397],\n",
      "         [0.9395],\n",
      "         [0.9795],\n",
      "         [0.2136],\n",
      "         [0.4010],\n",
      "         [0.9364],\n",
      "         [0.1026],\n",
      "         [0.6146],\n",
      "         [0.6214],\n",
      "         [0.5537],\n",
      "         [0.5655],\n",
      "         [0.2246],\n",
      "         [0.7434],\n",
      "         [0.9352],\n",
      "         [0.1453],\n",
      "         [0.7472],\n",
      "         [0.2150],\n",
      "         [0.5105],\n",
      "         [0.7675],\n",
      "         [0.6625],\n",
      "         [0.9780],\n",
      "         [0.5659],\n",
      "         [0.9033],\n",
      "         [0.0727],\n",
      "         [0.9789],\n",
      "         [0.7453],\n",
      "         [0.6440],\n",
      "         [0.6714],\n",
      "         [0.9200],\n",
      "         [0.7318],\n",
      "         [0.0823],\n",
      "         [0.4742],\n",
      "         [0.9783],\n",
      "         [0.4676],\n",
      "         [0.4668],\n",
      "         [0.4528],\n",
      "         [0.9695],\n",
      "         [0.0600],\n",
      "         [0.3053],\n",
      "         [0.1707],\n",
      "         [0.3599],\n",
      "         [0.9384],\n",
      "         [0.7598],\n",
      "         [0.4513]]], device='cuda:0', dtype=torch.float64)\n",
      "================iter 4============\n",
      "['shape/ellipsoid/1/ellipsoid_512_128_64_64_0_0_1']\n",
      "tensor([[ True,  True,  True, False,  True, False, False,  True, False,  True,\n",
      "          True,  True,  True,  True,  True,  True,  True,  True, False, False]],\n",
      "       device='cuda:0')\n",
      "acc torch.Size([1]) tensor([0.0556], device='cuda:0')\n",
      "acc_per_part torch.Size([1, 20]) tensor([[False, False, False, False, False, False, False, False, False, False,\n",
      "         False, False, False, False, False, False,  True, False, False, False]],\n",
      "       device='cuda:0')\n",
      "loss_per_data torch.Size([1, 20]) tensor([[  6.5960,   2.2917,  14.8492,   5.7055,   2.5361,  11.7559,  40.3449,\n",
      "          16.6858,   2.1075,   8.3803,   1.9493,   1.3560,   7.9590,   9.2579,\n",
      "           1.1723,   4.7819,   0.0000,  62.7091, 126.8866, 221.6324]],\n",
      "       device='cuda:0')\n",
      "scores torch.Size([1, 190, 1]) tensor([[[0.0597],\n",
      "         [0.7655],\n",
      "         [0.8121],\n",
      "         [0.7014],\n",
      "         [0.7947],\n",
      "         [0.3236],\n",
      "         [0.2702],\n",
      "         [0.0801],\n",
      "         [0.3299],\n",
      "         [0.6474],\n",
      "         [0.5748],\n",
      "         [0.3004],\n",
      "         [0.2533],\n",
      "         [0.5195],\n",
      "         [0.4999],\n",
      "         [0.0996],\n",
      "         [0.8432],\n",
      "         [0.5597],\n",
      "         [0.7880],\n",
      "         [0.7291],\n",
      "         [0.3003],\n",
      "         [0.6396],\n",
      "         [0.6295],\n",
      "         [0.5976],\n",
      "         [0.4799],\n",
      "         [0.9223],\n",
      "         [0.6245],\n",
      "         [0.0604],\n",
      "         [0.7765],\n",
      "         [0.3517],\n",
      "         [0.1541],\n",
      "         [0.7450],\n",
      "         [0.0252],\n",
      "         [0.0922],\n",
      "         [0.9095],\n",
      "         [0.7394],\n",
      "         [0.6315],\n",
      "         [0.3566],\n",
      "         [0.8751],\n",
      "         [0.8164],\n",
      "         [0.6649],\n",
      "         [0.6885],\n",
      "         [0.4296],\n",
      "         [0.6939],\n",
      "         [0.6459],\n",
      "         [0.3834],\n",
      "         [0.5822],\n",
      "         [0.1276],\n",
      "         [0.6999],\n",
      "         [0.2589],\n",
      "         [0.0411],\n",
      "         [0.8592],\n",
      "         [0.0607],\n",
      "         [0.2456],\n",
      "         [0.5445],\n",
      "         [0.4543],\n",
      "         [0.2006],\n",
      "         [0.6358],\n",
      "         [0.6881],\n",
      "         [0.7519],\n",
      "         [0.8231],\n",
      "         [0.0716],\n",
      "         [0.6995],\n",
      "         [0.0144],\n",
      "         [0.5350],\n",
      "         [0.5166],\n",
      "         [0.9148],\n",
      "         [0.7441],\n",
      "         [0.6532],\n",
      "         [0.4392],\n",
      "         [0.0866],\n",
      "         [0.2336],\n",
      "         [0.2221],\n",
      "         [0.5140],\n",
      "         [0.4886],\n",
      "         [0.9415],\n",
      "         [0.6500],\n",
      "         [0.6876],\n",
      "         [0.4126],\n",
      "         [0.7640],\n",
      "         [0.8851],\n",
      "         [0.3623],\n",
      "         [0.7784],\n",
      "         [0.3750],\n",
      "         [0.1092],\n",
      "         [0.5826],\n",
      "         [0.0281],\n",
      "         [0.6387],\n",
      "         [0.4912],\n",
      "         [0.9758],\n",
      "         [0.8097],\n",
      "         [0.9928],\n",
      "         [0.8446],\n",
      "         [0.0101],\n",
      "         [0.8719],\n",
      "         [0.1824],\n",
      "         [0.3728],\n",
      "         [0.6024],\n",
      "         [0.7751],\n",
      "         [0.0273],\n",
      "         [0.5420],\n",
      "         [0.0482],\n",
      "         [0.2412],\n",
      "         [0.4564],\n",
      "         [0.2504],\n",
      "         [0.5940],\n",
      "         [0.7789],\n",
      "         [0.7564],\n",
      "         [0.7045],\n",
      "         [0.6829],\n",
      "         [0.4907],\n",
      "         [0.8790],\n",
      "         [0.8637],\n",
      "         [0.1828],\n",
      "         [0.1966],\n",
      "         [0.3051],\n",
      "         [0.0676],\n",
      "         [0.8603],\n",
      "         [0.8973],\n",
      "         [0.6053],\n",
      "         [0.6265],\n",
      "         [0.2805],\n",
      "         [0.6125],\n",
      "         [0.2086],\n",
      "         [0.1251],\n",
      "         [0.5811],\n",
      "         [0.6110],\n",
      "         [0.4842],\n",
      "         [0.8431],\n",
      "         [0.6577],\n",
      "         [0.8547],\n",
      "         [0.5428],\n",
      "         [0.1321],\n",
      "         [0.4045],\n",
      "         [0.7765],\n",
      "         [0.7364],\n",
      "         [0.3796],\n",
      "         [0.2931],\n",
      "         [0.9894],\n",
      "         [0.3824],\n",
      "         [0.4541],\n",
      "         [0.7396],\n",
      "         [0.8445],\n",
      "         [0.5880],\n",
      "         [0.0086],\n",
      "         [0.5523],\n",
      "         [0.6280],\n",
      "         [0.6725],\n",
      "         [0.1426],\n",
      "         [0.5139],\n",
      "         [0.3950],\n",
      "         [0.8225],\n",
      "         [0.1027],\n",
      "         [0.0120],\n",
      "         [0.2919],\n",
      "         [0.3440],\n",
      "         [0.3791],\n",
      "         [0.5921],\n",
      "         [0.3287],\n",
      "         [0.0887],\n",
      "         [0.7738],\n",
      "         [0.6965],\n",
      "         [0.7042],\n",
      "         [0.2286],\n",
      "         [0.0231],\n",
      "         [0.1860],\n",
      "         [0.2371],\n",
      "         [0.4114],\n",
      "         [0.1623],\n",
      "         [0.9202],\n",
      "         [0.3040],\n",
      "         [0.6881],\n",
      "         [0.4742],\n",
      "         [0.1827],\n",
      "         [0.5286],\n",
      "         [0.1659],\n",
      "         [0.5800],\n",
      "         [0.0622],\n",
      "         [0.5115],\n",
      "         [0.3723],\n",
      "         [0.6655],\n",
      "         [0.3994],\n",
      "         [0.9890],\n",
      "         [0.0957],\n",
      "         [0.0592],\n",
      "         [0.0647],\n",
      "         [0.7906],\n",
      "         [0.2372],\n",
      "         [0.4876],\n",
      "         [0.9188]]], device='cuda:0', dtype=torch.float64)\n",
      "================iter 5============\n",
      "['shape/ellipsoid/1/ellipsoid_512_128_64_64_0_0_1']\n",
      "tensor([[ True,  True,  True,  True,  True,  True, False,  True,  True,  True,\n",
      "          True,  True,  True,  True,  True,  True,  True,  True, False, False]],\n",
      "       device='cuda:0')\n",
      "@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@\n",
      "['shape/ellipsoid/1/ellipsoid_512_128_64_64_0_1_1']\n",
      "gt_trans_torch.Size([1, 20, 3])_tensor([[[-9.7570e-02, -5.5852e-02, -5.8824e-02],\n",
      "         [-8.8954e-02, -5.3692e-02, -4.3312e-02],\n",
      "         [ 2.8451e-02, -4.0365e-03,  1.9364e-02],\n",
      "         [ 3.6588e-02, -9.1149e-03,  3.9942e-02],\n",
      "         [ 4.8680e-02,  1.4935e-02,  3.7053e-02],\n",
      "         [ 5.9443e-02,  9.4537e-03,  5.4054e-02],\n",
      "         [ 7.4249e-02,  1.2416e-02,  5.9634e-02],\n",
      "         [ 8.7868e-02,  1.7945e-02,  6.5965e-02],\n",
      "         [ 1.0178e-01,  1.5704e-02,  7.6085e-02],\n",
      "         [ 1.1244e-01,  2.7115e-02,  8.3146e-02],\n",
      "         [-7.2895e-02, -3.6487e-02, -4.7960e-02],\n",
      "         [-6.0226e-02, -3.2804e-02, -3.9195e-02],\n",
      "         [-4.6791e-02, -3.8488e-02, -2.6021e-02],\n",
      "         [-3.0328e-02, -3.2431e-02, -2.4509e-02],\n",
      "         [-2.5660e-02, -2.7259e-02, -5.2691e-03],\n",
      "         [-1.2929e-02, -1.2861e-02, -3.0151e-03],\n",
      "         [ 4.3299e-18,  7.1054e-18,  5.3291e-18],\n",
      "         [ 1.7346e-02, -2.4069e-02,  1.8360e-02],\n",
      "         [ 0.0000e+00,  0.0000e+00,  0.0000e+00],\n",
      "         [ 0.0000e+00,  0.0000e+00,  0.0000e+00]]], device='cuda:0')\n",
      "gt_rots_torch.Size([1, 20, 4])_tensor([[[-0.3513,  0.3530,  0.8394,  0.2177],\n",
      "         [ 0.9605, -0.0032,  0.0019,  0.2784],\n",
      "         [ 0.5119, -0.2535, -0.3820,  0.7265],\n",
      "         [ 0.5095,  0.5988, -0.5516,  0.2784],\n",
      "         [ 0.0206,  0.9240, -0.0947, -0.3700],\n",
      "         [-0.4322, -0.2821, -0.5287,  0.6738],\n",
      "         [ 0.7363, -0.3056,  0.5180, -0.3101],\n",
      "         [ 0.8875, -0.1515, -0.3739, -0.2226],\n",
      "         [ 0.4197, -0.1131,  0.4057,  0.8040],\n",
      "         [-0.3249,  0.2540,  0.7851,  0.4620],\n",
      "         [ 0.7226, -0.3917,  0.3110,  0.4771],\n",
      "         [ 0.4682,  0.7023,  0.2044,  0.4957],\n",
      "         [ 0.9234,  0.1739,  0.2055,  0.2736],\n",
      "         [-0.4426,  0.4078,  0.6727,  0.4305],\n",
      "         [ 0.0645,  0.7517,  0.5421, -0.3700],\n",
      "         [ 0.2661,  0.7171, -0.3641,  0.5314],\n",
      "         [ 0.5591,  0.5359,  0.5783, -0.2564],\n",
      "         [ 0.7624,  0.4643,  0.0556, -0.4473],\n",
      "         [ 0.0000,  0.0000,  0.0000,  0.0000],\n",
      "         [ 0.0000,  0.0000,  0.0000,  0.0000]]], device='cuda:0')\n",
      "noisy_trans_and_rots_torch.Size([1, 20, 7])_tensor([[[-2.6397e-01,  0.0000e+00,  2.3061e-03, -4.2827e-01,  0.0000e+00,\n",
      "           0.0000e+00,  1.9326e+00],\n",
      "         [ 6.4003e-01,  0.0000e+00,  3.4154e-01, -7.3889e-01,  0.0000e+00,\n",
      "           0.0000e+00,  3.5005e-01],\n",
      "         [-2.2541e-01,  0.0000e+00, -9.0553e-01, -1.3626e+00,  0.0000e+00,\n",
      "           0.0000e+00,  1.5038e+00],\n",
      "         [ 1.1299e+00,  0.0000e+00, -7.6888e-01, -6.9396e-01,  0.0000e+00,\n",
      "           0.0000e+00,  4.9673e-02],\n",
      "         [-7.7508e-01,  0.0000e+00,  7.1322e-01,  2.3533e+00,  0.0000e+00,\n",
      "           0.0000e+00,  3.2753e-01],\n",
      "         [-3.9317e-01,  0.0000e+00,  3.8629e-01,  1.9036e+00,  0.0000e+00,\n",
      "           0.0000e+00,  4.5547e-01],\n",
      "         [-1.0906e-01,  0.0000e+00, -3.8599e-01,  6.9003e-01,  0.0000e+00,\n",
      "           0.0000e+00,  1.2180e-01],\n",
      "         [ 1.6081e+00,  0.0000e+00, -9.7126e-01,  3.7474e-01,  0.0000e+00,\n",
      "           0.0000e+00, -2.1384e+00],\n",
      "         [-9.4873e-01,  0.0000e+00,  2.6110e+00,  5.6145e-01,  0.0000e+00,\n",
      "           0.0000e+00, -1.3147e+00],\n",
      "         [-4.7281e-01,  0.0000e+00, -2.1270e+00,  2.7010e-01,  0.0000e+00,\n",
      "           0.0000e+00,  8.2438e-01],\n",
      "         [ 1.7427e+00,  0.0000e+00,  2.8126e-01, -2.8287e-01,  0.0000e+00,\n",
      "           0.0000e+00, -1.2969e+00],\n",
      "         [ 8.4241e-01,  0.0000e+00, -3.4084e-01, -1.0264e+00,  0.0000e+00,\n",
      "           0.0000e+00,  4.0633e-01],\n",
      "         [ 5.7653e-01,  0.0000e+00,  4.1288e-01,  2.1661e+00,  0.0000e+00,\n",
      "           0.0000e+00,  2.8931e-01],\n",
      "         [-8.9467e-01,  0.0000e+00, -1.2205e+00, -3.9399e-01,  0.0000e+00,\n",
      "           0.0000e+00, -1.1804e+00],\n",
      "         [ 3.8169e-01,  0.0000e+00, -5.2276e-01, -1.3571e+00,  0.0000e+00,\n",
      "           0.0000e+00, -4.8827e-01],\n",
      "         [-8.2015e-01,  0.0000e+00,  3.2050e-01,  3.2709e-01,  0.0000e+00,\n",
      "           0.0000e+00,  7.3219e-02],\n",
      "         [ 8.6693e-01,  0.0000e+00, -5.3248e-01,  5.2149e-01,  0.0000e+00,\n",
      "           0.0000e+00, -6.5207e-01],\n",
      "         [-6.8958e-01,  0.0000e+00, -4.9756e-01, -5.4199e-01,  0.0000e+00,\n",
      "           0.0000e+00, -9.9397e-01],\n",
      "         [-3.3095e-02,  0.0000e+00,  2.2906e+00,  6.3515e-01,  0.0000e+00,\n",
      "           0.0000e+00,  2.3202e-01],\n",
      "         [ 9.3850e-01,  0.0000e+00, -3.8299e-01,  2.4604e-01,  0.0000e+00,\n",
      "           0.0000e+00, -7.8299e-01]]], device='cuda:0')\n",
      "================iter 0============\n",
      "['shape/ellipsoid/1/ellipsoid_512_128_64_64_0_1_1']\n",
      "tensor([[False, False, False, False, False, False, False, False, False, False,\n",
      "         False, False, False, False, False, False,  True, False, False, False]],\n",
      "       device='cuda:0')\n",
      "acc torch.Size([1]) tensor([0.0556], device='cuda:0')\n",
      "acc_per_part torch.Size([1, 20]) tensor([[False, False, False, False, False, False, False, False, False, False,\n",
      "         False, False, False, False, False, False,  True, False, False, False]],\n",
      "       device='cuda:0')\n",
      "loss_per_data torch.Size([1, 20]) tensor([[ 1.2896,  0.5118,  0.6574,  8.9368,  0.1247,  2.0263,  0.1415,  0.5122,\n",
      "         19.6129,  3.2924, 16.7235,  1.0644,  0.6824,  0.9109,  6.7218,  0.8626,\n",
      "          0.0000,  0.9923, 29.4679,  1.1072]], device='cuda:0')\n",
      "scores torch.Size([1, 190, 1]) tensor([[[0.9623],\n",
      "         [0.9156],\n",
      "         [0.4026],\n",
      "         [0.6835],\n",
      "         [0.9765],\n",
      "         [0.1987],\n",
      "         [0.0626],\n",
      "         [0.5110],\n",
      "         [0.6573],\n",
      "         [0.1747],\n",
      "         [0.0294],\n",
      "         [0.9182],\n",
      "         [0.6165],\n",
      "         [0.9073],\n",
      "         [0.3095],\n",
      "         [0.9078],\n",
      "         [0.2437],\n",
      "         [0.0045],\n",
      "         [0.3671],\n",
      "         [0.5637],\n",
      "         [0.6569],\n",
      "         [0.3940],\n",
      "         [0.3204],\n",
      "         [0.7754],\n",
      "         [0.2912],\n",
      "         [0.0259],\n",
      "         [0.5354],\n",
      "         [0.4772],\n",
      "         [0.5495],\n",
      "         [0.1742],\n",
      "         [0.3389],\n",
      "         [0.9478],\n",
      "         [0.9225],\n",
      "         [0.4601],\n",
      "         [0.0203],\n",
      "         [0.6180],\n",
      "         [0.1731],\n",
      "         [0.6555],\n",
      "         [0.5028],\n",
      "         [0.5094],\n",
      "         [0.0240],\n",
      "         [0.2359],\n",
      "         [0.0566],\n",
      "         [0.0337],\n",
      "         [0.2199],\n",
      "         [0.3650],\n",
      "         [0.7894],\n",
      "         [0.9691],\n",
      "         [0.0673],\n",
      "         [0.2212],\n",
      "         [0.0905],\n",
      "         [0.0747],\n",
      "         [0.0869],\n",
      "         [0.3391],\n",
      "         [0.7881],\n",
      "         [0.2990],\n",
      "         [0.7076],\n",
      "         [0.2027],\n",
      "         [0.5392],\n",
      "         [0.6711],\n",
      "         [0.0230],\n",
      "         [0.0104],\n",
      "         [0.7686],\n",
      "         [0.1909],\n",
      "         [0.3697],\n",
      "         [0.2297],\n",
      "         [0.6749],\n",
      "         [0.7638],\n",
      "         [0.8852],\n",
      "         [0.6911],\n",
      "         [0.3201],\n",
      "         [0.1041],\n",
      "         [0.7439],\n",
      "         [0.1516],\n",
      "         [0.1855],\n",
      "         [0.5613],\n",
      "         [0.0592],\n",
      "         [0.1489],\n",
      "         [0.4637],\n",
      "         [0.0435],\n",
      "         [0.2746],\n",
      "         [0.2871],\n",
      "         [0.8234],\n",
      "         [0.9741],\n",
      "         [0.4635],\n",
      "         [0.6730],\n",
      "         [0.1455],\n",
      "         [0.2928],\n",
      "         [0.6955],\n",
      "         [0.6720],\n",
      "         [0.7307],\n",
      "         [0.4785],\n",
      "         [0.7944],\n",
      "         [0.9740],\n",
      "         [0.7997],\n",
      "         [0.6385],\n",
      "         [0.7448],\n",
      "         [0.0630],\n",
      "         [0.1042],\n",
      "         [0.8020],\n",
      "         [0.4074],\n",
      "         [0.7999],\n",
      "         [0.0220],\n",
      "         [0.0770],\n",
      "         [0.1237],\n",
      "         [0.0397],\n",
      "         [0.6282],\n",
      "         [0.9630],\n",
      "         [0.6064],\n",
      "         [0.4888],\n",
      "         [0.9208],\n",
      "         [0.5979],\n",
      "         [0.9659],\n",
      "         [0.0061],\n",
      "         [0.8684],\n",
      "         [0.7411],\n",
      "         [0.6937],\n",
      "         [0.9260],\n",
      "         [0.3067],\n",
      "         [0.2710],\n",
      "         [0.7030],\n",
      "         [0.8646],\n",
      "         [0.0721],\n",
      "         [0.3492],\n",
      "         [0.5152],\n",
      "         [0.9086],\n",
      "         [0.3917],\n",
      "         [0.5401],\n",
      "         [0.8183],\n",
      "         [0.1846],\n",
      "         [0.7601],\n",
      "         [0.0295],\n",
      "         [0.9485],\n",
      "         [0.3680],\n",
      "         [0.7017],\n",
      "         [0.0323],\n",
      "         [0.7234],\n",
      "         [0.5677],\n",
      "         [0.2173],\n",
      "         [0.3227],\n",
      "         [0.7193],\n",
      "         [0.3231],\n",
      "         [0.1953],\n",
      "         [0.1854],\n",
      "         [0.6380],\n",
      "         [0.3681],\n",
      "         [0.3702],\n",
      "         [0.6202],\n",
      "         [0.1209],\n",
      "         [0.7589],\n",
      "         [0.2525],\n",
      "         [0.9448],\n",
      "         [0.1252],\n",
      "         [0.0326],\n",
      "         [0.3394],\n",
      "         [0.4131],\n",
      "         [0.0794],\n",
      "         [0.3787],\n",
      "         [0.2570],\n",
      "         [0.0959],\n",
      "         [0.2989],\n",
      "         [0.1399],\n",
      "         [0.8695],\n",
      "         [0.7409],\n",
      "         [0.2520],\n",
      "         [0.3840],\n",
      "         [0.1373],\n",
      "         [0.2057],\n",
      "         [0.6190],\n",
      "         [0.9513],\n",
      "         [0.9009],\n",
      "         [0.5253],\n",
      "         [0.9033],\n",
      "         [0.4557],\n",
      "         [0.3212],\n",
      "         [0.7075],\n",
      "         [0.9707],\n",
      "         [0.4417],\n",
      "         [0.3104],\n",
      "         [0.2659],\n",
      "         [0.2573],\n",
      "         [0.9019],\n",
      "         [0.4272],\n",
      "         [0.4527],\n",
      "         [0.4306],\n",
      "         [0.4643],\n",
      "         [0.6036],\n",
      "         [0.0584],\n",
      "         [0.4452],\n",
      "         [0.8773]]], device='cuda:0', dtype=torch.float64)\n",
      "================iter 1============\n",
      "['shape/ellipsoid/1/ellipsoid_512_128_64_64_0_1_1']\n",
      "tensor([[ True, False, False, False, False, False, False, False, False, False,\n",
      "         False, False, False, False,  True, False,  True, False, False, False]],\n",
      "       device='cuda:0')\n",
      "acc torch.Size([1]) tensor([0.0556], device='cuda:0')\n",
      "acc_per_part torch.Size([1, 20]) tensor([[False, False, False, False, False, False, False, False, False, False,\n",
      "         False, False, False, False, False, False,  True, False, False, False]],\n",
      "       device='cuda:0')\n",
      "loss_per_data torch.Size([1, 20]) tensor([[  1.2896,   4.0213,   2.5272,  12.0344,   4.9315,  15.5485,   8.7356,\n",
      "           1.3995,  18.8128,   2.8265,  28.4907,   7.9151,   4.8839,  18.2741,\n",
      "           6.7218,   9.7002,   0.0000, 146.9084,  27.5137,   1.0216]],\n",
      "       device='cuda:0')\n",
      "scores torch.Size([1, 190, 1]) tensor([[[0.1829],\n",
      "         [0.1695],\n",
      "         [0.4733],\n",
      "         [0.8363],\n",
      "         [0.4446],\n",
      "         [0.3472],\n",
      "         [0.1499],\n",
      "         [0.1060],\n",
      "         [0.5282],\n",
      "         [0.6450],\n",
      "         [0.8000],\n",
      "         [0.0285],\n",
      "         [0.0382],\n",
      "         [0.0072],\n",
      "         [0.3695],\n",
      "         [0.3090],\n",
      "         [0.5136],\n",
      "         [0.5090],\n",
      "         [0.3857],\n",
      "         [0.8302],\n",
      "         [0.8244],\n",
      "         [0.7944],\n",
      "         [0.8638],\n",
      "         [0.5727],\n",
      "         [0.6275],\n",
      "         [0.7287],\n",
      "         [0.1004],\n",
      "         [0.7636],\n",
      "         [0.8007],\n",
      "         [0.5448],\n",
      "         [0.7787],\n",
      "         [0.5741],\n",
      "         [0.4885],\n",
      "         [0.9814],\n",
      "         [0.7267],\n",
      "         [0.3020],\n",
      "         [0.7653],\n",
      "         [0.3165],\n",
      "         [0.6336],\n",
      "         [0.7533],\n",
      "         [0.6173],\n",
      "         [0.9309],\n",
      "         [0.6029],\n",
      "         [0.5880],\n",
      "         [0.4563],\n",
      "         [0.2615],\n",
      "         [0.6275],\n",
      "         [0.7974],\n",
      "         [0.2248],\n",
      "         [0.0427],\n",
      "         [0.0557],\n",
      "         [0.9634],\n",
      "         [0.1471],\n",
      "         [0.6043],\n",
      "         [0.1050],\n",
      "         [0.3584],\n",
      "         [0.6268],\n",
      "         [0.3526],\n",
      "         [0.2248],\n",
      "         [0.1118],\n",
      "         [0.7746],\n",
      "         [0.5793],\n",
      "         [0.0999],\n",
      "         [0.2617],\n",
      "         [0.5049],\n",
      "         [0.4029],\n",
      "         [0.8073],\n",
      "         [0.2163],\n",
      "         [0.1705],\n",
      "         [0.3215],\n",
      "         [0.6496],\n",
      "         [0.4166],\n",
      "         [0.8390],\n",
      "         [0.7272],\n",
      "         [0.5246],\n",
      "         [0.9897],\n",
      "         [0.4666],\n",
      "         [0.1098],\n",
      "         [0.1541],\n",
      "         [0.9460],\n",
      "         [0.7298],\n",
      "         [0.4047],\n",
      "         [0.7020],\n",
      "         [0.7741],\n",
      "         [0.6362],\n",
      "         [0.9865],\n",
      "         [0.5683],\n",
      "         [0.4551],\n",
      "         [0.7043],\n",
      "         [0.5436],\n",
      "         [0.3639],\n",
      "         [0.0337],\n",
      "         [0.8937],\n",
      "         [0.9219],\n",
      "         [0.1179],\n",
      "         [0.3409],\n",
      "         [0.3368],\n",
      "         [0.7704],\n",
      "         [0.3372],\n",
      "         [0.8185],\n",
      "         [0.1494],\n",
      "         [0.0543],\n",
      "         [0.2685],\n",
      "         [0.2647],\n",
      "         [0.1550],\n",
      "         [0.2647],\n",
      "         [0.3430],\n",
      "         [0.6030],\n",
      "         [0.0850],\n",
      "         [0.9803],\n",
      "         [0.5383],\n",
      "         [0.6623],\n",
      "         [0.7950],\n",
      "         [0.4876],\n",
      "         [0.8134],\n",
      "         [0.9002],\n",
      "         [0.2081],\n",
      "         [0.5380],\n",
      "         [0.1352],\n",
      "         [0.5451],\n",
      "         [0.0581],\n",
      "         [0.5597],\n",
      "         [0.1587],\n",
      "         [0.4221],\n",
      "         [0.7764],\n",
      "         [0.3174],\n",
      "         [0.6627],\n",
      "         [0.7848],\n",
      "         [0.7789],\n",
      "         [0.2941],\n",
      "         [0.1550],\n",
      "         [0.8381],\n",
      "         [0.3828],\n",
      "         [0.9954],\n",
      "         [0.1054],\n",
      "         [0.7540],\n",
      "         [0.7067],\n",
      "         [0.4244],\n",
      "         [0.2446],\n",
      "         [0.0884],\n",
      "         [0.4241],\n",
      "         [0.1815],\n",
      "         [0.7116],\n",
      "         [0.8136],\n",
      "         [0.1857],\n",
      "         [0.4956],\n",
      "         [0.5085],\n",
      "         [0.4758],\n",
      "         [0.6735],\n",
      "         [0.6476],\n",
      "         [0.9789],\n",
      "         [0.2642],\n",
      "         [0.8754],\n",
      "         [0.4712],\n",
      "         [0.5471],\n",
      "         [0.0789],\n",
      "         [0.9950],\n",
      "         [0.9410],\n",
      "         [0.0399],\n",
      "         [0.6591],\n",
      "         [0.4925],\n",
      "         [0.5869],\n",
      "         [0.0817],\n",
      "         [0.4803],\n",
      "         [0.0489],\n",
      "         [0.4309],\n",
      "         [0.4487],\n",
      "         [0.5928],\n",
      "         [0.1249],\n",
      "         [0.3996],\n",
      "         [0.8586],\n",
      "         [0.4247],\n",
      "         [0.2874],\n",
      "         [0.7367],\n",
      "         [0.5560],\n",
      "         [0.6607],\n",
      "         [0.8994],\n",
      "         [0.2409],\n",
      "         [0.8275],\n",
      "         [0.3737],\n",
      "         [0.5330],\n",
      "         [0.8263],\n",
      "         [0.3620],\n",
      "         [0.9976],\n",
      "         [0.1315],\n",
      "         [0.7025],\n",
      "         [0.9235],\n",
      "         [0.5393],\n",
      "         [0.1509],\n",
      "         [0.7035]]], device='cuda:0', dtype=torch.float64)\n",
      "================iter 2============\n",
      "['shape/ellipsoid/1/ellipsoid_512_128_64_64_0_1_1']\n",
      "tensor([[ True,  True, False, False,  True,  True, False, False, False, False,\n",
      "          True,  True, False, False,  True, False,  True, False, False, False]],\n",
      "       device='cuda:0')\n",
      "acc torch.Size([1]) tensor([0.0556], device='cuda:0')\n",
      "acc_per_part torch.Size([1, 20]) tensor([[False, False, False, False, False, False, False, False, False, False,\n",
      "         False, False, False, False, False, False,  True, False, False, False]],\n",
      "       device='cuda:0')\n",
      "loss_per_data torch.Size([1, 20]) tensor([[  1.2896,   4.0213,   4.7776,  24.5294,   4.9315,  15.5485,  27.1550,\n",
      "           6.3424,  77.3859,  19.1789,  28.4907,   7.9151,  25.2945, 133.8124,\n",
      "           6.7218,  91.8271,   0.0000, 340.3956,  85.7597,   2.1466]],\n",
      "       device='cuda:0')\n",
      "scores torch.Size([1, 190, 1]) tensor([[[7.8423e-01],\n",
      "         [1.5080e-01],\n",
      "         [7.6600e-01],\n",
      "         [8.3771e-01],\n",
      "         [7.5605e-01],\n",
      "         [7.6745e-01],\n",
      "         [3.1134e-02],\n",
      "         [3.7705e-01],\n",
      "         [7.8609e-01],\n",
      "         [4.6386e-01],\n",
      "         [5.9096e-01],\n",
      "         [7.7566e-01],\n",
      "         [3.5618e-01],\n",
      "         [3.8552e-01],\n",
      "         [8.6294e-01],\n",
      "         [4.8330e-01],\n",
      "         [5.8805e-01],\n",
      "         [2.3320e-01],\n",
      "         [3.6977e-01],\n",
      "         [4.3234e-01],\n",
      "         [2.8487e-01],\n",
      "         [3.2690e-01],\n",
      "         [3.3312e-01],\n",
      "         [7.2101e-01],\n",
      "         [6.6590e-01],\n",
      "         [3.2207e-01],\n",
      "         [6.3602e-01],\n",
      "         [2.9782e-01],\n",
      "         [3.3381e-01],\n",
      "         [6.8674e-01],\n",
      "         [8.4502e-01],\n",
      "         [7.0847e-01],\n",
      "         [7.8372e-01],\n",
      "         [5.6004e-01],\n",
      "         [3.8801e-01],\n",
      "         [6.0707e-03],\n",
      "         [2.8443e-01],\n",
      "         [2.3447e-01],\n",
      "         [3.1696e-01],\n",
      "         [8.9187e-01],\n",
      "         [1.1777e-02],\n",
      "         [5.2649e-01],\n",
      "         [6.9649e-01],\n",
      "         [6.6310e-01],\n",
      "         [5.3753e-01],\n",
      "         [9.2849e-01],\n",
      "         [9.3719e-01],\n",
      "         [2.0797e-01],\n",
      "         [7.1481e-01],\n",
      "         [8.4920e-01],\n",
      "         [5.6599e-01],\n",
      "         [9.8676e-01],\n",
      "         [3.1218e-01],\n",
      "         [2.8573e-01],\n",
      "         [2.5689e-01],\n",
      "         [5.4854e-01],\n",
      "         [3.9239e-01],\n",
      "         [2.7252e-01],\n",
      "         [6.3643e-01],\n",
      "         [2.1713e-01],\n",
      "         [3.2448e-01],\n",
      "         [8.9902e-01],\n",
      "         [5.6656e-01],\n",
      "         [9.7974e-02],\n",
      "         [3.8066e-01],\n",
      "         [1.6834e-01],\n",
      "         [6.3246e-01],\n",
      "         [8.4711e-01],\n",
      "         [1.5184e-01],\n",
      "         [1.9016e-01],\n",
      "         [9.3092e-01],\n",
      "         [5.2292e-01],\n",
      "         [6.4278e-01],\n",
      "         [7.6146e-01],\n",
      "         [1.8467e-01],\n",
      "         [1.3323e-02],\n",
      "         [2.6654e-01],\n",
      "         [5.1822e-01],\n",
      "         [8.5135e-01],\n",
      "         [1.0816e-01],\n",
      "         [7.6237e-02],\n",
      "         [9.1040e-01],\n",
      "         [2.7043e-01],\n",
      "         [3.1118e-01],\n",
      "         [2.7784e-01],\n",
      "         [8.5651e-01],\n",
      "         [2.8628e-01],\n",
      "         [6.5166e-01],\n",
      "         [6.6076e-01],\n",
      "         [3.0762e-01],\n",
      "         [3.3513e-01],\n",
      "         [4.9887e-01],\n",
      "         [4.8203e-01],\n",
      "         [7.6972e-01],\n",
      "         [6.7955e-01],\n",
      "         [1.6591e-01],\n",
      "         [2.5273e-01],\n",
      "         [6.6616e-01],\n",
      "         [7.7515e-01],\n",
      "         [5.2649e-01],\n",
      "         [7.6522e-01],\n",
      "         [8.8038e-04],\n",
      "         [9.7504e-01],\n",
      "         [7.0098e-01],\n",
      "         [8.7797e-02],\n",
      "         [2.5671e-01],\n",
      "         [6.2017e-01],\n",
      "         [8.6085e-02],\n",
      "         [6.9748e-01],\n",
      "         [3.2457e-01],\n",
      "         [9.7933e-01],\n",
      "         [7.0894e-01],\n",
      "         [1.5246e-01],\n",
      "         [6.5728e-02],\n",
      "         [7.5982e-01],\n",
      "         [6.9749e-01],\n",
      "         [7.5020e-01],\n",
      "         [3.4990e-01],\n",
      "         [6.6851e-02],\n",
      "         [3.2624e-01],\n",
      "         [7.5133e-01],\n",
      "         [5.1523e-01],\n",
      "         [4.5120e-01],\n",
      "         [5.9018e-01],\n",
      "         [1.3841e-01],\n",
      "         [5.8722e-01],\n",
      "         [2.8831e-01],\n",
      "         [6.3446e-01],\n",
      "         [4.7067e-01],\n",
      "         [5.8475e-01],\n",
      "         [8.1767e-01],\n",
      "         [2.3487e-01],\n",
      "         [8.5281e-01],\n",
      "         [9.1373e-02],\n",
      "         [6.2260e-01],\n",
      "         [4.1464e-01],\n",
      "         [1.7859e-01],\n",
      "         [4.8929e-01],\n",
      "         [3.7548e-01],\n",
      "         [7.1982e-01],\n",
      "         [6.5219e-01],\n",
      "         [3.0381e-01],\n",
      "         [7.6837e-01],\n",
      "         [1.3344e-01],\n",
      "         [7.1897e-01],\n",
      "         [2.1556e-01],\n",
      "         [5.3998e-01],\n",
      "         [6.5467e-01],\n",
      "         [3.2678e-01],\n",
      "         [5.1001e-02],\n",
      "         [4.0849e-01],\n",
      "         [1.5885e-01],\n",
      "         [3.5159e-01],\n",
      "         [1.4813e-01],\n",
      "         [8.0304e-02],\n",
      "         [1.5453e-01],\n",
      "         [1.6822e-01],\n",
      "         [3.9219e-01],\n",
      "         [6.0844e-01],\n",
      "         [5.8795e-02],\n",
      "         [4.0069e-01],\n",
      "         [9.4666e-01],\n",
      "         [5.2730e-03],\n",
      "         [4.9400e-01],\n",
      "         [3.7912e-01],\n",
      "         [2.0228e-02],\n",
      "         [8.7599e-02],\n",
      "         [7.8323e-01],\n",
      "         [8.7700e-01],\n",
      "         [6.9126e-01],\n",
      "         [1.8998e-01],\n",
      "         [4.4485e-02],\n",
      "         [5.7564e-02],\n",
      "         [8.6867e-01],\n",
      "         [1.3213e-01],\n",
      "         [7.7011e-01],\n",
      "         [4.6602e-01],\n",
      "         [2.1168e-01],\n",
      "         [7.9375e-03],\n",
      "         [6.7409e-01],\n",
      "         [5.9679e-01],\n",
      "         [3.6047e-01],\n",
      "         [4.7907e-01],\n",
      "         [3.6023e-01],\n",
      "         [1.5215e-01],\n",
      "         [5.9089e-01],\n",
      "         [2.8062e-01],\n",
      "         [1.3925e-01],\n",
      "         [2.2776e-01],\n",
      "         [8.9670e-01]]], device='cuda:0', dtype=torch.float64)\n",
      "================iter 3============\n",
      "['shape/ellipsoid/1/ellipsoid_512_128_64_64_0_1_1']\n",
      "tensor([[ True,  True,  True, False,  True,  True,  True, False, False, False,\n",
      "          True,  True, False, False,  True, False,  True, False, False, False]],\n",
      "       device='cuda:0')\n",
      "acc torch.Size([1]) tensor([0.0556], device='cuda:0')\n",
      "acc_per_part torch.Size([1, 20]) tensor([[False, False, False, False, False, False, False, False, False, False,\n",
      "         False, False, False, False, False, False,  True, False, False, False]],\n",
      "       device='cuda:0')\n",
      "loss_per_data torch.Size([1, 20]) tensor([[  1.2896,   4.0213,   4.7776, 126.9569,   4.9315,  15.5485,  27.1550,\n",
      "          27.7189, 227.0419,  43.8070,  28.4907,   7.9151,  81.6349, 445.4603,\n",
      "           6.7218, 279.3482,   0.0000, 816.9258, 144.8143,   2.9876]],\n",
      "       device='cuda:0')\n",
      "scores torch.Size([1, 190, 1]) tensor([[[0.8693],\n",
      "         [0.9392],\n",
      "         [0.7905],\n",
      "         [0.4413],\n",
      "         [0.6444],\n",
      "         [0.8809],\n",
      "         [0.4257],\n",
      "         [0.9984],\n",
      "         [0.5966],\n",
      "         [0.1414],\n",
      "         [0.2050],\n",
      "         [0.4251],\n",
      "         [0.2627],\n",
      "         [0.1519],\n",
      "         [0.0025],\n",
      "         [0.5974],\n",
      "         [0.2295],\n",
      "         [0.4923],\n",
      "         [0.2012],\n",
      "         [0.2104],\n",
      "         [0.5909],\n",
      "         [0.8214],\n",
      "         [0.4234],\n",
      "         [0.7663],\n",
      "         [0.5754],\n",
      "         [0.9852],\n",
      "         [0.3446],\n",
      "         [0.0103],\n",
      "         [0.5667],\n",
      "         [0.0398],\n",
      "         [0.4394],\n",
      "         [0.8202],\n",
      "         [0.0114],\n",
      "         [0.7528],\n",
      "         [0.0183],\n",
      "         [0.8515],\n",
      "         [0.2140],\n",
      "         [0.0687],\n",
      "         [0.1984],\n",
      "         [0.9962],\n",
      "         [0.4766],\n",
      "         [0.5449],\n",
      "         [0.4123],\n",
      "         [0.6379],\n",
      "         [0.7409],\n",
      "         [0.9417],\n",
      "         [0.5766],\n",
      "         [0.7589],\n",
      "         [0.4270],\n",
      "         [0.1167],\n",
      "         [0.1161],\n",
      "         [0.5517],\n",
      "         [0.2378],\n",
      "         [0.0692],\n",
      "         [0.9747],\n",
      "         [0.1787],\n",
      "         [0.5340],\n",
      "         [0.7332],\n",
      "         [0.9946],\n",
      "         [0.9873],\n",
      "         [0.1855],\n",
      "         [0.2238],\n",
      "         [0.3001],\n",
      "         [0.8191],\n",
      "         [0.2833],\n",
      "         [0.4126],\n",
      "         [0.4421],\n",
      "         [0.2032],\n",
      "         [0.6825],\n",
      "         [0.4277],\n",
      "         [0.8465],\n",
      "         [0.5723],\n",
      "         [0.5326],\n",
      "         [0.7793],\n",
      "         [0.0989],\n",
      "         [0.1123],\n",
      "         [0.2050],\n",
      "         [0.0802],\n",
      "         [0.6116],\n",
      "         [0.1611],\n",
      "         [0.8252],\n",
      "         [0.1850],\n",
      "         [0.4346],\n",
      "         [0.1023],\n",
      "         [0.1248],\n",
      "         [0.6387],\n",
      "         [0.8854],\n",
      "         [0.8514],\n",
      "         [0.9971],\n",
      "         [0.3776],\n",
      "         [0.5590],\n",
      "         [0.1792],\n",
      "         [0.3285],\n",
      "         [0.8163],\n",
      "         [0.5593],\n",
      "         [0.3322],\n",
      "         [0.6350],\n",
      "         [0.1364],\n",
      "         [0.4178],\n",
      "         [0.9926],\n",
      "         [0.8935],\n",
      "         [0.0992],\n",
      "         [0.4501],\n",
      "         [0.4193],\n",
      "         [0.5399],\n",
      "         [0.7514],\n",
      "         [0.1224],\n",
      "         [0.1882],\n",
      "         [0.5223],\n",
      "         [0.6628],\n",
      "         [0.5122],\n",
      "         [0.8482],\n",
      "         [0.9138],\n",
      "         [0.5203],\n",
      "         [0.5531],\n",
      "         [0.8771],\n",
      "         [0.1246],\n",
      "         [0.8636],\n",
      "         [0.7793],\n",
      "         [0.5468],\n",
      "         [0.5170],\n",
      "         [0.0450],\n",
      "         [0.2107],\n",
      "         [0.1892],\n",
      "         [0.5387],\n",
      "         [0.0642],\n",
      "         [0.2056],\n",
      "         [0.2857],\n",
      "         [0.2725],\n",
      "         [0.1023],\n",
      "         [0.1573],\n",
      "         [0.0185],\n",
      "         [0.8734],\n",
      "         [0.0932],\n",
      "         [0.3402],\n",
      "         [0.8979],\n",
      "         [0.0440],\n",
      "         [0.9293],\n",
      "         [0.7735],\n",
      "         [0.2528],\n",
      "         [0.1267],\n",
      "         [0.5536],\n",
      "         [0.1570],\n",
      "         [0.8132],\n",
      "         [0.7857],\n",
      "         [0.5969],\n",
      "         [0.9320],\n",
      "         [0.6954],\n",
      "         [0.0740],\n",
      "         [0.3474],\n",
      "         [0.7251],\n",
      "         [0.1135],\n",
      "         [0.1047],\n",
      "         [0.3005],\n",
      "         [0.4126],\n",
      "         [0.9022],\n",
      "         [0.3728],\n",
      "         [0.9988],\n",
      "         [0.3784],\n",
      "         [0.0813],\n",
      "         [0.4253],\n",
      "         [0.8825],\n",
      "         [0.7067],\n",
      "         [0.2624],\n",
      "         [0.2560],\n",
      "         [0.9766],\n",
      "         [0.2665],\n",
      "         [0.8818],\n",
      "         [0.2880],\n",
      "         [0.0711],\n",
      "         [0.3196],\n",
      "         [0.1627],\n",
      "         [0.6897],\n",
      "         [0.7596],\n",
      "         [0.0208],\n",
      "         [0.2975],\n",
      "         [0.3067],\n",
      "         [0.4580],\n",
      "         [0.8868],\n",
      "         [0.7846],\n",
      "         [0.3361],\n",
      "         [0.8667],\n",
      "         [0.3512],\n",
      "         [0.8110],\n",
      "         [0.6672],\n",
      "         [0.9894],\n",
      "         [0.7935],\n",
      "         [0.9056],\n",
      "         [0.1023],\n",
      "         [0.8820]]], device='cuda:0', dtype=torch.float64)\n",
      "================iter 4============\n",
      "['shape/ellipsoid/1/ellipsoid_512_128_64_64_0_1_1']\n",
      "tensor([[ True,  True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
      "          True,  True,  True,  True,  True,  True,  True, False, False, False]],\n",
      "       device='cuda:0')\n",
      "acc torch.Size([1]) tensor([0.0556], device='cuda:0')\n",
      "acc_per_part torch.Size([1, 20]) tensor([[False, False, False, False, False, False, False, False, False, False,\n",
      "         False, False, False, False, False, False,  True, False, False, False]],\n",
      "       device='cuda:0')\n",
      "loss_per_data torch.Size([1, 20]) tensor([[1.2896e+00, 4.0213e+00, 4.7776e+00, 1.2696e+02, 4.9315e+00, 1.5548e+01,\n",
      "         2.7155e+01, 2.7719e+01, 2.2704e+02, 4.3807e+01, 2.8491e+01, 7.9151e+00,\n",
      "         8.1635e+01, 4.4546e+02, 6.7218e+00, 2.7935e+02, 0.0000e+00, 2.7803e+03,\n",
      "         3.7500e+02, 9.1747e-01]], device='cuda:0')\n",
      "scores torch.Size([1, 190, 1]) tensor([[[9.4690e-01],\n",
      "         [3.0814e-01],\n",
      "         [4.4395e-01],\n",
      "         [1.2545e-01],\n",
      "         [5.7290e-01],\n",
      "         [2.8597e-01],\n",
      "         [2.1498e-01],\n",
      "         [5.6759e-01],\n",
      "         [2.2859e-01],\n",
      "         [7.0832e-01],\n",
      "         [6.1125e-01],\n",
      "         [8.0301e-01],\n",
      "         [6.6441e-01],\n",
      "         [5.4671e-01],\n",
      "         [1.8963e-01],\n",
      "         [7.1709e-01],\n",
      "         [3.5012e-01],\n",
      "         [8.9953e-01],\n",
      "         [8.7714e-01],\n",
      "         [3.3261e-01],\n",
      "         [8.7480e-01],\n",
      "         [2.2268e-01],\n",
      "         [3.7449e-01],\n",
      "         [6.1992e-01],\n",
      "         [6.7231e-01],\n",
      "         [8.1001e-01],\n",
      "         [5.7699e-01],\n",
      "         [9.1133e-01],\n",
      "         [1.1361e-01],\n",
      "         [3.0060e-01],\n",
      "         [3.9583e-01],\n",
      "         [4.0402e-04],\n",
      "         [8.9441e-01],\n",
      "         [6.7762e-01],\n",
      "         [4.9060e-01],\n",
      "         [9.0910e-01],\n",
      "         [5.8191e-01],\n",
      "         [4.4969e-01],\n",
      "         [3.2552e-01],\n",
      "         [5.0429e-01],\n",
      "         [9.1676e-01],\n",
      "         [4.0413e-01],\n",
      "         [3.9212e-01],\n",
      "         [2.0460e-01],\n",
      "         [1.3021e-01],\n",
      "         [6.6816e-01],\n",
      "         [9.4101e-01],\n",
      "         [5.0848e-01],\n",
      "         [4.3662e-01],\n",
      "         [9.3324e-01],\n",
      "         [2.2199e-01],\n",
      "         [7.3544e-01],\n",
      "         [1.0258e-01],\n",
      "         [4.9037e-01],\n",
      "         [6.9453e-01],\n",
      "         [7.0976e-01],\n",
      "         [1.9465e-01],\n",
      "         [9.3723e-01],\n",
      "         [5.6243e-01],\n",
      "         [3.4087e-01],\n",
      "         [3.6273e-01],\n",
      "         [7.0629e-01],\n",
      "         [8.1912e-01],\n",
      "         [1.2135e-01],\n",
      "         [9.7682e-01],\n",
      "         [9.6176e-01],\n",
      "         [5.6191e-01],\n",
      "         [2.6752e-01],\n",
      "         [2.7808e-01],\n",
      "         [8.7489e-01],\n",
      "         [9.5601e-01],\n",
      "         [7.3894e-01],\n",
      "         [5.9503e-01],\n",
      "         [7.8842e-01],\n",
      "         [2.9994e-01],\n",
      "         [7.7854e-01],\n",
      "         [5.9323e-01],\n",
      "         [2.8161e-01],\n",
      "         [7.2431e-03],\n",
      "         [2.8120e-01],\n",
      "         [2.7213e-01],\n",
      "         [2.7685e-01],\n",
      "         [1.6466e-01],\n",
      "         [4.2931e-01],\n",
      "         [8.0654e-01],\n",
      "         [5.1759e-01],\n",
      "         [9.2415e-01],\n",
      "         [1.8070e-01],\n",
      "         [1.4899e-01],\n",
      "         [5.5860e-01],\n",
      "         [7.9156e-01],\n",
      "         [2.4119e-01],\n",
      "         [2.5159e-01],\n",
      "         [5.4491e-01],\n",
      "         [2.0346e-01],\n",
      "         [4.5883e-01],\n",
      "         [4.3156e-01],\n",
      "         [3.0629e-01],\n",
      "         [4.0885e-01],\n",
      "         [8.1439e-01],\n",
      "         [5.2375e-01],\n",
      "         [8.1649e-01],\n",
      "         [7.3292e-01],\n",
      "         [7.3565e-01],\n",
      "         [5.5674e-01],\n",
      "         [8.7678e-01],\n",
      "         [5.7052e-01],\n",
      "         [4.2458e-01],\n",
      "         [5.0323e-01],\n",
      "         [6.8526e-01],\n",
      "         [6.7640e-01],\n",
      "         [2.5425e-01],\n",
      "         [9.4395e-01],\n",
      "         [4.6481e-01],\n",
      "         [3.5625e-01],\n",
      "         [3.5784e-01],\n",
      "         [3.6848e-01],\n",
      "         [8.2874e-01],\n",
      "         [5.4269e-01],\n",
      "         [8.7017e-01],\n",
      "         [3.9412e-01],\n",
      "         [9.7210e-02],\n",
      "         [3.2871e-01],\n",
      "         [1.8473e-01],\n",
      "         [1.3606e-01],\n",
      "         [6.6877e-01],\n",
      "         [1.5515e-01],\n",
      "         [3.5886e-01],\n",
      "         [5.9014e-01],\n",
      "         [4.1796e-01],\n",
      "         [3.7259e-01],\n",
      "         [5.1726e-02],\n",
      "         [7.9407e-01],\n",
      "         [6.3988e-01],\n",
      "         [7.9918e-02],\n",
      "         [9.0574e-01],\n",
      "         [5.6031e-01],\n",
      "         [3.2441e-01],\n",
      "         [4.1881e-01],\n",
      "         [3.7576e-01],\n",
      "         [8.5953e-01],\n",
      "         [2.0835e-01],\n",
      "         [3.4526e-01],\n",
      "         [1.9945e-01],\n",
      "         [5.2108e-01],\n",
      "         [9.1347e-01],\n",
      "         [2.0522e-01],\n",
      "         [8.2600e-01],\n",
      "         [1.6703e-01],\n",
      "         [5.4707e-01],\n",
      "         [2.9202e-01],\n",
      "         [8.0153e-01],\n",
      "         [1.3286e-01],\n",
      "         [3.4350e-01],\n",
      "         [3.8340e-01],\n",
      "         [3.0996e-01],\n",
      "         [5.7094e-01],\n",
      "         [8.6461e-01],\n",
      "         [9.8291e-01],\n",
      "         [8.6321e-01],\n",
      "         [1.6716e-01],\n",
      "         [1.9123e-01],\n",
      "         [2.6902e-01],\n",
      "         [6.7806e-01],\n",
      "         [8.8256e-01],\n",
      "         [8.7296e-01],\n",
      "         [4.7163e-01],\n",
      "         [4.6030e-02],\n",
      "         [7.1966e-01],\n",
      "         [5.7992e-01],\n",
      "         [9.2785e-01],\n",
      "         [7.9196e-01],\n",
      "         [3.9445e-01],\n",
      "         [6.9020e-01],\n",
      "         [2.0737e-01],\n",
      "         [9.6520e-01],\n",
      "         [7.0476e-01],\n",
      "         [8.0967e-01],\n",
      "         [4.9068e-01],\n",
      "         [3.1634e-01],\n",
      "         [1.0152e-01],\n",
      "         [9.8348e-01],\n",
      "         [3.9764e-01],\n",
      "         [4.2628e-01],\n",
      "         [4.5433e-01],\n",
      "         [9.1569e-01],\n",
      "         [7.4606e-01],\n",
      "         [8.4691e-01],\n",
      "         [5.5405e-01],\n",
      "         [9.1021e-01]]], device='cuda:0', dtype=torch.float64)\n",
      "================iter 5============\n",
      "['shape/ellipsoid/1/ellipsoid_512_128_64_64_0_1_1']\n",
      "tensor([[ True,  True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
      "          True,  True,  True,  True,  True,  True,  True,  True, False, False]],\n",
      "       device='cuda:0')\n",
      "@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@\n",
      "['shape/ellipsoid/1/ellipsoid_512_128_64_64_0_2_1']\n",
      "gt_trans_torch.Size([1, 20, 3])_tensor([[[-2.1520e-02, -8.4658e-02, -9.0206e-02],\n",
      "         [-2.9963e-02, -7.6414e-02, -7.4747e-02],\n",
      "         [-1.9249e-03,  9.5002e-03,  3.4924e-02],\n",
      "         [ 1.1055e-02,  2.9639e-02,  3.5547e-02],\n",
      "         [-4.5667e-03,  4.2515e-02,  4.8002e-02],\n",
      "         [-1.7340e-03,  4.8410e-02,  6.3362e-02],\n",
      "         [-2.7846e-03,  6.2636e-02,  7.1759e-02],\n",
      "         [ 1.3728e-02,  7.7467e-02,  7.6994e-02],\n",
      "         [ 1.8428e-02,  8.1523e-02,  9.3986e-02],\n",
      "         [ 1.3475e-02,  8.8459e-02,  1.0990e-01],\n",
      "         [-1.3207e-02, -6.7649e-02, -6.4096e-02],\n",
      "         [-2.6269e-02, -5.4216e-02, -5.2513e-02],\n",
      "         [-1.3129e-02, -4.1531e-02, -4.5248e-02],\n",
      "         [-2.0006e-02, -2.9133e-02, -3.4288e-02],\n",
      "         [-1.1202e-02, -2.3990e-02, -1.8537e-02],\n",
      "         [-1.1999e-02, -9.0767e-03, -1.0752e-02],\n",
      "         [ 6.6613e-18, -8.8818e-19,  4.8850e-18],\n",
      "         [ 2.1973e-03,  7.5317e-03,  1.4366e-02],\n",
      "         [ 0.0000e+00,  0.0000e+00,  0.0000e+00],\n",
      "         [ 0.0000e+00,  0.0000e+00,  0.0000e+00]]], device='cuda:0')\n",
      "gt_rots_torch.Size([1, 20, 4])_tensor([[[ 8.8044e-01,  2.3422e-01,  1.9275e-01, -3.6444e-01],\n",
      "         [ 1.2754e-01,  7.0873e-01,  6.9280e-01, -3.8302e-02],\n",
      "         [ 3.3019e-01, -2.8103e-01,  6.7147e-01, -6.0094e-01],\n",
      "         [ 5.4103e-01,  3.9310e-01,  2.9512e-01,  6.8239e-01],\n",
      "         [ 1.4170e-01,  2.3066e-03,  9.7345e-01,  1.7976e-01],\n",
      "         [ 4.6485e-01, -1.7743e-01,  5.2147e-01,  6.9318e-01],\n",
      "         [ 7.5250e-01, -6.0932e-01,  1.3889e-01, -2.0783e-01],\n",
      "         [-5.8458e-01, -5.8695e-02, -1.3969e-01,  7.9707e-01],\n",
      "         [ 1.5434e-01,  7.6644e-02, -4.2615e-01,  8.8809e-01],\n",
      "         [ 1.8127e-01, -9.3889e-04,  6.2681e-01,  7.5779e-01],\n",
      "         [ 7.0739e-01, -5.8226e-01,  3.7307e-01,  1.4624e-01],\n",
      "         [-6.3523e-02,  5.4058e-01, -2.1364e-01,  8.1123e-01],\n",
      "         [ 2.3432e-01,  9.6107e-01, -6.1378e-02, -1.3296e-01],\n",
      "         [ 6.2626e-01,  3.5498e-01, -1.6632e-01,  6.7389e-01],\n",
      "         [-2.8049e-01, -8.8909e-02, -1.5818e-01,  9.4255e-01],\n",
      "         [ 8.1366e-01,  5.7858e-01,  5.6019e-02,  8.2100e-03],\n",
      "         [-3.0515e-01, -4.5494e-01,  8.1419e-01,  1.9237e-01],\n",
      "         [-1.0364e-01,  8.6281e-01,  3.9910e-01,  2.9247e-01],\n",
      "         [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00],\n",
      "         [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00]]],\n",
      "       device='cuda:0')\n",
      "noisy_trans_and_rots_torch.Size([1, 20, 7])_tensor([[[-0.7068,  0.0000, -0.7919, -1.2403,  0.0000,  0.0000, -0.7986],\n",
      "         [-1.2024,  0.0000, -0.6152, -0.1100,  0.0000,  0.0000,  0.1227],\n",
      "         [ 1.4966,  0.0000,  0.1192,  0.8161,  0.0000,  0.0000,  0.3892],\n",
      "         [-0.6182,  0.0000,  1.1040, -0.4076,  0.0000,  0.0000, -0.3319],\n",
      "         [ 0.8079,  0.0000, -0.0931,  0.4629,  0.0000,  0.0000,  0.1653],\n",
      "         [-0.7112,  0.0000,  0.2824, -1.2575,  0.0000,  0.0000, -0.0803],\n",
      "         [ 0.0456,  0.0000,  0.7951, -0.6903,  0.0000,  0.0000, -1.8577],\n",
      "         [-0.1645,  0.0000,  0.5961, -1.7799,  0.0000,  0.0000, -0.8450],\n",
      "         [-0.0116,  0.0000, -0.0969,  1.5627,  0.0000,  0.0000, -1.0321],\n",
      "         [ 0.1496,  0.0000,  1.2871,  0.1043,  0.0000,  0.0000, -0.1353],\n",
      "         [-0.5705,  0.0000,  0.1880,  0.6701,  0.0000,  0.0000, -1.6320],\n",
      "         [ 0.4127,  0.0000, -0.1933,  0.4551,  0.0000,  0.0000,  0.9756],\n",
      "         [-0.8905,  0.0000,  1.0578, -0.1371,  0.0000,  0.0000,  0.7350],\n",
      "         [-1.6295,  0.0000, -1.1496, -0.3454,  0.0000,  0.0000,  0.1079],\n",
      "         [ 0.2484,  0.0000, -0.6333, -1.4533,  0.0000,  0.0000, -1.2749],\n",
      "         [ 1.2686,  0.0000, -1.3078, -0.5116,  0.0000,  0.0000, -0.5196],\n",
      "         [-1.3268,  0.0000,  0.1805,  0.9161,  0.0000,  0.0000, -1.1804],\n",
      "         [ 0.0360,  0.0000,  0.1815,  0.6843,  0.0000,  0.0000, -0.5055],\n",
      "         [-0.6546,  0.0000,  0.6728, -1.1110,  0.0000,  0.0000,  0.2876],\n",
      "         [-1.5675,  0.0000, -0.6126,  1.0043,  0.0000,  0.0000,  1.5171]]],\n",
      "       device='cuda:0')\n",
      "================iter 0============\n",
      "['shape/ellipsoid/1/ellipsoid_512_128_64_64_0_2_1']\n",
      "tensor([[False, False, False, False, False, False, False, False, False, False,\n",
      "         False, False, False, False, False, False,  True, False, False, False]],\n",
      "       device='cuda:0')\n",
      "acc torch.Size([1]) tensor([0.0556], device='cuda:0')\n",
      "acc_per_part torch.Size([1, 20]) tensor([[False, False, False, False, False, False, False, False, False, False,\n",
      "         False, False, False, False, False, False,  True, False, False, False]],\n",
      "       device='cuda:0')\n",
      "loss_per_data torch.Size([1, 20]) tensor([[ 0.4402,  2.4455,  1.7758,  1.0950,  0.8265,  2.4924,  2.0602,  1.5149,\n",
      "          1.6384,  3.9813,  1.9201,  1.7680,  0.6847,  9.4685,  2.4165,  1.6423,\n",
      "          0.0000,  1.1936, 20.0715,  0.8324]], device='cuda:0')\n",
      "scores torch.Size([1, 190, 1]) tensor([[[0.3766],\n",
      "         [0.6622],\n",
      "         [0.8058],\n",
      "         [0.9298],\n",
      "         [0.5705],\n",
      "         [0.5185],\n",
      "         [0.5742],\n",
      "         [0.5470],\n",
      "         [0.5597],\n",
      "         [0.8848],\n",
      "         [0.3493],\n",
      "         [0.2843],\n",
      "         [0.2755],\n",
      "         [0.9783],\n",
      "         [0.4070],\n",
      "         [0.8436],\n",
      "         [0.7866],\n",
      "         [0.7607],\n",
      "         [0.7729],\n",
      "         [0.2749],\n",
      "         [0.2952],\n",
      "         [0.4667],\n",
      "         [0.9014],\n",
      "         [0.0059],\n",
      "         [0.7699],\n",
      "         [0.6257],\n",
      "         [0.5048],\n",
      "         [0.2136],\n",
      "         [0.7293],\n",
      "         [0.3008],\n",
      "         [0.1240],\n",
      "         [0.8816],\n",
      "         [0.1334],\n",
      "         [0.4560],\n",
      "         [0.8475],\n",
      "         [0.3792],\n",
      "         [0.8295],\n",
      "         [0.2541],\n",
      "         [0.1216],\n",
      "         [0.9707],\n",
      "         [0.1339],\n",
      "         [0.8733],\n",
      "         [0.9711],\n",
      "         [0.3352],\n",
      "         [0.9670],\n",
      "         [0.3077],\n",
      "         [0.6539],\n",
      "         [0.7232],\n",
      "         [0.7461],\n",
      "         [0.3427],\n",
      "         [0.7037],\n",
      "         [0.0412],\n",
      "         [0.6658],\n",
      "         [0.5500],\n",
      "         [0.7708],\n",
      "         [0.6575],\n",
      "         [0.3539],\n",
      "         [0.3960],\n",
      "         [0.9682],\n",
      "         [0.6675],\n",
      "         [0.0717],\n",
      "         [0.1634],\n",
      "         [0.9288],\n",
      "         [0.7839],\n",
      "         [0.2719],\n",
      "         [0.8110],\n",
      "         [0.3716],\n",
      "         [0.6307],\n",
      "         [0.3011],\n",
      "         [0.6923],\n",
      "         [0.8949],\n",
      "         [0.2110],\n",
      "         [0.8412],\n",
      "         [0.2503],\n",
      "         [0.2654],\n",
      "         [0.5834],\n",
      "         [0.5698],\n",
      "         [0.4378],\n",
      "         [0.1518],\n",
      "         [0.0287],\n",
      "         [0.6994],\n",
      "         [0.0401],\n",
      "         [0.1869],\n",
      "         [0.5832],\n",
      "         [0.9520],\n",
      "         [0.2123],\n",
      "         [0.9693],\n",
      "         [0.9609],\n",
      "         [0.8747],\n",
      "         [0.1031],\n",
      "         [0.9125],\n",
      "         [0.2003],\n",
      "         [0.6555],\n",
      "         [0.5795],\n",
      "         [0.5234],\n",
      "         [0.6943],\n",
      "         [0.7514],\n",
      "         [0.2595],\n",
      "         [0.6145],\n",
      "         [0.9529],\n",
      "         [0.9492],\n",
      "         [0.8181],\n",
      "         [0.9491],\n",
      "         [0.5025],\n",
      "         [0.8137],\n",
      "         [0.2538],\n",
      "         [0.9044],\n",
      "         [0.8275],\n",
      "         [0.9800],\n",
      "         [0.2611],\n",
      "         [0.4897],\n",
      "         [0.8109],\n",
      "         [0.1536],\n",
      "         [0.9982],\n",
      "         [0.2495],\n",
      "         [0.9393],\n",
      "         [0.1861],\n",
      "         [0.4727],\n",
      "         [0.2870],\n",
      "         [0.7259],\n",
      "         [0.1017],\n",
      "         [0.6086],\n",
      "         [0.3416],\n",
      "         [0.5018],\n",
      "         [0.5189],\n",
      "         [0.1183],\n",
      "         [0.8736],\n",
      "         [0.6128],\n",
      "         [0.6811],\n",
      "         [0.1873],\n",
      "         [0.5192],\n",
      "         [0.7051],\n",
      "         [0.8998],\n",
      "         [0.7803],\n",
      "         [0.0570],\n",
      "         [0.4743],\n",
      "         [0.1493],\n",
      "         [0.6375],\n",
      "         [0.3567],\n",
      "         [0.5701],\n",
      "         [0.9824],\n",
      "         [0.2106],\n",
      "         [0.8717],\n",
      "         [0.2570],\n",
      "         [0.6913],\n",
      "         [0.7465],\n",
      "         [0.8378],\n",
      "         [0.6916],\n",
      "         [0.4110],\n",
      "         [0.8244],\n",
      "         [0.4169],\n",
      "         [0.6136],\n",
      "         [0.8027],\n",
      "         [0.4104],\n",
      "         [0.3665],\n",
      "         [0.5192],\n",
      "         [0.5584],\n",
      "         [0.4983],\n",
      "         [0.0943],\n",
      "         [0.2333],\n",
      "         [0.1768],\n",
      "         [0.9720],\n",
      "         [0.3476],\n",
      "         [0.2278],\n",
      "         [0.3590],\n",
      "         [0.3868],\n",
      "         [0.0773],\n",
      "         [0.7374],\n",
      "         [0.1021],\n",
      "         [0.9307],\n",
      "         [0.8258],\n",
      "         [0.1159],\n",
      "         [0.0617],\n",
      "         [0.8667],\n",
      "         [0.7239],\n",
      "         [0.1569],\n",
      "         [0.1665],\n",
      "         [0.7221],\n",
      "         [0.9200],\n",
      "         [0.5291],\n",
      "         [0.4723],\n",
      "         [0.0884],\n",
      "         [0.5556],\n",
      "         [0.3230],\n",
      "         [0.8877],\n",
      "         [0.4166],\n",
      "         [0.4433],\n",
      "         [0.1936],\n",
      "         [0.4553],\n",
      "         [0.2767]]], device='cuda:0', dtype=torch.float64)\n",
      "================iter 1============\n",
      "['shape/ellipsoid/1/ellipsoid_512_128_64_64_0_2_1']\n",
      "tensor([[False, False, False, False, False, False,  True, False, False, False,\n",
      "         False, False, False, False, False, False,  True, False, False, False]],\n",
      "       device='cuda:0')\n",
      "acc torch.Size([1]) tensor([0.0556], device='cuda:0')\n",
      "acc_per_part torch.Size([1, 20]) tensor([[False, False, False, False, False, False, False, False, False, False,\n",
      "         False, False, False, False, False, False,  True, False, False, False]],\n",
      "       device='cuda:0')\n",
      "loss_per_data torch.Size([1, 20]) tensor([[ 1.2199,  2.1615,  2.0024,  0.1299,  1.3299,  6.2482,  2.0602,  2.4445,\n",
      "          1.1675,  1.7654,  1.7338,  0.9649,  0.3577,  6.2006,  2.1714,  0.8831,\n",
      "          0.0000,  3.4840, 18.6741,  3.8227]], device='cuda:0')\n",
      "scores torch.Size([1, 190, 1]) tensor([[[0.9136],\n",
      "         [0.7752],\n",
      "         [0.6847],\n",
      "         [0.1340],\n",
      "         [0.5990],\n",
      "         [0.7768],\n",
      "         [0.2482],\n",
      "         [0.4989],\n",
      "         [0.0266],\n",
      "         [0.6502],\n",
      "         [0.6445],\n",
      "         [0.4169],\n",
      "         [0.4664],\n",
      "         [0.1089],\n",
      "         [0.2348],\n",
      "         [0.9819],\n",
      "         [0.7840],\n",
      "         [0.8482],\n",
      "         [0.4810],\n",
      "         [0.9115],\n",
      "         [0.6398],\n",
      "         [0.8604],\n",
      "         [0.9446],\n",
      "         [0.9677],\n",
      "         [0.1519],\n",
      "         [0.5615],\n",
      "         [0.7963],\n",
      "         [0.5116],\n",
      "         [0.8068],\n",
      "         [0.0576],\n",
      "         [0.0297],\n",
      "         [0.7428],\n",
      "         [0.8376],\n",
      "         [0.9423],\n",
      "         [0.4656],\n",
      "         [0.3037],\n",
      "         [0.7622],\n",
      "         [0.8789],\n",
      "         [0.6965],\n",
      "         [0.7293],\n",
      "         [0.8176],\n",
      "         [0.3937],\n",
      "         [0.2517],\n",
      "         [0.7867],\n",
      "         [0.6548],\n",
      "         [0.3893],\n",
      "         [0.5517],\n",
      "         [0.1820],\n",
      "         [0.8619],\n",
      "         [0.2832],\n",
      "         [0.3212],\n",
      "         [0.5773],\n",
      "         [0.5196],\n",
      "         [0.0752],\n",
      "         [0.2686],\n",
      "         [0.4658],\n",
      "         [0.0032],\n",
      "         [0.1002],\n",
      "         [0.1790],\n",
      "         [0.6327],\n",
      "         [0.9820],\n",
      "         [0.5706],\n",
      "         [0.9239],\n",
      "         [0.5108],\n",
      "         [0.0727],\n",
      "         [0.4654],\n",
      "         [0.6990],\n",
      "         [0.3249],\n",
      "         [0.0054],\n",
      "         [0.1312],\n",
      "         [0.2613],\n",
      "         [0.6557],\n",
      "         [0.8622],\n",
      "         [0.4353],\n",
      "         [0.6343],\n",
      "         [0.7807],\n",
      "         [0.9958],\n",
      "         [0.7449],\n",
      "         [0.3449],\n",
      "         [0.8750],\n",
      "         [0.7358],\n",
      "         [0.4954],\n",
      "         [0.9467],\n",
      "         [0.9511],\n",
      "         [0.3983],\n",
      "         [0.7180],\n",
      "         [0.0509],\n",
      "         [0.4906],\n",
      "         [0.7428],\n",
      "         [0.0616],\n",
      "         [0.1089],\n",
      "         [0.8893],\n",
      "         [0.1101],\n",
      "         [0.8590],\n",
      "         [0.8903],\n",
      "         [0.4448],\n",
      "         [0.2021],\n",
      "         [0.4774],\n",
      "         [0.4307],\n",
      "         [0.4046],\n",
      "         [0.6651],\n",
      "         [0.7062],\n",
      "         [0.7052],\n",
      "         [0.9786],\n",
      "         [0.9372],\n",
      "         [0.0169],\n",
      "         [0.3731],\n",
      "         [0.3535],\n",
      "         [0.4047],\n",
      "         [0.6919],\n",
      "         [0.7846],\n",
      "         [0.6529],\n",
      "         [0.8854],\n",
      "         [0.3585],\n",
      "         [0.7160],\n",
      "         [0.0097],\n",
      "         [0.0872],\n",
      "         [0.0585],\n",
      "         [0.6795],\n",
      "         [0.0348],\n",
      "         [0.6783],\n",
      "         [0.4368],\n",
      "         [0.5585],\n",
      "         [0.7204],\n",
      "         [0.1546],\n",
      "         [0.0229],\n",
      "         [0.0416],\n",
      "         [0.8065],\n",
      "         [0.9011],\n",
      "         [0.7626],\n",
      "         [0.5077],\n",
      "         [0.2089],\n",
      "         [0.3031],\n",
      "         [0.8649],\n",
      "         [0.0475],\n",
      "         [0.2318],\n",
      "         [0.3811],\n",
      "         [0.6941],\n",
      "         [0.8475],\n",
      "         [0.0920],\n",
      "         [0.0590],\n",
      "         [0.5948],\n",
      "         [0.5327],\n",
      "         [0.5386],\n",
      "         [0.6196],\n",
      "         [0.8478],\n",
      "         [0.4976],\n",
      "         [0.0303],\n",
      "         [0.7922],\n",
      "         [0.4514],\n",
      "         [0.8887],\n",
      "         [0.3926],\n",
      "         [0.1194],\n",
      "         [0.7594],\n",
      "         [0.8778],\n",
      "         [0.1202],\n",
      "         [0.7513],\n",
      "         [0.0204],\n",
      "         [0.8163],\n",
      "         [0.4097],\n",
      "         [0.6389],\n",
      "         [0.8158],\n",
      "         [0.8650],\n",
      "         [0.6246],\n",
      "         [0.4966],\n",
      "         [0.7109],\n",
      "         [0.8150],\n",
      "         [0.2879],\n",
      "         [0.9838],\n",
      "         [0.2917],\n",
      "         [0.2427],\n",
      "         [0.2967],\n",
      "         [0.9047],\n",
      "         [0.1163],\n",
      "         [0.5009],\n",
      "         [0.4652],\n",
      "         [0.0574],\n",
      "         [0.0200],\n",
      "         [0.0910],\n",
      "         [0.3865],\n",
      "         [0.4470],\n",
      "         [0.2975],\n",
      "         [0.5758],\n",
      "         [0.7800],\n",
      "         [0.2057],\n",
      "         [0.6600],\n",
      "         [0.7327],\n",
      "         [0.0336],\n",
      "         [0.3992],\n",
      "         [0.2429]]], device='cuda:0', dtype=torch.float64)\n",
      "================iter 2============\n",
      "['shape/ellipsoid/1/ellipsoid_512_128_64_64_0_2_1']\n",
      "tensor([[ True,  True, False, False, False, False,  True, False, False, False,\n",
      "         False,  True,  True, False, False, False,  True, False, False, False]],\n",
      "       device='cuda:0')\n",
      "acc torch.Size([1]) tensor([0.0556], device='cuda:0')\n",
      "acc_per_part torch.Size([1, 20]) tensor([[False, False, False, False, False, False, False, False, False, False,\n",
      "         False, False, False, False, False, False,  True, False, False, False]],\n",
      "       device='cuda:0')\n",
      "loss_per_data torch.Size([1, 20]) tensor([[1.2199e+00, 2.1615e+00, 1.3651e-01, 6.3203e-01, 1.1248e+00, 1.5357e+00,\n",
      "         2.0602e+00, 2.7295e+00, 1.0705e+00, 1.8740e+00, 2.3438e+00, 9.6489e-01,\n",
      "         3.5772e-01, 2.4089e+01, 2.5763e-02, 1.2208e+00, 0.0000e+00, 1.1577e+00,\n",
      "         2.7407e+01, 1.2023e+01]], device='cuda:0')\n",
      "scores torch.Size([1, 190, 1]) tensor([[[0.6794],\n",
      "         [0.4960],\n",
      "         [0.7191],\n",
      "         [0.6783],\n",
      "         [0.8670],\n",
      "         [0.9503],\n",
      "         [0.4039],\n",
      "         [0.7513],\n",
      "         [0.9330],\n",
      "         [0.2492],\n",
      "         [0.7223],\n",
      "         [0.1150],\n",
      "         [0.2603],\n",
      "         [0.5332],\n",
      "         [0.5091],\n",
      "         [0.0674],\n",
      "         [0.5750],\n",
      "         [0.3972],\n",
      "         [0.5536],\n",
      "         [0.8658],\n",
      "         [0.2801],\n",
      "         [0.5574],\n",
      "         [0.6400],\n",
      "         [0.4145],\n",
      "         [0.1574],\n",
      "         [0.9460],\n",
      "         [0.9835],\n",
      "         [0.5372],\n",
      "         [0.5251],\n",
      "         [0.3346],\n",
      "         [0.0283],\n",
      "         [0.1626],\n",
      "         [0.6179],\n",
      "         [0.1036],\n",
      "         [0.7544],\n",
      "         [0.0999],\n",
      "         [0.2108],\n",
      "         [0.1613],\n",
      "         [0.3920],\n",
      "         [0.5406],\n",
      "         [0.3858],\n",
      "         [0.4883],\n",
      "         [0.6561],\n",
      "         [0.0988],\n",
      "         [0.7657],\n",
      "         [0.8075],\n",
      "         [0.2573],\n",
      "         [0.4158],\n",
      "         [0.0794],\n",
      "         [0.4165],\n",
      "         [0.5439],\n",
      "         [0.7707],\n",
      "         [0.6867],\n",
      "         [0.4069],\n",
      "         [0.1946],\n",
      "         [0.2507],\n",
      "         [0.6584],\n",
      "         [0.1939],\n",
      "         [0.7331],\n",
      "         [0.1194],\n",
      "         [0.3448],\n",
      "         [0.8738],\n",
      "         [0.8281],\n",
      "         [0.5201],\n",
      "         [0.2631],\n",
      "         [0.0345],\n",
      "         [0.1979],\n",
      "         [0.7506],\n",
      "         [0.6311],\n",
      "         [0.3588],\n",
      "         [0.4731],\n",
      "         [0.8674],\n",
      "         [0.7502],\n",
      "         [0.1972],\n",
      "         [0.9077],\n",
      "         [0.1041],\n",
      "         [0.8530],\n",
      "         [0.4618],\n",
      "         [0.5870],\n",
      "         [0.8031],\n",
      "         [0.8853],\n",
      "         [0.7129],\n",
      "         [0.2125],\n",
      "         [0.5254],\n",
      "         [0.4523],\n",
      "         [0.7400],\n",
      "         [0.5174],\n",
      "         [0.2790],\n",
      "         [0.3836],\n",
      "         [0.1256],\n",
      "         [0.3919],\n",
      "         [0.6673],\n",
      "         [0.1848],\n",
      "         [0.9024],\n",
      "         [0.6539],\n",
      "         [0.2015],\n",
      "         [0.7721],\n",
      "         [0.0823],\n",
      "         [0.0424],\n",
      "         [0.7254],\n",
      "         [0.7004],\n",
      "         [0.9134],\n",
      "         [0.4694],\n",
      "         [0.9572],\n",
      "         [0.9785],\n",
      "         [0.6458],\n",
      "         [0.3975],\n",
      "         [0.4472],\n",
      "         [0.7822],\n",
      "         [0.7182],\n",
      "         [0.8814],\n",
      "         [0.9668],\n",
      "         [0.8953],\n",
      "         [0.2509],\n",
      "         [0.0898],\n",
      "         [0.5989],\n",
      "         [0.4538],\n",
      "         [0.5989],\n",
      "         [0.3722],\n",
      "         [0.4433],\n",
      "         [0.3086],\n",
      "         [0.0460],\n",
      "         [0.5306],\n",
      "         [0.6838],\n",
      "         [0.4574],\n",
      "         [0.9913],\n",
      "         [0.4137],\n",
      "         [0.7208],\n",
      "         [0.4678],\n",
      "         [0.4752],\n",
      "         [0.0943],\n",
      "         [0.0264],\n",
      "         [0.5035],\n",
      "         [0.7656],\n",
      "         [0.7890],\n",
      "         [0.6591],\n",
      "         [0.8282],\n",
      "         [0.5018],\n",
      "         [0.3006],\n",
      "         [0.9467],\n",
      "         [0.7545],\n",
      "         [0.5098],\n",
      "         [0.0795],\n",
      "         [0.7281],\n",
      "         [0.0892],\n",
      "         [0.4065],\n",
      "         [0.5495],\n",
      "         [0.2640],\n",
      "         [0.4123],\n",
      "         [0.2660],\n",
      "         [0.6976],\n",
      "         [0.1455],\n",
      "         [0.7616],\n",
      "         [0.2980],\n",
      "         [0.6450],\n",
      "         [0.2419],\n",
      "         [0.0316],\n",
      "         [0.4170],\n",
      "         [0.8328],\n",
      "         [0.3656],\n",
      "         [0.9691],\n",
      "         [0.8486],\n",
      "         [0.7475],\n",
      "         [0.2164],\n",
      "         [0.6746],\n",
      "         [0.9009],\n",
      "         [0.6000],\n",
      "         [0.9007],\n",
      "         [0.0558],\n",
      "         [0.9852],\n",
      "         [0.0396],\n",
      "         [0.4962],\n",
      "         [0.1271],\n",
      "         [0.1893],\n",
      "         [0.5053],\n",
      "         [0.5636],\n",
      "         [0.0804],\n",
      "         [0.6828],\n",
      "         [0.2236],\n",
      "         [0.7422],\n",
      "         [0.3485],\n",
      "         [0.8840],\n",
      "         [0.6348],\n",
      "         [0.7693],\n",
      "         [0.4484],\n",
      "         [0.3165],\n",
      "         [0.1125],\n",
      "         [0.9359],\n",
      "         [0.8526],\n",
      "         [0.4425]]], device='cuda:0', dtype=torch.float64)\n",
      "================iter 3============\n",
      "['shape/ellipsoid/1/ellipsoid_512_128_64_64_0_2_1']\n",
      "tensor([[ True,  True, False, False, False, False,  True, False,  True,  True,\n",
      "         False,  True,  True, False, False, False,  True, False, False, False]],\n",
      "       device='cuda:0')\n",
      "acc torch.Size([1]) tensor([0.0556], device='cuda:0')\n",
      "acc_per_part torch.Size([1, 20]) tensor([[False, False, False, False, False, False, False, False, False, False,\n",
      "         False, False, False, False, False, False,  True, False, False, False]],\n",
      "       device='cuda:0')\n",
      "loss_per_data torch.Size([1, 20]) tensor([[ 1.2199,  2.1615,  0.5933,  0.7691,  1.4428,  4.3270,  2.0602,  1.7449,\n",
      "          1.0705,  1.8740,  1.8406,  0.9649,  0.3577, 31.0894,  0.1711,  3.1374,\n",
      "          0.0000,  0.8343, 34.2437, 11.1423]], device='cuda:0')\n",
      "scores torch.Size([1, 190, 1]) tensor([[[0.5665],\n",
      "         [0.2002],\n",
      "         [0.5143],\n",
      "         [0.9413],\n",
      "         [0.9281],\n",
      "         [0.9245],\n",
      "         [0.4499],\n",
      "         [0.2663],\n",
      "         [0.6983],\n",
      "         [0.4761],\n",
      "         [0.7486],\n",
      "         [0.5258],\n",
      "         [0.5662],\n",
      "         [0.9091],\n",
      "         [0.3572],\n",
      "         [0.2213],\n",
      "         [0.4967],\n",
      "         [0.7351],\n",
      "         [0.5168],\n",
      "         [0.9748],\n",
      "         [0.2413],\n",
      "         [0.6204],\n",
      "         [0.7990],\n",
      "         [0.2513],\n",
      "         [0.0191],\n",
      "         [0.9276],\n",
      "         [0.6981],\n",
      "         [0.2927],\n",
      "         [0.6361],\n",
      "         [0.5992],\n",
      "         [0.7992],\n",
      "         [0.0306],\n",
      "         [0.9522],\n",
      "         [0.2791],\n",
      "         [0.0857],\n",
      "         [0.9119],\n",
      "         [0.8707],\n",
      "         [0.9731],\n",
      "         [0.3643],\n",
      "         [0.6764],\n",
      "         [0.5815],\n",
      "         [0.9343],\n",
      "         [0.9184],\n",
      "         [0.3205],\n",
      "         [0.7805],\n",
      "         [0.7088],\n",
      "         [0.0143],\n",
      "         [0.3185],\n",
      "         [0.5119],\n",
      "         [0.9346],\n",
      "         [0.4390],\n",
      "         [0.1946],\n",
      "         [0.0123],\n",
      "         [0.4609],\n",
      "         [0.1698],\n",
      "         [0.3733],\n",
      "         [0.2298],\n",
      "         [0.4038],\n",
      "         [0.1264],\n",
      "         [0.0784],\n",
      "         [0.1717],\n",
      "         [0.2950],\n",
      "         [0.2566],\n",
      "         [0.4357],\n",
      "         [0.9968],\n",
      "         [0.5570],\n",
      "         [0.9914],\n",
      "         [0.4465],\n",
      "         [0.1113],\n",
      "         [0.9801],\n",
      "         [0.9902],\n",
      "         [0.6998],\n",
      "         [0.7018],\n",
      "         [0.3677],\n",
      "         [0.2411],\n",
      "         [0.8405],\n",
      "         [0.5707],\n",
      "         [0.9959],\n",
      "         [0.9705],\n",
      "         [0.9457],\n",
      "         [0.3451],\n",
      "         [0.2002],\n",
      "         [0.1539],\n",
      "         [0.7241],\n",
      "         [0.7843],\n",
      "         [0.7308],\n",
      "         [0.4181],\n",
      "         [0.6137],\n",
      "         [0.5334],\n",
      "         [0.8788],\n",
      "         [0.7704],\n",
      "         [0.4870],\n",
      "         [0.1095],\n",
      "         [0.9348],\n",
      "         [0.5182],\n",
      "         [0.3070],\n",
      "         [0.6525],\n",
      "         [0.5865],\n",
      "         [0.7548],\n",
      "         [0.3903],\n",
      "         [0.6366],\n",
      "         [0.7549],\n",
      "         [0.1486],\n",
      "         [0.3803],\n",
      "         [0.5410],\n",
      "         [0.1541],\n",
      "         [0.1721],\n",
      "         [0.3815],\n",
      "         [0.1178],\n",
      "         [0.6825],\n",
      "         [0.7707],\n",
      "         [0.2767],\n",
      "         [0.1727],\n",
      "         [0.1688],\n",
      "         [0.3146],\n",
      "         [0.4476],\n",
      "         [0.0551],\n",
      "         [0.9759],\n",
      "         [0.2258],\n",
      "         [0.6206],\n",
      "         [0.7614],\n",
      "         [0.5910],\n",
      "         [0.0239],\n",
      "         [0.6910],\n",
      "         [0.2104],\n",
      "         [0.6647],\n",
      "         [0.0337],\n",
      "         [0.0673],\n",
      "         [0.4773],\n",
      "         [0.8057],\n",
      "         [0.2921],\n",
      "         [0.2471],\n",
      "         [0.9858],\n",
      "         [0.1187],\n",
      "         [0.9920],\n",
      "         [0.4200],\n",
      "         [0.1276],\n",
      "         [0.6439],\n",
      "         [0.4042],\n",
      "         [0.2195],\n",
      "         [0.1546],\n",
      "         [0.4436],\n",
      "         [0.7814],\n",
      "         [0.0643],\n",
      "         [0.8515],\n",
      "         [0.3542],\n",
      "         [0.5271],\n",
      "         [0.8829],\n",
      "         [0.7699],\n",
      "         [0.1317],\n",
      "         [0.5136],\n",
      "         [0.9366],\n",
      "         [0.3355],\n",
      "         [0.8086],\n",
      "         [0.7645],\n",
      "         [0.9425],\n",
      "         [0.0896],\n",
      "         [0.1448],\n",
      "         [0.2907],\n",
      "         [0.5666],\n",
      "         [0.6103],\n",
      "         [0.4430],\n",
      "         [0.5381],\n",
      "         [0.5945],\n",
      "         [0.4379],\n",
      "         [0.8605],\n",
      "         [0.5293],\n",
      "         [0.5962],\n",
      "         [0.8177],\n",
      "         [0.3358],\n",
      "         [0.8733],\n",
      "         [0.0206],\n",
      "         [0.8600],\n",
      "         [0.3694],\n",
      "         [0.8492],\n",
      "         [0.5142],\n",
      "         [0.2922],\n",
      "         [0.5957],\n",
      "         [0.3662],\n",
      "         [0.6400],\n",
      "         [0.2970],\n",
      "         [0.6350],\n",
      "         [0.6427],\n",
      "         [0.1656],\n",
      "         [0.4009],\n",
      "         [0.3893],\n",
      "         [0.8679],\n",
      "         [0.2917],\n",
      "         [0.3810],\n",
      "         [0.9522]]], device='cuda:0', dtype=torch.float64)\n",
      "================iter 4============\n",
      "['shape/ellipsoid/1/ellipsoid_512_128_64_64_0_2_1']\n",
      "tensor([[ True,  True,  True,  True,  True,  True,  True, False,  True,  True,\n",
      "         False,  True,  True,  True,  True,  True,  True,  True, False, False]],\n",
      "       device='cuda:0')\n",
      "acc torch.Size([1]) tensor([0.0556], device='cuda:0')\n",
      "acc_per_part torch.Size([1, 20]) tensor([[False, False, False, False, False, False, False, False, False, False,\n",
      "         False, False, False, False, False, False,  True, False, False, False]],\n",
      "       device='cuda:0')\n",
      "loss_per_data torch.Size([1, 20]) tensor([[  1.2199,   2.1615,   0.5933,   0.7691,   1.4428,   4.3270,   2.0602,\n",
      "          11.9791,   1.0705,   1.8740,   3.5914,   0.9649,   0.3577,  31.0894,\n",
      "           0.1711,   3.1374,   0.0000,   0.8343, 114.6023,  17.2090]],\n",
      "       device='cuda:0')\n",
      "scores torch.Size([1, 190, 1]) tensor([[[7.6858e-01],\n",
      "         [4.8033e-01],\n",
      "         [6.5261e-01],\n",
      "         [8.9156e-01],\n",
      "         [5.1211e-02],\n",
      "         [7.8907e-01],\n",
      "         [3.8441e-01],\n",
      "         [1.6282e-01],\n",
      "         [9.3395e-02],\n",
      "         [8.1501e-01],\n",
      "         [2.9642e-01],\n",
      "         [8.5214e-01],\n",
      "         [1.8415e-02],\n",
      "         [3.8178e-01],\n",
      "         [7.9171e-01],\n",
      "         [7.8979e-01],\n",
      "         [4.5407e-01],\n",
      "         [9.7330e-01],\n",
      "         [7.7534e-03],\n",
      "         [4.1139e-01],\n",
      "         [7.8250e-01],\n",
      "         [4.3669e-01],\n",
      "         [6.0992e-01],\n",
      "         [5.5458e-01],\n",
      "         [2.7952e-01],\n",
      "         [2.5988e-01],\n",
      "         [7.3182e-01],\n",
      "         [7.6576e-01],\n",
      "         [8.6332e-01],\n",
      "         [1.0592e-01],\n",
      "         [8.0706e-01],\n",
      "         [4.6536e-01],\n",
      "         [4.2454e-01],\n",
      "         [5.9490e-01],\n",
      "         [3.5337e-01],\n",
      "         [8.9338e-01],\n",
      "         [4.3239e-01],\n",
      "         [1.9509e-01],\n",
      "         [9.5153e-01],\n",
      "         [4.5599e-01],\n",
      "         [7.1057e-01],\n",
      "         [3.6301e-01],\n",
      "         [2.0003e-01],\n",
      "         [7.4130e-01],\n",
      "         [9.3341e-01],\n",
      "         [6.6547e-01],\n",
      "         [9.6327e-01],\n",
      "         [6.1355e-01],\n",
      "         [8.8100e-02],\n",
      "         [5.6696e-01],\n",
      "         [4.6126e-01],\n",
      "         [7.5808e-01],\n",
      "         [6.7645e-02],\n",
      "         [5.7295e-01],\n",
      "         [1.4107e-01],\n",
      "         [2.3112e-01],\n",
      "         [9.2916e-01],\n",
      "         [8.5720e-02],\n",
      "         [2.7368e-02],\n",
      "         [4.5805e-01],\n",
      "         [5.6430e-02],\n",
      "         [9.8967e-01],\n",
      "         [4.3168e-01],\n",
      "         [7.1406e-01],\n",
      "         [9.4636e-01],\n",
      "         [4.3387e-02],\n",
      "         [6.1534e-01],\n",
      "         [9.7951e-01],\n",
      "         [5.3300e-01],\n",
      "         [3.0407e-01],\n",
      "         [1.4248e-01],\n",
      "         [6.2111e-01],\n",
      "         [4.4332e-01],\n",
      "         [4.0715e-01],\n",
      "         [7.7555e-01],\n",
      "         [1.4120e-01],\n",
      "         [8.5241e-01],\n",
      "         [6.3332e-01],\n",
      "         [3.8766e-01],\n",
      "         [6.3976e-01],\n",
      "         [9.3735e-01],\n",
      "         [4.0534e-01],\n",
      "         [4.1656e-01],\n",
      "         [3.5091e-02],\n",
      "         [2.3989e-01],\n",
      "         [6.2905e-01],\n",
      "         [3.4504e-01],\n",
      "         [4.8957e-01],\n",
      "         [9.8398e-01],\n",
      "         [8.0954e-01],\n",
      "         [6.2019e-01],\n",
      "         [2.9299e-01],\n",
      "         [7.1720e-02],\n",
      "         [4.9843e-01],\n",
      "         [8.5002e-01],\n",
      "         [2.2370e-01],\n",
      "         [5.5229e-02],\n",
      "         [5.6977e-01],\n",
      "         [3.4610e-01],\n",
      "         [4.8941e-01],\n",
      "         [6.3213e-02],\n",
      "         [3.0769e-01],\n",
      "         [9.8807e-01],\n",
      "         [1.0908e-01],\n",
      "         [3.3560e-01],\n",
      "         [4.1294e-01],\n",
      "         [5.5241e-01],\n",
      "         [1.0111e-01],\n",
      "         [2.2571e-01],\n",
      "         [2.7465e-01],\n",
      "         [1.1437e-01],\n",
      "         [8.0178e-01],\n",
      "         [3.8064e-01],\n",
      "         [1.9942e-01],\n",
      "         [8.9416e-01],\n",
      "         [9.7618e-03],\n",
      "         [3.0327e-01],\n",
      "         [5.3906e-01],\n",
      "         [9.1737e-01],\n",
      "         [7.0403e-01],\n",
      "         [6.5842e-01],\n",
      "         [7.0247e-01],\n",
      "         [7.9103e-01],\n",
      "         [7.5434e-01],\n",
      "         [5.1741e-01],\n",
      "         [1.6625e-01],\n",
      "         [2.7607e-01],\n",
      "         [5.5906e-01],\n",
      "         [4.8057e-01],\n",
      "         [9.9982e-01],\n",
      "         [4.0113e-01],\n",
      "         [3.2198e-01],\n",
      "         [7.4716e-01],\n",
      "         [8.9013e-01],\n",
      "         [8.4219e-01],\n",
      "         [5.5206e-01],\n",
      "         [5.4408e-01],\n",
      "         [4.8133e-01],\n",
      "         [6.7196e-01],\n",
      "         [4.9004e-01],\n",
      "         [2.5607e-01],\n",
      "         [4.1266e-01],\n",
      "         [3.2251e-01],\n",
      "         [5.1239e-02],\n",
      "         [2.5041e-01],\n",
      "         [6.5186e-02],\n",
      "         [6.5962e-02],\n",
      "         [8.3283e-02],\n",
      "         [2.1644e-01],\n",
      "         [6.1825e-01],\n",
      "         [8.0782e-01],\n",
      "         [3.2656e-01],\n",
      "         [9.1696e-01],\n",
      "         [9.5451e-01],\n",
      "         [5.1951e-01],\n",
      "         [1.9336e-01],\n",
      "         [9.1086e-01],\n",
      "         [9.1380e-01],\n",
      "         [8.0894e-01],\n",
      "         [8.4299e-02],\n",
      "         [6.6006e-01],\n",
      "         [5.5022e-01],\n",
      "         [3.3551e-01],\n",
      "         [4.4006e-01],\n",
      "         [9.3464e-02],\n",
      "         [4.8214e-03],\n",
      "         [3.0762e-01],\n",
      "         [3.0006e-01],\n",
      "         [7.2924e-01],\n",
      "         [3.0118e-02],\n",
      "         [6.5070e-01],\n",
      "         [9.6713e-01],\n",
      "         [6.2828e-02],\n",
      "         [7.4701e-04],\n",
      "         [9.4446e-01],\n",
      "         [8.3246e-01],\n",
      "         [4.1657e-01],\n",
      "         [4.8971e-01],\n",
      "         [7.1896e-01],\n",
      "         [3.8179e-02],\n",
      "         [9.8900e-01],\n",
      "         [7.6654e-01],\n",
      "         [1.9885e-02],\n",
      "         [5.6621e-01],\n",
      "         [1.6036e-01],\n",
      "         [7.4076e-01],\n",
      "         [8.1284e-01],\n",
      "         [7.1176e-01],\n",
      "         [8.9552e-01],\n",
      "         [1.8470e-01]]], device='cuda:0', dtype=torch.float64)\n",
      "================iter 5============\n",
      "['shape/ellipsoid/1/ellipsoid_512_128_64_64_0_2_1']\n",
      "tensor([[ True,  True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
      "          True,  True,  True,  True,  True,  True,  True,  True, False, False]],\n",
      "       device='cuda:0')\n",
      "@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@\n",
      "['shape/ellipsoid/1/ellipsoid_512_128_64_64_0_3_1']\n",
      "gt_trans_torch.Size([1, 20, 3])_tensor([[[ 2.3838e-02,  7.5595e-02,  9.8058e-02],\n",
      "         [ 2.4373e-02,  6.8680e-02,  8.2816e-02],\n",
      "         [-6.2725e-03, -1.8054e-02, -2.4586e-02],\n",
      "         [ 2.1477e-04, -3.6565e-02, -3.0683e-02],\n",
      "         [ 3.8635e-03, -4.4983e-02, -4.5013e-02],\n",
      "         [ 6.3452e-03, -5.7324e-02, -5.5780e-02],\n",
      "         [-2.6338e-03, -7.2098e-02, -6.2690e-02],\n",
      "         [-4.8486e-03, -7.9999e-02, -7.6208e-02],\n",
      "         [-3.4296e-03, -9.2076e-02, -8.7495e-02],\n",
      "         [-1.5717e-02, -9.9345e-02, -9.9641e-02],\n",
      "         [ 2.3979e-02,  5.2972e-02,  7.5389e-02],\n",
      "         [-6.1382e-03,  4.9452e-02,  6.3284e-02],\n",
      "         [ 2.9960e-02,  4.4129e-02,  4.0267e-02],\n",
      "         [ 1.1894e-02,  2.7022e-02,  3.7471e-02],\n",
      "         [ 6.6349e-03,  2.1834e-02,  2.2181e-02],\n",
      "         [ 8.5806e-03,  1.8585e-03,  1.8131e-02],\n",
      "         [-9.7700e-18,  7.1054e-18,  5.3291e-18],\n",
      "         [-3.1156e-03, -1.2603e-02, -9.2152e-03],\n",
      "         [ 0.0000e+00,  0.0000e+00,  0.0000e+00],\n",
      "         [ 0.0000e+00,  0.0000e+00,  0.0000e+00]]], device='cuda:0')\n",
      "gt_rots_torch.Size([1, 20, 4])_tensor([[[ 0.6524, -0.4730,  0.0271,  0.5915],\n",
      "         [ 0.9604,  0.1203,  0.2204, -0.1209],\n",
      "         [-0.6386,  0.2313,  0.7188, -0.1484],\n",
      "         [ 0.5473,  0.1195,  0.7085,  0.4292],\n",
      "         [ 0.5711, -0.3110,  0.7236, -0.2314],\n",
      "         [-0.4259,  0.1158,  0.3484,  0.8269],\n",
      "         [ 0.4681,  0.6438,  0.1527,  0.5858],\n",
      "         [ 0.0668,  0.5509,  0.6536, -0.5146],\n",
      "         [-0.0223,  0.4199,  0.0684,  0.9047],\n",
      "         [-0.1090,  0.8919, -0.4177, -0.1348],\n",
      "         [-0.5259, -0.1388,  0.7621,  0.3513],\n",
      "         [ 0.5039,  0.7422,  0.0815, -0.4342],\n",
      "         [ 0.0650, -0.5998,  0.1845,  0.7759],\n",
      "         [ 0.3966,  0.6720,  0.2402,  0.5774],\n",
      "         [ 0.9445, -0.1558, -0.2865,  0.0388],\n",
      "         [ 0.6775, -0.4828, -0.4057,  0.3784],\n",
      "         [ 0.8472, -0.1686, -0.2342,  0.4460],\n",
      "         [ 0.4625,  0.4113,  0.6189,  0.4836],\n",
      "         [ 0.0000,  0.0000,  0.0000,  0.0000],\n",
      "         [ 0.0000,  0.0000,  0.0000,  0.0000]]], device='cuda:0')\n",
      "noisy_trans_and_rots_torch.Size([1, 20, 7])_tensor([[[ 0.6703,  0.0000,  0.5084, -1.2632,  0.0000,  0.0000,  2.3976],\n",
      "         [-0.4578,  0.0000, -0.7779,  0.6698,  0.0000,  0.0000, -1.9401],\n",
      "         [-0.9104,  0.0000, -0.1272, -0.4210,  0.0000,  0.0000, -0.1214],\n",
      "         [ 1.2721,  0.0000,  1.2050, -0.4202,  0.0000,  0.0000,  0.9999],\n",
      "         [-0.6907,  0.0000,  1.3176,  0.6430,  0.0000,  0.0000, -0.3401],\n",
      "         [-2.0598,  0.0000, -0.0124,  0.9301,  0.0000,  0.0000,  0.2342],\n",
      "         [-0.4730,  0.0000,  0.9500,  0.3414,  0.0000,  0.0000,  0.0055],\n",
      "         [ 0.3833,  0.0000, -1.3026,  1.3615,  0.0000,  0.0000, -1.7929],\n",
      "         [-1.0737,  0.0000, -1.0661, -0.7117,  0.0000,  0.0000, -0.3399],\n",
      "         [-1.1588,  0.0000, -1.9022, -1.3755,  0.0000,  0.0000,  1.1775],\n",
      "         [-0.2789,  0.0000,  0.7420,  0.6360,  0.0000,  0.0000,  0.7642],\n",
      "         [-0.8168,  0.0000, -1.1174, -0.1396,  0.0000,  0.0000,  1.4879],\n",
      "         [ 0.0186,  0.0000,  0.4048,  0.0682,  0.0000,  0.0000, -1.7862],\n",
      "         [-1.4638,  0.0000, -0.4840, -1.0405,  0.0000,  0.0000,  1.9213],\n",
      "         [ 0.4041,  0.0000, -0.1975, -0.5943,  0.0000,  0.0000, -0.0567],\n",
      "         [-1.6597,  0.0000, -0.9194,  0.2848,  0.0000,  0.0000, -0.6340],\n",
      "         [ 0.1091,  0.0000,  0.5607,  1.2964,  0.0000,  0.0000, -0.9238],\n",
      "         [-0.0725,  0.0000,  0.7127, -0.5402,  0.0000,  0.0000,  0.2131],\n",
      "         [-0.7918,  0.0000,  0.9112, -1.0311,  0.0000,  0.0000,  0.6568],\n",
      "         [-0.0223,  0.0000,  0.4192, -1.1305,  0.0000,  0.0000, -1.1883]]],\n",
      "       device='cuda:0')\n",
      "================iter 0============\n",
      "['shape/ellipsoid/1/ellipsoid_512_128_64_64_0_3_1']\n",
      "tensor([[False, False, False, False, False, False, False, False, False, False,\n",
      "         False, False, False, False, False, False,  True, False, False, False]],\n",
      "       device='cuda:0')\n",
      "acc torch.Size([1]) tensor([0.0556], device='cuda:0')\n",
      "acc_per_part torch.Size([1, 20]) tensor([[False, False, False, False, False, False, False, False, False, False,\n",
      "         False, False, False, False, False, False,  True, False, False, False]],\n",
      "       device='cuda:0')\n",
      "loss_per_data torch.Size([1, 20]) tensor([[ 1.4473,  0.9444,  0.9895,  1.2568,  2.0573,  5.5456,  7.0087,  0.5422,\n",
      "          3.2056,  9.9450,  1.4094,  0.4550,  0.2933,  0.3107,  0.4288, 10.1044,\n",
      "          0.0000,  2.9065,  0.7076,  3.9750]], device='cuda:0')\n",
      "scores torch.Size([1, 190, 1]) tensor([[[0.8298],\n",
      "         [0.4245],\n",
      "         [0.5173],\n",
      "         [0.3183],\n",
      "         [0.5281],\n",
      "         [0.5146],\n",
      "         [0.8583],\n",
      "         [0.6392],\n",
      "         [0.3460],\n",
      "         [0.9005],\n",
      "         [0.6340],\n",
      "         [0.5747],\n",
      "         [0.1321],\n",
      "         [0.0229],\n",
      "         [0.8372],\n",
      "         [0.0014],\n",
      "         [0.4255],\n",
      "         [0.6468],\n",
      "         [0.6141],\n",
      "         [0.0465],\n",
      "         [0.3894],\n",
      "         [0.0882],\n",
      "         [0.4708],\n",
      "         [0.0915],\n",
      "         [0.0966],\n",
      "         [0.7139],\n",
      "         [0.2453],\n",
      "         [0.9392],\n",
      "         [0.7428],\n",
      "         [0.6225],\n",
      "         [0.4506],\n",
      "         [0.1617],\n",
      "         [0.3400],\n",
      "         [0.8321],\n",
      "         [0.3191],\n",
      "         [0.3822],\n",
      "         [0.6718],\n",
      "         [0.0056],\n",
      "         [0.3594],\n",
      "         [0.7457],\n",
      "         [0.9043],\n",
      "         [0.6477],\n",
      "         [0.1524],\n",
      "         [0.9924],\n",
      "         [0.2466],\n",
      "         [0.3573],\n",
      "         [0.0114],\n",
      "         [0.9592],\n",
      "         [0.9460],\n",
      "         [0.6762],\n",
      "         [0.4495],\n",
      "         [0.2053],\n",
      "         [0.3234],\n",
      "         [0.9683],\n",
      "         [0.0187],\n",
      "         [0.7022],\n",
      "         [0.8526],\n",
      "         [0.0744],\n",
      "         [0.3306],\n",
      "         [0.7825],\n",
      "         [0.9150],\n",
      "         [0.4618],\n",
      "         [0.3257],\n",
      "         [0.3025],\n",
      "         [0.2745],\n",
      "         [0.1202],\n",
      "         [0.6009],\n",
      "         [0.3273],\n",
      "         [0.7460],\n",
      "         [0.7068],\n",
      "         [0.0659],\n",
      "         [0.4891],\n",
      "         [0.5525],\n",
      "         [0.4639],\n",
      "         [0.4995],\n",
      "         [0.7459],\n",
      "         [0.6369],\n",
      "         [0.1365],\n",
      "         [0.8450],\n",
      "         [0.0585],\n",
      "         [0.2985],\n",
      "         [0.5920],\n",
      "         [0.1437],\n",
      "         [0.6937],\n",
      "         [0.2783],\n",
      "         [0.7087],\n",
      "         [0.6413],\n",
      "         [0.9947],\n",
      "         [0.4652],\n",
      "         [0.8396],\n",
      "         [0.5223],\n",
      "         [0.3985],\n",
      "         [0.7138],\n",
      "         [0.7863],\n",
      "         [0.6082],\n",
      "         [0.7812],\n",
      "         [0.8776],\n",
      "         [0.5869],\n",
      "         [0.2595],\n",
      "         [0.2896],\n",
      "         [0.3130],\n",
      "         [0.0782],\n",
      "         [0.0412],\n",
      "         [0.9594],\n",
      "         [0.7532],\n",
      "         [0.3275],\n",
      "         [0.3310],\n",
      "         [0.1931],\n",
      "         [0.6153],\n",
      "         [0.8385],\n",
      "         [0.6174],\n",
      "         [0.2407],\n",
      "         [0.4542],\n",
      "         [0.9097],\n",
      "         [0.7842],\n",
      "         [0.9893],\n",
      "         [0.1914],\n",
      "         [0.6245],\n",
      "         [0.8723],\n",
      "         [0.2741],\n",
      "         [0.0240],\n",
      "         [0.9789],\n",
      "         [0.0571],\n",
      "         [0.8266],\n",
      "         [0.4685],\n",
      "         [0.2428],\n",
      "         [0.6140],\n",
      "         [0.4944],\n",
      "         [0.3206],\n",
      "         [0.1779],\n",
      "         [0.5849],\n",
      "         [0.0642],\n",
      "         [0.6409],\n",
      "         [0.9911],\n",
      "         [0.1969],\n",
      "         [0.4338],\n",
      "         [0.6278],\n",
      "         [0.6062],\n",
      "         [0.8564],\n",
      "         [0.8248],\n",
      "         [0.4413],\n",
      "         [0.3033],\n",
      "         [0.8735],\n",
      "         [0.9232],\n",
      "         [0.7165],\n",
      "         [0.8563],\n",
      "         [0.9658],\n",
      "         [0.9701],\n",
      "         [0.9832],\n",
      "         [0.1269],\n",
      "         [0.7191],\n",
      "         [0.9684],\n",
      "         [0.0715],\n",
      "         [0.0875],\n",
      "         [0.1867],\n",
      "         [0.7375],\n",
      "         [0.6810],\n",
      "         [0.8415],\n",
      "         [0.2805],\n",
      "         [0.0478],\n",
      "         [0.4091],\n",
      "         [0.3038],\n",
      "         [0.6926],\n",
      "         [0.6589],\n",
      "         [0.2458],\n",
      "         [0.2255],\n",
      "         [0.1433],\n",
      "         [0.3998],\n",
      "         [0.0326],\n",
      "         [0.3176],\n",
      "         [0.5298],\n",
      "         [0.4491],\n",
      "         [0.2399],\n",
      "         [0.5926],\n",
      "         [0.4754],\n",
      "         [0.2976],\n",
      "         [0.7970],\n",
      "         [0.0343],\n",
      "         [0.0110],\n",
      "         [0.0566],\n",
      "         [0.1513],\n",
      "         [0.8720],\n",
      "         [0.5405],\n",
      "         [0.6540],\n",
      "         [0.9752],\n",
      "         [0.5965],\n",
      "         [0.9118],\n",
      "         [0.2238],\n",
      "         [0.0215],\n",
      "         [0.4798]]], device='cuda:0', dtype=torch.float64)\n",
      "================iter 1============\n",
      "['shape/ellipsoid/1/ellipsoid_512_128_64_64_0_3_1']\n",
      "tensor([[False, False, False, False, False, False, False, False, False, False,\n",
      "         False, False, False, False, False, False,  True,  True, False, False]],\n",
      "       device='cuda:0')\n",
      "acc torch.Size([1]) tensor([0.0556], device='cuda:0')\n",
      "acc_per_part torch.Size([1, 20]) tensor([[False, False, False, False, False, False, False, False, False, False,\n",
      "         False, False, False, False, False, False,  True, False, False, False]],\n",
      "       device='cuda:0')\n",
      "loss_per_data torch.Size([1, 20]) tensor([[1.2360e+00, 8.0361e+00, 3.5228e+01, 2.1721e+01, 1.0382e+01, 7.2261e+02,\n",
      "         3.7745e+00, 6.1155e-01, 7.2301e+00, 2.3189e+01, 3.9781e+00, 7.2324e+00,\n",
      "         1.6985e+00, 1.2373e+01, 5.7789e+00, 4.8618e+01, 0.0000e+00, 2.9065e+00,\n",
      "         4.9988e+00, 3.2564e+00]], device='cuda:0')\n",
      "scores torch.Size([1, 190, 1]) tensor([[[9.5452e-01],\n",
      "         [1.0402e-01],\n",
      "         [9.1476e-01],\n",
      "         [1.8187e-01],\n",
      "         [3.8043e-04],\n",
      "         [4.9166e-01],\n",
      "         [2.2781e-01],\n",
      "         [9.3343e-01],\n",
      "         [8.3084e-01],\n",
      "         [5.2553e-01],\n",
      "         [8.1611e-01],\n",
      "         [4.0021e-01],\n",
      "         [7.3060e-01],\n",
      "         [5.6189e-01],\n",
      "         [3.5569e-01],\n",
      "         [1.7548e-01],\n",
      "         [2.4871e-01],\n",
      "         [6.4551e-01],\n",
      "         [2.5884e-01],\n",
      "         [2.2126e-01],\n",
      "         [2.4636e-01],\n",
      "         [6.6449e-01],\n",
      "         [4.7180e-01],\n",
      "         [4.8124e-01],\n",
      "         [9.4595e-01],\n",
      "         [3.6572e-01],\n",
      "         [7.2799e-02],\n",
      "         [4.5700e-02],\n",
      "         [6.7710e-01],\n",
      "         [2.1122e-01],\n",
      "         [2.6861e-01],\n",
      "         [2.4438e-01],\n",
      "         [3.5638e-01],\n",
      "         [3.2604e-01],\n",
      "         [5.3757e-01],\n",
      "         [8.9582e-01],\n",
      "         [6.4844e-01],\n",
      "         [3.2725e-01],\n",
      "         [4.2249e-01],\n",
      "         [6.5595e-01],\n",
      "         [2.9926e-01],\n",
      "         [2.7886e-01],\n",
      "         [4.3276e-02],\n",
      "         [2.3368e-01],\n",
      "         [9.9521e-01],\n",
      "         [3.6532e-01],\n",
      "         [7.4258e-01],\n",
      "         [6.0274e-01],\n",
      "         [3.9725e-01],\n",
      "         [1.7018e-01],\n",
      "         [7.2356e-01],\n",
      "         [7.3114e-01],\n",
      "         [4.3951e-01],\n",
      "         [8.5119e-01],\n",
      "         [4.9257e-01],\n",
      "         [1.1128e-01],\n",
      "         [1.4032e-01],\n",
      "         [4.5000e-01],\n",
      "         [5.9302e-01],\n",
      "         [7.5443e-01],\n",
      "         [2.9927e-01],\n",
      "         [5.8530e-01],\n",
      "         [7.5961e-01],\n",
      "         [8.1083e-01],\n",
      "         [4.5802e-01],\n",
      "         [4.9242e-01],\n",
      "         [5.5736e-01],\n",
      "         [1.7823e-01],\n",
      "         [4.1970e-01],\n",
      "         [1.2323e-01],\n",
      "         [1.5310e-01],\n",
      "         [4.2092e-01],\n",
      "         [9.6048e-02],\n",
      "         [6.3705e-01],\n",
      "         [1.1327e-01],\n",
      "         [7.1613e-01],\n",
      "         [9.9072e-01],\n",
      "         [9.8832e-01],\n",
      "         [9.6760e-01],\n",
      "         [4.4575e-01],\n",
      "         [8.7886e-01],\n",
      "         [2.3964e-01],\n",
      "         [3.0658e-01],\n",
      "         [1.0092e-01],\n",
      "         [7.3135e-01],\n",
      "         [7.1724e-01],\n",
      "         [9.3853e-01],\n",
      "         [7.1375e-01],\n",
      "         [8.5757e-01],\n",
      "         [8.8310e-03],\n",
      "         [2.8114e-01],\n",
      "         [3.4756e-01],\n",
      "         [8.3341e-01],\n",
      "         [8.2755e-01],\n",
      "         [9.2743e-01],\n",
      "         [5.0769e-01],\n",
      "         [1.6398e-01],\n",
      "         [5.4227e-01],\n",
      "         [7.2789e-01],\n",
      "         [9.5488e-01],\n",
      "         [1.0421e-01],\n",
      "         [1.3250e-01],\n",
      "         [9.9575e-02],\n",
      "         [9.0836e-01],\n",
      "         [8.4021e-01],\n",
      "         [1.8153e-01],\n",
      "         [1.1620e-01],\n",
      "         [4.7130e-01],\n",
      "         [7.3464e-01],\n",
      "         [1.5692e-02],\n",
      "         [5.7749e-02],\n",
      "         [9.7885e-01],\n",
      "         [1.4359e-01],\n",
      "         [9.7769e-01],\n",
      "         [4.8845e-01],\n",
      "         [6.0984e-01],\n",
      "         [7.1281e-01],\n",
      "         [4.8318e-01],\n",
      "         [5.5074e-01],\n",
      "         [2.8243e-01],\n",
      "         [9.5997e-01],\n",
      "         [7.8784e-01],\n",
      "         [5.6279e-01],\n",
      "         [4.2009e-01],\n",
      "         [8.1658e-01],\n",
      "         [3.2335e-01],\n",
      "         [2.4734e-01],\n",
      "         [2.3863e-01],\n",
      "         [3.4893e-01],\n",
      "         [1.5378e-01],\n",
      "         [2.9323e-01],\n",
      "         [4.5107e-01],\n",
      "         [9.8616e-02],\n",
      "         [3.6418e-01],\n",
      "         [8.4626e-01],\n",
      "         [3.6240e-01],\n",
      "         [3.4648e-01],\n",
      "         [6.2469e-01],\n",
      "         [3.0392e-01],\n",
      "         [9.6850e-01],\n",
      "         [3.3727e-01],\n",
      "         [6.6769e-01],\n",
      "         [4.1641e-01],\n",
      "         [6.5842e-01],\n",
      "         [9.8020e-01],\n",
      "         [8.2518e-02],\n",
      "         [9.6995e-01],\n",
      "         [5.5792e-02],\n",
      "         [9.1282e-01],\n",
      "         [3.6787e-01],\n",
      "         [2.0721e-02],\n",
      "         [5.2058e-01],\n",
      "         [6.7086e-01],\n",
      "         [7.8148e-01],\n",
      "         [3.0698e-01],\n",
      "         [2.5585e-01],\n",
      "         [6.6363e-01],\n",
      "         [3.3110e-01],\n",
      "         [9.5548e-01],\n",
      "         [7.6657e-01],\n",
      "         [6.3237e-01],\n",
      "         [3.8149e-01],\n",
      "         [5.2993e-01],\n",
      "         [6.4050e-01],\n",
      "         [7.3474e-02],\n",
      "         [7.0617e-01],\n",
      "         [8.0269e-01],\n",
      "         [3.9596e-01],\n",
      "         [5.3768e-02],\n",
      "         [1.7092e-01],\n",
      "         [6.9469e-01],\n",
      "         [4.2492e-01],\n",
      "         [1.3150e-03],\n",
      "         [6.7229e-02],\n",
      "         [1.8164e-01],\n",
      "         [8.3797e-01],\n",
      "         [3.4741e-01],\n",
      "         [9.9930e-01],\n",
      "         [2.4939e-01],\n",
      "         [4.0777e-01],\n",
      "         [2.1503e-01],\n",
      "         [3.8671e-01],\n",
      "         [6.0488e-01],\n",
      "         [3.8064e-01],\n",
      "         [7.5830e-01],\n",
      "         [5.5329e-01],\n",
      "         [9.0644e-01],\n",
      "         [3.0442e-01],\n",
      "         [8.3623e-01],\n",
      "         [1.0609e-01]]], device='cuda:0', dtype=torch.float64)\n",
      "================iter 2============\n",
      "['shape/ellipsoid/1/ellipsoid_512_128_64_64_0_3_1']\n",
      "tensor([[False, False, False, False, False, False, False,  True, False, False,\n",
      "         False,  True, False, False,  True, False,  True,  True, False, False]],\n",
      "       device='cuda:0')\n",
      "acc torch.Size([1]) tensor([0.0556], device='cuda:0')\n",
      "acc_per_part torch.Size([1, 20]) tensor([[False, False, False, False, False, False, False, False, False, False,\n",
      "         False, False, False, False, False, False,  True, False, False, False]],\n",
      "       device='cuda:0')\n",
      "loss_per_data torch.Size([1, 20]) tensor([[1.1658e+01, 2.7095e+01, 4.8621e+02, 1.6263e+02, 5.3182e+01, 1.5936e+03,\n",
      "         2.1514e+01, 6.1155e-01, 2.3274e+01, 5.3956e+01, 9.9705e+00, 7.2324e+00,\n",
      "         2.8619e+00, 2.8727e+01, 5.7789e+00, 1.2651e+02, 0.0000e+00, 2.9065e+00,\n",
      "         1.8882e+01, 1.0168e+00]], device='cuda:0')\n",
      "scores torch.Size([1, 190, 1]) tensor([[[0.2528],\n",
      "         [0.9343],\n",
      "         [0.2480],\n",
      "         [0.9500],\n",
      "         [0.2776],\n",
      "         [0.4309],\n",
      "         [0.5735],\n",
      "         [0.1968],\n",
      "         [0.3037],\n",
      "         [0.4036],\n",
      "         [0.5341],\n",
      "         [0.5602],\n",
      "         [0.4656],\n",
      "         [0.0462],\n",
      "         [0.0275],\n",
      "         [0.9711],\n",
      "         [0.8156],\n",
      "         [0.6592],\n",
      "         [0.4020],\n",
      "         [0.4419],\n",
      "         [0.1748],\n",
      "         [0.9984],\n",
      "         [0.3910],\n",
      "         [0.4992],\n",
      "         [0.2618],\n",
      "         [0.1544],\n",
      "         [0.6025],\n",
      "         [0.0270],\n",
      "         [0.3884],\n",
      "         [0.9751],\n",
      "         [0.5660],\n",
      "         [0.2679],\n",
      "         [0.0473],\n",
      "         [0.4728],\n",
      "         [0.8088],\n",
      "         [0.6196],\n",
      "         [0.7550],\n",
      "         [0.6459],\n",
      "         [0.0145],\n",
      "         [0.3111],\n",
      "         [0.9792],\n",
      "         [0.3423],\n",
      "         [0.9413],\n",
      "         [0.1408],\n",
      "         [0.2171],\n",
      "         [0.2900],\n",
      "         [0.0774],\n",
      "         [0.1618],\n",
      "         [0.6698],\n",
      "         [0.3103],\n",
      "         [0.0403],\n",
      "         [0.8719],\n",
      "         [0.4406],\n",
      "         [0.2178],\n",
      "         [0.7189],\n",
      "         [0.4666],\n",
      "         [0.9780],\n",
      "         [0.4561],\n",
      "         [0.1737],\n",
      "         [0.7530],\n",
      "         [0.3910],\n",
      "         [0.6592],\n",
      "         [0.5336],\n",
      "         [0.8549],\n",
      "         [0.5394],\n",
      "         [0.7333],\n",
      "         [0.3828],\n",
      "         [0.2894],\n",
      "         [0.5520],\n",
      "         [0.3266],\n",
      "         [0.4232],\n",
      "         [0.9382],\n",
      "         [0.5985],\n",
      "         [0.1516],\n",
      "         [0.6231],\n",
      "         [0.5683],\n",
      "         [0.6276],\n",
      "         [0.7784],\n",
      "         [0.0078],\n",
      "         [0.4563],\n",
      "         [0.8356],\n",
      "         [0.9389],\n",
      "         [0.3281],\n",
      "         [0.1053],\n",
      "         [0.2775],\n",
      "         [0.2304],\n",
      "         [0.0439],\n",
      "         [0.8549],\n",
      "         [0.0625],\n",
      "         [0.8078],\n",
      "         [0.0217],\n",
      "         [0.0362],\n",
      "         [0.3697],\n",
      "         [0.7863],\n",
      "         [0.2172],\n",
      "         [0.4810],\n",
      "         [0.2591],\n",
      "         [0.8772],\n",
      "         [0.9360],\n",
      "         [0.0396],\n",
      "         [0.4926],\n",
      "         [0.4696],\n",
      "         [0.1115],\n",
      "         [0.6078],\n",
      "         [0.3033],\n",
      "         [0.3584],\n",
      "         [0.4903],\n",
      "         [0.6457],\n",
      "         [0.3288],\n",
      "         [0.4147],\n",
      "         [0.2548],\n",
      "         [0.5069],\n",
      "         [0.1106],\n",
      "         [0.0110],\n",
      "         [0.4180],\n",
      "         [0.1329],\n",
      "         [0.8854],\n",
      "         [0.9420],\n",
      "         [0.8495],\n",
      "         [0.1891],\n",
      "         [0.9113],\n",
      "         [0.3272],\n",
      "         [0.8546],\n",
      "         [0.4617],\n",
      "         [0.4297],\n",
      "         [0.6665],\n",
      "         [0.6307],\n",
      "         [0.1622],\n",
      "         [0.6568],\n",
      "         [0.1982],\n",
      "         [0.5627],\n",
      "         [0.4542],\n",
      "         [0.6555],\n",
      "         [0.7312],\n",
      "         [0.4462],\n",
      "         [0.7669],\n",
      "         [0.1773],\n",
      "         [0.9644],\n",
      "         [0.9525],\n",
      "         [0.8739],\n",
      "         [0.0103],\n",
      "         [0.7483],\n",
      "         [0.0594],\n",
      "         [0.4930],\n",
      "         [0.0048],\n",
      "         [0.9640],\n",
      "         [0.5228],\n",
      "         [0.5451],\n",
      "         [0.6062],\n",
      "         [0.1854],\n",
      "         [0.9802],\n",
      "         [0.7414],\n",
      "         [0.6537],\n",
      "         [0.4432],\n",
      "         [0.0259],\n",
      "         [0.4688],\n",
      "         [0.3648],\n",
      "         [0.2303],\n",
      "         [0.7076],\n",
      "         [0.9787],\n",
      "         [0.0927],\n",
      "         [0.9612],\n",
      "         [0.7483],\n",
      "         [0.9509],\n",
      "         [0.3012],\n",
      "         [0.5466],\n",
      "         [0.8554],\n",
      "         [0.8707],\n",
      "         [0.9918],\n",
      "         [0.6697],\n",
      "         [0.9149],\n",
      "         [0.1054],\n",
      "         [0.0502],\n",
      "         [0.9563],\n",
      "         [0.1998],\n",
      "         [0.3487],\n",
      "         [0.9581],\n",
      "         [0.1578],\n",
      "         [0.0207],\n",
      "         [0.4350],\n",
      "         [0.6642],\n",
      "         [0.0821],\n",
      "         [0.2353],\n",
      "         [0.5875],\n",
      "         [0.3668],\n",
      "         [0.5207],\n",
      "         [0.3965],\n",
      "         [0.7837],\n",
      "         [0.4267],\n",
      "         [0.4320]]], device='cuda:0', dtype=torch.float64)\n",
      "================iter 3============\n",
      "['shape/ellipsoid/1/ellipsoid_512_128_64_64_0_3_1']\n",
      "tensor([[ True, False, False, False,  True, False, False,  True, False, False,\n",
      "          True,  True,  True,  True,  True, False,  True,  True, False, False]],\n",
      "       device='cuda:0')\n",
      "acc torch.Size([1]) tensor([0.0556], device='cuda:0')\n",
      "acc_per_part torch.Size([1, 20]) tensor([[False, False, False, False, False, False, False, False, False, False,\n",
      "         False, False, False, False, False, False,  True, False, False, False]],\n",
      "       device='cuda:0')\n",
      "loss_per_data torch.Size([1, 20]) tensor([[1.1658e+01, 8.1613e+01, 1.7239e+03, 5.2795e+02, 5.3182e+01, 5.0270e+03,\n",
      "         1.2096e+02, 6.1155e-01, 9.6959e+01, 1.1236e+02, 9.9705e+00, 7.2324e+00,\n",
      "         2.8619e+00, 2.8727e+01, 5.7789e+00, 6.8613e+02, 0.0000e+00, 2.9065e+00,\n",
      "         4.8832e+01, 5.3837e+00]], device='cuda:0')\n",
      "scores torch.Size([1, 190, 1]) tensor([[[0.6271],\n",
      "         [0.4332],\n",
      "         [0.0631],\n",
      "         [0.3467],\n",
      "         [0.1613],\n",
      "         [0.9787],\n",
      "         [0.4187],\n",
      "         [0.0503],\n",
      "         [0.8800],\n",
      "         [0.8829],\n",
      "         [0.5203],\n",
      "         [0.6641],\n",
      "         [0.2774],\n",
      "         [0.0675],\n",
      "         [0.0745],\n",
      "         [0.2076],\n",
      "         [0.3790],\n",
      "         [0.5155],\n",
      "         [0.1285],\n",
      "         [0.5497],\n",
      "         [0.1877],\n",
      "         [0.1563],\n",
      "         [0.5826],\n",
      "         [0.8031],\n",
      "         [0.5501],\n",
      "         [0.6634],\n",
      "         [0.8326],\n",
      "         [0.3899],\n",
      "         [0.7329],\n",
      "         [0.1609],\n",
      "         [0.7268],\n",
      "         [0.8539],\n",
      "         [0.1879],\n",
      "         [0.1324],\n",
      "         [0.5414],\n",
      "         [0.3004],\n",
      "         [0.8982],\n",
      "         [0.0768],\n",
      "         [0.6201],\n",
      "         [0.0125],\n",
      "         [0.4547],\n",
      "         [0.9906],\n",
      "         [0.6210],\n",
      "         [0.6638],\n",
      "         [0.6865],\n",
      "         [0.5789],\n",
      "         [0.5404],\n",
      "         [0.2413],\n",
      "         [0.8549],\n",
      "         [0.0649],\n",
      "         [0.5401],\n",
      "         [0.9516],\n",
      "         [0.4027],\n",
      "         [0.8430],\n",
      "         [0.1239],\n",
      "         [0.1877],\n",
      "         [0.4990],\n",
      "         [0.8220],\n",
      "         [0.6514],\n",
      "         [0.7371],\n",
      "         [0.3819],\n",
      "         [0.0295],\n",
      "         [0.8323],\n",
      "         [0.0829],\n",
      "         [0.8022],\n",
      "         [0.9118],\n",
      "         [0.3524],\n",
      "         [0.4305],\n",
      "         [0.2896],\n",
      "         [0.7481],\n",
      "         [0.4755],\n",
      "         [0.9923],\n",
      "         [0.3429],\n",
      "         [0.1879],\n",
      "         [0.1512],\n",
      "         [0.4788],\n",
      "         [0.2288],\n",
      "         [0.4424],\n",
      "         [0.5816],\n",
      "         [0.2196],\n",
      "         [0.0573],\n",
      "         [0.8075],\n",
      "         [0.2841],\n",
      "         [0.3828],\n",
      "         [0.4979],\n",
      "         [0.6553],\n",
      "         [0.7282],\n",
      "         [0.5154],\n",
      "         [0.6656],\n",
      "         [0.1477],\n",
      "         [0.5258],\n",
      "         [0.1382],\n",
      "         [0.0298],\n",
      "         [0.2148],\n",
      "         [0.5504],\n",
      "         [0.0376],\n",
      "         [0.4491],\n",
      "         [0.5181],\n",
      "         [0.7928],\n",
      "         [0.3734],\n",
      "         [0.5617],\n",
      "         [0.2258],\n",
      "         [0.1045],\n",
      "         [0.8310],\n",
      "         [0.6153],\n",
      "         [0.7186],\n",
      "         [0.1929],\n",
      "         [0.0443],\n",
      "         [0.9323],\n",
      "         [0.1955],\n",
      "         [0.2981],\n",
      "         [0.4427],\n",
      "         [0.2408],\n",
      "         [0.1233],\n",
      "         [0.3192],\n",
      "         [0.8809],\n",
      "         [0.0170],\n",
      "         [0.3234],\n",
      "         [0.9309],\n",
      "         [0.7257],\n",
      "         [0.1997],\n",
      "         [0.2935],\n",
      "         [0.6768],\n",
      "         [0.0686],\n",
      "         [0.0771],\n",
      "         [0.3199],\n",
      "         [0.7831],\n",
      "         [0.6882],\n",
      "         [0.2909],\n",
      "         [0.9754],\n",
      "         [0.5322],\n",
      "         [0.8836],\n",
      "         [0.6287],\n",
      "         [0.6542],\n",
      "         [0.3294],\n",
      "         [0.1192],\n",
      "         [0.3087],\n",
      "         [0.4529],\n",
      "         [0.2368],\n",
      "         [0.1215],\n",
      "         [0.1813],\n",
      "         [0.7197],\n",
      "         [0.5045],\n",
      "         [0.9927],\n",
      "         [0.6832],\n",
      "         [0.3393],\n",
      "         [0.4613],\n",
      "         [0.8329],\n",
      "         [0.4213],\n",
      "         [0.3472],\n",
      "         [0.4109],\n",
      "         [0.5438],\n",
      "         [0.7338],\n",
      "         [0.0075],\n",
      "         [0.7871],\n",
      "         [0.7435],\n",
      "         [0.3122],\n",
      "         [0.1167],\n",
      "         [0.2332],\n",
      "         [0.7422],\n",
      "         [0.9538],\n",
      "         [0.0597],\n",
      "         [0.5934],\n",
      "         [0.8506],\n",
      "         [0.0842],\n",
      "         [0.1670],\n",
      "         [0.2158],\n",
      "         [0.4832],\n",
      "         [0.3426],\n",
      "         [0.9962],\n",
      "         [0.2055],\n",
      "         [0.4797],\n",
      "         [0.3630],\n",
      "         [0.8373],\n",
      "         [0.2473],\n",
      "         [0.9383],\n",
      "         [0.3069],\n",
      "         [0.0926],\n",
      "         [0.1671],\n",
      "         [0.7195],\n",
      "         [0.7878],\n",
      "         [0.0602],\n",
      "         [0.0649],\n",
      "         [0.4191],\n",
      "         [0.0737],\n",
      "         [0.5030],\n",
      "         [0.7980],\n",
      "         [0.1210],\n",
      "         [0.7210],\n",
      "         [0.5586]]], device='cuda:0', dtype=torch.float64)\n",
      "================iter 4============\n",
      "['shape/ellipsoid/1/ellipsoid_512_128_64_64_0_3_1']\n",
      "tensor([[ True, False,  True, False,  True, False,  True,  True,  True, False,\n",
      "          True,  True,  True,  True,  True,  True,  True,  True, False, False]],\n",
      "       device='cuda:0')\n",
      "acc torch.Size([1]) tensor([0.0556], device='cuda:0')\n",
      "acc_per_part torch.Size([1, 20]) tensor([[False, False, False, False, False, False, False, False, False, False,\n",
      "         False, False, False, False, False, False,  True, False, False, False]],\n",
      "       device='cuda:0')\n",
      "loss_per_data torch.Size([1, 20]) tensor([[1.1658e+01, 1.4716e+02, 1.7239e+03, 9.5278e+02, 5.3182e+01, 1.0830e+04,\n",
      "         1.2096e+02, 6.1155e-01, 9.6959e+01, 3.6312e+02, 9.9705e+00, 7.2324e+00,\n",
      "         2.8619e+00, 2.8727e+01, 5.7789e+00, 6.8613e+02, 0.0000e+00, 2.9065e+00,\n",
      "         7.2496e+01, 2.6770e+01]], device='cuda:0')\n",
      "scores torch.Size([1, 190, 1]) tensor([[[1.4346e-01],\n",
      "         [9.6396e-01],\n",
      "         [9.6415e-01],\n",
      "         [1.9791e-01],\n",
      "         [4.9161e-01],\n",
      "         [4.6501e-01],\n",
      "         [1.2843e-01],\n",
      "         [3.4234e-01],\n",
      "         [3.1966e-01],\n",
      "         [6.6404e-02],\n",
      "         [6.6955e-01],\n",
      "         [9.0509e-01],\n",
      "         [3.4569e-01],\n",
      "         [1.4535e-01],\n",
      "         [7.5551e-01],\n",
      "         [4.4564e-01],\n",
      "         [7.1457e-01],\n",
      "         [3.2218e-01],\n",
      "         [5.9545e-01],\n",
      "         [2.5228e-02],\n",
      "         [4.7821e-01],\n",
      "         [3.2036e-01],\n",
      "         [7.6893e-01],\n",
      "         [7.9260e-01],\n",
      "         [2.2768e-01],\n",
      "         [2.6748e-01],\n",
      "         [4.1319e-01],\n",
      "         [4.9834e-01],\n",
      "         [7.3945e-01],\n",
      "         [8.3290e-01],\n",
      "         [8.8218e-01],\n",
      "         [8.0341e-01],\n",
      "         [2.9730e-03],\n",
      "         [4.8963e-01],\n",
      "         [5.4553e-01],\n",
      "         [8.3044e-01],\n",
      "         [9.1403e-01],\n",
      "         [6.5630e-01],\n",
      "         [6.7108e-01],\n",
      "         [1.6773e-01],\n",
      "         [3.0754e-02],\n",
      "         [3.1719e-01],\n",
      "         [6.9472e-01],\n",
      "         [8.9810e-01],\n",
      "         [4.9943e-01],\n",
      "         [8.3762e-01],\n",
      "         [9.6524e-01],\n",
      "         [4.0814e-01],\n",
      "         [8.2756e-01],\n",
      "         [1.8860e-02],\n",
      "         [5.4693e-01],\n",
      "         [7.6689e-01],\n",
      "         [5.0957e-01],\n",
      "         [8.2788e-02],\n",
      "         [1.5778e-01],\n",
      "         [7.1129e-01],\n",
      "         [9.3273e-01],\n",
      "         [6.6924e-01],\n",
      "         [3.4404e-01],\n",
      "         [6.1335e-01],\n",
      "         [2.1757e-01],\n",
      "         [9.9399e-01],\n",
      "         [3.0904e-01],\n",
      "         [3.8639e-01],\n",
      "         [7.7926e-01],\n",
      "         [4.8668e-02],\n",
      "         [1.2138e-01],\n",
      "         [4.2874e-01],\n",
      "         [4.0365e-01],\n",
      "         [3.8921e-01],\n",
      "         [7.9267e-01],\n",
      "         [1.8859e-01],\n",
      "         [8.0650e-01],\n",
      "         [1.0492e-01],\n",
      "         [2.9951e-01],\n",
      "         [9.6617e-01],\n",
      "         [8.2578e-01],\n",
      "         [3.4585e-01],\n",
      "         [8.4697e-01],\n",
      "         [5.6226e-01],\n",
      "         [4.4034e-01],\n",
      "         [8.7925e-01],\n",
      "         [6.0538e-01],\n",
      "         [2.9239e-01],\n",
      "         [7.2457e-01],\n",
      "         [4.2954e-01],\n",
      "         [4.7485e-01],\n",
      "         [8.0621e-01],\n",
      "         [9.0443e-01],\n",
      "         [8.4659e-01],\n",
      "         [9.1481e-02],\n",
      "         [5.4352e-01],\n",
      "         [6.4696e-01],\n",
      "         [4.6658e-01],\n",
      "         [9.3243e-01],\n",
      "         [9.2914e-02],\n",
      "         [9.2369e-01],\n",
      "         [8.4730e-01],\n",
      "         [9.8185e-01],\n",
      "         [8.1301e-01],\n",
      "         [1.9759e-01],\n",
      "         [1.5633e-01],\n",
      "         [9.6913e-01],\n",
      "         [9.5446e-01],\n",
      "         [9.4134e-01],\n",
      "         [4.4296e-01],\n",
      "         [7.6395e-01],\n",
      "         [9.1564e-02],\n",
      "         [9.1033e-01],\n",
      "         [6.3902e-01],\n",
      "         [9.1440e-01],\n",
      "         [1.8312e-01],\n",
      "         [6.4173e-01],\n",
      "         [6.9326e-01],\n",
      "         [3.1622e-01],\n",
      "         [6.0818e-01],\n",
      "         [9.8025e-01],\n",
      "         [6.0476e-02],\n",
      "         [8.9062e-01],\n",
      "         [6.7848e-01],\n",
      "         [8.5811e-01],\n",
      "         [6.4149e-01],\n",
      "         [9.3248e-01],\n",
      "         [4.6226e-02],\n",
      "         [7.1516e-01],\n",
      "         [4.8055e-01],\n",
      "         [2.2360e-01],\n",
      "         [3.1941e-02],\n",
      "         [4.9399e-01],\n",
      "         [8.6540e-01],\n",
      "         [2.2886e-01],\n",
      "         [1.9828e-01],\n",
      "         [8.5254e-01],\n",
      "         [5.0152e-01],\n",
      "         [5.3827e-02],\n",
      "         [5.6459e-02],\n",
      "         [4.4640e-01],\n",
      "         [2.3873e-01],\n",
      "         [1.7909e-01],\n",
      "         [1.2012e-01],\n",
      "         [5.7019e-02],\n",
      "         [1.7937e-01],\n",
      "         [9.2048e-01],\n",
      "         [6.5905e-01],\n",
      "         [8.1805e-01],\n",
      "         [4.5338e-01],\n",
      "         [5.9908e-01],\n",
      "         [4.8447e-01],\n",
      "         [8.1529e-01],\n",
      "         [5.8502e-04],\n",
      "         [4.8737e-01],\n",
      "         [8.1804e-01],\n",
      "         [8.0281e-01],\n",
      "         [2.2369e-02],\n",
      "         [2.2468e-01],\n",
      "         [2.4487e-01],\n",
      "         [8.3117e-01],\n",
      "         [4.8468e-01],\n",
      "         [5.4929e-01],\n",
      "         [3.9975e-01],\n",
      "         [7.1279e-01],\n",
      "         [7.7346e-01],\n",
      "         [1.7422e-01],\n",
      "         [3.5635e-01],\n",
      "         [5.3514e-01],\n",
      "         [1.0618e-01],\n",
      "         [2.1335e-01],\n",
      "         [4.2745e-01],\n",
      "         [8.6918e-01],\n",
      "         [6.3337e-01],\n",
      "         [1.1447e-02],\n",
      "         [6.7210e-01],\n",
      "         [8.7116e-01],\n",
      "         [1.1801e-01],\n",
      "         [8.1957e-01],\n",
      "         [4.3465e-01],\n",
      "         [3.0589e-01],\n",
      "         [5.3632e-01],\n",
      "         [2.2046e-01],\n",
      "         [7.9007e-01],\n",
      "         [4.0660e-01],\n",
      "         [1.3149e-02],\n",
      "         [1.8294e-01],\n",
      "         [1.7143e-01],\n",
      "         [9.1975e-01],\n",
      "         [1.5443e-01],\n",
      "         [2.4370e-01],\n",
      "         [3.0475e-01],\n",
      "         [3.0344e-02],\n",
      "         [3.8526e-02]]], device='cuda:0', dtype=torch.float64)\n",
      "================iter 5============\n",
      "['shape/ellipsoid/1/ellipsoid_512_128_64_64_0_3_1']\n",
      "tensor([[ True, False,  True,  True,  True,  True,  True,  True,  True,  True,\n",
      "          True,  True,  True,  True,  True,  True,  True,  True, False, False]],\n",
      "       device='cuda:0')\n",
      "@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@\n",
      "['shape/ellipsoid/1/ellipsoid_512_128_64_64_1_0_1']\n",
      "gt_trans_torch.Size([1, 20, 3])_tensor([[[-5.7873e-02,  2.8748e-01, -1.3399e-02],\n",
      "         [-5.3101e-02,  2.6039e-01, -3.9590e-03],\n",
      "         [-2.0430e-03, -8.1657e-02, -2.0957e-02],\n",
      "         [ 3.3420e-03, -1.2054e-01, -2.3689e-02],\n",
      "         [ 1.3928e-02, -1.5493e-01, -1.7423e-02],\n",
      "         [ 2.0850e-02, -1.9004e-01, -1.4747e-02],\n",
      "         [ 1.9480e-02, -2.2044e-01, -1.4243e-02],\n",
      "         [ 3.1474e-02, -2.6395e-01, -1.6608e-02],\n",
      "         [ 2.9240e-02, -2.8056e-01, -3.3577e-03],\n",
      "         [ 5.4273e-02, -3.4416e-01, -1.4700e-02],\n",
      "         [-4.6580e-02,  2.1272e-01, -1.5024e-02],\n",
      "         [-3.5164e-02,  1.8346e-01, -3.7099e-03],\n",
      "         [-3.5379e-02,  1.4807e-01, -8.1136e-03],\n",
      "         [-4.1578e-02,  1.1236e-01, -1.6620e-02],\n",
      "         [-2.5248e-02,  7.2792e-02, -1.1520e-02],\n",
      "         [-2.4743e-02,  3.8837e-02, -1.3151e-02],\n",
      "         [-2.6645e-18, -7.5495e-18,  1.3323e-18],\n",
      "         [ 4.0472e-03, -4.4463e-02, -9.6127e-03],\n",
      "         [ 0.0000e+00,  0.0000e+00,  0.0000e+00],\n",
      "         [ 0.0000e+00,  0.0000e+00,  0.0000e+00]]], device='cuda:0')\n",
      "gt_rots_torch.Size([1, 20, 4])_tensor([[[ 1.1514e-01, -3.7826e-01,  8.9709e-01, -1.9720e-01],\n",
      "         [ 4.0243e-01, -4.6846e-01,  7.8211e-01, -8.3096e-02],\n",
      "         [-1.7630e-01,  5.2835e-01,  5.8000e-01,  5.9445e-01],\n",
      "         [ 7.1602e-01, -6.4051e-01,  2.1180e-01, -1.7945e-01],\n",
      "         [ 3.3239e-01,  4.2580e-01,  8.3670e-01,  9.0267e-02],\n",
      "         [-1.0378e-01,  8.8816e-01,  4.3821e-01, -9.1504e-02],\n",
      "         [-5.1207e-01, -3.5242e-01,  7.8022e-01,  6.9563e-02],\n",
      "         [-2.2385e-01,  7.1330e-01,  4.6268e-01,  4.7646e-01],\n",
      "         [-1.6291e-01,  6.7301e-01,  7.1413e-01,  1.0264e-01],\n",
      "         [ 7.9884e-01,  8.5726e-02,  1.6906e-02, -5.9516e-01],\n",
      "         [-9.7916e-02, -5.0020e-02,  8.3832e-01, -5.3398e-01],\n",
      "         [-3.5235e-01,  7.1529e-01, -1.9345e-01, -5.7165e-01],\n",
      "         [ 5.3591e-01,  2.3258e-01,  6.3094e-01,  5.1051e-01],\n",
      "         [-5.3151e-01, -5.2971e-01,  5.6372e-01,  3.4515e-01],\n",
      "         [ 2.9480e-01,  9.5203e-01,  4.5084e-02,  6.8489e-02],\n",
      "         [ 2.9680e-01,  6.4823e-01,  6.8848e-01,  1.3304e-01],\n",
      "         [-4.3819e-01,  8.4599e-01,  2.1387e-04,  3.0379e-01],\n",
      "         [ 1.2006e-01,  9.5003e-01,  2.5291e-01,  1.3809e-01],\n",
      "         [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00],\n",
      "         [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00]]],\n",
      "       device='cuda:0')\n",
      "noisy_trans_and_rots_torch.Size([1, 20, 7])_tensor([[[ 0.2246,  0.0000,  0.0894, -0.7072,  0.0000,  0.0000,  0.0518],\n",
      "         [-0.2191,  0.0000, -0.1840, -0.9683,  0.0000,  0.0000,  1.0448],\n",
      "         [ 0.2170,  0.0000, -0.3926, -0.2608,  0.0000,  0.0000,  0.8718],\n",
      "         [ 0.5272,  0.0000, -0.6791, -1.4010,  0.0000,  0.0000,  0.4192],\n",
      "         [-0.7639,  0.0000, -1.0244,  1.1187,  0.0000,  0.0000,  0.7568],\n",
      "         [-0.0474,  0.0000, -0.4480,  0.3917,  0.0000,  0.0000, -0.9308],\n",
      "         [ 1.2861,  0.0000, -1.6652,  1.1239,  0.0000,  0.0000,  0.4579],\n",
      "         [ 0.2922,  0.0000,  0.1070,  1.6197,  0.0000,  0.0000, -0.1359],\n",
      "         [ 1.7639,  0.0000,  0.1234,  0.6865,  0.0000,  0.0000,  1.0679],\n",
      "         [-0.7807,  0.0000, -0.8770,  0.2656,  0.0000,  0.0000, -0.3827],\n",
      "         [-0.3062,  0.0000,  0.1527, -0.2925,  0.0000,  0.0000,  0.8226],\n",
      "         [-1.3629,  0.0000,  0.6947,  0.7220,  0.0000,  0.0000,  1.2599],\n",
      "         [-1.4351,  0.0000,  2.2052,  0.9722,  0.0000,  0.0000,  0.5977],\n",
      "         [-0.5630,  0.0000, -0.0097,  0.8286,  0.0000,  0.0000, -0.1933],\n",
      "         [-0.4083,  0.0000,  0.5764, -0.3200,  0.0000,  0.0000,  1.6439],\n",
      "         [-0.6892,  0.0000,  0.2128,  1.5672,  0.0000,  0.0000, -1.1021],\n",
      "         [-0.7411,  0.0000,  0.3492, -1.5343,  0.0000,  0.0000,  0.2443],\n",
      "         [ 0.3130,  0.0000, -0.9784, -0.1671,  0.0000,  0.0000,  1.4091],\n",
      "         [-0.0761,  0.0000,  0.6751,  0.4039,  0.0000,  0.0000, -0.9921],\n",
      "         [-2.0575,  0.0000, -1.1609,  0.2029,  0.0000,  0.0000,  2.0528]]],\n",
      "       device='cuda:0')\n",
      "================iter 0============\n",
      "['shape/ellipsoid/1/ellipsoid_512_128_64_64_1_0_1']\n",
      "tensor([[False, False, False, False, False, False, False, False, False, False,\n",
      "         False, False, False, False, False, False,  True, False, False, False]],\n",
      "       device='cuda:0')\n",
      "acc torch.Size([1]) tensor([0.0556], device='cuda:0')\n",
      "acc_per_part torch.Size([1, 20]) tensor([[False, False, False, False, False, False, False, False, False, False,\n",
      "         False, False, False, False, False, False,  True, False, False, False]],\n",
      "       device='cuda:0')\n",
      "loss_per_data torch.Size([1, 20]) tensor([[ 1.9424,  1.7659,  0.9434,  1.9341,  0.6585,  1.5420,  7.9957,  2.6629,\n",
      "          8.0735,  0.1723,  0.8571,  1.2087,  3.7641,  0.3765,  1.9403,  0.3502,\n",
      "          0.0000,  2.0231,  2.9367, 13.9685]], device='cuda:0')\n",
      "scores torch.Size([1, 190, 1]) tensor([[[0.1324],\n",
      "         [0.0090],\n",
      "         [0.6425],\n",
      "         [0.9565],\n",
      "         [0.9368],\n",
      "         [0.2577],\n",
      "         [0.2473],\n",
      "         [0.2891],\n",
      "         [0.5931],\n",
      "         [0.6883],\n",
      "         [0.5953],\n",
      "         [0.2006],\n",
      "         [0.4095],\n",
      "         [0.8907],\n",
      "         [0.3233],\n",
      "         [0.8750],\n",
      "         [0.6872],\n",
      "         [0.1943],\n",
      "         [0.9394],\n",
      "         [0.0580],\n",
      "         [0.4472],\n",
      "         [0.5231],\n",
      "         [0.9776],\n",
      "         [0.4771],\n",
      "         [0.6529],\n",
      "         [0.1518],\n",
      "         [0.2442],\n",
      "         [0.9200],\n",
      "         [0.6980],\n",
      "         [0.9529],\n",
      "         [0.5744],\n",
      "         [0.9206],\n",
      "         [0.8852],\n",
      "         [0.0110],\n",
      "         [0.5897],\n",
      "         [0.8480],\n",
      "         [0.4581],\n",
      "         [0.3626],\n",
      "         [0.6790],\n",
      "         [0.8139],\n",
      "         [0.4047],\n",
      "         [0.9043],\n",
      "         [0.2902],\n",
      "         [0.3285],\n",
      "         [0.9515],\n",
      "         [0.3439],\n",
      "         [0.0555],\n",
      "         [0.3009],\n",
      "         [0.9346],\n",
      "         [0.5922],\n",
      "         [0.9835],\n",
      "         [0.0075],\n",
      "         [0.3741],\n",
      "         [0.1364],\n",
      "         [0.7031],\n",
      "         [0.2068],\n",
      "         [0.7804],\n",
      "         [0.3949],\n",
      "         [0.2748],\n",
      "         [0.2802],\n",
      "         [0.2474],\n",
      "         [0.7679],\n",
      "         [0.0764],\n",
      "         [0.8320],\n",
      "         [0.5015],\n",
      "         [0.2191],\n",
      "         [0.9590],\n",
      "         [0.4747],\n",
      "         [0.1815],\n",
      "         [0.2469],\n",
      "         [0.9322],\n",
      "         [0.8370],\n",
      "         [0.8405],\n",
      "         [0.2380],\n",
      "         [0.9483],\n",
      "         [0.5777],\n",
      "         [0.4026],\n",
      "         [0.9860],\n",
      "         [0.7534],\n",
      "         [0.3027],\n",
      "         [0.8361],\n",
      "         [0.6883],\n",
      "         [0.6847],\n",
      "         [0.7847],\n",
      "         [0.5173],\n",
      "         [0.6405],\n",
      "         [0.7274],\n",
      "         [0.6065],\n",
      "         [0.0633],\n",
      "         [0.2461],\n",
      "         [0.4736],\n",
      "         [0.9599],\n",
      "         [0.4147],\n",
      "         [0.2096],\n",
      "         [0.1108],\n",
      "         [0.6632],\n",
      "         [0.6228],\n",
      "         [0.5337],\n",
      "         [0.7821],\n",
      "         [0.2096],\n",
      "         [0.7508],\n",
      "         [0.0196],\n",
      "         [0.8714],\n",
      "         [0.4030],\n",
      "         [0.5297],\n",
      "         [0.9725],\n",
      "         [0.3837],\n",
      "         [0.2700],\n",
      "         [0.7272],\n",
      "         [0.0937],\n",
      "         [0.9343],\n",
      "         [0.8950],\n",
      "         [0.2422],\n",
      "         [0.5198],\n",
      "         [0.8751],\n",
      "         [0.2510],\n",
      "         [0.9649],\n",
      "         [0.2058],\n",
      "         [0.1320],\n",
      "         [0.6734],\n",
      "         [0.3574],\n",
      "         [0.2131],\n",
      "         [0.5856],\n",
      "         [0.7609],\n",
      "         [0.4236],\n",
      "         [0.0704],\n",
      "         [0.9093],\n",
      "         [0.9655],\n",
      "         [0.6081],\n",
      "         [0.3868],\n",
      "         [0.4165],\n",
      "         [0.5841],\n",
      "         [0.9003],\n",
      "         [0.5890],\n",
      "         [0.7888],\n",
      "         [0.2947],\n",
      "         [0.7735],\n",
      "         [0.9942],\n",
      "         [0.3263],\n",
      "         [0.6275],\n",
      "         [0.3241],\n",
      "         [0.5093],\n",
      "         [0.3287],\n",
      "         [0.4902],\n",
      "         [0.6681],\n",
      "         [0.0248],\n",
      "         [0.8638],\n",
      "         [0.2482],\n",
      "         [0.1384],\n",
      "         [0.6989],\n",
      "         [0.6606],\n",
      "         [0.8986],\n",
      "         [0.7879],\n",
      "         [0.3764],\n",
      "         [0.9683],\n",
      "         [0.3198],\n",
      "         [0.1897],\n",
      "         [0.3935],\n",
      "         [0.4943],\n",
      "         [0.8503],\n",
      "         [0.8315],\n",
      "         [0.3881],\n",
      "         [0.0880],\n",
      "         [0.7037],\n",
      "         [0.2631],\n",
      "         [0.5468],\n",
      "         [0.1527],\n",
      "         [0.5829],\n",
      "         [0.4796],\n",
      "         [0.3256],\n",
      "         [0.1313],\n",
      "         [0.9417],\n",
      "         [0.0693],\n",
      "         [0.9477],\n",
      "         [0.2446],\n",
      "         [0.0341],\n",
      "         [0.4957],\n",
      "         [0.6787],\n",
      "         [0.5379],\n",
      "         [0.0709],\n",
      "         [0.5679],\n",
      "         [0.5611],\n",
      "         [0.3810],\n",
      "         [0.0995],\n",
      "         [0.1694],\n",
      "         [0.9222],\n",
      "         [0.3933],\n",
      "         [0.0284],\n",
      "         [0.5351],\n",
      "         [0.0870]]], device='cuda:0', dtype=torch.float64)\n",
      "================iter 1============\n",
      "['shape/ellipsoid/1/ellipsoid_512_128_64_64_1_0_1']\n",
      "tensor([[False, False,  True,  True, False, False, False, False, False, False,\n",
      "         False, False, False,  True, False, False,  True, False, False, False]],\n",
      "       device='cuda:0')\n",
      "acc torch.Size([1]) tensor([0.0556], device='cuda:0')\n",
      "acc_per_part torch.Size([1, 20]) tensor([[False, False, False, False, False, False, False, False, False, False,\n",
      "         False, False, False, False, False, False,  True, False, False, False]],\n",
      "       device='cuda:0')\n",
      "loss_per_data torch.Size([1, 20]) tensor([[ 5.9656,  4.7712,  0.9434,  1.9341,  8.0053,  2.0789, 15.5952,  9.3739,\n",
      "          9.0591,  0.2479,  1.4700,  2.9448,  8.7614,  0.3765,  1.1985,  1.1303,\n",
      "          0.0000,  5.4655,  0.6830, 57.9235]], device='cuda:0')\n",
      "scores torch.Size([1, 190, 1]) tensor([[[0.8283],\n",
      "         [0.3365],\n",
      "         [0.8659],\n",
      "         [0.6244],\n",
      "         [0.9003],\n",
      "         [0.6057],\n",
      "         [0.8879],\n",
      "         [0.8363],\n",
      "         [0.9303],\n",
      "         [0.5365],\n",
      "         [0.0317],\n",
      "         [0.5961],\n",
      "         [0.9572],\n",
      "         [0.0331],\n",
      "         [0.1544],\n",
      "         [0.0044],\n",
      "         [0.4043],\n",
      "         [0.6320],\n",
      "         [0.3714],\n",
      "         [0.5696],\n",
      "         [0.5916],\n",
      "         [0.9082],\n",
      "         [0.1059],\n",
      "         [0.4801],\n",
      "         [0.4296],\n",
      "         [0.6574],\n",
      "         [0.9783],\n",
      "         [0.8120],\n",
      "         [0.3767],\n",
      "         [0.0808],\n",
      "         [0.8201],\n",
      "         [0.1360],\n",
      "         [0.1026],\n",
      "         [0.5095],\n",
      "         [0.2083],\n",
      "         [0.2836],\n",
      "         [0.5677],\n",
      "         [0.2137],\n",
      "         [0.3263],\n",
      "         [0.5512],\n",
      "         [0.1520],\n",
      "         [0.0056],\n",
      "         [0.2032],\n",
      "         [0.5514],\n",
      "         [0.6628],\n",
      "         [0.4551],\n",
      "         [0.3753],\n",
      "         [0.9717],\n",
      "         [0.2959],\n",
      "         [0.5510],\n",
      "         [0.1901],\n",
      "         [0.2083],\n",
      "         [0.3217],\n",
      "         [0.7488],\n",
      "         [0.3051],\n",
      "         [0.4637],\n",
      "         [0.6576],\n",
      "         [0.9473],\n",
      "         [0.5455],\n",
      "         [0.3554],\n",
      "         [0.2496],\n",
      "         [0.0096],\n",
      "         [0.3995],\n",
      "         [0.2990],\n",
      "         [0.6252],\n",
      "         [0.9707],\n",
      "         [0.4019],\n",
      "         [0.5025],\n",
      "         [0.1509],\n",
      "         [0.8399],\n",
      "         [0.8020],\n",
      "         [0.8655],\n",
      "         [0.5976],\n",
      "         [0.6194],\n",
      "         [0.7595],\n",
      "         [0.6614],\n",
      "         [0.6991],\n",
      "         [0.8512],\n",
      "         [0.5903],\n",
      "         [0.6716],\n",
      "         [0.2121],\n",
      "         [0.8704],\n",
      "         [0.8160],\n",
      "         [0.8822],\n",
      "         [0.5071],\n",
      "         [0.3248],\n",
      "         [0.3840],\n",
      "         [0.6307],\n",
      "         [0.9223],\n",
      "         [0.6363],\n",
      "         [0.9721],\n",
      "         [0.9779],\n",
      "         [0.5811],\n",
      "         [0.3158],\n",
      "         [0.1384],\n",
      "         [0.0818],\n",
      "         [0.9808],\n",
      "         [0.3122],\n",
      "         [0.4002],\n",
      "         [0.2595],\n",
      "         [0.6364],\n",
      "         [0.3965],\n",
      "         [0.8108],\n",
      "         [0.8310],\n",
      "         [0.7520],\n",
      "         [0.8950],\n",
      "         [0.7973],\n",
      "         [0.5053],\n",
      "         [0.7370],\n",
      "         [0.4559],\n",
      "         [0.4383],\n",
      "         [0.6551],\n",
      "         [0.6706],\n",
      "         [0.1319],\n",
      "         [0.5906],\n",
      "         [0.8680],\n",
      "         [0.0460],\n",
      "         [0.8945],\n",
      "         [0.6103],\n",
      "         [0.5283],\n",
      "         [0.4320],\n",
      "         [0.9290],\n",
      "         [0.8031],\n",
      "         [0.9312],\n",
      "         [0.2047],\n",
      "         [0.7242],\n",
      "         [0.7090],\n",
      "         [0.6889],\n",
      "         [0.8909],\n",
      "         [0.0049],\n",
      "         [0.4859],\n",
      "         [0.2789],\n",
      "         [0.6141],\n",
      "         [0.3752],\n",
      "         [0.9730],\n",
      "         [0.5923],\n",
      "         [0.7562],\n",
      "         [0.9794],\n",
      "         [0.9574],\n",
      "         [0.8242],\n",
      "         [0.5254],\n",
      "         [0.7431],\n",
      "         [0.2676],\n",
      "         [0.8483],\n",
      "         [0.6192],\n",
      "         [0.2694],\n",
      "         [0.3401],\n",
      "         [0.7572],\n",
      "         [0.1491],\n",
      "         [0.6586],\n",
      "         [0.8392],\n",
      "         [0.7347],\n",
      "         [0.9587],\n",
      "         [0.3418],\n",
      "         [0.3603],\n",
      "         [0.7421],\n",
      "         [0.6841],\n",
      "         [0.5846],\n",
      "         [0.0454],\n",
      "         [0.8760],\n",
      "         [0.7895],\n",
      "         [0.9912],\n",
      "         [0.4815],\n",
      "         [0.1827],\n",
      "         [0.9724],\n",
      "         [0.5010],\n",
      "         [0.5245],\n",
      "         [0.8443],\n",
      "         [0.7743],\n",
      "         [0.2291],\n",
      "         [0.8518],\n",
      "         [0.9417],\n",
      "         [0.9634],\n",
      "         [0.3988],\n",
      "         [0.5353],\n",
      "         [0.8133],\n",
      "         [0.0206],\n",
      "         [0.9482],\n",
      "         [0.5232],\n",
      "         [0.6407],\n",
      "         [0.9204],\n",
      "         [0.6307],\n",
      "         [0.4207],\n",
      "         [0.3426],\n",
      "         [0.9759],\n",
      "         [0.3562],\n",
      "         [0.3802],\n",
      "         [0.6722],\n",
      "         [0.4649],\n",
      "         [0.3755]]], device='cuda:0', dtype=torch.float64)\n",
      "================iter 2============\n",
      "['shape/ellipsoid/1/ellipsoid_512_128_64_64_1_0_1']\n",
      "tensor([[ True, False,  True,  True, False, False, False,  True, False,  True,\n",
      "         False, False, False,  True, False,  True,  True,  True, False, False]],\n",
      "       device='cuda:0')\n",
      "acc torch.Size([1]) tensor([0.0556], device='cuda:0')\n",
      "acc_per_part torch.Size([1, 20]) tensor([[False, False, False, False, False, False, False, False, False, False,\n",
      "         False, False, False, False, False, False,  True, False, False, False]],\n",
      "       device='cuda:0')\n",
      "loss_per_data torch.Size([1, 20]) tensor([[  5.9656,   2.1885,   0.9434,   1.9341,  33.6973,  18.6588,  27.4337,\n",
      "           9.3739,   8.5890,   0.2479,  13.0293,  10.3565,  34.4822,   0.3765,\n",
      "           7.3657,   1.1303,   0.0000,   5.4655,   0.2841, 137.1276]],\n",
      "       device='cuda:0')\n",
      "scores torch.Size([1, 190, 1]) tensor([[[0.3169],\n",
      "         [0.6881],\n",
      "         [0.5337],\n",
      "         [0.1696],\n",
      "         [0.3748],\n",
      "         [0.1967],\n",
      "         [0.6010],\n",
      "         [0.1225],\n",
      "         [0.3101],\n",
      "         [0.5717],\n",
      "         [0.9741],\n",
      "         [0.4911],\n",
      "         [0.1820],\n",
      "         [0.6930],\n",
      "         [0.9104],\n",
      "         [0.4620],\n",
      "         [0.3211],\n",
      "         [0.6067],\n",
      "         [0.4105],\n",
      "         [0.9136],\n",
      "         [0.2281],\n",
      "         [0.7005],\n",
      "         [0.9599],\n",
      "         [0.1408],\n",
      "         [0.9530],\n",
      "         [0.5999],\n",
      "         [0.0089],\n",
      "         [0.7615],\n",
      "         [0.6876],\n",
      "         [0.7705],\n",
      "         [0.7388],\n",
      "         [0.2206],\n",
      "         [0.4037],\n",
      "         [0.9692],\n",
      "         [0.8483],\n",
      "         [0.4805],\n",
      "         [0.6093],\n",
      "         [0.1599],\n",
      "         [0.6081],\n",
      "         [0.5302],\n",
      "         [0.5535],\n",
      "         [0.6953],\n",
      "         [0.8313],\n",
      "         [0.7387],\n",
      "         [0.8167],\n",
      "         [0.0917],\n",
      "         [0.9996],\n",
      "         [0.6761],\n",
      "         [0.6461],\n",
      "         [0.4330],\n",
      "         [0.2914],\n",
      "         [0.3449],\n",
      "         [0.5876],\n",
      "         [0.6048],\n",
      "         [0.1715],\n",
      "         [0.9849],\n",
      "         [0.2116],\n",
      "         [0.2958],\n",
      "         [0.5571],\n",
      "         [0.3590],\n",
      "         [0.1814],\n",
      "         [0.5040],\n",
      "         [0.1502],\n",
      "         [0.8901],\n",
      "         [0.6837],\n",
      "         [0.7806],\n",
      "         [0.0333],\n",
      "         [0.6774],\n",
      "         [0.4070],\n",
      "         [0.0171],\n",
      "         [0.9345],\n",
      "         [0.3664],\n",
      "         [0.8936],\n",
      "         [0.3986],\n",
      "         [0.8028],\n",
      "         [0.9270],\n",
      "         [0.0850],\n",
      "         [0.6982],\n",
      "         [0.1476],\n",
      "         [0.6936],\n",
      "         [0.3903],\n",
      "         [0.3981],\n",
      "         [0.3040],\n",
      "         [0.5807],\n",
      "         [0.2031],\n",
      "         [0.8144],\n",
      "         [0.5427],\n",
      "         [0.3066],\n",
      "         [0.3964],\n",
      "         [0.5618],\n",
      "         [0.2597],\n",
      "         [0.5503],\n",
      "         [0.9979],\n",
      "         [0.2808],\n",
      "         [0.0636],\n",
      "         [0.5271],\n",
      "         [0.9595],\n",
      "         [0.4591],\n",
      "         [0.4609],\n",
      "         [0.2011],\n",
      "         [0.9297],\n",
      "         [0.9814],\n",
      "         [0.4305],\n",
      "         [0.8144],\n",
      "         [0.4212],\n",
      "         [0.4663],\n",
      "         [0.4139],\n",
      "         [0.1405],\n",
      "         [0.2950],\n",
      "         [0.6557],\n",
      "         [0.0600],\n",
      "         [0.4304],\n",
      "         [0.3641],\n",
      "         [0.3394],\n",
      "         [0.6141],\n",
      "         [0.1722],\n",
      "         [0.0933],\n",
      "         [0.3278],\n",
      "         [0.2573],\n",
      "         [0.1929],\n",
      "         [0.4799],\n",
      "         [0.0566],\n",
      "         [0.3231],\n",
      "         [0.5818],\n",
      "         [0.5574],\n",
      "         [0.5929],\n",
      "         [0.7314],\n",
      "         [0.6403],\n",
      "         [0.7186],\n",
      "         [0.1674],\n",
      "         [0.3929],\n",
      "         [0.3821],\n",
      "         [0.6273],\n",
      "         [0.7548],\n",
      "         [0.8415],\n",
      "         [0.8157],\n",
      "         [0.0758],\n",
      "         [0.0253],\n",
      "         [0.1522],\n",
      "         [0.7463],\n",
      "         [0.4583],\n",
      "         [0.6568],\n",
      "         [0.6203],\n",
      "         [0.6004],\n",
      "         [0.1090],\n",
      "         [0.9233],\n",
      "         [0.7825],\n",
      "         [0.4832],\n",
      "         [0.2946],\n",
      "         [0.1315],\n",
      "         [0.7308],\n",
      "         [0.7766],\n",
      "         [0.4450],\n",
      "         [0.0245],\n",
      "         [0.5683],\n",
      "         [0.9991],\n",
      "         [0.5919],\n",
      "         [0.2458],\n",
      "         [0.4141],\n",
      "         [0.5714],\n",
      "         [0.5135],\n",
      "         [0.2354],\n",
      "         [0.3690],\n",
      "         [0.2005],\n",
      "         [0.2697],\n",
      "         [0.7296],\n",
      "         [0.6807],\n",
      "         [0.6982],\n",
      "         [0.6790],\n",
      "         [0.8673],\n",
      "         [0.4758],\n",
      "         [0.1075],\n",
      "         [0.0606],\n",
      "         [0.1414],\n",
      "         [0.4708],\n",
      "         [0.1015],\n",
      "         [0.2069],\n",
      "         [0.2825],\n",
      "         [0.9177],\n",
      "         [0.7455],\n",
      "         [0.8793],\n",
      "         [0.3844],\n",
      "         [0.0664],\n",
      "         [0.4346],\n",
      "         [0.7716],\n",
      "         [0.1179],\n",
      "         [0.1983],\n",
      "         [0.1813],\n",
      "         [0.7854],\n",
      "         [0.3000]]], device='cuda:0', dtype=torch.float64)\n",
      "================iter 3============\n",
      "['shape/ellipsoid/1/ellipsoid_512_128_64_64_1_0_1']\n",
      "tensor([[ True,  True,  True,  True, False,  True,  True,  True, False,  True,\n",
      "         False,  True,  True,  True, False,  True,  True,  True, False, False]],\n",
      "       device='cuda:0')\n",
      "acc torch.Size([1]) tensor([0.0556], device='cuda:0')\n",
      "acc_per_part torch.Size([1, 20]) tensor([[False, False, False, False, False, False, False, False, False, False,\n",
      "         False, False, False, False, False, False,  True, False, False, False]],\n",
      "       device='cuda:0')\n",
      "loss_per_data torch.Size([1, 20]) tensor([[  5.9656,   2.1885,   0.9434,   1.9341,  83.0042,  18.6588,  27.4337,\n",
      "           9.3739,  20.0978,   0.2479,  62.0651,  10.3565,  34.4822,   0.3765,\n",
      "          10.7137,   1.1303,   0.0000,   5.4655,   4.7663, 230.8540]],\n",
      "       device='cuda:0')\n",
      "scores torch.Size([1, 190, 1]) tensor([[[0.0339],\n",
      "         [0.6075],\n",
      "         [0.3175],\n",
      "         [0.8191],\n",
      "         [0.5174],\n",
      "         [0.0905],\n",
      "         [0.5364],\n",
      "         [0.1587],\n",
      "         [0.4670],\n",
      "         [0.6508],\n",
      "         [0.7362],\n",
      "         [0.6726],\n",
      "         [0.5351],\n",
      "         [0.3246],\n",
      "         [0.6893],\n",
      "         [0.4466],\n",
      "         [0.3590],\n",
      "         [0.4245],\n",
      "         [0.4031],\n",
      "         [0.6887],\n",
      "         [0.3418],\n",
      "         [0.6903],\n",
      "         [0.8739],\n",
      "         [0.1932],\n",
      "         [0.2360],\n",
      "         [0.9277],\n",
      "         [0.4059],\n",
      "         [0.7919],\n",
      "         [0.1352],\n",
      "         [0.9409],\n",
      "         [0.3477],\n",
      "         [0.9450],\n",
      "         [0.6309],\n",
      "         [0.0155],\n",
      "         [0.1699],\n",
      "         [0.8776],\n",
      "         [0.1901],\n",
      "         [0.4492],\n",
      "         [0.1709],\n",
      "         [0.6167],\n",
      "         [0.1818],\n",
      "         [0.0333],\n",
      "         [0.8378],\n",
      "         [0.7054],\n",
      "         [0.3995],\n",
      "         [0.5864],\n",
      "         [0.1107],\n",
      "         [0.0378],\n",
      "         [0.8871],\n",
      "         [0.8128],\n",
      "         [0.9945],\n",
      "         [0.8271],\n",
      "         [0.2928],\n",
      "         [0.0745],\n",
      "         [0.6203],\n",
      "         [0.7911],\n",
      "         [0.6965],\n",
      "         [0.3720],\n",
      "         [0.0315],\n",
      "         [0.4916],\n",
      "         [0.7963],\n",
      "         [0.8738],\n",
      "         [0.4801],\n",
      "         [0.0555],\n",
      "         [0.8361],\n",
      "         [0.7921],\n",
      "         [0.1205],\n",
      "         [0.4718],\n",
      "         [0.5320],\n",
      "         [0.1674],\n",
      "         [0.7462],\n",
      "         [0.4420],\n",
      "         [0.5463],\n",
      "         [0.9402],\n",
      "         [0.7363],\n",
      "         [0.3496],\n",
      "         [0.1107],\n",
      "         [0.3634],\n",
      "         [0.4089],\n",
      "         [0.9994],\n",
      "         [0.7472],\n",
      "         [0.0636],\n",
      "         [0.7750],\n",
      "         [0.8003],\n",
      "         [0.2602],\n",
      "         [0.6051],\n",
      "         [0.4502],\n",
      "         [0.6830],\n",
      "         [0.0963],\n",
      "         [0.5278],\n",
      "         [0.2779],\n",
      "         [0.1157],\n",
      "         [0.1429],\n",
      "         [0.1701],\n",
      "         [0.8018],\n",
      "         [0.7327],\n",
      "         [0.4372],\n",
      "         [0.0148],\n",
      "         [0.5541],\n",
      "         [0.4122],\n",
      "         [0.0178],\n",
      "         [0.5555],\n",
      "         [0.2257],\n",
      "         [0.2190],\n",
      "         [0.2291],\n",
      "         [0.5221],\n",
      "         [0.6681],\n",
      "         [0.5495],\n",
      "         [0.5684],\n",
      "         [0.4945],\n",
      "         [0.8354],\n",
      "         [0.9069],\n",
      "         [0.1219],\n",
      "         [0.6755],\n",
      "         [0.2213],\n",
      "         [0.9775],\n",
      "         [0.8924],\n",
      "         [0.7115],\n",
      "         [0.8899],\n",
      "         [0.3139],\n",
      "         [0.0228],\n",
      "         [0.6084],\n",
      "         [0.0230],\n",
      "         [0.7807],\n",
      "         [0.5113],\n",
      "         [0.2656],\n",
      "         [0.7819],\n",
      "         [0.3739],\n",
      "         [0.1307],\n",
      "         [0.4294],\n",
      "         [0.4255],\n",
      "         [0.8657],\n",
      "         [0.5294],\n",
      "         [0.7800],\n",
      "         [0.2974],\n",
      "         [0.3200],\n",
      "         [0.3300],\n",
      "         [0.2987],\n",
      "         [0.1157],\n",
      "         [0.1975],\n",
      "         [0.1394],\n",
      "         [0.9749],\n",
      "         [0.8673],\n",
      "         [0.6336],\n",
      "         [0.7319],\n",
      "         [0.1423],\n",
      "         [0.0748],\n",
      "         [0.7827],\n",
      "         [0.0246],\n",
      "         [0.9246],\n",
      "         [0.2923],\n",
      "         [0.8806],\n",
      "         [0.7616],\n",
      "         [0.8376],\n",
      "         [0.8981],\n",
      "         [0.0225],\n",
      "         [0.2838],\n",
      "         [0.6058],\n",
      "         [0.6445],\n",
      "         [0.4405],\n",
      "         [0.0869],\n",
      "         [0.6288],\n",
      "         [0.3823],\n",
      "         [0.6967],\n",
      "         [0.0582],\n",
      "         [0.8706],\n",
      "         [0.9837],\n",
      "         [0.3156],\n",
      "         [0.7008],\n",
      "         [0.2583],\n",
      "         [0.0590],\n",
      "         [0.6652],\n",
      "         [0.2653],\n",
      "         [0.0874],\n",
      "         [0.1707],\n",
      "         [0.6263],\n",
      "         [0.4166],\n",
      "         [0.2042],\n",
      "         [0.8919],\n",
      "         [0.0584],\n",
      "         [0.3091],\n",
      "         [0.8324],\n",
      "         [0.3142],\n",
      "         [0.1361],\n",
      "         [0.9135],\n",
      "         [0.3174],\n",
      "         [0.0704],\n",
      "         [0.6649],\n",
      "         [0.3719],\n",
      "         [0.3465]]], device='cuda:0', dtype=torch.float64)\n",
      "================iter 4============\n",
      "['shape/ellipsoid/1/ellipsoid_512_128_64_64_1_0_1']\n",
      "tensor([[ True,  True,  True,  True, False,  True,  True,  True,  True,  True,\n",
      "          True,  True,  True,  True,  True,  True,  True,  True, False, False]],\n",
      "       device='cuda:0')\n",
      "acc torch.Size([1]) tensor([0.0556], device='cuda:0')\n",
      "acc_per_part torch.Size([1, 20]) tensor([[False, False, False, False, False, False, False, False, False, False,\n",
      "         False, False, False, False, False, False,  True, False, False, False]],\n",
      "       device='cuda:0')\n",
      "loss_per_data torch.Size([1, 20]) tensor([[5.9656e+00, 2.1885e+00, 9.4343e-01, 1.9341e+00, 1.5502e+02, 1.8659e+01,\n",
      "         2.7434e+01, 9.3739e+00, 2.0098e+01, 2.4794e-01, 6.2065e+01, 1.0357e+01,\n",
      "         3.4482e+01, 3.7648e-01, 1.0714e+01, 1.1303e+00, 0.0000e+00, 5.4655e+00,\n",
      "         1.9045e+01, 5.7331e+02]], device='cuda:0')\n",
      "scores torch.Size([1, 190, 1]) tensor([[[0.1465],\n",
      "         [0.8192],\n",
      "         [0.8365],\n",
      "         [0.3476],\n",
      "         [0.8261],\n",
      "         [0.7646],\n",
      "         [0.9695],\n",
      "         [0.5161],\n",
      "         [0.8484],\n",
      "         [0.4430],\n",
      "         [0.5510],\n",
      "         [0.0943],\n",
      "         [0.9587],\n",
      "         [0.9655],\n",
      "         [0.2333],\n",
      "         [0.6989],\n",
      "         [0.8739],\n",
      "         [0.6464],\n",
      "         [0.3081],\n",
      "         [0.7004],\n",
      "         [0.2274],\n",
      "         [0.7957],\n",
      "         [0.9246],\n",
      "         [0.3063],\n",
      "         [0.7939],\n",
      "         [0.2369],\n",
      "         [0.7438],\n",
      "         [0.0243],\n",
      "         [0.0471],\n",
      "         [0.4725],\n",
      "         [0.6233],\n",
      "         [0.2655],\n",
      "         [0.6265],\n",
      "         [0.2529],\n",
      "         [0.3165],\n",
      "         [0.2493],\n",
      "         [0.1939],\n",
      "         [0.2450],\n",
      "         [0.4549],\n",
      "         [0.1443],\n",
      "         [0.1776],\n",
      "         [0.7253],\n",
      "         [0.5581],\n",
      "         [0.5143],\n",
      "         [0.7735],\n",
      "         [0.7262],\n",
      "         [0.4742],\n",
      "         [0.7487],\n",
      "         [0.8632],\n",
      "         [0.6264],\n",
      "         [0.7448],\n",
      "         [0.1385],\n",
      "         [0.4811],\n",
      "         [0.7955],\n",
      "         [0.3792],\n",
      "         [0.5782],\n",
      "         [0.2567],\n",
      "         [0.5353],\n",
      "         [0.9830],\n",
      "         [0.7142],\n",
      "         [0.4560],\n",
      "         [0.4306],\n",
      "         [0.2241],\n",
      "         [0.1880],\n",
      "         [0.4120],\n",
      "         [0.1819],\n",
      "         [0.9165],\n",
      "         [0.0333],\n",
      "         [0.9045],\n",
      "         [0.5598],\n",
      "         [0.2598],\n",
      "         [0.8754],\n",
      "         [0.9114],\n",
      "         [0.5129],\n",
      "         [0.1546],\n",
      "         [0.9850],\n",
      "         [0.7028],\n",
      "         [0.4096],\n",
      "         [0.4494],\n",
      "         [0.2588],\n",
      "         [0.3896],\n",
      "         [0.2442],\n",
      "         [0.6141],\n",
      "         [0.6605],\n",
      "         [0.1181],\n",
      "         [0.3232],\n",
      "         [0.8010],\n",
      "         [0.9728],\n",
      "         [0.3320],\n",
      "         [0.1320],\n",
      "         [0.8363],\n",
      "         [0.3023],\n",
      "         [0.6187],\n",
      "         [0.0248],\n",
      "         [0.1279],\n",
      "         [0.4571],\n",
      "         [0.8119],\n",
      "         [0.6880],\n",
      "         [0.3123],\n",
      "         [0.9532],\n",
      "         [0.5145],\n",
      "         [0.4735],\n",
      "         [0.3958],\n",
      "         [0.8392],\n",
      "         [0.0946],\n",
      "         [0.1580],\n",
      "         [0.3252],\n",
      "         [0.0032],\n",
      "         [0.6477],\n",
      "         [0.4225],\n",
      "         [0.2652],\n",
      "         [0.5242],\n",
      "         [0.2230],\n",
      "         [0.4214],\n",
      "         [0.7204],\n",
      "         [0.6979],\n",
      "         [0.3705],\n",
      "         [0.2141],\n",
      "         [0.8797],\n",
      "         [0.1366],\n",
      "         [0.7888],\n",
      "         [0.7774],\n",
      "         [0.8885],\n",
      "         [0.2511],\n",
      "         [0.7018],\n",
      "         [0.3973],\n",
      "         [0.2128],\n",
      "         [0.5119],\n",
      "         [0.4225],\n",
      "         [0.1166],\n",
      "         [0.6564],\n",
      "         [0.2162],\n",
      "         [0.5896],\n",
      "         [0.8160],\n",
      "         [0.6035],\n",
      "         [0.4479],\n",
      "         [0.5098],\n",
      "         [0.4636],\n",
      "         [0.9576],\n",
      "         [0.0659],\n",
      "         [0.8025],\n",
      "         [0.2254],\n",
      "         [0.0988],\n",
      "         [0.3223],\n",
      "         [0.5046],\n",
      "         [0.3152],\n",
      "         [0.1004],\n",
      "         [0.6901],\n",
      "         [0.5854],\n",
      "         [0.8291],\n",
      "         [0.9094],\n",
      "         [0.9616],\n",
      "         [0.6378],\n",
      "         [0.1566],\n",
      "         [0.5018],\n",
      "         [0.6977],\n",
      "         [0.7937],\n",
      "         [0.3526],\n",
      "         [0.6292],\n",
      "         [0.1013],\n",
      "         [0.4461],\n",
      "         [0.1866],\n",
      "         [0.0276],\n",
      "         [0.3045],\n",
      "         [0.6321],\n",
      "         [0.1025],\n",
      "         [0.6621],\n",
      "         [0.0963],\n",
      "         [0.1591],\n",
      "         [0.9979],\n",
      "         [0.9105],\n",
      "         [0.5258],\n",
      "         [0.8045],\n",
      "         [0.6992],\n",
      "         [0.3438],\n",
      "         [0.8019],\n",
      "         [0.8820],\n",
      "         [0.2155],\n",
      "         [0.9579],\n",
      "         [0.6004],\n",
      "         [0.4823],\n",
      "         [0.7703],\n",
      "         [0.8095],\n",
      "         [0.8478],\n",
      "         [0.1427],\n",
      "         [0.7988],\n",
      "         [0.4814],\n",
      "         [0.4583],\n",
      "         [0.1057],\n",
      "         [0.2625]]], device='cuda:0', dtype=torch.float64)\n",
      "================iter 5============\n",
      "['shape/ellipsoid/1/ellipsoid_512_128_64_64_1_0_1']\n",
      "tensor([[ True,  True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
      "          True,  True,  True,  True,  True,  True,  True,  True, False, False]],\n",
      "       device='cuda:0')\n",
      "@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@\n",
      "['shape/ellipsoid/1/ellipsoid_512_128_64_64_1_1_1']\n",
      "gt_trans_torch.Size([1, 20, 3])_tensor([[[ 1.3785e-01, -2.4308e-01,  6.3828e-02],\n",
      "         [ 1.2559e-01, -2.0210e-01,  3.9943e-02],\n",
      "         [-3.9058e-02,  6.7687e-02, -1.5983e-03],\n",
      "         [-5.4799e-02,  9.0456e-02, -1.3041e-02],\n",
      "         [-6.7131e-02,  1.3562e-01, -3.7117e-02],\n",
      "         [-8.9347e-02,  1.4249e-01, -2.8617e-02],\n",
      "         [-1.0487e-01,  1.8598e-01, -4.2172e-02],\n",
      "         [-1.2029e-01,  2.2396e-01, -5.7220e-02],\n",
      "         [-1.4048e-01,  2.6071e-01, -5.5981e-02],\n",
      "         [-1.6042e-01,  2.9247e-01, -5.4094e-02],\n",
      "         [ 1.0771e-01, -1.7155e-01,  3.4289e-02],\n",
      "         [ 8.6281e-02, -1.6078e-01,  4.0666e-02],\n",
      "         [ 6.9428e-02, -1.0738e-01,  2.9908e-02],\n",
      "         [ 5.0103e-02, -7.8262e-02,  2.8045e-02],\n",
      "         [ 3.2934e-02, -5.4526e-02,  2.2420e-02],\n",
      "         [ 1.6057e-02, -1.6917e-02,  1.1472e-02],\n",
      "         [-4.4409e-19,  1.2434e-17, -8.8818e-19],\n",
      "         [-2.2360e-02,  3.5279e-02,  7.6158e-03],\n",
      "         [ 0.0000e+00,  0.0000e+00,  0.0000e+00],\n",
      "         [ 0.0000e+00,  0.0000e+00,  0.0000e+00]]], device='cuda:0')\n",
      "gt_rots_torch.Size([1, 20, 4])_tensor([[[ 0.1768,  0.8047, -0.5224, -0.2197],\n",
      "         [ 0.1685,  0.2919,  0.8943,  0.2942],\n",
      "         [ 0.4262,  0.8688,  0.1440, -0.2069],\n",
      "         [-0.3926,  0.5959,  0.6787,  0.1738],\n",
      "         [ 0.1566, -0.1130,  0.9532,  0.2326],\n",
      "         [ 0.1459,  0.8113, -0.2485,  0.5087],\n",
      "         [-0.6187,  0.1316,  0.7444, -0.2140],\n",
      "         [-0.1924,  0.7929,  0.1275,  0.5640],\n",
      "         [ 0.5547, -0.1812,  0.0503,  0.8105],\n",
      "         [-0.3193, -0.5423,  0.7769, -0.0230],\n",
      "         [ 0.7639, -0.5159, -0.3512, -0.1643],\n",
      "         [ 0.2977,  0.8348, -0.3197,  0.3349],\n",
      "         [ 0.2736,  0.5080,  0.7670, -0.2807],\n",
      "         [ 0.3157,  0.5772, -0.4492,  0.6045],\n",
      "         [-0.2142,  0.9142, -0.1606,  0.3043],\n",
      "         [ 0.9021, -0.4163,  0.1114, -0.0227],\n",
      "         [-0.5074, -0.1952,  0.6332, -0.5509],\n",
      "         [-0.1921, -0.4130,  0.6859, -0.5675],\n",
      "         [ 0.0000,  0.0000,  0.0000,  0.0000],\n",
      "         [ 0.0000,  0.0000,  0.0000,  0.0000]]], device='cuda:0')\n",
      "noisy_trans_and_rots_torch.Size([1, 20, 7])_tensor([[[-0.0053,  0.0000,  1.0099, -0.1526,  0.0000,  0.0000,  0.0951],\n",
      "         [ 0.3841,  0.0000,  1.6996, -0.3454,  0.0000,  0.0000,  1.6989],\n",
      "         [-1.2371,  0.0000, -1.3043, -0.7749,  0.0000,  0.0000,  0.9726],\n",
      "         [-0.1668,  0.0000, -0.2206, -0.3208,  0.0000,  0.0000,  0.5986],\n",
      "         [-2.0021,  0.0000, -0.8952, -1.4673,  0.0000,  0.0000, -0.4652],\n",
      "         [ 1.2924,  0.0000, -0.8284,  0.8114,  0.0000,  0.0000,  1.0482],\n",
      "         [-0.2372,  0.0000,  0.2659,  0.8418,  0.0000,  0.0000,  0.3137],\n",
      "         [-0.0240,  0.0000,  1.0151,  0.7376,  0.0000,  0.0000, -2.5252],\n",
      "         [-0.6489,  0.0000, -1.9829,  0.4202,  0.0000,  0.0000, -0.4211],\n",
      "         [-0.0716,  0.0000, -0.4647, -0.6343,  0.0000,  0.0000, -0.0092],\n",
      "         [-1.2789,  0.0000, -0.4646,  0.4348,  0.0000,  0.0000,  0.0104],\n",
      "         [ 1.3072,  0.0000, -0.7048,  1.9290,  0.0000,  0.0000,  1.7472],\n",
      "         [-0.2742,  0.0000,  0.5443,  0.5649,  0.0000,  0.0000,  1.0789],\n",
      "         [-0.3944,  0.0000,  0.2322, -1.4814,  0.0000,  0.0000, -0.6670],\n",
      "         [-1.1212,  0.0000,  1.9652, -0.0679,  0.0000,  0.0000, -0.0077],\n",
      "         [-0.6857,  0.0000, -0.4417,  0.1933,  0.0000,  0.0000, -0.7477],\n",
      "         [ 0.6658,  0.0000, -0.5220,  1.1113,  0.0000,  0.0000,  0.4885],\n",
      "         [ 0.5890,  0.0000,  1.1678,  0.1909,  0.0000,  0.0000,  0.3016],\n",
      "         [-1.0803,  0.0000,  0.7071,  0.6550,  0.0000,  0.0000,  1.0654],\n",
      "         [-0.4956,  0.0000,  1.7112, -0.3899,  0.0000,  0.0000,  0.4463]]],\n",
      "       device='cuda:0')\n",
      "================iter 0============\n",
      "['shape/ellipsoid/1/ellipsoid_512_128_64_64_1_1_1']\n",
      "tensor([[False, False, False, False, False, False, False, False, False, False,\n",
      "         False, False, False, False, False, False,  True, False, False, False]],\n",
      "       device='cuda:0')\n",
      "acc torch.Size([1]) tensor([0.0556], device='cuda:0')\n",
      "acc_per_part torch.Size([1, 20]) tensor([[False, False, False, False, False, False, False, False, False, False,\n",
      "         False, False, False, False, False, False,  True, False, False, False]],\n",
      "       device='cuda:0')\n",
      "loss_per_data torch.Size([1, 20]) tensor([[1.5517, 0.7675, 0.7500, 0.3630, 2.4141, 2.2107, 1.9062, 6.8822, 8.6477,\n",
      "         1.9745, 0.3636, 4.0824, 1.0865, 0.4817, 0.5384, 0.8411, 0.0000, 0.6707,\n",
      "         1.3926, 9.6236]], device='cuda:0')\n",
      "scores torch.Size([1, 190, 1]) tensor([[[0.2993],\n",
      "         [0.9772],\n",
      "         [0.4380],\n",
      "         [0.9776],\n",
      "         [0.7336],\n",
      "         [0.0033],\n",
      "         [0.2251],\n",
      "         [0.2947],\n",
      "         [0.9835],\n",
      "         [0.0941],\n",
      "         [0.6946],\n",
      "         [0.1155],\n",
      "         [0.4992],\n",
      "         [0.0502],\n",
      "         [0.3153],\n",
      "         [0.5233],\n",
      "         [0.9794],\n",
      "         [0.7348],\n",
      "         [0.6461],\n",
      "         [0.7063],\n",
      "         [0.6566],\n",
      "         [0.1910],\n",
      "         [0.4790],\n",
      "         [0.0130],\n",
      "         [0.2030],\n",
      "         [0.6177],\n",
      "         [0.2296],\n",
      "         [0.3539],\n",
      "         [0.7070],\n",
      "         [0.9097],\n",
      "         [0.1453],\n",
      "         [0.3446],\n",
      "         [0.6541],\n",
      "         [0.4011],\n",
      "         [0.6060],\n",
      "         [0.1115],\n",
      "         [0.8900],\n",
      "         [0.0383],\n",
      "         [0.0972],\n",
      "         [0.0719],\n",
      "         [0.2163],\n",
      "         [0.8502],\n",
      "         [0.4446],\n",
      "         [0.1663],\n",
      "         [0.8076],\n",
      "         [0.5535],\n",
      "         [0.3104],\n",
      "         [0.9957],\n",
      "         [0.8722],\n",
      "         [0.1003],\n",
      "         [0.3458],\n",
      "         [0.8546],\n",
      "         [0.1851],\n",
      "         [0.3355],\n",
      "         [0.3176],\n",
      "         [0.9452],\n",
      "         [0.3433],\n",
      "         [0.4804],\n",
      "         [0.0092],\n",
      "         [0.9218],\n",
      "         [0.6612],\n",
      "         [0.2183],\n",
      "         [0.7567],\n",
      "         [0.9778],\n",
      "         [0.3966],\n",
      "         [0.8643],\n",
      "         [0.1420],\n",
      "         [0.1176],\n",
      "         [0.5453],\n",
      "         [0.8696],\n",
      "         [0.7562],\n",
      "         [0.7576],\n",
      "         [0.0726],\n",
      "         [0.4997],\n",
      "         [0.6627],\n",
      "         [0.3801],\n",
      "         [0.0512],\n",
      "         [0.2024],\n",
      "         [0.7173],\n",
      "         [0.0110],\n",
      "         [0.3326],\n",
      "         [0.4938],\n",
      "         [0.5515],\n",
      "         [0.0265],\n",
      "         [0.8460],\n",
      "         [0.6537],\n",
      "         [0.0360],\n",
      "         [0.3797],\n",
      "         [0.0230],\n",
      "         [0.5967],\n",
      "         [0.3602],\n",
      "         [0.6735],\n",
      "         [0.8820],\n",
      "         [0.6473],\n",
      "         [0.2229],\n",
      "         [0.7055],\n",
      "         [0.2255],\n",
      "         [0.1759],\n",
      "         [0.1906],\n",
      "         [0.3077],\n",
      "         [0.7088],\n",
      "         [0.7070],\n",
      "         [0.4982],\n",
      "         [0.0759],\n",
      "         [0.7772],\n",
      "         [0.3376],\n",
      "         [0.3812],\n",
      "         [0.2645],\n",
      "         [0.5507],\n",
      "         [0.5606],\n",
      "         [0.9917],\n",
      "         [0.3599],\n",
      "         [0.8843],\n",
      "         [0.7964],\n",
      "         [0.1678],\n",
      "         [0.4422],\n",
      "         [0.0805],\n",
      "         [0.6874],\n",
      "         [0.8679],\n",
      "         [0.8977],\n",
      "         [0.1366],\n",
      "         [0.1439],\n",
      "         [0.5420],\n",
      "         [0.7169],\n",
      "         [0.3280],\n",
      "         [0.3922],\n",
      "         [0.7444],\n",
      "         [0.0525],\n",
      "         [0.4828],\n",
      "         [0.1672],\n",
      "         [0.3555],\n",
      "         [0.8818],\n",
      "         [0.2147],\n",
      "         [0.8223],\n",
      "         [0.0506],\n",
      "         [0.7178],\n",
      "         [0.5979],\n",
      "         [0.1626],\n",
      "         [0.8981],\n",
      "         [0.7577],\n",
      "         [0.1472],\n",
      "         [0.8687],\n",
      "         [0.4861],\n",
      "         [0.5514],\n",
      "         [0.3865],\n",
      "         [0.6998],\n",
      "         [0.2496],\n",
      "         [0.5995],\n",
      "         [0.4007],\n",
      "         [0.3861],\n",
      "         [0.1133],\n",
      "         [0.3031],\n",
      "         [0.8108],\n",
      "         [0.6648],\n",
      "         [0.7508],\n",
      "         [0.5940],\n",
      "         [0.8914],\n",
      "         [0.8341],\n",
      "         [0.7916],\n",
      "         [0.0240],\n",
      "         [0.1589],\n",
      "         [0.9867],\n",
      "         [0.3420],\n",
      "         [0.4564],\n",
      "         [0.2029],\n",
      "         [0.0184],\n",
      "         [0.0703],\n",
      "         [0.1483],\n",
      "         [0.4417],\n",
      "         [0.7238],\n",
      "         [0.6034],\n",
      "         [0.0260],\n",
      "         [0.8364],\n",
      "         [0.2921],\n",
      "         [0.5498],\n",
      "         [0.7115],\n",
      "         [0.3593],\n",
      "         [0.3078],\n",
      "         [0.8520],\n",
      "         [0.3887],\n",
      "         [0.7753],\n",
      "         [0.0146],\n",
      "         [0.3478],\n",
      "         [0.8270],\n",
      "         [0.0058],\n",
      "         [0.0720],\n",
      "         [0.2596],\n",
      "         [0.8994],\n",
      "         [0.0817],\n",
      "         [0.0207]]], device='cuda:0', dtype=torch.float64)\n",
      "================iter 1============\n",
      "['shape/ellipsoid/1/ellipsoid_512_128_64_64_1_1_1']\n",
      "tensor([[False, False, False, False, False, False, False, False, False, False,\n",
      "         False, False, False, False, False, False,  True, False, False, False]],\n",
      "       device='cuda:0')\n",
      "acc torch.Size([1]) tensor([0.0556], device='cuda:0')\n",
      "acc_per_part torch.Size([1, 20]) tensor([[False, False, False, False, False, False, False, False, False, False,\n",
      "         False, False, False, False, False, False,  True, False, False, False]],\n",
      "       device='cuda:0')\n",
      "loss_per_data torch.Size([1, 20]) tensor([[ 0.0956,  2.0030,  4.6352,  2.1158,  2.8845,  2.6299,  1.5702, 12.5509,\n",
      "          2.4055, 10.1647,  1.8762,  1.4047,  0.7779,  0.7833,  1.4551,  2.8079,\n",
      "          0.0000,  3.5996, 11.2792, 24.2594]], device='cuda:0')\n",
      "scores torch.Size([1, 190, 1]) tensor([[[0.4034],\n",
      "         [0.9044],\n",
      "         [0.4174],\n",
      "         [0.4272],\n",
      "         [0.2348],\n",
      "         [0.7582],\n",
      "         [0.4450],\n",
      "         [0.0893],\n",
      "         [0.7159],\n",
      "         [0.4759],\n",
      "         [0.6691],\n",
      "         [0.4762],\n",
      "         [0.6497],\n",
      "         [0.9371],\n",
      "         [0.6587],\n",
      "         [0.6067],\n",
      "         [0.7804],\n",
      "         [0.0366],\n",
      "         [0.9213],\n",
      "         [0.0946],\n",
      "         [0.6086],\n",
      "         [0.3105],\n",
      "         [0.3983],\n",
      "         [0.8346],\n",
      "         [0.6085],\n",
      "         [0.2461],\n",
      "         [0.1626],\n",
      "         [0.1949],\n",
      "         [0.6127],\n",
      "         [0.8708],\n",
      "         [0.9329],\n",
      "         [0.9012],\n",
      "         [0.3618],\n",
      "         [0.9139],\n",
      "         [0.4284],\n",
      "         [0.3751],\n",
      "         [0.5354],\n",
      "         [0.0492],\n",
      "         [0.2019],\n",
      "         [0.2538],\n",
      "         [0.3052],\n",
      "         [0.1162],\n",
      "         [0.2378],\n",
      "         [0.3296],\n",
      "         [0.3294],\n",
      "         [0.4042],\n",
      "         [0.8550],\n",
      "         [0.8122],\n",
      "         [0.4507],\n",
      "         [0.8642],\n",
      "         [0.2705],\n",
      "         [0.8736],\n",
      "         [0.4714],\n",
      "         [0.9809],\n",
      "         [0.3806],\n",
      "         [0.4044],\n",
      "         [0.8672],\n",
      "         [0.7107],\n",
      "         [0.1931],\n",
      "         [0.6244],\n",
      "         [0.0044],\n",
      "         [0.7279],\n",
      "         [0.6216],\n",
      "         [0.3557],\n",
      "         [0.6755],\n",
      "         [0.6871],\n",
      "         [0.1201],\n",
      "         [0.1059],\n",
      "         [0.6982],\n",
      "         [0.3638],\n",
      "         [0.8713],\n",
      "         [0.4551],\n",
      "         [0.1761],\n",
      "         [0.6749],\n",
      "         [0.6630],\n",
      "         [0.6047],\n",
      "         [0.8294],\n",
      "         [0.9184],\n",
      "         [0.0512],\n",
      "         [0.2175],\n",
      "         [0.7726],\n",
      "         [0.1673],\n",
      "         [0.2302],\n",
      "         [0.4758],\n",
      "         [0.9695],\n",
      "         [0.7589],\n",
      "         [0.6528],\n",
      "         [0.3825],\n",
      "         [0.1195],\n",
      "         [0.5322],\n",
      "         [0.6294],\n",
      "         [0.1899],\n",
      "         [0.1483],\n",
      "         [0.9590],\n",
      "         [0.7976],\n",
      "         [0.6980],\n",
      "         [0.0711],\n",
      "         [0.1882],\n",
      "         [0.5054],\n",
      "         [0.7635],\n",
      "         [0.1772],\n",
      "         [0.4226],\n",
      "         [0.8594],\n",
      "         [0.0236],\n",
      "         [0.9369],\n",
      "         [0.9965],\n",
      "         [0.6078],\n",
      "         [0.8909],\n",
      "         [0.4002],\n",
      "         [0.0375],\n",
      "         [0.2034],\n",
      "         [0.4525],\n",
      "         [0.8624],\n",
      "         [0.8776],\n",
      "         [0.3797],\n",
      "         [0.5001],\n",
      "         [0.3456],\n",
      "         [0.3912],\n",
      "         [0.7627],\n",
      "         [0.6283],\n",
      "         [0.0977],\n",
      "         [0.4016],\n",
      "         [0.9984],\n",
      "         [0.4260],\n",
      "         [0.5345],\n",
      "         [0.8568],\n",
      "         [0.2042],\n",
      "         [0.5403],\n",
      "         [0.5387],\n",
      "         [0.7245],\n",
      "         [0.7491],\n",
      "         [0.8919],\n",
      "         [0.7746],\n",
      "         [0.8222],\n",
      "         [0.8759],\n",
      "         [0.6630],\n",
      "         [0.2365],\n",
      "         [0.7227],\n",
      "         [0.3134],\n",
      "         [0.0232],\n",
      "         [0.2725],\n",
      "         [0.5339],\n",
      "         [0.6849],\n",
      "         [0.6527],\n",
      "         [0.2529],\n",
      "         [0.6382],\n",
      "         [0.2780],\n",
      "         [0.4877],\n",
      "         [0.2910],\n",
      "         [0.7885],\n",
      "         [0.8949],\n",
      "         [0.4058],\n",
      "         [0.2219],\n",
      "         [0.2572],\n",
      "         [0.8638],\n",
      "         [0.7028],\n",
      "         [0.5849],\n",
      "         [0.9646],\n",
      "         [0.6283],\n",
      "         [0.2363],\n",
      "         [0.4143],\n",
      "         [0.0708],\n",
      "         [0.6517],\n",
      "         [0.9506],\n",
      "         [0.3399],\n",
      "         [0.5942],\n",
      "         [0.2585],\n",
      "         [0.2001],\n",
      "         [0.1447],\n",
      "         [0.4019],\n",
      "         [0.9905],\n",
      "         [0.1617],\n",
      "         [0.6489],\n",
      "         [0.2265],\n",
      "         [0.4049],\n",
      "         [0.0855],\n",
      "         [0.5622],\n",
      "         [0.9820],\n",
      "         [0.7815],\n",
      "         [0.9605],\n",
      "         [0.9619],\n",
      "         [0.3568],\n",
      "         [0.8821],\n",
      "         [0.7893],\n",
      "         [0.5656],\n",
      "         [0.1696],\n",
      "         [0.9863],\n",
      "         [0.1693],\n",
      "         [0.4082],\n",
      "         [0.0635]]], device='cuda:0', dtype=torch.float64)\n",
      "================iter 2============\n",
      "['shape/ellipsoid/1/ellipsoid_512_128_64_64_1_1_1']\n",
      "tensor([[False,  True, False, False, False, False, False, False, False, False,\n",
      "         False, False, False, False, False,  True,  True, False, False, False]],\n",
      "       device='cuda:0')\n",
      "acc torch.Size([1]) tensor([0.0556], device='cuda:0')\n",
      "acc_per_part torch.Size([1, 20]) tensor([[False, False, False, False, False, False, False, False, False, False,\n",
      "         False, False, False, False, False, False,  True, False, False, False]],\n",
      "       device='cuda:0')\n",
      "loss_per_data torch.Size([1, 20]) tensor([[11.6108,  2.0030,  8.7837,  5.2520,  6.2437,  4.4779,  2.4630, 31.2499,\n",
      "         16.4425, 29.8453,  0.9812,  4.7613, 26.6335,  7.1407,  9.5906,  2.8079,\n",
      "          0.0000, 11.6865, 43.2148, 35.5203]], device='cuda:0')\n",
      "scores torch.Size([1, 190, 1]) tensor([[[0.9899],\n",
      "         [0.2815],\n",
      "         [0.4047],\n",
      "         [0.7938],\n",
      "         [0.9337],\n",
      "         [0.0301],\n",
      "         [0.4638],\n",
      "         [0.6585],\n",
      "         [0.4593],\n",
      "         [0.8660],\n",
      "         [0.4468],\n",
      "         [0.4268],\n",
      "         [0.3652],\n",
      "         [0.6030],\n",
      "         [0.5216],\n",
      "         [0.4020],\n",
      "         [0.6455],\n",
      "         [0.7754],\n",
      "         [0.2805],\n",
      "         [0.9593],\n",
      "         [0.9786],\n",
      "         [0.2445],\n",
      "         [0.9477],\n",
      "         [0.8308],\n",
      "         [0.7893],\n",
      "         [0.7698],\n",
      "         [0.6907],\n",
      "         [0.1929],\n",
      "         [0.1356],\n",
      "         [0.9803],\n",
      "         [0.6027],\n",
      "         [0.0845],\n",
      "         [0.0270],\n",
      "         [0.9116],\n",
      "         [0.3066],\n",
      "         [0.6255],\n",
      "         [0.2711],\n",
      "         [0.5722],\n",
      "         [0.2695],\n",
      "         [0.5969],\n",
      "         [0.1967],\n",
      "         [0.1425],\n",
      "         [0.8483],\n",
      "         [0.2367],\n",
      "         [0.5805],\n",
      "         [0.8840],\n",
      "         [0.7453],\n",
      "         [0.8676],\n",
      "         [0.1347],\n",
      "         [0.4084],\n",
      "         [0.6945],\n",
      "         [0.9461],\n",
      "         [0.9782],\n",
      "         [0.7597],\n",
      "         [0.6328],\n",
      "         [0.5647],\n",
      "         [0.0400],\n",
      "         [0.2239],\n",
      "         [0.6238],\n",
      "         [0.5410],\n",
      "         [0.4625],\n",
      "         [0.3886],\n",
      "         [0.9165],\n",
      "         [0.6212],\n",
      "         [0.4959],\n",
      "         [0.5018],\n",
      "         [0.0559],\n",
      "         [0.5725],\n",
      "         [0.0167],\n",
      "         [0.2530],\n",
      "         [0.7321],\n",
      "         [0.0184],\n",
      "         [0.9637],\n",
      "         [0.0794],\n",
      "         [0.3603],\n",
      "         [0.6486],\n",
      "         [0.6666],\n",
      "         [0.0678],\n",
      "         [0.3458],\n",
      "         [0.5977],\n",
      "         [0.1646],\n",
      "         [0.7267],\n",
      "         [0.2351],\n",
      "         [0.1322],\n",
      "         [0.5491],\n",
      "         [0.8202],\n",
      "         [0.0645],\n",
      "         [0.2486],\n",
      "         [0.8597],\n",
      "         [0.3887],\n",
      "         [0.0911],\n",
      "         [0.7394],\n",
      "         [0.8580],\n",
      "         [0.8203],\n",
      "         [0.5017],\n",
      "         [0.6860],\n",
      "         [0.3719],\n",
      "         [0.6530],\n",
      "         [0.3187],\n",
      "         [0.6068],\n",
      "         [0.1700],\n",
      "         [0.4013],\n",
      "         [0.7825],\n",
      "         [0.4369],\n",
      "         [0.9056],\n",
      "         [0.7058],\n",
      "         [0.1648],\n",
      "         [0.0365],\n",
      "         [0.5090],\n",
      "         [0.5655],\n",
      "         [0.9274],\n",
      "         [0.3861],\n",
      "         [0.6097],\n",
      "         [0.2136],\n",
      "         [0.4427],\n",
      "         [0.0042],\n",
      "         [0.2831],\n",
      "         [0.0278],\n",
      "         [0.8285],\n",
      "         [0.9959],\n",
      "         [0.0640],\n",
      "         [0.1380],\n",
      "         [0.9513],\n",
      "         [0.6002],\n",
      "         [0.1724],\n",
      "         [0.5813],\n",
      "         [0.3980],\n",
      "         [0.4726],\n",
      "         [0.1368],\n",
      "         [0.7266],\n",
      "         [0.0912],\n",
      "         [0.5843],\n",
      "         [0.8885],\n",
      "         [0.6732],\n",
      "         [0.2556],\n",
      "         [0.3445],\n",
      "         [0.5909],\n",
      "         [0.4715],\n",
      "         [0.7796],\n",
      "         [0.1617],\n",
      "         [0.6031],\n",
      "         [0.2173],\n",
      "         [0.2389],\n",
      "         [0.5685],\n",
      "         [0.6105],\n",
      "         [0.5673],\n",
      "         [0.0157],\n",
      "         [0.7861],\n",
      "         [0.4548],\n",
      "         [0.9535],\n",
      "         [0.2527],\n",
      "         [0.1287],\n",
      "         [0.2908],\n",
      "         [0.5981],\n",
      "         [0.6301],\n",
      "         [0.7121],\n",
      "         [0.9859],\n",
      "         [0.1032],\n",
      "         [0.7829],\n",
      "         [0.0370],\n",
      "         [0.2379],\n",
      "         [0.5232],\n",
      "         [0.8881],\n",
      "         [0.8587],\n",
      "         [0.3682],\n",
      "         [0.6644],\n",
      "         [0.9037],\n",
      "         [0.8384],\n",
      "         [0.4015],\n",
      "         [0.3985],\n",
      "         [0.9793],\n",
      "         [0.4135],\n",
      "         [0.0750],\n",
      "         [0.8250],\n",
      "         [0.7833],\n",
      "         [0.4445],\n",
      "         [0.8656],\n",
      "         [0.3555],\n",
      "         [0.1112],\n",
      "         [0.8129],\n",
      "         [0.5936],\n",
      "         [0.6262],\n",
      "         [0.8225],\n",
      "         [0.4698],\n",
      "         [0.5518],\n",
      "         [0.6432],\n",
      "         [0.1437],\n",
      "         [0.4937],\n",
      "         [0.5195],\n",
      "         [0.7736]]], device='cuda:0', dtype=torch.float64)\n",
      "================iter 3============\n",
      "['shape/ellipsoid/1/ellipsoid_512_128_64_64_1_1_1']\n",
      "tensor([[ True,  True,  True,  True, False,  True, False,  True, False, False,\n",
      "          True, False,  True,  True, False,  True,  True, False, False, False]],\n",
      "       device='cuda:0')\n",
      "acc torch.Size([1]) tensor([0.0556], device='cuda:0')\n",
      "acc_per_part torch.Size([1, 20]) tensor([[False, False, False, False, False, False, False, False, False, False,\n",
      "         False, False, False, False, False, False,  True, False, False, False]],\n",
      "       device='cuda:0')\n",
      "loss_per_data torch.Size([1, 20]) tensor([[11.6108,  2.0030,  8.7837,  5.2520, 20.6629,  4.4779,  6.5213, 31.2499,\n",
      "          7.9558, 54.2454,  0.9812, 12.2034, 26.6335,  7.1407, 56.7388,  2.8079,\n",
      "          0.0000, 12.7368, 39.9947, 46.6120]], device='cuda:0')\n",
      "scores torch.Size([1, 190, 1]) tensor([[[0.5618],\n",
      "         [0.3802],\n",
      "         [0.9988],\n",
      "         [0.8978],\n",
      "         [0.3173],\n",
      "         [0.0770],\n",
      "         [0.1201],\n",
      "         [0.1457],\n",
      "         [0.1163],\n",
      "         [0.4516],\n",
      "         [0.4507],\n",
      "         [0.8662],\n",
      "         [0.4301],\n",
      "         [0.7238],\n",
      "         [0.0860],\n",
      "         [0.5126],\n",
      "         [0.8304],\n",
      "         [0.6324],\n",
      "         [0.7691],\n",
      "         [0.8283],\n",
      "         [0.2520],\n",
      "         [0.7791],\n",
      "         [0.3465],\n",
      "         [0.6620],\n",
      "         [0.0054],\n",
      "         [0.7806],\n",
      "         [0.4887],\n",
      "         [0.5507],\n",
      "         [0.4365],\n",
      "         [0.3399],\n",
      "         [0.4705],\n",
      "         [0.3335],\n",
      "         [0.2741],\n",
      "         [0.0462],\n",
      "         [0.1195],\n",
      "         [0.0918],\n",
      "         [0.1314],\n",
      "         [0.8393],\n",
      "         [0.4767],\n",
      "         [0.0289],\n",
      "         [0.7853],\n",
      "         [0.1052],\n",
      "         [0.6557],\n",
      "         [0.5728],\n",
      "         [0.5540],\n",
      "         [0.3682],\n",
      "         [0.5001],\n",
      "         [0.4936],\n",
      "         [0.1362],\n",
      "         [0.8798],\n",
      "         [0.5374],\n",
      "         [0.0265],\n",
      "         [0.5778],\n",
      "         [0.7128],\n",
      "         [0.1566],\n",
      "         [0.4496],\n",
      "         [0.4716],\n",
      "         [0.5089],\n",
      "         [0.9377],\n",
      "         [0.8131],\n",
      "         [0.7183],\n",
      "         [0.5083],\n",
      "         [0.9653],\n",
      "         [0.7923],\n",
      "         [0.7036],\n",
      "         [0.6132],\n",
      "         [0.0291],\n",
      "         [0.8101],\n",
      "         [0.9567],\n",
      "         [0.5044],\n",
      "         [0.4405],\n",
      "         [0.8870],\n",
      "         [0.7561],\n",
      "         [0.8732],\n",
      "         [0.7036],\n",
      "         [0.1949],\n",
      "         [0.3822],\n",
      "         [0.5874],\n",
      "         [0.1533],\n",
      "         [0.6284],\n",
      "         [0.0442],\n",
      "         [0.5202],\n",
      "         [0.3561],\n",
      "         [0.9237],\n",
      "         [0.7987],\n",
      "         [0.2382],\n",
      "         [0.9034],\n",
      "         [0.2820],\n",
      "         [0.1211],\n",
      "         [0.4350],\n",
      "         [0.2375],\n",
      "         [0.9784],\n",
      "         [0.6369],\n",
      "         [0.9651],\n",
      "         [0.5926],\n",
      "         [0.6385],\n",
      "         [0.5878],\n",
      "         [0.6354],\n",
      "         [0.2141],\n",
      "         [0.7692],\n",
      "         [0.3775],\n",
      "         [0.4582],\n",
      "         [0.8939],\n",
      "         [0.0030],\n",
      "         [0.3207],\n",
      "         [0.4893],\n",
      "         [0.8530],\n",
      "         [0.1258],\n",
      "         [0.5625],\n",
      "         [0.6380],\n",
      "         [0.3823],\n",
      "         [0.8767],\n",
      "         [0.2133],\n",
      "         [0.3479],\n",
      "         [0.0020],\n",
      "         [0.9656],\n",
      "         [0.9339],\n",
      "         [0.0045],\n",
      "         [0.0702],\n",
      "         [0.2112],\n",
      "         [0.1570],\n",
      "         [0.6522],\n",
      "         [0.0164],\n",
      "         [0.9892],\n",
      "         [0.8143],\n",
      "         [0.0831],\n",
      "         [0.9589],\n",
      "         [0.1179],\n",
      "         [0.5752],\n",
      "         [0.2167],\n",
      "         [0.6187],\n",
      "         [0.0625],\n",
      "         [0.3074],\n",
      "         [0.3404],\n",
      "         [0.2356],\n",
      "         [0.3432],\n",
      "         [0.4421],\n",
      "         [0.7786],\n",
      "         [0.0850],\n",
      "         [0.9852],\n",
      "         [0.0642],\n",
      "         [0.2630],\n",
      "         [0.1693],\n",
      "         [0.0062],\n",
      "         [0.4299],\n",
      "         [0.6258],\n",
      "         [0.7911],\n",
      "         [0.5641],\n",
      "         [0.1926],\n",
      "         [0.3098],\n",
      "         [0.1409],\n",
      "         [0.3744],\n",
      "         [0.8216],\n",
      "         [0.5017],\n",
      "         [0.7270],\n",
      "         [0.2260],\n",
      "         [0.1290],\n",
      "         [0.7580],\n",
      "         [0.6665],\n",
      "         [0.4682],\n",
      "         [0.8613],\n",
      "         [0.8497],\n",
      "         [0.3546],\n",
      "         [0.7354],\n",
      "         [0.4280],\n",
      "         [0.9526],\n",
      "         [0.6214],\n",
      "         [0.0749],\n",
      "         [0.1969],\n",
      "         [0.8667],\n",
      "         [0.0908],\n",
      "         [0.7463],\n",
      "         [0.0028],\n",
      "         [0.4200],\n",
      "         [0.0283],\n",
      "         [0.9074],\n",
      "         [0.9232],\n",
      "         [0.8402],\n",
      "         [0.3043],\n",
      "         [0.2225],\n",
      "         [0.2178],\n",
      "         [0.4474],\n",
      "         [0.7521],\n",
      "         [0.7914],\n",
      "         [0.8959],\n",
      "         [0.6370],\n",
      "         [0.0781],\n",
      "         [0.6709],\n",
      "         [0.0227],\n",
      "         [0.8585]]], device='cuda:0', dtype=torch.float64)\n",
      "================iter 4============\n",
      "['shape/ellipsoid/1/ellipsoid_512_128_64_64_1_1_1']\n",
      "tensor([[ True,  True,  True,  True, False,  True, False,  True,  True, False,\n",
      "          True,  True,  True,  True,  True,  True,  True, False, False, False]],\n",
      "       device='cuda:0')\n",
      "acc torch.Size([1]) tensor([0.0556], device='cuda:0')\n",
      "acc_per_part torch.Size([1, 20]) tensor([[False, False, False, False, False, False, False, False, False, False,\n",
      "         False, False, False, False, False, False,  True, False, False, False]],\n",
      "       device='cuda:0')\n",
      "loss_per_data torch.Size([1, 20]) tensor([[ 11.6108,   2.0030,   8.7837,   5.2520,  37.0124,   4.4779,  19.1880,\n",
      "          31.2499,   7.9558, 121.7208,   0.9812,  12.2034,  26.6335,   7.1407,\n",
      "          56.7388,   2.8079,   0.0000,  38.3992, 107.5713,  99.1383]],\n",
      "       device='cuda:0')\n",
      "scores torch.Size([1, 190, 1]) tensor([[[0.2749],\n",
      "         [0.7662],\n",
      "         [0.0303],\n",
      "         [0.8434],\n",
      "         [0.1562],\n",
      "         [0.9430],\n",
      "         [0.6392],\n",
      "         [0.9984],\n",
      "         [0.8445],\n",
      "         [0.7061],\n",
      "         [0.2435],\n",
      "         [0.6915],\n",
      "         [0.2400],\n",
      "         [0.6066],\n",
      "         [0.2732],\n",
      "         [0.3749],\n",
      "         [0.4424],\n",
      "         [0.8380],\n",
      "         [0.7692],\n",
      "         [0.6199],\n",
      "         [0.1814],\n",
      "         [0.6095],\n",
      "         [0.6133],\n",
      "         [0.4946],\n",
      "         [0.3804],\n",
      "         [0.0521],\n",
      "         [0.7255],\n",
      "         [0.9242],\n",
      "         [0.4344],\n",
      "         [0.2834],\n",
      "         [0.1291],\n",
      "         [0.2022],\n",
      "         [0.6050],\n",
      "         [0.8420],\n",
      "         [0.6031],\n",
      "         [0.9708],\n",
      "         [0.2362],\n",
      "         [0.4178],\n",
      "         [0.8051],\n",
      "         [0.9055],\n",
      "         [0.9510],\n",
      "         [0.6744],\n",
      "         [0.6732],\n",
      "         [0.3705],\n",
      "         [0.1970],\n",
      "         [0.8328],\n",
      "         [0.2263],\n",
      "         [0.8829],\n",
      "         [0.4185],\n",
      "         [0.0759],\n",
      "         [0.5295],\n",
      "         [0.3760],\n",
      "         [0.0769],\n",
      "         [0.8853],\n",
      "         [0.1207],\n",
      "         [0.3270],\n",
      "         [0.5586],\n",
      "         [0.7099],\n",
      "         [0.7139],\n",
      "         [0.3388],\n",
      "         [0.1223],\n",
      "         [0.0116],\n",
      "         [0.3980],\n",
      "         [0.5621],\n",
      "         [0.5993],\n",
      "         [0.2188],\n",
      "         [0.8896],\n",
      "         [0.7133],\n",
      "         [0.9787],\n",
      "         [0.7754],\n",
      "         [0.0735],\n",
      "         [0.4830],\n",
      "         [0.4512],\n",
      "         [0.8171],\n",
      "         [0.3697],\n",
      "         [0.8071],\n",
      "         [0.6746],\n",
      "         [0.5587],\n",
      "         [0.8087],\n",
      "         [0.2905],\n",
      "         [0.1091],\n",
      "         [0.5498],\n",
      "         [0.9787],\n",
      "         [0.5921],\n",
      "         [0.8867],\n",
      "         [0.1726],\n",
      "         [0.4556],\n",
      "         [0.2583],\n",
      "         [0.4972],\n",
      "         [0.2870],\n",
      "         [0.2931],\n",
      "         [0.7650],\n",
      "         [0.6641],\n",
      "         [0.3204],\n",
      "         [0.5772],\n",
      "         [0.3982],\n",
      "         [0.8287],\n",
      "         [0.5055],\n",
      "         [0.4420],\n",
      "         [0.5958],\n",
      "         [0.6726],\n",
      "         [0.2096],\n",
      "         [0.7451],\n",
      "         [0.4324],\n",
      "         [0.0672],\n",
      "         [0.4389],\n",
      "         [0.2051],\n",
      "         [0.8615],\n",
      "         [0.7392],\n",
      "         [0.8262],\n",
      "         [0.9862],\n",
      "         [0.7656],\n",
      "         [0.5012],\n",
      "         [0.8586],\n",
      "         [0.4643],\n",
      "         [0.3904],\n",
      "         [0.2786],\n",
      "         [0.7177],\n",
      "         [0.0038],\n",
      "         [0.1006],\n",
      "         [0.1489],\n",
      "         [0.8648],\n",
      "         [0.8553],\n",
      "         [0.3090],\n",
      "         [0.8088],\n",
      "         [0.2501],\n",
      "         [0.1405],\n",
      "         [0.4861],\n",
      "         [0.0730],\n",
      "         [0.7173],\n",
      "         [0.9096],\n",
      "         [0.5141],\n",
      "         [0.5182],\n",
      "         [0.3162],\n",
      "         [0.9977],\n",
      "         [0.1969],\n",
      "         [0.4229],\n",
      "         [0.8663],\n",
      "         [0.8666],\n",
      "         [0.4483],\n",
      "         [0.4570],\n",
      "         [0.0417],\n",
      "         [0.9638],\n",
      "         [0.0475],\n",
      "         [0.1049],\n",
      "         [0.5121],\n",
      "         [0.3790],\n",
      "         [0.7406],\n",
      "         [0.0837],\n",
      "         [0.3236],\n",
      "         [0.5620],\n",
      "         [0.7594],\n",
      "         [0.8153],\n",
      "         [0.3241],\n",
      "         [0.6414],\n",
      "         [0.6992],\n",
      "         [0.6616],\n",
      "         [0.3990],\n",
      "         [0.8932],\n",
      "         [0.6503],\n",
      "         [0.4574],\n",
      "         [0.2432],\n",
      "         [0.6633],\n",
      "         [0.3258],\n",
      "         [0.6972],\n",
      "         [0.7205],\n",
      "         [0.5380],\n",
      "         [0.3301],\n",
      "         [0.6271],\n",
      "         [0.1088],\n",
      "         [0.1809],\n",
      "         [0.8053],\n",
      "         [0.9518],\n",
      "         [0.1854],\n",
      "         [0.3946],\n",
      "         [0.8560],\n",
      "         [0.0911],\n",
      "         [0.0145],\n",
      "         [0.7776],\n",
      "         [0.8802],\n",
      "         [0.3774],\n",
      "         [0.2665],\n",
      "         [0.2265],\n",
      "         [0.7560],\n",
      "         [0.2936],\n",
      "         [0.0516],\n",
      "         [0.7524],\n",
      "         [0.0615],\n",
      "         [0.5278],\n",
      "         [0.3845]]], device='cuda:0', dtype=torch.float64)\n",
      "================iter 5============\n",
      "['shape/ellipsoid/1/ellipsoid_512_128_64_64_1_1_1']\n",
      "tensor([[ True,  True,  True,  True, False,  True,  True,  True,  True, False,\n",
      "          True,  True,  True,  True,  True,  True,  True,  True, False, False]],\n",
      "       device='cuda:0')\n",
      "@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@\n",
      "['shape/ellipsoid/1/ellipsoid_512_128_64_64_1_2_1']\n",
      "gt_trans_torch.Size([1, 20, 3])_tensor([[[ 8.3627e-02, -2.4715e-01,  7.3868e-02],\n",
      "         [ 7.2652e-02, -2.1152e-01,  5.9383e-02],\n",
      "         [-7.9918e-03,  4.4222e-02,  3.0683e-03],\n",
      "         [-2.2806e-02,  7.9009e-02, -1.1331e-02],\n",
      "         [-1.4326e-02,  1.0663e-01, -1.1494e-02],\n",
      "         [-3.2358e-02,  1.3337e-01, -1.8649e-02],\n",
      "         [-3.8948e-02,  1.7781e-01, -4.0083e-02],\n",
      "         [-4.9147e-02,  1.9696e-01, -3.7906e-02],\n",
      "         [-6.0153e-02,  2.2816e-01, -4.7806e-02],\n",
      "         [ 6.0016e-02, -1.8474e-01,  5.3740e-02],\n",
      "         [ 4.9361e-02, -1.4851e-01,  3.9588e-02],\n",
      "         [ 3.6483e-02, -1.2175e-01,  3.3255e-02],\n",
      "         [ 4.4002e-02, -9.1874e-02,  3.0911e-02],\n",
      "         [ 2.2485e-02, -6.6279e-02,  2.3279e-02],\n",
      "         [ 2.2647e-02, -4.3910e-02,  2.6077e-02],\n",
      "         [-4.4409e-19,  3.5527e-18,  0.0000e+00],\n",
      "         [ 4.9421e-03,  1.8386e-02,  8.1545e-03],\n",
      "         [ 0.0000e+00,  0.0000e+00,  0.0000e+00],\n",
      "         [ 0.0000e+00,  0.0000e+00,  0.0000e+00],\n",
      "         [ 0.0000e+00,  0.0000e+00,  0.0000e+00]]], device='cuda:0')\n",
      "gt_rots_torch.Size([1, 20, 4])_tensor([[[ 0.5571, -0.1197,  0.7933, -0.2144],\n",
      "         [ 0.4668,  0.4386,  0.6908,  0.3353],\n",
      "         [ 0.2159, -0.0137,  0.3488,  0.9119],\n",
      "         [-0.5768,  0.3552,  0.6641,  0.3164],\n",
      "         [ 0.8194, -0.2458,  0.4177,  0.3060],\n",
      "         [ 0.7675, -0.1298, -0.2537, -0.5742],\n",
      "         [-0.2133,  0.9685, -0.0874,  0.0939],\n",
      "         [ 0.4893,  0.4030,  0.6726,  0.3818],\n",
      "         [-0.5646, -0.0175,  0.7099,  0.4208],\n",
      "         [ 0.6070,  0.7920, -0.0475,  0.0459],\n",
      "         [ 0.9459, -0.2374, -0.0770,  0.2074],\n",
      "         [-0.3620,  0.7730, -0.2149,  0.4746],\n",
      "         [ 0.7963,  0.5147, -0.2411,  0.2072],\n",
      "         [-0.4356,  0.7052, -0.1211, -0.5461],\n",
      "         [ 0.0631,  0.6864,  0.6556, -0.3083],\n",
      "         [-0.4075, -0.5868, -0.1093,  0.6911],\n",
      "         [-0.3533,  0.4917,  0.7954, -0.0256],\n",
      "         [ 0.0000,  0.0000,  0.0000,  0.0000],\n",
      "         [ 0.0000,  0.0000,  0.0000,  0.0000],\n",
      "         [ 0.0000,  0.0000,  0.0000,  0.0000]]], device='cuda:0')\n",
      "noisy_trans_and_rots_torch.Size([1, 20, 7])_tensor([[[-1.2598,  0.0000, -0.5341,  0.4135,  0.0000,  0.0000,  0.5939],\n",
      "         [-0.4848,  0.0000,  0.6966, -0.3285,  0.0000,  0.0000,  0.3242],\n",
      "         [-1.5370,  0.0000, -1.4744, -0.9310,  0.0000,  0.0000, -0.1450],\n",
      "         [-0.1320,  0.0000, -0.4654, -0.9438,  0.0000,  0.0000,  1.7166],\n",
      "         [-0.2904,  0.0000,  1.5918, -0.2315,  0.0000,  0.0000,  0.0868],\n",
      "         [ 0.3797,  0.0000,  0.3956,  0.6806,  0.0000,  0.0000,  1.0233],\n",
      "         [ 0.7797,  0.0000,  0.1152, -0.0341,  0.0000,  0.0000,  0.3751],\n",
      "         [-0.5275,  0.0000, -0.9514,  0.2514,  0.0000,  0.0000, -0.4234],\n",
      "         [-0.0342,  0.0000,  0.3935, -0.5287,  0.0000,  0.0000,  0.1820],\n",
      "         [-0.5726,  0.0000, -0.1602, -0.1751,  0.0000,  0.0000,  0.5738],\n",
      "         [-3.2148,  0.0000,  0.9435, -0.3984,  0.0000,  0.0000, -1.0217],\n",
      "         [-0.5421,  0.0000, -0.6216,  0.2095,  0.0000,  0.0000,  0.3134],\n",
      "         [ 1.6829,  0.0000,  0.4429, -0.5094,  0.0000,  0.0000, -0.9227],\n",
      "         [-0.7306,  0.0000, -0.8645,  0.1762,  0.0000,  0.0000,  1.2482],\n",
      "         [-0.2476,  0.0000,  0.3748, -0.0663,  0.0000,  0.0000, -1.8340],\n",
      "         [ 1.3516,  0.0000,  0.2753,  0.2444,  0.0000,  0.0000,  0.0377],\n",
      "         [ 0.8914,  0.0000,  0.5476, -0.4430,  0.0000,  0.0000,  1.3013],\n",
      "         [-0.0664,  0.0000,  0.0962, -0.4809,  0.0000,  0.0000,  0.0294],\n",
      "         [-0.4198,  0.0000,  1.3737, -1.7387,  0.0000,  0.0000, -0.2591],\n",
      "         [-2.0583,  0.0000,  0.9363,  1.1556,  0.0000,  0.0000,  1.3233]]],\n",
      "       device='cuda:0')\n",
      "================iter 0============\n",
      "['shape/ellipsoid/1/ellipsoid_512_128_64_64_1_2_1']\n",
      "tensor([[False, False, False, False, False, False, False, False, False, False,\n",
      "         False, False, False, False, False,  True, False, False, False, False]],\n",
      "       device='cuda:0')\n",
      "acc torch.Size([1]) tensor([0.0588], device='cuda:0')\n",
      "acc_per_part torch.Size([1, 20]) tensor([[False, False, False, False, False, False, False, False, False, False,\n",
      "         False, False, False, False, False,  True, False, False, False, False]],\n",
      "       device='cuda:0')\n",
      "loss_per_data torch.Size([1, 20]) tensor([[ 1.0016,  1.8460,  3.1242,  0.2047,  2.5638,  1.6584,  0.9516,  1.0607,\n",
      "          2.4481,  0.9898,  6.2807,  3.1079,  1.6236,  2.0830,  0.6357,  0.0000,\n",
      "          0.3449,  5.9322, 16.9118, 12.5102]], device='cuda:0')\n",
      "scores torch.Size([1, 190, 1]) tensor([[[0.9846],\n",
      "         [0.7698],\n",
      "         [0.3631],\n",
      "         [0.8027],\n",
      "         [0.0457],\n",
      "         [0.4911],\n",
      "         [0.0295],\n",
      "         [0.7630],\n",
      "         [0.0670],\n",
      "         [0.0184],\n",
      "         [0.0589],\n",
      "         [0.6204],\n",
      "         [0.8502],\n",
      "         [0.7670],\n",
      "         [0.1346],\n",
      "         [0.3148],\n",
      "         [0.0911],\n",
      "         [0.8260],\n",
      "         [0.5113],\n",
      "         [0.2290],\n",
      "         [0.6077],\n",
      "         [0.1034],\n",
      "         [0.9429],\n",
      "         [0.9580],\n",
      "         [0.5481],\n",
      "         [0.7559],\n",
      "         [0.7011],\n",
      "         [0.7795],\n",
      "         [0.7914],\n",
      "         [0.7356],\n",
      "         [0.3487],\n",
      "         [0.0404],\n",
      "         [0.1382],\n",
      "         [0.8971],\n",
      "         [0.9522],\n",
      "         [0.7176],\n",
      "         [0.1854],\n",
      "         [0.4410],\n",
      "         [0.8233],\n",
      "         [0.7997],\n",
      "         [0.2247],\n",
      "         [0.2724],\n",
      "         [0.6870],\n",
      "         [0.7503],\n",
      "         [0.7817],\n",
      "         [0.2112],\n",
      "         [0.8425],\n",
      "         [0.0128],\n",
      "         [0.4699],\n",
      "         [0.9639],\n",
      "         [0.3273],\n",
      "         [0.5628],\n",
      "         [0.6544],\n",
      "         [0.2038],\n",
      "         [0.1767],\n",
      "         [0.6318],\n",
      "         [0.0646],\n",
      "         [0.8889],\n",
      "         [0.1889],\n",
      "         [0.3324],\n",
      "         [0.2235],\n",
      "         [0.2568],\n",
      "         [0.5349],\n",
      "         [0.7617],\n",
      "         [0.9758],\n",
      "         [0.6761],\n",
      "         [0.7882],\n",
      "         [0.2964],\n",
      "         [0.6967],\n",
      "         [0.1413],\n",
      "         [0.2444],\n",
      "         [0.1086],\n",
      "         [0.9124],\n",
      "         [0.4307],\n",
      "         [0.0301],\n",
      "         [0.6769],\n",
      "         [0.7871],\n",
      "         [0.4634],\n",
      "         [0.8484],\n",
      "         [0.0328],\n",
      "         [0.5314],\n",
      "         [0.2722],\n",
      "         [0.3662],\n",
      "         [0.3493],\n",
      "         [0.6544],\n",
      "         [0.1011],\n",
      "         [0.9443],\n",
      "         [0.8345],\n",
      "         [0.5354],\n",
      "         [0.4633],\n",
      "         [0.9043],\n",
      "         [0.6174],\n",
      "         [0.5863],\n",
      "         [0.5284],\n",
      "         [0.2201],\n",
      "         [0.8488],\n",
      "         [0.0206],\n",
      "         [0.4993],\n",
      "         [0.6815],\n",
      "         [0.5605],\n",
      "         [0.5229],\n",
      "         [0.2067],\n",
      "         [0.3970],\n",
      "         [0.7052],\n",
      "         [0.7183],\n",
      "         [0.8008],\n",
      "         [0.1465],\n",
      "         [0.3773],\n",
      "         [0.8211],\n",
      "         [0.7628],\n",
      "         [0.0499],\n",
      "         [0.2423],\n",
      "         [0.9626],\n",
      "         [0.1597],\n",
      "         [0.4140],\n",
      "         [0.8239],\n",
      "         [0.8311],\n",
      "         [0.5576],\n",
      "         [0.3938],\n",
      "         [0.9773],\n",
      "         [0.6662],\n",
      "         [0.5425],\n",
      "         [0.4244],\n",
      "         [0.9427],\n",
      "         [0.8350],\n",
      "         [0.3699],\n",
      "         [0.7396],\n",
      "         [0.6783],\n",
      "         [0.9858],\n",
      "         [0.7264],\n",
      "         [0.3631],\n",
      "         [0.8326],\n",
      "         [0.2727],\n",
      "         [0.9589],\n",
      "         [0.7966],\n",
      "         [0.6449],\n",
      "         [0.1620],\n",
      "         [0.1747],\n",
      "         [0.0511],\n",
      "         [0.2799],\n",
      "         [0.0378],\n",
      "         [0.4337],\n",
      "         [0.2759],\n",
      "         [0.7318],\n",
      "         [0.2032],\n",
      "         [0.9813],\n",
      "         [0.6831],\n",
      "         [0.0084],\n",
      "         [0.6781],\n",
      "         [0.2082],\n",
      "         [0.0579],\n",
      "         [0.4065],\n",
      "         [0.1346],\n",
      "         [0.1258],\n",
      "         [0.3002],\n",
      "         [0.6026],\n",
      "         [0.9572],\n",
      "         [0.3741],\n",
      "         [0.1595],\n",
      "         [0.6817],\n",
      "         [0.6747],\n",
      "         [0.4087],\n",
      "         [0.3980],\n",
      "         [0.7648],\n",
      "         [0.4820],\n",
      "         [0.4839],\n",
      "         [0.6670],\n",
      "         [0.7223],\n",
      "         [0.9822],\n",
      "         [0.5112],\n",
      "         [0.5931],\n",
      "         [0.9471],\n",
      "         [0.7176],\n",
      "         [0.8354],\n",
      "         [0.5793],\n",
      "         [0.0368],\n",
      "         [0.7740],\n",
      "         [0.7174],\n",
      "         [0.7458],\n",
      "         [0.1576],\n",
      "         [0.9169],\n",
      "         [0.0127],\n",
      "         [0.8007],\n",
      "         [0.8189],\n",
      "         [0.3681],\n",
      "         [0.8771],\n",
      "         [0.3190],\n",
      "         [0.8320],\n",
      "         [0.0675],\n",
      "         [0.0451]]], device='cuda:0', dtype=torch.float64)\n",
      "================iter 1============\n",
      "['shape/ellipsoid/1/ellipsoid_512_128_64_64_1_2_1']\n",
      "tensor([[False, False,  True, False, False, False, False,  True, False, False,\n",
      "         False, False, False, False, False,  True,  True, False, False, False]],\n",
      "       device='cuda:0')\n",
      "acc torch.Size([1]) tensor([0.0588], device='cuda:0')\n",
      "acc_per_part torch.Size([1, 20]) tensor([[False, False, False, False, False, False, False, False, False, False,\n",
      "         False, False, False, False, False,  True, False, False, False, False]],\n",
      "       device='cuda:0')\n",
      "loss_per_data torch.Size([1, 20]) tensor([[ 6.2302,  1.0264,  3.1242,  4.0388,  0.6604,  1.8299,  1.7724,  1.0607,\n",
      "          0.6783, 12.2282,  9.4797,  7.9979,  0.9316, 24.3641,  0.4376,  0.0000,\n",
      "          0.3449, 12.3284, 11.5551,  9.7756]], device='cuda:0')\n",
      "scores torch.Size([1, 190, 1]) tensor([[[0.7416],\n",
      "         [0.5357],\n",
      "         [0.7880],\n",
      "         [0.8501],\n",
      "         [0.2636],\n",
      "         [0.2468],\n",
      "         [0.3023],\n",
      "         [0.8620],\n",
      "         [0.2750],\n",
      "         [0.0041],\n",
      "         [0.6814],\n",
      "         [0.0320],\n",
      "         [0.5678],\n",
      "         [0.0289],\n",
      "         [0.0248],\n",
      "         [0.4552],\n",
      "         [0.0132],\n",
      "         [0.8601],\n",
      "         [0.7308],\n",
      "         [0.1140],\n",
      "         [0.1229],\n",
      "         [0.0060],\n",
      "         [0.7257],\n",
      "         [0.4155],\n",
      "         [0.1536],\n",
      "         [0.7706],\n",
      "         [0.9003],\n",
      "         [0.1080],\n",
      "         [0.0851],\n",
      "         [0.2078],\n",
      "         [0.3938],\n",
      "         [0.5453],\n",
      "         [0.1923],\n",
      "         [0.1019],\n",
      "         [0.5794],\n",
      "         [0.4888],\n",
      "         [0.0309],\n",
      "         [0.1015],\n",
      "         [0.1212],\n",
      "         [0.8253],\n",
      "         [0.8361],\n",
      "         [0.5036],\n",
      "         [0.2057],\n",
      "         [0.6398],\n",
      "         [0.1127],\n",
      "         [0.2982],\n",
      "         [0.8360],\n",
      "         [0.3249],\n",
      "         [0.6298],\n",
      "         [0.2211],\n",
      "         [0.4058],\n",
      "         [0.7258],\n",
      "         [0.9524],\n",
      "         [0.0710],\n",
      "         [0.5994],\n",
      "         [0.3856],\n",
      "         [0.8986],\n",
      "         [0.6045],\n",
      "         [0.1994],\n",
      "         [0.4939],\n",
      "         [0.5589],\n",
      "         [0.4568],\n",
      "         [0.2055],\n",
      "         [0.2851],\n",
      "         [0.4735],\n",
      "         [0.3112],\n",
      "         [0.7257],\n",
      "         [0.9298],\n",
      "         [0.4576],\n",
      "         [0.2430],\n",
      "         [0.1681],\n",
      "         [0.7402],\n",
      "         [0.8899],\n",
      "         [0.8184],\n",
      "         [0.7904],\n",
      "         [0.4016],\n",
      "         [0.1212],\n",
      "         [0.8299],\n",
      "         [0.0679],\n",
      "         [0.3869],\n",
      "         [0.1724],\n",
      "         [0.6808],\n",
      "         [0.6433],\n",
      "         [0.5558],\n",
      "         [0.5134],\n",
      "         [0.3640],\n",
      "         [0.3365],\n",
      "         [0.0385],\n",
      "         [0.9574],\n",
      "         [0.1527],\n",
      "         [0.9000],\n",
      "         [0.6759],\n",
      "         [0.6298],\n",
      "         [0.4241],\n",
      "         [0.3710],\n",
      "         [0.9425],\n",
      "         [0.6086],\n",
      "         [0.0429],\n",
      "         [0.9061],\n",
      "         [0.8059],\n",
      "         [0.8228],\n",
      "         [0.9839],\n",
      "         [0.0136],\n",
      "         [0.7232],\n",
      "         [0.0541],\n",
      "         [0.8891],\n",
      "         [0.4389],\n",
      "         [0.2654],\n",
      "         [0.6581],\n",
      "         [0.8993],\n",
      "         [0.0273],\n",
      "         [0.4334],\n",
      "         [0.4772],\n",
      "         [0.9428],\n",
      "         [0.8417],\n",
      "         [0.7948],\n",
      "         [0.7710],\n",
      "         [0.4959],\n",
      "         [0.5018],\n",
      "         [0.4621],\n",
      "         [0.5416],\n",
      "         [0.8343],\n",
      "         [0.0108],\n",
      "         [0.6895],\n",
      "         [0.1100],\n",
      "         [0.1705],\n",
      "         [0.5029],\n",
      "         [0.5662],\n",
      "         [0.2831],\n",
      "         [0.8729],\n",
      "         [0.5585],\n",
      "         [0.1237],\n",
      "         [0.4692],\n",
      "         [0.0260],\n",
      "         [0.8318],\n",
      "         [0.0521],\n",
      "         [0.5546],\n",
      "         [0.8213],\n",
      "         [0.3865],\n",
      "         [0.0329],\n",
      "         [0.6180],\n",
      "         [0.7686],\n",
      "         [0.6085],\n",
      "         [0.3000],\n",
      "         [0.7131],\n",
      "         [0.8243],\n",
      "         [0.5362],\n",
      "         [0.9275],\n",
      "         [0.1993],\n",
      "         [0.5546],\n",
      "         [0.1025],\n",
      "         [0.4112],\n",
      "         [0.9502],\n",
      "         [0.1526],\n",
      "         [0.1318],\n",
      "         [0.5800],\n",
      "         [0.8153],\n",
      "         [0.7272],\n",
      "         [0.4320],\n",
      "         [0.7695],\n",
      "         [0.5764],\n",
      "         [0.2648],\n",
      "         [0.8712],\n",
      "         [0.3172],\n",
      "         [0.7100],\n",
      "         [0.5039],\n",
      "         [0.9009],\n",
      "         [0.9930],\n",
      "         [0.0184],\n",
      "         [0.0743],\n",
      "         [0.1075],\n",
      "         [0.0742],\n",
      "         [0.8923],\n",
      "         [0.5081],\n",
      "         [0.0333],\n",
      "         [0.4267],\n",
      "         [0.3149],\n",
      "         [0.2148],\n",
      "         [0.3158],\n",
      "         [0.8462],\n",
      "         [0.7160],\n",
      "         [0.8142],\n",
      "         [0.4496],\n",
      "         [0.2572],\n",
      "         [0.2145],\n",
      "         [0.0339],\n",
      "         [0.9359],\n",
      "         [0.3116],\n",
      "         [0.2631],\n",
      "         [0.3791]]], device='cuda:0', dtype=torch.float64)\n",
      "================iter 2============\n",
      "['shape/ellipsoid/1/ellipsoid_512_128_64_64_1_2_1']\n",
      "tensor([[False, False,  True, False, False,  True, False,  True, False,  True,\n",
      "         False, False, False, False, False,  True,  True, False, False, False]],\n",
      "       device='cuda:0')\n",
      "acc torch.Size([1]) tensor([0.0588], device='cuda:0')\n",
      "acc_per_part torch.Size([1, 20]) tensor([[False, False, False, False, False, False, False, False, False, False,\n",
      "         False, False, False, False, False,  True, False, False, False, False]],\n",
      "       device='cuda:0')\n",
      "loss_per_data torch.Size([1, 20]) tensor([[7.0317e+00, 1.9184e+00, 3.1242e+00, 2.1076e+00, 6.5336e+00, 1.8299e+00,\n",
      "         1.6359e+00, 1.0607e+00, 6.8980e+00, 1.2228e+01, 3.6615e+01, 3.7030e+01,\n",
      "         7.2585e+00, 4.5032e+02, 2.1946e+00, 0.0000e+00, 3.4492e-01, 1.7281e+01,\n",
      "         1.8122e+01, 2.5090e+00]], device='cuda:0')\n",
      "scores torch.Size([1, 190, 1]) tensor([[[0.9215],\n",
      "         [0.7356],\n",
      "         [0.3897],\n",
      "         [0.9335],\n",
      "         [0.1090],\n",
      "         [0.6702],\n",
      "         [0.7616],\n",
      "         [0.4991],\n",
      "         [0.7716],\n",
      "         [0.5468],\n",
      "         [0.6679],\n",
      "         [0.6244],\n",
      "         [0.7541],\n",
      "         [0.6142],\n",
      "         [0.5771],\n",
      "         [0.5629],\n",
      "         [0.8631],\n",
      "         [0.2643],\n",
      "         [0.4421],\n",
      "         [0.2880],\n",
      "         [0.3638],\n",
      "         [0.8591],\n",
      "         [0.2032],\n",
      "         [0.2024],\n",
      "         [0.9306],\n",
      "         [0.1513],\n",
      "         [0.8373],\n",
      "         [0.4161],\n",
      "         [0.9725],\n",
      "         [0.8126],\n",
      "         [0.2258],\n",
      "         [0.9407],\n",
      "         [0.5830],\n",
      "         [0.4570],\n",
      "         [0.4749],\n",
      "         [0.5624],\n",
      "         [0.8331],\n",
      "         [0.4765],\n",
      "         [0.1935],\n",
      "         [0.7356],\n",
      "         [0.4812],\n",
      "         [0.9633],\n",
      "         [0.0561],\n",
      "         [0.6044],\n",
      "         [0.8859],\n",
      "         [0.2115],\n",
      "         [0.7500],\n",
      "         [0.9287],\n",
      "         [0.8169],\n",
      "         [0.2467],\n",
      "         [0.7645],\n",
      "         [0.0198],\n",
      "         [0.9707],\n",
      "         [0.8843],\n",
      "         [0.4179],\n",
      "         [0.1664],\n",
      "         [0.4773],\n",
      "         [0.7378],\n",
      "         [0.5044],\n",
      "         [0.4188],\n",
      "         [0.7582],\n",
      "         [0.4641],\n",
      "         [0.9854],\n",
      "         [0.5550],\n",
      "         [0.5071],\n",
      "         [0.9976],\n",
      "         [0.7533],\n",
      "         [0.6989],\n",
      "         [0.8142],\n",
      "         [0.2947],\n",
      "         [0.1548],\n",
      "         [0.0145],\n",
      "         [0.0508],\n",
      "         [0.7621],\n",
      "         [0.9631],\n",
      "         [0.4043],\n",
      "         [0.8944],\n",
      "         [0.6956],\n",
      "         [0.0986],\n",
      "         [0.3531],\n",
      "         [0.3073],\n",
      "         [0.0770],\n",
      "         [0.8942],\n",
      "         [0.2811],\n",
      "         [0.0968],\n",
      "         [0.2786],\n",
      "         [0.3360],\n",
      "         [0.8854],\n",
      "         [0.8210],\n",
      "         [0.5299],\n",
      "         [0.8879],\n",
      "         [0.2179],\n",
      "         [0.6485],\n",
      "         [0.1094],\n",
      "         [0.5332],\n",
      "         [0.9958],\n",
      "         [0.6122],\n",
      "         [0.5962],\n",
      "         [0.2252],\n",
      "         [0.9975],\n",
      "         [0.4968],\n",
      "         [0.1465],\n",
      "         [0.7912],\n",
      "         [0.4412],\n",
      "         [0.9095],\n",
      "         [0.5976],\n",
      "         [0.6862],\n",
      "         [0.0283],\n",
      "         [0.7285],\n",
      "         [0.9409],\n",
      "         [0.9265],\n",
      "         [0.2561],\n",
      "         [0.0905],\n",
      "         [0.8023],\n",
      "         [0.1735],\n",
      "         [0.0870],\n",
      "         [0.0355],\n",
      "         [0.9122],\n",
      "         [0.3970],\n",
      "         [0.0655],\n",
      "         [0.0865],\n",
      "         [0.4352],\n",
      "         [0.7586],\n",
      "         [0.5832],\n",
      "         [0.9074],\n",
      "         [0.1412],\n",
      "         [0.6918],\n",
      "         [0.9163],\n",
      "         [0.7457],\n",
      "         [0.2617],\n",
      "         [0.0955],\n",
      "         [0.5886],\n",
      "         [0.9665],\n",
      "         [0.5371],\n",
      "         [0.5331],\n",
      "         [0.5051],\n",
      "         [0.4455],\n",
      "         [0.4177],\n",
      "         [0.7859],\n",
      "         [0.0011],\n",
      "         [0.7296],\n",
      "         [0.6564],\n",
      "         [0.7578],\n",
      "         [0.1216],\n",
      "         [0.9122],\n",
      "         [0.0796],\n",
      "         [0.1400],\n",
      "         [0.0736],\n",
      "         [0.3506],\n",
      "         [0.6357],\n",
      "         [0.1222],\n",
      "         [0.7722],\n",
      "         [0.3573],\n",
      "         [0.0276],\n",
      "         [0.5212],\n",
      "         [0.7368],\n",
      "         [0.9968],\n",
      "         [0.7572],\n",
      "         [0.2546],\n",
      "         [0.6759],\n",
      "         [0.8479],\n",
      "         [0.0370],\n",
      "         [0.4555],\n",
      "         [0.1244],\n",
      "         [0.4714],\n",
      "         [0.4696],\n",
      "         [0.9045],\n",
      "         [0.3615],\n",
      "         [0.4257],\n",
      "         [0.6795],\n",
      "         [0.1287],\n",
      "         [0.5520],\n",
      "         [0.7165],\n",
      "         [0.7626],\n",
      "         [0.0398],\n",
      "         [0.6536],\n",
      "         [0.4792],\n",
      "         [0.0079],\n",
      "         [0.2196],\n",
      "         [0.9563],\n",
      "         [0.7111],\n",
      "         [0.4445],\n",
      "         [0.5868],\n",
      "         [0.1540],\n",
      "         [0.5978],\n",
      "         [0.4119],\n",
      "         [0.3012],\n",
      "         [0.7083],\n",
      "         [0.8156],\n",
      "         [0.1651]]], device='cuda:0', dtype=torch.float64)\n",
      "================iter 3============\n",
      "['shape/ellipsoid/1/ellipsoid_512_128_64_64_1_2_1']\n",
      "tensor([[False,  True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
      "         False, False, False,  True, False,  True,  True, False, False, False]],\n",
      "       device='cuda:0')\n",
      "acc torch.Size([1]) tensor([0.0588], device='cuda:0')\n",
      "acc_per_part torch.Size([1, 20]) tensor([[False, False, False, False, False, False, False, False, False, False,\n",
      "         False, False, False, False, False,  True, False, False, False, False]],\n",
      "       device='cuda:0')\n",
      "loss_per_data torch.Size([1, 20]) tensor([[1.4314e+01, 1.9184e+00, 3.1242e+00, 2.1076e+00, 6.5336e+00, 1.8299e+00,\n",
      "         1.6359e+00, 1.0607e+00, 6.8980e+00, 1.2228e+01, 7.2038e+01, 7.8040e+01,\n",
      "         4.2367e+01, 4.5032e+02, 2.5428e+00, 0.0000e+00, 3.4492e-01, 8.2787e+01,\n",
      "         5.9392e+01, 7.1145e+00]], device='cuda:0')\n",
      "scores torch.Size([1, 190, 1]) tensor([[[0.7237],\n",
      "         [0.2330],\n",
      "         [0.2998],\n",
      "         [0.2150],\n",
      "         [0.6657],\n",
      "         [0.0210],\n",
      "         [0.5145],\n",
      "         [0.7964],\n",
      "         [0.2451],\n",
      "         [0.8030],\n",
      "         [0.5016],\n",
      "         [0.1426],\n",
      "         [0.1612],\n",
      "         [0.3131],\n",
      "         [0.8150],\n",
      "         [0.7661],\n",
      "         [0.8035],\n",
      "         [0.6285],\n",
      "         [0.2681],\n",
      "         [0.6237],\n",
      "         [0.0636],\n",
      "         [0.2402],\n",
      "         [0.5549],\n",
      "         [0.3738],\n",
      "         [0.7322],\n",
      "         [0.6338],\n",
      "         [0.8443],\n",
      "         [0.6439],\n",
      "         [0.4332],\n",
      "         [0.4937],\n",
      "         [0.6130],\n",
      "         [0.2261],\n",
      "         [0.5015],\n",
      "         [0.1856],\n",
      "         [0.8674],\n",
      "         [0.6155],\n",
      "         [0.1807],\n",
      "         [0.1619],\n",
      "         [0.4684],\n",
      "         [0.9265],\n",
      "         [0.3567],\n",
      "         [0.9752],\n",
      "         [0.4270],\n",
      "         [0.5913],\n",
      "         [0.2683],\n",
      "         [0.0567],\n",
      "         [0.7750],\n",
      "         [0.1570],\n",
      "         [0.8631],\n",
      "         [0.4760],\n",
      "         [0.4368],\n",
      "         [0.7138],\n",
      "         [0.5321],\n",
      "         [0.0229],\n",
      "         [0.1069],\n",
      "         [0.7895],\n",
      "         [0.7909],\n",
      "         [0.6931],\n",
      "         [0.1849],\n",
      "         [0.4469],\n",
      "         [0.4803],\n",
      "         [0.6436],\n",
      "         [0.7862],\n",
      "         [0.5874],\n",
      "         [0.2186],\n",
      "         [0.0694],\n",
      "         [0.3429],\n",
      "         [0.7102],\n",
      "         [0.4482],\n",
      "         [0.6897],\n",
      "         [0.3081],\n",
      "         [0.6330],\n",
      "         [0.3256],\n",
      "         [0.8370],\n",
      "         [0.2303],\n",
      "         [0.8039],\n",
      "         [0.7715],\n",
      "         [0.0337],\n",
      "         [0.2991],\n",
      "         [0.1583],\n",
      "         [0.1156],\n",
      "         [0.0637],\n",
      "         [0.6254],\n",
      "         [0.1186],\n",
      "         [0.6188],\n",
      "         [0.3132],\n",
      "         [0.1698],\n",
      "         [0.4690],\n",
      "         [0.1069],\n",
      "         [0.0354],\n",
      "         [0.5179],\n",
      "         [0.4862],\n",
      "         [0.5393],\n",
      "         [0.4822],\n",
      "         [0.2705],\n",
      "         [0.1629],\n",
      "         [0.5123],\n",
      "         [0.0081],\n",
      "         [0.8396],\n",
      "         [0.4695],\n",
      "         [0.9892],\n",
      "         [0.3092],\n",
      "         [0.0685],\n",
      "         [0.7601],\n",
      "         [0.6550],\n",
      "         [0.4467],\n",
      "         [0.3949],\n",
      "         [0.5814],\n",
      "         [0.9105],\n",
      "         [0.1241],\n",
      "         [0.5929],\n",
      "         [0.0344],\n",
      "         [0.5863],\n",
      "         [0.2915],\n",
      "         [0.2307],\n",
      "         [0.2698],\n",
      "         [0.8148],\n",
      "         [0.9769],\n",
      "         [0.2774],\n",
      "         [0.1285],\n",
      "         [0.0022],\n",
      "         [0.4265],\n",
      "         [0.0546],\n",
      "         [0.1714],\n",
      "         [0.5482],\n",
      "         [0.2307],\n",
      "         [0.9195],\n",
      "         [0.5574],\n",
      "         [0.4103],\n",
      "         [0.4590],\n",
      "         [0.8775],\n",
      "         [0.0140],\n",
      "         [0.4687],\n",
      "         [0.3486],\n",
      "         [0.5922],\n",
      "         [0.3285],\n",
      "         [0.7293],\n",
      "         [0.5231],\n",
      "         [0.7461],\n",
      "         [0.3140],\n",
      "         [0.3708],\n",
      "         [0.2215],\n",
      "         [0.3619],\n",
      "         [0.6456],\n",
      "         [0.4079],\n",
      "         [0.6960],\n",
      "         [0.2227],\n",
      "         [0.1064],\n",
      "         [0.3797],\n",
      "         [0.0955],\n",
      "         [0.1838],\n",
      "         [0.4862],\n",
      "         [0.2405],\n",
      "         [0.7826],\n",
      "         [0.1605],\n",
      "         [0.9437],\n",
      "         [0.9332],\n",
      "         [0.1924],\n",
      "         [0.2893],\n",
      "         [0.0375],\n",
      "         [0.0818],\n",
      "         [0.6822],\n",
      "         [0.6890],\n",
      "         [0.4698],\n",
      "         [0.7068],\n",
      "         [0.0850],\n",
      "         [0.3901],\n",
      "         [0.3605],\n",
      "         [0.8700],\n",
      "         [0.6004],\n",
      "         [0.7679],\n",
      "         [0.5648],\n",
      "         [0.0854],\n",
      "         [0.3134],\n",
      "         [0.7966],\n",
      "         [0.3519],\n",
      "         [0.9141],\n",
      "         [0.8122],\n",
      "         [0.0742],\n",
      "         [0.4685],\n",
      "         [0.7785],\n",
      "         [0.1639],\n",
      "         [0.2352],\n",
      "         [0.1696],\n",
      "         [0.9142],\n",
      "         [0.6061],\n",
      "         [0.0734],\n",
      "         [0.5789],\n",
      "         [0.6022],\n",
      "         [0.9167]]], device='cuda:0', dtype=torch.float64)\n",
      "================iter 4============\n",
      "['shape/ellipsoid/1/ellipsoid_512_128_64_64_1_2_1']\n",
      "tensor([[False,  True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
      "         False,  True, False,  True,  True,  True,  True, False, False, False]],\n",
      "       device='cuda:0')\n",
      "acc torch.Size([1]) tensor([0.0588], device='cuda:0')\n",
      "acc_per_part torch.Size([1, 20]) tensor([[False, False, False, False, False, False, False, False, False, False,\n",
      "         False, False, False, False, False,  True, False, False, False, False]],\n",
      "       device='cuda:0')\n",
      "loss_per_data torch.Size([1, 20]) tensor([[1.5516e+01, 1.9184e+00, 3.1242e+00, 2.1076e+00, 6.5336e+00, 1.8299e+00,\n",
      "         1.6359e+00, 1.0607e+00, 6.8980e+00, 1.2228e+01, 1.3161e+02, 7.8040e+01,\n",
      "         5.5104e+01, 4.5032e+02, 2.5428e+00, 0.0000e+00, 3.4492e-01, 1.5210e+02,\n",
      "         8.7623e+01, 2.0904e+01]], device='cuda:0')\n",
      "scores torch.Size([1, 190, 1]) tensor([[[0.4642],\n",
      "         [0.3492],\n",
      "         [0.6781],\n",
      "         [0.1153],\n",
      "         [0.6475],\n",
      "         [0.3428],\n",
      "         [0.7525],\n",
      "         [0.7385],\n",
      "         [0.6923],\n",
      "         [0.0744],\n",
      "         [0.7928],\n",
      "         [0.0206],\n",
      "         [0.7148],\n",
      "         [0.5103],\n",
      "         [0.0054],\n",
      "         [0.1798],\n",
      "         [0.0810],\n",
      "         [0.2791],\n",
      "         [0.3898],\n",
      "         [0.3978],\n",
      "         [0.1573],\n",
      "         [0.5645],\n",
      "         [0.6460],\n",
      "         [0.3752],\n",
      "         [0.1646],\n",
      "         [0.9893],\n",
      "         [0.1887],\n",
      "         [0.9195],\n",
      "         [0.4512],\n",
      "         [0.0511],\n",
      "         [0.8904],\n",
      "         [0.5945],\n",
      "         [0.7677],\n",
      "         [0.0752],\n",
      "         [0.2775],\n",
      "         [0.3954],\n",
      "         [0.5835],\n",
      "         [0.8431],\n",
      "         [0.1946],\n",
      "         [0.5502],\n",
      "         [0.0921],\n",
      "         [0.1998],\n",
      "         [0.5752],\n",
      "         [0.6576],\n",
      "         [0.2521],\n",
      "         [0.2847],\n",
      "         [0.8027],\n",
      "         [0.2854],\n",
      "         [0.6308],\n",
      "         [0.2665],\n",
      "         [0.6699],\n",
      "         [0.9464],\n",
      "         [0.5053],\n",
      "         [0.8149],\n",
      "         [0.1994],\n",
      "         [0.6157],\n",
      "         [0.7503],\n",
      "         [0.1180],\n",
      "         [0.8876],\n",
      "         [0.3706],\n",
      "         [0.0733],\n",
      "         [0.5614],\n",
      "         [0.5260],\n",
      "         [0.7779],\n",
      "         [0.8955],\n",
      "         [0.5543],\n",
      "         [0.5510],\n",
      "         [0.6267],\n",
      "         [0.7033],\n",
      "         [0.5246],\n",
      "         [0.9078],\n",
      "         [0.9756],\n",
      "         [0.2959],\n",
      "         [0.3736],\n",
      "         [0.3818],\n",
      "         [0.9007],\n",
      "         [0.0833],\n",
      "         [0.5761],\n",
      "         [0.9922],\n",
      "         [0.9109],\n",
      "         [0.7264],\n",
      "         [0.7349],\n",
      "         [0.8691],\n",
      "         [0.6327],\n",
      "         [0.1475],\n",
      "         [0.8633],\n",
      "         [0.4445],\n",
      "         [0.7096],\n",
      "         [0.1998],\n",
      "         [0.0255],\n",
      "         [0.6158],\n",
      "         [0.6496],\n",
      "         [0.9827],\n",
      "         [0.4692],\n",
      "         [0.6613],\n",
      "         [0.5959],\n",
      "         [0.2262],\n",
      "         [0.4935],\n",
      "         [0.3729],\n",
      "         [0.2975],\n",
      "         [0.1120],\n",
      "         [0.8169],\n",
      "         [0.9323],\n",
      "         [0.3615],\n",
      "         [0.9105],\n",
      "         [0.4340],\n",
      "         [0.1315],\n",
      "         [0.8569],\n",
      "         [0.7950],\n",
      "         [0.4507],\n",
      "         [0.8486],\n",
      "         [0.8220],\n",
      "         [0.8675],\n",
      "         [0.0752],\n",
      "         [0.9711],\n",
      "         [0.3781],\n",
      "         [0.7802],\n",
      "         [0.3497],\n",
      "         [0.9518],\n",
      "         [0.8002],\n",
      "         [0.9791],\n",
      "         [0.7275],\n",
      "         [0.4908],\n",
      "         [0.7360],\n",
      "         [0.6793],\n",
      "         [0.7462],\n",
      "         [0.0977],\n",
      "         [0.2935],\n",
      "         [0.7463],\n",
      "         [0.5589],\n",
      "         [0.2647],\n",
      "         [0.7162],\n",
      "         [0.9270],\n",
      "         [0.9067],\n",
      "         [0.3598],\n",
      "         [0.3911],\n",
      "         [0.5037],\n",
      "         [0.4853],\n",
      "         [0.6008],\n",
      "         [0.0370],\n",
      "         [0.4248],\n",
      "         [0.0698],\n",
      "         [0.6534],\n",
      "         [0.3821],\n",
      "         [0.7741],\n",
      "         [0.1464],\n",
      "         [0.7515],\n",
      "         [0.6068],\n",
      "         [0.8370],\n",
      "         [0.2219],\n",
      "         [0.8588],\n",
      "         [0.0090],\n",
      "         [0.9558],\n",
      "         [0.5592],\n",
      "         [0.6026],\n",
      "         [0.3499],\n",
      "         [0.2025],\n",
      "         [0.3240],\n",
      "         [0.0156],\n",
      "         [0.7049],\n",
      "         [0.8295],\n",
      "         [0.2471],\n",
      "         [0.8986],\n",
      "         [0.5180],\n",
      "         [0.4161],\n",
      "         [0.4329],\n",
      "         [0.3658],\n",
      "         [0.7183],\n",
      "         [0.6769],\n",
      "         [0.4506],\n",
      "         [0.9565],\n",
      "         [0.2198],\n",
      "         [0.7312],\n",
      "         [0.4813],\n",
      "         [0.1196],\n",
      "         [0.3872],\n",
      "         [0.2307],\n",
      "         [0.3281],\n",
      "         [0.6699],\n",
      "         [0.4068],\n",
      "         [0.5654],\n",
      "         [0.1878],\n",
      "         [0.5031],\n",
      "         [0.5277],\n",
      "         [0.0478],\n",
      "         [0.3715],\n",
      "         [0.1791],\n",
      "         [0.4454],\n",
      "         [0.4473],\n",
      "         [0.5331]]], device='cuda:0', dtype=torch.float64)\n",
      "================iter 5============\n",
      "['shape/ellipsoid/1/ellipsoid_512_128_64_64_1_2_1']\n",
      "tensor([[False,  True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
      "          True,  True,  True,  True,  True,  True,  True, False, False, False]],\n",
      "       device='cuda:0')\n",
      "@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@\n",
      "['shape/ellipsoid/1/ellipsoid_512_128_64_64_1_3_1']\n",
      "gt_trans_torch.Size([1, 20, 3])_tensor([[[-1.9845e-01,  2.8193e-02,  1.8542e-02],\n",
      "         [-1.8265e-01,  3.5148e-02,  8.3595e-03],\n",
      "         [ 5.7190e-02, -1.5510e-02, -8.3963e-03],\n",
      "         [ 7.7724e-02, -1.4310e-02,  3.0629e-03],\n",
      "         [ 1.1741e-01, -3.4617e-02, -1.6607e-02],\n",
      "         [ 1.4351e-01, -3.9765e-02, -9.7605e-03],\n",
      "         [ 1.6472e-01, -3.8759e-02, -1.5587e-02],\n",
      "         [ 1.8951e-01, -4.2550e-02, -2.2385e-02],\n",
      "         [ 2.2510e-01, -5.8139e-02, -1.9485e-02],\n",
      "         [ 2.5187e-01, -6.3945e-02, -2.0194e-02],\n",
      "         [-1.5097e-01,  2.3458e-02,  5.6720e-03],\n",
      "         [-1.2636e-01,  2.0126e-02,  9.5803e-03],\n",
      "         [-9.4203e-02,  8.3578e-03,  5.6124e-03],\n",
      "         [-6.2372e-02, -3.3589e-03,  9.1414e-03],\n",
      "         [-4.6626e-02,  3.4860e-03,  8.9978e-03],\n",
      "         [-1.4124e-02, -9.0570e-03,  8.4842e-03],\n",
      "         [-7.3275e-18,  6.4393e-18,  4.9960e-18],\n",
      "         [ 3.5900e-02, -1.6607e-02, -6.9600e-03],\n",
      "         [ 0.0000e+00,  0.0000e+00,  0.0000e+00],\n",
      "         [ 0.0000e+00,  0.0000e+00,  0.0000e+00]]], device='cuda:0')\n",
      "gt_rots_torch.Size([1, 20, 4])_tensor([[[ 0.2339, -0.4234,  0.8749,  0.0221],\n",
      "         [-0.5106, -0.4259,  0.6866, -0.2940],\n",
      "         [-0.5103, -0.4268,  0.2391,  0.7073],\n",
      "         [ 0.5883, -0.2366,  0.6544, -0.4120],\n",
      "         [ 0.2498, -0.2933, -0.2394,  0.8912],\n",
      "         [ 0.8084,  0.5599,  0.0840,  0.1613],\n",
      "         [-0.6587,  0.2160,  0.1499,  0.7050],\n",
      "         [ 0.0568, -0.4265, -0.2273,  0.8736],\n",
      "         [-0.1514, -0.4851,  0.4834,  0.7128],\n",
      "         [-0.3950,  0.0663,  0.9152,  0.0451],\n",
      "         [-0.0854, -0.2128,  0.7463, -0.6249],\n",
      "         [ 0.5406,  0.5878, -0.5551, -0.2327],\n",
      "         [-0.4505,  0.2588,  0.6975, -0.4936],\n",
      "         [ 0.4234,  0.3897,  0.2158,  0.7889],\n",
      "         [-0.1600,  0.8714, -0.3720, -0.2769],\n",
      "         [-0.2703,  0.8300,  0.1943,  0.4476],\n",
      "         [-0.1132,  0.1707,  0.8177,  0.5380],\n",
      "         [-0.4833, -0.3198,  0.2448,  0.7773],\n",
      "         [ 0.0000,  0.0000,  0.0000,  0.0000],\n",
      "         [ 0.0000,  0.0000,  0.0000,  0.0000]]], device='cuda:0')\n",
      "noisy_trans_and_rots_torch.Size([1, 20, 7])_tensor([[[-0.5196,  0.0000, -2.1778,  1.3530,  0.0000,  0.0000, -0.0738],\n",
      "         [-1.0738,  0.0000,  0.4768, -0.5500,  0.0000,  0.0000, -1.8407],\n",
      "         [-0.3352,  0.0000, -0.0534,  0.1566,  0.0000,  0.0000,  0.7015],\n",
      "         [-0.6622,  0.0000, -0.0326,  0.1471,  0.0000,  0.0000,  0.0390],\n",
      "         [ 1.4074,  0.0000,  0.3340,  0.7474,  0.0000,  0.0000, -1.6031],\n",
      "         [ 1.8827,  0.0000,  0.3097, -0.4239,  0.0000,  0.0000,  0.3707],\n",
      "         [-0.6592,  0.0000, -0.7903, -0.1723,  0.0000,  0.0000, -1.3618],\n",
      "         [ 1.1588,  0.0000,  0.7617, -0.2550,  0.0000,  0.0000,  0.0054],\n",
      "         [-0.2663,  0.0000,  1.5148, -2.7319,  0.0000,  0.0000, -1.3378],\n",
      "         [-1.6010,  0.0000,  0.5586, -0.5705,  0.0000,  0.0000, -0.8377],\n",
      "         [-0.3773,  0.0000,  1.9061, -0.2334,  0.0000,  0.0000, -0.7273],\n",
      "         [ 2.1469,  0.0000, -0.6964,  1.4515,  0.0000,  0.0000,  0.9827],\n",
      "         [ 0.4721,  0.0000,  1.2078, -0.0130,  0.0000,  0.0000, -0.0205],\n",
      "         [-0.8887,  0.0000,  0.5635, -1.2712,  0.0000,  0.0000, -0.7968],\n",
      "         [-1.5993,  0.0000, -1.2943,  1.3058,  0.0000,  0.0000, -0.9729],\n",
      "         [-0.6362,  0.0000, -0.4387, -1.3465,  0.0000,  0.0000,  1.6080],\n",
      "         [ 1.1083,  0.0000,  0.1937,  0.0338,  0.0000,  0.0000, -0.3328],\n",
      "         [-1.6243,  0.0000, -0.2462,  0.3462,  0.0000,  0.0000, -1.0512],\n",
      "         [-0.5579,  0.0000,  1.2300, -1.0413,  0.0000,  0.0000, -0.7712],\n",
      "         [-0.3657,  0.0000,  0.1651, -0.1867,  0.0000,  0.0000, -0.9044]]],\n",
      "       device='cuda:0')\n",
      "================iter 0============\n",
      "['shape/ellipsoid/1/ellipsoid_512_128_64_64_1_3_1']\n",
      "tensor([[False, False, False, False, False, False, False, False, False, False,\n",
      "         False, False, False, False, False, False,  True, False, False, False]],\n",
      "       device='cuda:0')\n",
      "acc torch.Size([1]) tensor([0.0556], device='cuda:0')\n",
      "acc_per_part torch.Size([1, 20]) tensor([[False, False, False, False, False, False, False, False, False, False,\n",
      "         False, False, False, False, False, False,  True, False, False, False]],\n",
      "       device='cuda:0')\n",
      "loss_per_data torch.Size([1, 20]) tensor([[ 0.1508,  0.3866,  1.8482,  1.2896,  3.7095,  1.4170,  4.1835,  1.7461,\n",
      "          0.7752,  1.3665, 19.1333,  4.6476,  1.4822,  0.5796, 17.7144,  1.3580,\n",
      "          0.0000,  4.6078,  1.5059,  2.3198]], device='cuda:0')\n",
      "scores torch.Size([1, 190, 1]) tensor([[[0.4542],\n",
      "         [0.9977],\n",
      "         [0.3733],\n",
      "         [0.5431],\n",
      "         [0.0742],\n",
      "         [0.5396],\n",
      "         [0.8589],\n",
      "         [0.2066],\n",
      "         [0.7369],\n",
      "         [0.0325],\n",
      "         [0.0191],\n",
      "         [0.2265],\n",
      "         [0.3495],\n",
      "         [0.8508],\n",
      "         [0.6195],\n",
      "         [0.8511],\n",
      "         [0.1667],\n",
      "         [0.3203],\n",
      "         [0.4423],\n",
      "         [0.0271],\n",
      "         [0.8127],\n",
      "         [0.2579],\n",
      "         [0.3234],\n",
      "         [0.4022],\n",
      "         [0.6507],\n",
      "         [0.3328],\n",
      "         [0.2895],\n",
      "         [0.8644],\n",
      "         [0.9320],\n",
      "         [0.9520],\n",
      "         [0.9009],\n",
      "         [0.2118],\n",
      "         [0.8482],\n",
      "         [0.1924],\n",
      "         [0.0283],\n",
      "         [0.7745],\n",
      "         [0.8122],\n",
      "         [0.6372],\n",
      "         [0.7008],\n",
      "         [0.8996],\n",
      "         [0.1653],\n",
      "         [0.1261],\n",
      "         [0.3572],\n",
      "         [0.2403],\n",
      "         [0.9078],\n",
      "         [0.3548],\n",
      "         [0.3800],\n",
      "         [0.1084],\n",
      "         [0.7470],\n",
      "         [0.4397],\n",
      "         [0.6843],\n",
      "         [0.9683],\n",
      "         [0.3730],\n",
      "         [0.8447],\n",
      "         [0.2775],\n",
      "         [0.3508],\n",
      "         [0.6296],\n",
      "         [0.9348],\n",
      "         [0.3246],\n",
      "         [0.2903],\n",
      "         [0.2563],\n",
      "         [0.9737],\n",
      "         [0.2383],\n",
      "         [0.2818],\n",
      "         [0.1638],\n",
      "         [0.2698],\n",
      "         [0.9949],\n",
      "         [0.6903],\n",
      "         [0.3424],\n",
      "         [0.1765],\n",
      "         [0.6752],\n",
      "         [0.5566],\n",
      "         [0.1568],\n",
      "         [0.5578],\n",
      "         [0.1484],\n",
      "         [0.8104],\n",
      "         [0.1552],\n",
      "         [0.5650],\n",
      "         [0.1424],\n",
      "         [0.9006],\n",
      "         [0.3764],\n",
      "         [0.8998],\n",
      "         [0.1008],\n",
      "         [0.5508],\n",
      "         [0.3276],\n",
      "         [0.3008],\n",
      "         [0.6481],\n",
      "         [0.5632],\n",
      "         [0.5128],\n",
      "         [0.5696],\n",
      "         [0.0526],\n",
      "         [0.1661],\n",
      "         [0.2098],\n",
      "         [0.6865],\n",
      "         [0.0868],\n",
      "         [0.9875],\n",
      "         [0.1985],\n",
      "         [0.6269],\n",
      "         [0.3799],\n",
      "         [0.3640],\n",
      "         [0.5291],\n",
      "         [0.1337],\n",
      "         [0.1094],\n",
      "         [0.2529],\n",
      "         [0.2088],\n",
      "         [0.3910],\n",
      "         [0.2907],\n",
      "         [0.1781],\n",
      "         [0.6662],\n",
      "         [0.3732],\n",
      "         [0.7048],\n",
      "         [0.2095],\n",
      "         [0.6939],\n",
      "         [0.9733],\n",
      "         [0.7609],\n",
      "         [0.3545],\n",
      "         [0.7185],\n",
      "         [0.1693],\n",
      "         [0.4125],\n",
      "         [0.8425],\n",
      "         [0.7289],\n",
      "         [0.8208],\n",
      "         [0.3792],\n",
      "         [0.3741],\n",
      "         [0.7983],\n",
      "         [0.2890],\n",
      "         [0.2850],\n",
      "         [0.1466],\n",
      "         [0.9617],\n",
      "         [0.0877],\n",
      "         [0.9559],\n",
      "         [0.1750],\n",
      "         [0.4597],\n",
      "         [0.8978],\n",
      "         [0.3474],\n",
      "         [0.0766],\n",
      "         [0.5761],\n",
      "         [0.4962],\n",
      "         [0.0171],\n",
      "         [0.9215],\n",
      "         [0.6145],\n",
      "         [0.2057],\n",
      "         [0.6560],\n",
      "         [0.9870],\n",
      "         [0.3721],\n",
      "         [0.9592],\n",
      "         [0.7614],\n",
      "         [0.4354],\n",
      "         [0.2126],\n",
      "         [0.3016],\n",
      "         [0.1136],\n",
      "         [0.5737],\n",
      "         [0.1198],\n",
      "         [0.2623],\n",
      "         [0.4754],\n",
      "         [0.8327],\n",
      "         [0.1454],\n",
      "         [0.1566],\n",
      "         [0.7506],\n",
      "         [0.0289],\n",
      "         [0.5712],\n",
      "         [0.3248],\n",
      "         [0.8554],\n",
      "         [0.1630],\n",
      "         [0.8546],\n",
      "         [0.4958],\n",
      "         [0.3534],\n",
      "         [0.7694],\n",
      "         [0.5982],\n",
      "         [0.5790],\n",
      "         [0.0493],\n",
      "         [0.9670],\n",
      "         [0.3349],\n",
      "         [0.7509],\n",
      "         [0.4693],\n",
      "         [0.2990],\n",
      "         [0.9966],\n",
      "         [0.3027],\n",
      "         [0.3252],\n",
      "         [0.9874],\n",
      "         [0.6046],\n",
      "         [0.6987],\n",
      "         [0.6827],\n",
      "         [0.8529],\n",
      "         [0.1865],\n",
      "         [0.0402],\n",
      "         [0.1057],\n",
      "         [0.9562],\n",
      "         [0.0113],\n",
      "         [0.5582]]], device='cuda:0', dtype=torch.float64)\n",
      "================iter 1============\n",
      "['shape/ellipsoid/1/ellipsoid_512_128_64_64_1_3_1']\n",
      "tensor([[False, False, False,  True, False,  True, False, False, False, False,\n",
      "         False, False, False,  True,  True, False,  True, False, False, False]],\n",
      "       device='cuda:0')\n",
      "acc torch.Size([1]) tensor([0.0556], device='cuda:0')\n",
      "acc_per_part torch.Size([1, 20]) tensor([[False, False, False, False, False, False, False, False, False, False,\n",
      "         False, False, False, False, False, False,  True, False, False, False]],\n",
      "       device='cuda:0')\n",
      "loss_per_data torch.Size([1, 20]) tensor([[ 1.2682,  1.6054,  3.4218,  1.2896,  2.6126,  1.4170,  6.3370, 20.1874,\n",
      "          7.2523,  0.1035, 26.3604,  0.8851,  3.6767,  0.5796, 17.7144,  2.1901,\n",
      "          0.0000, 11.6594,  0.2919,  1.1309]], device='cuda:0')\n",
      "scores torch.Size([1, 190, 1]) tensor([[[0.6407],\n",
      "         [0.0992],\n",
      "         [0.1767],\n",
      "         [0.3660],\n",
      "         [0.4669],\n",
      "         [0.7146],\n",
      "         [0.7399],\n",
      "         [0.8233],\n",
      "         [0.0830],\n",
      "         [0.0784],\n",
      "         [0.9172],\n",
      "         [0.2212],\n",
      "         [0.7538],\n",
      "         [0.0430],\n",
      "         [0.3292],\n",
      "         [0.2438],\n",
      "         [0.7462],\n",
      "         [0.4628],\n",
      "         [0.3312],\n",
      "         [0.7930],\n",
      "         [0.5555],\n",
      "         [0.7119],\n",
      "         [0.6663],\n",
      "         [0.2222],\n",
      "         [0.4392],\n",
      "         [0.2091],\n",
      "         [0.2496],\n",
      "         [0.4398],\n",
      "         [0.8696],\n",
      "         [0.6298],\n",
      "         [0.4061],\n",
      "         [0.5129],\n",
      "         [0.4546],\n",
      "         [0.1264],\n",
      "         [0.7205],\n",
      "         [0.4663],\n",
      "         [0.9110],\n",
      "         [0.4542],\n",
      "         [0.4374],\n",
      "         [0.0187],\n",
      "         [0.2720],\n",
      "         [0.5535],\n",
      "         [0.7140],\n",
      "         [0.4245],\n",
      "         [0.0620],\n",
      "         [0.1488],\n",
      "         [0.8594],\n",
      "         [0.0593],\n",
      "         [0.2001],\n",
      "         [0.0433],\n",
      "         [0.7362],\n",
      "         [0.2575],\n",
      "         [0.0478],\n",
      "         [0.6067],\n",
      "         [0.7384],\n",
      "         [0.3232],\n",
      "         [0.2820],\n",
      "         [0.1725],\n",
      "         [0.3174],\n",
      "         [0.0388],\n",
      "         [0.2640],\n",
      "         [0.1116],\n",
      "         [0.8621],\n",
      "         [0.8848],\n",
      "         [0.3042],\n",
      "         [0.1542],\n",
      "         [0.4583],\n",
      "         [0.5182],\n",
      "         [0.3674],\n",
      "         [0.7508],\n",
      "         [0.5883],\n",
      "         [0.0571],\n",
      "         [0.7087],\n",
      "         [0.0582],\n",
      "         [0.4163],\n",
      "         [0.9399],\n",
      "         [0.0905],\n",
      "         [0.0581],\n",
      "         [0.6453],\n",
      "         [0.3540],\n",
      "         [0.3740],\n",
      "         [0.4936],\n",
      "         [0.4133],\n",
      "         [0.3873],\n",
      "         [0.0133],\n",
      "         [0.9575],\n",
      "         [0.0234],\n",
      "         [0.4319],\n",
      "         [0.8399],\n",
      "         [0.8625],\n",
      "         [0.3078],\n",
      "         [0.0466],\n",
      "         [0.1421],\n",
      "         [0.2090],\n",
      "         [0.2879],\n",
      "         [0.9329],\n",
      "         [0.1117],\n",
      "         [0.9742],\n",
      "         [0.4524],\n",
      "         [0.2000],\n",
      "         [0.5261],\n",
      "         [0.8633],\n",
      "         [0.3690],\n",
      "         [0.9604],\n",
      "         [0.3844],\n",
      "         [0.4679],\n",
      "         [0.7899],\n",
      "         [0.3743],\n",
      "         [0.0155],\n",
      "         [0.7252],\n",
      "         [0.7144],\n",
      "         [0.3200],\n",
      "         [0.2911],\n",
      "         [0.8041],\n",
      "         [0.6144],\n",
      "         [0.0523],\n",
      "         [0.4650],\n",
      "         [0.7805],\n",
      "         [0.8216],\n",
      "         [0.3219],\n",
      "         [0.7159],\n",
      "         [0.1534],\n",
      "         [0.4779],\n",
      "         [0.4187],\n",
      "         [0.6761],\n",
      "         [0.9975],\n",
      "         [0.5208],\n",
      "         [0.5292],\n",
      "         [0.8373],\n",
      "         [0.5161],\n",
      "         [0.0232],\n",
      "         [0.0253],\n",
      "         [0.0201],\n",
      "         [0.3769],\n",
      "         [0.4851],\n",
      "         [0.5103],\n",
      "         [0.5380],\n",
      "         [0.4006],\n",
      "         [0.8178],\n",
      "         [0.3865],\n",
      "         [0.6344],\n",
      "         [0.8536],\n",
      "         [0.8708],\n",
      "         [0.0939],\n",
      "         [0.1913],\n",
      "         [0.6089],\n",
      "         [0.1707],\n",
      "         [0.7652],\n",
      "         [0.2399],\n",
      "         [0.1151],\n",
      "         [0.1803],\n",
      "         [0.5290],\n",
      "         [0.1336],\n",
      "         [0.3990],\n",
      "         [0.9971],\n",
      "         [0.2555],\n",
      "         [0.3626],\n",
      "         [0.9968],\n",
      "         [0.3354],\n",
      "         [0.7688],\n",
      "         [0.6070],\n",
      "         [0.6018],\n",
      "         [0.1763],\n",
      "         [0.0680],\n",
      "         [0.9053],\n",
      "         [0.4677],\n",
      "         [0.0343],\n",
      "         [0.8874],\n",
      "         [0.8860],\n",
      "         [0.1913],\n",
      "         [0.8687],\n",
      "         [0.5860],\n",
      "         [0.1106],\n",
      "         [0.1284],\n",
      "         [0.6649],\n",
      "         [0.4188],\n",
      "         [0.3618],\n",
      "         [0.0449],\n",
      "         [0.7781],\n",
      "         [0.9317],\n",
      "         [0.5208],\n",
      "         [0.3051],\n",
      "         [0.5706],\n",
      "         [0.9457],\n",
      "         [0.0841],\n",
      "         [0.4046],\n",
      "         [0.2761],\n",
      "         [0.1645],\n",
      "         [0.2887],\n",
      "         [0.3641]]], device='cuda:0', dtype=torch.float64)\n",
      "================iter 2============\n",
      "['shape/ellipsoid/1/ellipsoid_512_128_64_64_1_3_1']\n",
      "tensor([[False, False, False,  True, False,  True,  True, False, False, False,\n",
      "         False, False, False,  True,  True, False,  True, False, False, False]],\n",
      "       device='cuda:0')\n",
      "acc torch.Size([1]) tensor([0.0556], device='cuda:0')\n",
      "acc_per_part torch.Size([1, 20]) tensor([[False, False, False, False, False, False, False, False, False, False,\n",
      "         False, False, False, False, False, False,  True, False, False, False]],\n",
      "       device='cuda:0')\n",
      "loss_per_data torch.Size([1, 20]) tensor([[ 0.9065,  2.0710, 21.2241,  1.2896, 18.4693,  1.4170,  6.3370, 31.9242,\n",
      "         13.7994,  4.6207, 33.1275,  1.1217,  7.3085,  0.5796, 17.7144,  1.0892,\n",
      "          0.0000, 29.0875,  4.6505,  1.3309]], device='cuda:0')\n",
      "scores torch.Size([1, 190, 1]) tensor([[[0.2786],\n",
      "         [0.6160],\n",
      "         [0.1881],\n",
      "         [0.8866],\n",
      "         [0.4860],\n",
      "         [0.6654],\n",
      "         [0.5253],\n",
      "         [0.8055],\n",
      "         [0.3427],\n",
      "         [0.5244],\n",
      "         [0.4285],\n",
      "         [0.5095],\n",
      "         [0.9743],\n",
      "         [0.3133],\n",
      "         [0.0108],\n",
      "         [0.2338],\n",
      "         [0.7922],\n",
      "         [0.5524],\n",
      "         [0.1677],\n",
      "         [0.1930],\n",
      "         [0.4105],\n",
      "         [0.0469],\n",
      "         [0.0892],\n",
      "         [0.3268],\n",
      "         [0.1956],\n",
      "         [0.5728],\n",
      "         [0.9340],\n",
      "         [0.2500],\n",
      "         [0.3059],\n",
      "         [0.4503],\n",
      "         [0.1906],\n",
      "         [0.4562],\n",
      "         [0.7906],\n",
      "         [0.1803],\n",
      "         [0.1446],\n",
      "         [0.3001],\n",
      "         [0.7326],\n",
      "         [0.7348],\n",
      "         [0.3088],\n",
      "         [0.6182],\n",
      "         [0.6309],\n",
      "         [0.8884],\n",
      "         [0.1674],\n",
      "         [0.2980],\n",
      "         [0.9347],\n",
      "         [0.5681],\n",
      "         [0.5501],\n",
      "         [0.7795],\n",
      "         [0.4052],\n",
      "         [0.2083],\n",
      "         [0.1177],\n",
      "         [0.2385],\n",
      "         [0.6441],\n",
      "         [0.6635],\n",
      "         [0.7128],\n",
      "         [0.8406],\n",
      "         [0.4418],\n",
      "         [0.5107],\n",
      "         [0.6441],\n",
      "         [0.5764],\n",
      "         [0.0916],\n",
      "         [0.3312],\n",
      "         [0.9503],\n",
      "         [0.3900],\n",
      "         [0.9514],\n",
      "         [0.8280],\n",
      "         [0.0839],\n",
      "         [0.1448],\n",
      "         [0.4066],\n",
      "         [0.2162],\n",
      "         [0.7684],\n",
      "         [0.5171],\n",
      "         [0.4336],\n",
      "         [0.6449],\n",
      "         [0.0818],\n",
      "         [0.5949],\n",
      "         [0.3745],\n",
      "         [0.0675],\n",
      "         [0.0927],\n",
      "         [0.3885],\n",
      "         [0.9238],\n",
      "         [0.7555],\n",
      "         [0.2055],\n",
      "         [0.2865],\n",
      "         [0.4838],\n",
      "         [0.3193],\n",
      "         [0.1024],\n",
      "         [0.5676],\n",
      "         [0.4734],\n",
      "         [0.9475],\n",
      "         [0.0564],\n",
      "         [0.8406],\n",
      "         [0.5086],\n",
      "         [0.7109],\n",
      "         [0.0289],\n",
      "         [0.1276],\n",
      "         [0.9235],\n",
      "         [0.8043],\n",
      "         [0.2347],\n",
      "         [0.8305],\n",
      "         [0.5807],\n",
      "         [0.0218],\n",
      "         [0.7481],\n",
      "         [0.4808],\n",
      "         [0.9565],\n",
      "         [0.8983],\n",
      "         [0.4506],\n",
      "         [0.5473],\n",
      "         [0.3511],\n",
      "         [0.2505],\n",
      "         [0.7257],\n",
      "         [0.8202],\n",
      "         [0.0380],\n",
      "         [0.0584],\n",
      "         [0.5469],\n",
      "         [0.3512],\n",
      "         [0.8794],\n",
      "         [0.4248],\n",
      "         [0.9033],\n",
      "         [0.7453],\n",
      "         [0.4918],\n",
      "         [0.2341],\n",
      "         [0.1111],\n",
      "         [0.1374],\n",
      "         [0.5337],\n",
      "         [0.2905],\n",
      "         [0.8755],\n",
      "         [0.8381],\n",
      "         [0.6388],\n",
      "         [0.2700],\n",
      "         [0.3961],\n",
      "         [0.6963],\n",
      "         [0.6922],\n",
      "         [0.2384],\n",
      "         [0.6590],\n",
      "         [0.7839],\n",
      "         [0.0462],\n",
      "         [0.0564],\n",
      "         [0.0953],\n",
      "         [0.5038],\n",
      "         [0.0990],\n",
      "         [0.7443],\n",
      "         [0.5946],\n",
      "         [0.9252],\n",
      "         [0.7504],\n",
      "         [0.7422],\n",
      "         [0.5856],\n",
      "         [0.6764],\n",
      "         [0.9035],\n",
      "         [0.2008],\n",
      "         [0.1995],\n",
      "         [0.7094],\n",
      "         [0.5602],\n",
      "         [0.1718],\n",
      "         [0.8069],\n",
      "         [0.8130],\n",
      "         [0.1595],\n",
      "         [0.2791],\n",
      "         [0.5849],\n",
      "         [0.6565],\n",
      "         [0.1276],\n",
      "         [0.3371],\n",
      "         [0.0973],\n",
      "         [0.6787],\n",
      "         [0.3502],\n",
      "         [0.2237],\n",
      "         [0.3969],\n",
      "         [0.0184],\n",
      "         [0.8027],\n",
      "         [0.1057],\n",
      "         [0.7810],\n",
      "         [0.0192],\n",
      "         [0.3434],\n",
      "         [0.4592],\n",
      "         [0.9360],\n",
      "         [0.3598],\n",
      "         [0.6756],\n",
      "         [0.2189],\n",
      "         [0.2043],\n",
      "         [0.8521],\n",
      "         [0.5122],\n",
      "         [0.8593],\n",
      "         [0.7791],\n",
      "         [0.2686],\n",
      "         [0.3526],\n",
      "         [0.6616],\n",
      "         [0.7606],\n",
      "         [0.1293],\n",
      "         [0.8383],\n",
      "         [0.3997]]], device='cuda:0', dtype=torch.float64)\n",
      "================iter 3============\n",
      "['shape/ellipsoid/1/ellipsoid_512_128_64_64_1_3_1']\n",
      "tensor([[ True, False, False,  True, False,  True,  True,  True, False, False,\n",
      "          True, False,  True,  True,  True, False,  True,  True, False, False]],\n",
      "       device='cuda:0')\n",
      "acc torch.Size([1]) tensor([0.0556], device='cuda:0')\n",
      "acc_per_part torch.Size([1, 20]) tensor([[False, False, False, False, False, False, False, False, False, False,\n",
      "         False, False, False, False, False, False,  True, False, False, False]],\n",
      "       device='cuda:0')\n",
      "loss_per_data torch.Size([1, 20]) tensor([[ 0.9065,  1.4086, 18.9843,  1.2896, 20.8184,  1.4170,  6.3370, 31.9242,\n",
      "         24.3575,  5.2809, 33.1275,  3.9378,  7.3085,  0.5796, 17.7144,  0.4449,\n",
      "          0.0000, 29.0875,  3.9303,  0.0370]], device='cuda:0')\n",
      "scores torch.Size([1, 190, 1]) tensor([[[0.3389],\n",
      "         [0.0123],\n",
      "         [0.1363],\n",
      "         [0.0052],\n",
      "         [0.3005],\n",
      "         [0.3750],\n",
      "         [0.2388],\n",
      "         [0.2989],\n",
      "         [0.6214],\n",
      "         [0.3235],\n",
      "         [0.2664],\n",
      "         [0.4897],\n",
      "         [0.4282],\n",
      "         [0.4681],\n",
      "         [0.9325],\n",
      "         [0.9035],\n",
      "         [0.2887],\n",
      "         [0.1559],\n",
      "         [0.3643],\n",
      "         [0.7557],\n",
      "         [0.1823],\n",
      "         [0.7225],\n",
      "         [0.2778],\n",
      "         [0.1324],\n",
      "         [0.2163],\n",
      "         [0.2230],\n",
      "         [0.9384],\n",
      "         [0.0454],\n",
      "         [0.3649],\n",
      "         [0.4656],\n",
      "         [0.1191],\n",
      "         [0.1254],\n",
      "         [0.6160],\n",
      "         [0.4385],\n",
      "         [0.5606],\n",
      "         [0.3887],\n",
      "         [0.1691],\n",
      "         [0.8494],\n",
      "         [0.0934],\n",
      "         [0.9127],\n",
      "         [0.9805],\n",
      "         [0.9463],\n",
      "         [0.0693],\n",
      "         [0.1144],\n",
      "         [0.9831],\n",
      "         [0.9346],\n",
      "         [0.0539],\n",
      "         [0.8505],\n",
      "         [0.3220],\n",
      "         [0.8800],\n",
      "         [0.7613],\n",
      "         [0.5357],\n",
      "         [0.3069],\n",
      "         [0.9243],\n",
      "         [0.9241],\n",
      "         [0.0206],\n",
      "         [0.9930],\n",
      "         [0.1441],\n",
      "         [0.6473],\n",
      "         [0.7568],\n",
      "         [0.7166],\n",
      "         [0.0026],\n",
      "         [0.7719],\n",
      "         [0.3267],\n",
      "         [0.6641],\n",
      "         [0.3812],\n",
      "         [0.1714],\n",
      "         [0.9785],\n",
      "         [0.5730],\n",
      "         [0.4364],\n",
      "         [0.3953],\n",
      "         [0.6632],\n",
      "         [0.5786],\n",
      "         [0.6908],\n",
      "         [0.0230],\n",
      "         [0.6216],\n",
      "         [0.2822],\n",
      "         [0.5082],\n",
      "         [0.8720],\n",
      "         [0.6471],\n",
      "         [0.9835],\n",
      "         [0.3661],\n",
      "         [0.6609],\n",
      "         [0.6681],\n",
      "         [0.0606],\n",
      "         [0.1459],\n",
      "         [0.6791],\n",
      "         [0.6465],\n",
      "         [0.2918],\n",
      "         [0.9648],\n",
      "         [0.1889],\n",
      "         [0.4702],\n",
      "         [0.2507],\n",
      "         [0.4862],\n",
      "         [0.8509],\n",
      "         [0.3249],\n",
      "         [0.3842],\n",
      "         [0.1342],\n",
      "         [0.9277],\n",
      "         [0.5470],\n",
      "         [0.7351],\n",
      "         [0.6645],\n",
      "         [0.8205],\n",
      "         [0.2754],\n",
      "         [0.9872],\n",
      "         [0.9818],\n",
      "         [0.4953],\n",
      "         [0.9333],\n",
      "         [0.4854],\n",
      "         [0.5160],\n",
      "         [0.4546],\n",
      "         [0.8268],\n",
      "         [0.1095],\n",
      "         [0.5725],\n",
      "         [0.5800],\n",
      "         [0.5025],\n",
      "         [0.2385],\n",
      "         [0.0815],\n",
      "         [0.0807],\n",
      "         [0.1128],\n",
      "         [0.6755],\n",
      "         [0.3180],\n",
      "         [0.1229],\n",
      "         [0.3290],\n",
      "         [0.5762],\n",
      "         [0.2809],\n",
      "         [0.3026],\n",
      "         [0.2147],\n",
      "         [0.0891],\n",
      "         [0.3228],\n",
      "         [0.1785],\n",
      "         [0.9723],\n",
      "         [0.1478],\n",
      "         [0.9553],\n",
      "         [0.3321],\n",
      "         [0.1831],\n",
      "         [0.0417],\n",
      "         [0.6266],\n",
      "         [0.7749],\n",
      "         [0.7789],\n",
      "         [0.4385],\n",
      "         [0.4467],\n",
      "         [0.0354],\n",
      "         [0.5938],\n",
      "         [0.9631],\n",
      "         [0.4625],\n",
      "         [0.6074],\n",
      "         [0.1177],\n",
      "         [0.5531],\n",
      "         [0.1221],\n",
      "         [0.1789],\n",
      "         [0.6850],\n",
      "         [0.5233],\n",
      "         [0.2130],\n",
      "         [0.7869],\n",
      "         [0.7357],\n",
      "         [0.1923],\n",
      "         [0.8457],\n",
      "         [0.4983],\n",
      "         [0.0486],\n",
      "         [0.0422],\n",
      "         [0.8103],\n",
      "         [0.1160],\n",
      "         [0.3225],\n",
      "         [0.2045],\n",
      "         [0.6686],\n",
      "         [0.4771],\n",
      "         [0.3825],\n",
      "         [0.8542],\n",
      "         [0.5230],\n",
      "         [0.7087],\n",
      "         [0.3502],\n",
      "         [0.0732],\n",
      "         [0.9912],\n",
      "         [0.1426],\n",
      "         [0.7197],\n",
      "         [0.6016],\n",
      "         [0.8814],\n",
      "         [0.6118],\n",
      "         [0.1261],\n",
      "         [0.8492],\n",
      "         [0.8015],\n",
      "         [0.4232],\n",
      "         [0.5629],\n",
      "         [0.3124],\n",
      "         [0.6307],\n",
      "         [0.0484],\n",
      "         [0.8648],\n",
      "         [0.7724],\n",
      "         [0.0588]]], device='cuda:0', dtype=torch.float64)\n",
      "================iter 4============\n",
      "['shape/ellipsoid/1/ellipsoid_512_128_64_64_1_3_1']\n",
      "tensor([[ True, False,  True,  True,  True,  True,  True,  True,  True, False,\n",
      "          True, False,  True,  True,  True,  True,  True,  True, False, False]],\n",
      "       device='cuda:0')\n",
      "acc torch.Size([1]) tensor([0.0556], device='cuda:0')\n",
      "acc_per_part torch.Size([1, 20]) tensor([[False, False, False, False, False, False, False, False, False, False,\n",
      "         False, False, False, False, False, False,  True, False, False, False]],\n",
      "       device='cuda:0')\n",
      "loss_per_data torch.Size([1, 20]) tensor([[ 0.9065,  1.2724, 18.9843,  1.2896, 20.8184,  1.4170,  6.3370, 31.9242,\n",
      "         24.3575, 28.0258, 33.1275, 16.5968,  7.3085,  0.5796, 17.7144,  0.4449,\n",
      "          0.0000, 29.0875,  3.6146, 12.7724]], device='cuda:0')\n",
      "scores torch.Size([1, 190, 1]) tensor([[[0.3294],\n",
      "         [0.0187],\n",
      "         [0.5383],\n",
      "         [0.8656],\n",
      "         [0.6520],\n",
      "         [0.2250],\n",
      "         [0.1122],\n",
      "         [0.9951],\n",
      "         [0.4042],\n",
      "         [0.0629],\n",
      "         [0.4770],\n",
      "         [0.9139],\n",
      "         [0.4098],\n",
      "         [0.1729],\n",
      "         [0.3803],\n",
      "         [0.4734],\n",
      "         [0.9809],\n",
      "         [0.3307],\n",
      "         [0.6602],\n",
      "         [0.1081],\n",
      "         [0.2464],\n",
      "         [0.5763],\n",
      "         [0.2554],\n",
      "         [0.8676],\n",
      "         [0.2228],\n",
      "         [0.8465],\n",
      "         [0.2889],\n",
      "         [0.3737],\n",
      "         [0.5170],\n",
      "         [0.2084],\n",
      "         [0.8805],\n",
      "         [0.0184],\n",
      "         [0.6616],\n",
      "         [0.9555],\n",
      "         [0.3169],\n",
      "         [0.6148],\n",
      "         [0.5862],\n",
      "         [0.0910],\n",
      "         [0.2241],\n",
      "         [0.8764],\n",
      "         [0.5701],\n",
      "         [0.3483],\n",
      "         [0.4976],\n",
      "         [0.4685],\n",
      "         [0.1294],\n",
      "         [0.7287],\n",
      "         [0.5275],\n",
      "         [0.7424],\n",
      "         [0.9720],\n",
      "         [0.3834],\n",
      "         [0.2145],\n",
      "         [0.5695],\n",
      "         [0.9641],\n",
      "         [0.8597],\n",
      "         [0.6979],\n",
      "         [0.2065],\n",
      "         [0.2310],\n",
      "         [0.7235],\n",
      "         [0.1375],\n",
      "         [0.9048],\n",
      "         [0.8504],\n",
      "         [0.0672],\n",
      "         [0.0134],\n",
      "         [0.3336],\n",
      "         [0.3886],\n",
      "         [0.4767],\n",
      "         [0.4791],\n",
      "         [0.9420],\n",
      "         [0.2169],\n",
      "         [0.0804],\n",
      "         [0.8508],\n",
      "         [0.0603],\n",
      "         [0.2071],\n",
      "         [0.3153],\n",
      "         [0.8063],\n",
      "         [0.2994],\n",
      "         [0.6869],\n",
      "         [0.7904],\n",
      "         [0.6494],\n",
      "         [0.6426],\n",
      "         [0.4202],\n",
      "         [0.2112],\n",
      "         [0.0365],\n",
      "         [0.9252],\n",
      "         [0.5080],\n",
      "         [0.2645],\n",
      "         [0.4283],\n",
      "         [0.1602],\n",
      "         [0.2909],\n",
      "         [0.4322],\n",
      "         [0.7045],\n",
      "         [0.6691],\n",
      "         [0.1209],\n",
      "         [0.0623],\n",
      "         [0.6520],\n",
      "         [0.8026],\n",
      "         [0.6500],\n",
      "         [0.7079],\n",
      "         [0.1962],\n",
      "         [0.5461],\n",
      "         [0.7465],\n",
      "         [0.2914],\n",
      "         [0.7994],\n",
      "         [0.3038],\n",
      "         [0.6262],\n",
      "         [0.5671],\n",
      "         [0.4626],\n",
      "         [0.6379],\n",
      "         [0.8284],\n",
      "         [0.6089],\n",
      "         [0.3804],\n",
      "         [0.1559],\n",
      "         [0.8816],\n",
      "         [0.4194],\n",
      "         [0.8025],\n",
      "         [0.3641],\n",
      "         [0.8731],\n",
      "         [0.2921],\n",
      "         [0.0854],\n",
      "         [0.9537],\n",
      "         [0.9991],\n",
      "         [0.4122],\n",
      "         [0.6846],\n",
      "         [0.7174],\n",
      "         [0.5973],\n",
      "         [0.2395],\n",
      "         [0.5320],\n",
      "         [0.6891],\n",
      "         [0.6541],\n",
      "         [0.4425],\n",
      "         [0.6339],\n",
      "         [0.1211],\n",
      "         [0.3976],\n",
      "         [0.8552],\n",
      "         [0.4011],\n",
      "         [0.3314],\n",
      "         [0.6658],\n",
      "         [0.4680],\n",
      "         [0.3265],\n",
      "         [0.1127],\n",
      "         [0.7188],\n",
      "         [0.3201],\n",
      "         [0.0894],\n",
      "         [0.2156],\n",
      "         [0.6052],\n",
      "         [0.6619],\n",
      "         [0.1683],\n",
      "         [0.1457],\n",
      "         [0.7788],\n",
      "         [0.5581],\n",
      "         [0.2963],\n",
      "         [0.2804],\n",
      "         [0.8650],\n",
      "         [0.8975],\n",
      "         [0.3566],\n",
      "         [0.5579],\n",
      "         [0.9317],\n",
      "         [0.5975],\n",
      "         [0.7975],\n",
      "         [0.7624],\n",
      "         [0.3974],\n",
      "         [0.4267],\n",
      "         [0.4033],\n",
      "         [0.1729],\n",
      "         [0.3235],\n",
      "         [0.8193],\n",
      "         [0.1504],\n",
      "         [0.6064],\n",
      "         [0.6140],\n",
      "         [0.9377],\n",
      "         [0.0525],\n",
      "         [0.0326],\n",
      "         [0.8947],\n",
      "         [0.8475],\n",
      "         [0.1297],\n",
      "         [0.1113],\n",
      "         [0.1096],\n",
      "         [0.7041],\n",
      "         [0.2720],\n",
      "         [0.9331],\n",
      "         [0.9578],\n",
      "         [0.3517],\n",
      "         [0.8461],\n",
      "         [0.8545],\n",
      "         [0.8296],\n",
      "         [0.5025],\n",
      "         [0.7229],\n",
      "         [0.8470],\n",
      "         [0.2546],\n",
      "         [0.0833]]], device='cuda:0', dtype=torch.float64)\n",
      "================iter 5============\n",
      "['shape/ellipsoid/1/ellipsoid_512_128_64_64_1_3_1']\n",
      "tensor([[ True,  True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
      "          True,  True,  True,  True,  True,  True,  True,  True, False, False]],\n",
      "       device='cuda:0')\n",
      "@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@\n",
      "['shape/ellipsoid/1/ellipsoid_512_128_64_64_2_0_1']\n",
      "gt_trans_torch.Size([1, 20, 3])_tensor([[[ 5.6911e-02, -3.7090e-01,  1.7492e-01],\n",
      "         [ 5.0134e-02, -3.3635e-01,  1.5463e-01],\n",
      "         [ 3.0354e-02, -2.8700e-02,  2.8842e-02],\n",
      "         [ 1.0658e-17, -2.0428e-17,  5.3291e-18],\n",
      "         [ 1.0397e-02,  3.0926e-02,  4.6098e-03],\n",
      "         [-4.1723e-03,  6.4516e-02, -2.0013e-02],\n",
      "         [-1.2542e-02,  9.9281e-02, -4.1453e-02],\n",
      "         [-2.5881e-02,  1.2492e-01, -4.6929e-02],\n",
      "         [-1.9803e-02,  1.6928e-01, -7.6889e-02],\n",
      "         [-2.8203e-02,  1.9811e-01, -8.4261e-02],\n",
      "         [ 5.3208e-02, -3.0164e-01,  1.4518e-01],\n",
      "         [ 3.4255e-02, -2.7803e-01,  1.3828e-01],\n",
      "         [ 4.2939e-02, -2.3716e-01,  1.2077e-01],\n",
      "         [ 4.6113e-02, -2.0410e-01,  1.1358e-01],\n",
      "         [ 2.5147e-02, -1.7237e-01,  8.7664e-02],\n",
      "         [ 2.7891e-02, -1.3533e-01,  7.0951e-02],\n",
      "         [ 3.3816e-02, -9.6116e-02,  5.3100e-02],\n",
      "         [ 1.0168e-02, -6.5605e-02,  2.7661e-02],\n",
      "         [ 0.0000e+00,  0.0000e+00,  0.0000e+00],\n",
      "         [ 0.0000e+00,  0.0000e+00,  0.0000e+00]]], device='cuda:0')\n",
      "gt_rots_torch.Size([1, 20, 4])_tensor([[[ 0.7654, -0.5496,  0.2692, -0.1991],\n",
      "         [-0.4212,  0.8060,  0.3188,  0.2673],\n",
      "         [ 0.2146, -0.4045,  0.2279,  0.8593],\n",
      "         [ 0.6367, -0.2340,  0.4548, -0.5771],\n",
      "         [ 0.3987,  0.1734,  0.5066,  0.7445],\n",
      "         [-0.4562,  0.6824, -0.4701,  0.3245],\n",
      "         [ 0.0054,  0.1144, -0.2614,  0.9584],\n",
      "         [ 0.3144,  0.6520, -0.5821,  0.3705],\n",
      "         [ 0.3751, -0.0505,  0.8655,  0.3280],\n",
      "         [ 0.7433,  0.5578, -0.2713,  0.2503],\n",
      "         [-0.2855,  0.9418, -0.0918, -0.1518],\n",
      "         [-0.3469, -0.2766,  0.8819,  0.1592],\n",
      "         [ 0.7378,  0.5994, -0.1863,  0.2483],\n",
      "         [ 0.2669,  0.4299,  0.7235, -0.4696],\n",
      "         [-0.2601,  0.5198,  0.1774,  0.7942],\n",
      "         [-0.0830, -0.2619,  0.6923, -0.6673],\n",
      "         [ 0.4584, -0.3613,  0.7877,  0.1970],\n",
      "         [-0.1530,  0.9336, -0.2985, -0.1262],\n",
      "         [ 0.0000,  0.0000,  0.0000,  0.0000],\n",
      "         [ 0.0000,  0.0000,  0.0000,  0.0000]]], device='cuda:0')\n",
      "noisy_trans_and_rots_torch.Size([1, 20, 7])_tensor([[[ 0.3974,  0.0000,  0.7043,  0.2805,  0.0000,  0.0000, -1.0236],\n",
      "         [-1.8722,  0.0000,  0.5823,  0.3088,  0.0000,  0.0000, -1.1803],\n",
      "         [-0.8696,  0.0000,  0.1990, -0.8121,  0.0000,  0.0000,  0.9935],\n",
      "         [ 0.5683,  0.0000,  0.7735,  0.0969,  0.0000,  0.0000, -0.2207],\n",
      "         [ 1.6833,  0.0000,  0.9433, -1.0589,  0.0000,  0.0000,  0.3362],\n",
      "         [ 1.4850,  0.0000,  0.3703, -0.7361,  0.0000,  0.0000,  0.1385],\n",
      "         [-0.0554,  0.0000,  0.2634, -0.6475,  0.0000,  0.0000,  1.5711],\n",
      "         [ 1.3459,  0.0000, -0.3547, -1.2552,  0.0000,  0.0000, -0.3496],\n",
      "         [-0.5281,  0.0000, -0.7054, -1.1560,  0.0000,  0.0000, -1.2308],\n",
      "         [-1.3794,  0.0000,  0.6094,  0.1229,  0.0000,  0.0000,  2.1209],\n",
      "         [ 0.3605,  0.0000,  1.3917, -0.6320,  0.0000,  0.0000, -1.3511],\n",
      "         [-0.3178,  0.0000,  0.6360, -0.2525,  0.0000,  0.0000,  1.7642],\n",
      "         [ 1.1829,  0.0000, -0.7396, -0.9295,  0.0000,  0.0000, -1.5970],\n",
      "         [-0.2374,  0.0000, -0.0898,  0.2834,  0.0000,  0.0000, -0.3977],\n",
      "         [-1.2279,  0.0000, -0.9966,  0.5699,  0.0000,  0.0000, -1.1384],\n",
      "         [-0.9922,  0.0000, -0.1512,  0.6237,  0.0000,  0.0000,  0.1365],\n",
      "         [ 1.3401,  0.0000, -0.6418, -0.1246,  0.0000,  0.0000,  1.2950],\n",
      "         [-0.6869,  0.0000, -0.7702,  1.7053,  0.0000,  0.0000, -2.2147],\n",
      "         [ 0.2256,  0.0000, -0.3116,  0.6426,  0.0000,  0.0000, -0.7201],\n",
      "         [ 0.5936,  0.0000,  1.5875, -0.3714,  0.0000,  0.0000, -0.8786]]],\n",
      "       device='cuda:0')\n",
      "================iter 0============\n",
      "['shape/ellipsoid/1/ellipsoid_512_128_64_64_2_0_1']\n",
      "tensor([[False, False, False,  True, False, False, False, False, False, False,\n",
      "         False, False, False, False, False, False, False, False, False, False]],\n",
      "       device='cuda:0')\n",
      "acc torch.Size([1]) tensor([0.0556], device='cuda:0')\n",
      "acc_per_part torch.Size([1, 20]) tensor([[False, False, False,  True, False, False, False, False, False, False,\n",
      "         False, False, False, False, False, False, False, False, False, False]],\n",
      "       device='cuda:0')\n",
      "loss_per_data torch.Size([1, 20]) tensor([[ 1.4574,  0.5909,  2.2527,  0.0000,  2.0074,  1.0614,  1.3146,  2.6925,\n",
      "          0.9839,  1.7586,  1.5365,  0.9374,  0.7898,  0.9870,  0.2395,  0.8097,\n",
      "          2.9667,  0.4011,  3.9041, 36.2973]], device='cuda:0')\n",
      "scores torch.Size([1, 190, 1]) tensor([[[0.7542],\n",
      "         [0.7710],\n",
      "         [0.4589],\n",
      "         [0.3006],\n",
      "         [0.8105],\n",
      "         [0.4281],\n",
      "         [0.7705],\n",
      "         [0.8317],\n",
      "         [0.3146],\n",
      "         [0.2272],\n",
      "         [0.3813],\n",
      "         [0.4573],\n",
      "         [0.8275],\n",
      "         [0.3434],\n",
      "         [0.9570],\n",
      "         [0.3394],\n",
      "         [0.8367],\n",
      "         [0.6593],\n",
      "         [0.5882],\n",
      "         [0.3848],\n",
      "         [0.6524],\n",
      "         [0.7533],\n",
      "         [0.1213],\n",
      "         [0.9583],\n",
      "         [0.3976],\n",
      "         [0.4979],\n",
      "         [0.4866],\n",
      "         [0.3986],\n",
      "         [0.9234],\n",
      "         [0.0298],\n",
      "         [0.9364],\n",
      "         [0.9545],\n",
      "         [0.7469],\n",
      "         [0.0806],\n",
      "         [0.7859],\n",
      "         [0.3660],\n",
      "         [0.5271],\n",
      "         [0.8830],\n",
      "         [0.7242],\n",
      "         [0.6042],\n",
      "         [0.8165],\n",
      "         [0.3762],\n",
      "         [0.6226],\n",
      "         [0.4926],\n",
      "         [0.2091],\n",
      "         [0.5203],\n",
      "         [0.1777],\n",
      "         [0.6994],\n",
      "         [0.5616],\n",
      "         [0.2437],\n",
      "         [0.5309],\n",
      "         [0.3634],\n",
      "         [0.1266],\n",
      "         [0.9110],\n",
      "         [0.6064],\n",
      "         [0.0334],\n",
      "         [0.4920],\n",
      "         [0.3804],\n",
      "         [0.1404],\n",
      "         [0.8960],\n",
      "         [0.2799],\n",
      "         [0.3974],\n",
      "         [0.6005],\n",
      "         [0.8620],\n",
      "         [0.3958],\n",
      "         [0.9115],\n",
      "         [0.0420],\n",
      "         [0.9005],\n",
      "         [0.2939],\n",
      "         [0.9670],\n",
      "         [0.9176],\n",
      "         [0.9595],\n",
      "         [0.1069],\n",
      "         [0.7411],\n",
      "         [0.5138],\n",
      "         [0.5225],\n",
      "         [0.5386],\n",
      "         [0.1950],\n",
      "         [0.7055],\n",
      "         [0.4604],\n",
      "         [0.2985],\n",
      "         [0.6535],\n",
      "         [0.6688],\n",
      "         [0.5376],\n",
      "         [0.8105],\n",
      "         [0.5738],\n",
      "         [0.6376],\n",
      "         [0.9432],\n",
      "         [0.6722],\n",
      "         [0.1289],\n",
      "         [0.1075],\n",
      "         [0.2841],\n",
      "         [0.3530],\n",
      "         [0.7794],\n",
      "         [0.0378],\n",
      "         [0.4227],\n",
      "         [0.2130],\n",
      "         [0.9914],\n",
      "         [0.0426],\n",
      "         [0.1074],\n",
      "         [0.9104],\n",
      "         [0.2784],\n",
      "         [0.0350],\n",
      "         [0.0451],\n",
      "         [0.3836],\n",
      "         [0.8498],\n",
      "         [0.3031],\n",
      "         [0.1426],\n",
      "         [0.8503],\n",
      "         [0.9273],\n",
      "         [0.3487],\n",
      "         [0.9415],\n",
      "         [0.9520],\n",
      "         [0.0758],\n",
      "         [0.0316],\n",
      "         [0.2338],\n",
      "         [0.0513],\n",
      "         [0.1982],\n",
      "         [0.6316],\n",
      "         [0.0502],\n",
      "         [0.8107],\n",
      "         [0.8387],\n",
      "         [0.3276],\n",
      "         [0.1055],\n",
      "         [0.1124],\n",
      "         [0.1336],\n",
      "         [0.6290],\n",
      "         [0.5301],\n",
      "         [0.2267],\n",
      "         [0.4025],\n",
      "         [0.9775],\n",
      "         [0.9739],\n",
      "         [0.3625],\n",
      "         [0.0649],\n",
      "         [0.1828],\n",
      "         [0.5797],\n",
      "         [0.2892],\n",
      "         [0.7000],\n",
      "         [0.0235],\n",
      "         [0.5868],\n",
      "         [0.9584],\n",
      "         [0.2182],\n",
      "         [0.8020],\n",
      "         [0.2780],\n",
      "         [0.1728],\n",
      "         [0.5849],\n",
      "         [0.1450],\n",
      "         [0.0132],\n",
      "         [0.3717],\n",
      "         [0.0074],\n",
      "         [0.2551],\n",
      "         [0.5624],\n",
      "         [0.2450],\n",
      "         [0.5023],\n",
      "         [0.7815],\n",
      "         [0.1195],\n",
      "         [0.2976],\n",
      "         [0.2745],\n",
      "         [0.9684],\n",
      "         [0.8243],\n",
      "         [0.6543],\n",
      "         [0.1332],\n",
      "         [0.7981],\n",
      "         [0.0058],\n",
      "         [0.1835],\n",
      "         [0.3527],\n",
      "         [0.3981],\n",
      "         [0.9745],\n",
      "         [0.9825],\n",
      "         [0.5189],\n",
      "         [0.4439],\n",
      "         [0.9461],\n",
      "         [0.2609],\n",
      "         [0.4888],\n",
      "         [0.0127],\n",
      "         [0.5844],\n",
      "         [0.4569],\n",
      "         [0.8122],\n",
      "         [0.5791],\n",
      "         [0.6652],\n",
      "         [0.1512],\n",
      "         [0.9793],\n",
      "         [0.0487],\n",
      "         [0.2650],\n",
      "         [0.8492],\n",
      "         [0.8621],\n",
      "         [0.6545],\n",
      "         [0.1856],\n",
      "         [0.8811],\n",
      "         [0.0621]]], device='cuda:0', dtype=torch.float64)\n",
      "================iter 1============\n",
      "['shape/ellipsoid/1/ellipsoid_512_128_64_64_2_0_1']\n",
      "tensor([[False, False, False,  True, False, False, False, False, False, False,\n",
      "         False, False, False, False, False,  True, False,  True, False, False]],\n",
      "       device='cuda:0')\n",
      "acc torch.Size([1]) tensor([0.0556], device='cuda:0')\n",
      "acc_per_part torch.Size([1, 20]) tensor([[False, False, False,  True, False, False, False, False, False, False,\n",
      "         False, False, False, False, False, False, False, False, False, False]],\n",
      "       device='cuda:0')\n",
      "loss_per_data torch.Size([1, 20]) tensor([[ 3.1571,  0.7620,  0.9805,  0.0000, 25.7818,  1.1415,  4.7734,  0.4378,\n",
      "          0.7510,  1.4379,  3.8210,  4.8288,  0.6604,  0.0850,  2.0618,  0.8097,\n",
      "          1.2123,  0.4011,  5.2505, 63.2982]], device='cuda:0')\n",
      "scores torch.Size([1, 190, 1]) tensor([[[0.3958],\n",
      "         [0.8349],\n",
      "         [0.1854],\n",
      "         [0.8517],\n",
      "         [0.2462],\n",
      "         [0.9109],\n",
      "         [0.1135],\n",
      "         [0.9466],\n",
      "         [0.2471],\n",
      "         [0.2960],\n",
      "         [0.4774],\n",
      "         [0.4005],\n",
      "         [0.3024],\n",
      "         [0.3517],\n",
      "         [0.0771],\n",
      "         [0.9786],\n",
      "         [0.9790],\n",
      "         [0.7505],\n",
      "         [0.6714],\n",
      "         [0.8330],\n",
      "         [0.9275],\n",
      "         [0.1748],\n",
      "         [0.3764],\n",
      "         [0.0075],\n",
      "         [0.1139],\n",
      "         [0.5034],\n",
      "         [0.2052],\n",
      "         [0.1201],\n",
      "         [0.8715],\n",
      "         [0.2886],\n",
      "         [0.2811],\n",
      "         [0.9932],\n",
      "         [0.4979],\n",
      "         [0.1543],\n",
      "         [0.7947],\n",
      "         [0.4615],\n",
      "         [0.6815],\n",
      "         [0.5295],\n",
      "         [0.7245],\n",
      "         [0.9035],\n",
      "         [0.0499],\n",
      "         [0.0525],\n",
      "         [0.2506],\n",
      "         [0.9813],\n",
      "         [0.0449],\n",
      "         [0.9164],\n",
      "         [0.3654],\n",
      "         [0.5972],\n",
      "         [0.3501],\n",
      "         [0.0066],\n",
      "         [0.1194],\n",
      "         [0.6582],\n",
      "         [0.7694],\n",
      "         [0.6957],\n",
      "         [0.2828],\n",
      "         [0.7740],\n",
      "         [0.2568],\n",
      "         [0.6126],\n",
      "         [0.5494],\n",
      "         [0.8601],\n",
      "         [0.1918],\n",
      "         [0.4851],\n",
      "         [0.7942],\n",
      "         [0.1286],\n",
      "         [0.6750],\n",
      "         [0.6540],\n",
      "         [0.2723],\n",
      "         [0.6607],\n",
      "         [0.7971],\n",
      "         [0.8523],\n",
      "         [0.2826],\n",
      "         [0.9226],\n",
      "         [0.5276],\n",
      "         [0.3880],\n",
      "         [0.2127],\n",
      "         [0.3984],\n",
      "         [0.1950],\n",
      "         [0.4293],\n",
      "         [0.9953],\n",
      "         [0.6224],\n",
      "         [0.5757],\n",
      "         [0.9892],\n",
      "         [0.6284],\n",
      "         [0.9636],\n",
      "         [0.3610],\n",
      "         [0.1253],\n",
      "         [0.9009],\n",
      "         [0.3201],\n",
      "         [0.5285],\n",
      "         [0.5353],\n",
      "         [0.7785],\n",
      "         [0.7470],\n",
      "         [0.4634],\n",
      "         [0.5602],\n",
      "         [0.5330],\n",
      "         [0.2163],\n",
      "         [0.2431],\n",
      "         [0.8526],\n",
      "         [0.2434],\n",
      "         [0.7761],\n",
      "         [0.3574],\n",
      "         [0.0688],\n",
      "         [0.6502],\n",
      "         [0.1267],\n",
      "         [0.7023],\n",
      "         [0.1210],\n",
      "         [0.8163],\n",
      "         [0.2401],\n",
      "         [0.5559],\n",
      "         [0.1264],\n",
      "         [0.5987],\n",
      "         [0.1729],\n",
      "         [0.9252],\n",
      "         [0.6998],\n",
      "         [0.3161],\n",
      "         [0.2208],\n",
      "         [0.5817],\n",
      "         [0.0220],\n",
      "         [0.2006],\n",
      "         [0.8778],\n",
      "         [0.4400],\n",
      "         [0.8146],\n",
      "         [0.6297],\n",
      "         [0.2580],\n",
      "         [0.7124],\n",
      "         [0.6324],\n",
      "         [0.7711],\n",
      "         [0.4210],\n",
      "         [0.2501],\n",
      "         [0.5368],\n",
      "         [0.5855],\n",
      "         [0.6454],\n",
      "         [0.1148],\n",
      "         [0.8605],\n",
      "         [0.1527],\n",
      "         [0.9188],\n",
      "         [0.4570],\n",
      "         [0.4715],\n",
      "         [0.2893],\n",
      "         [0.4205],\n",
      "         [0.4548],\n",
      "         [0.6768],\n",
      "         [0.2028],\n",
      "         [0.2586],\n",
      "         [0.5920],\n",
      "         [0.3769],\n",
      "         [0.9115],\n",
      "         [0.3816],\n",
      "         [0.3720],\n",
      "         [0.0206],\n",
      "         [0.9007],\n",
      "         [0.7009],\n",
      "         [0.4610],\n",
      "         [0.6398],\n",
      "         [0.4075],\n",
      "         [0.4806],\n",
      "         [0.2483],\n",
      "         [0.5320],\n",
      "         [0.5487],\n",
      "         [0.5184],\n",
      "         [0.5464],\n",
      "         [0.3450],\n",
      "         [0.5907],\n",
      "         [0.1802],\n",
      "         [0.2813],\n",
      "         [0.1134],\n",
      "         [0.8127],\n",
      "         [0.3572],\n",
      "         [0.3356],\n",
      "         [0.9513],\n",
      "         [0.0398],\n",
      "         [0.5621],\n",
      "         [0.0924],\n",
      "         [0.4149],\n",
      "         [0.9894],\n",
      "         [0.2977],\n",
      "         [0.7103],\n",
      "         [0.3963],\n",
      "         [0.8274],\n",
      "         [0.0407],\n",
      "         [0.5741],\n",
      "         [0.9011],\n",
      "         [0.7878],\n",
      "         [0.4754],\n",
      "         [0.9530],\n",
      "         [0.0955],\n",
      "         [0.3614],\n",
      "         [0.3365],\n",
      "         [0.5043],\n",
      "         [0.8220]]], device='cuda:0', dtype=torch.float64)\n",
      "================iter 2============\n",
      "['shape/ellipsoid/1/ellipsoid_512_128_64_64_2_0_1']\n",
      "tensor([[ True,  True, False,  True, False, False, False, False, False, False,\n",
      "         False, False, False, False, False,  True,  True,  True, False, False]],\n",
      "       device='cuda:0')\n",
      "acc torch.Size([1]) tensor([0.0556], device='cuda:0')\n",
      "acc_per_part torch.Size([1, 20]) tensor([[False, False, False,  True, False, False, False, False, False, False,\n",
      "         False, False, False, False, False, False, False, False, False, False]],\n",
      "       device='cuda:0')\n",
      "loss_per_data torch.Size([1, 20]) tensor([[  3.1571,   0.7620,   5.1676,   0.0000,  26.4125,   5.8946,  13.4725,\n",
      "           1.6193,   0.5948,   2.2270,   3.8375,   6.8485,   2.7173,   0.3233,\n",
      "          21.7658,   0.8097,   1.2123,   0.4011,   9.8666, 118.5064]],\n",
      "       device='cuda:0')\n",
      "scores torch.Size([1, 190, 1]) tensor([[[0.1354],\n",
      "         [0.2248],\n",
      "         [0.4773],\n",
      "         [0.8109],\n",
      "         [0.3566],\n",
      "         [0.0666],\n",
      "         [0.7180],\n",
      "         [0.0639],\n",
      "         [0.8563],\n",
      "         [0.1302],\n",
      "         [0.9347],\n",
      "         [0.6722],\n",
      "         [0.7708],\n",
      "         [0.6482],\n",
      "         [0.4388],\n",
      "         [0.7818],\n",
      "         [0.6238],\n",
      "         [0.3724],\n",
      "         [0.3461],\n",
      "         [0.4811],\n",
      "         [0.0170],\n",
      "         [0.7311],\n",
      "         [0.2142],\n",
      "         [0.1589],\n",
      "         [0.8924],\n",
      "         [0.0904],\n",
      "         [0.2108],\n",
      "         [0.5467],\n",
      "         [0.0882],\n",
      "         [0.2384],\n",
      "         [0.4639],\n",
      "         [0.2684],\n",
      "         [0.1490],\n",
      "         [0.2345],\n",
      "         [0.6013],\n",
      "         [0.2642],\n",
      "         [0.5530],\n",
      "         [0.1519],\n",
      "         [0.5891],\n",
      "         [0.2319],\n",
      "         [0.3957],\n",
      "         [0.1671],\n",
      "         [0.9355],\n",
      "         [0.6682],\n",
      "         [0.3653],\n",
      "         [0.0905],\n",
      "         [0.7157],\n",
      "         [0.9936],\n",
      "         [0.5454],\n",
      "         [0.5911],\n",
      "         [0.4333],\n",
      "         [0.1140],\n",
      "         [0.3783],\n",
      "         [0.5342],\n",
      "         [0.2072],\n",
      "         [0.9922],\n",
      "         [0.2213],\n",
      "         [0.7427],\n",
      "         [0.6939],\n",
      "         [0.4778],\n",
      "         [0.2654],\n",
      "         [0.4416],\n",
      "         [0.1486],\n",
      "         [0.7031],\n",
      "         [0.8686],\n",
      "         [0.3295],\n",
      "         [0.6285],\n",
      "         [0.7900],\n",
      "         [0.1771],\n",
      "         [0.0683],\n",
      "         [0.8012],\n",
      "         [0.2443],\n",
      "         [0.4922],\n",
      "         [0.8387],\n",
      "         [0.4450],\n",
      "         [0.1235],\n",
      "         [0.7691],\n",
      "         [0.5162],\n",
      "         [0.2055],\n",
      "         [0.2894],\n",
      "         [0.2967],\n",
      "         [0.9838],\n",
      "         [0.3474],\n",
      "         [0.1378],\n",
      "         [0.9405],\n",
      "         [0.5502],\n",
      "         [0.3394],\n",
      "         [0.1618],\n",
      "         [0.7760],\n",
      "         [0.1196],\n",
      "         [0.4908],\n",
      "         [0.0011],\n",
      "         [0.1685],\n",
      "         [0.0972],\n",
      "         [0.9401],\n",
      "         [0.7066],\n",
      "         [0.1496],\n",
      "         [0.0709],\n",
      "         [0.3223],\n",
      "         [0.0957],\n",
      "         [0.2233],\n",
      "         [0.8710],\n",
      "         [0.0954],\n",
      "         [0.8273],\n",
      "         [0.7882],\n",
      "         [0.6597],\n",
      "         [0.8815],\n",
      "         [0.6297],\n",
      "         [0.7185],\n",
      "         [0.4626],\n",
      "         [0.1614],\n",
      "         [0.9902],\n",
      "         [0.0666],\n",
      "         [0.4596],\n",
      "         [0.2635],\n",
      "         [0.4447],\n",
      "         [0.1727],\n",
      "         [0.9274],\n",
      "         [0.4757],\n",
      "         [0.9195],\n",
      "         [0.8979],\n",
      "         [0.0138],\n",
      "         [0.9156],\n",
      "         [0.7789],\n",
      "         [0.3045],\n",
      "         [0.6179],\n",
      "         [0.1967],\n",
      "         [0.7440],\n",
      "         [0.6155],\n",
      "         [0.2718],\n",
      "         [0.3498],\n",
      "         [0.7913],\n",
      "         [0.3735],\n",
      "         [0.7547],\n",
      "         [0.2865],\n",
      "         [0.2934],\n",
      "         [0.8772],\n",
      "         [0.2942],\n",
      "         [0.8149],\n",
      "         [0.8011],\n",
      "         [0.4420],\n",
      "         [0.3772],\n",
      "         [0.4327],\n",
      "         [0.8917],\n",
      "         [0.6942],\n",
      "         [0.2119],\n",
      "         [0.6626],\n",
      "         [0.4615],\n",
      "         [0.8033],\n",
      "         [0.4812],\n",
      "         [0.0092],\n",
      "         [0.4079],\n",
      "         [0.8488],\n",
      "         [0.1593],\n",
      "         [0.4818],\n",
      "         [0.0833],\n",
      "         [0.0500],\n",
      "         [0.3025],\n",
      "         [0.8419],\n",
      "         [0.7804],\n",
      "         [0.4736],\n",
      "         [0.2707],\n",
      "         [0.7530],\n",
      "         [0.4107],\n",
      "         [0.8907],\n",
      "         [0.4752],\n",
      "         [0.6118],\n",
      "         [0.8080],\n",
      "         [0.1400],\n",
      "         [0.5227],\n",
      "         [0.7127],\n",
      "         [0.0906],\n",
      "         [0.8943],\n",
      "         [0.0526],\n",
      "         [0.2148],\n",
      "         [0.0923],\n",
      "         [0.3026],\n",
      "         [0.6271],\n",
      "         [0.5370],\n",
      "         [0.7861],\n",
      "         [0.1490],\n",
      "         [0.0617],\n",
      "         [0.7318],\n",
      "         [0.8706],\n",
      "         [0.1592],\n",
      "         [0.2509],\n",
      "         [0.3859],\n",
      "         [0.4329],\n",
      "         [0.9856],\n",
      "         [0.9732]]], device='cuda:0', dtype=torch.float64)\n",
      "================iter 3============\n",
      "['shape/ellipsoid/1/ellipsoid_512_128_64_64_2_0_1']\n",
      "tensor([[ True,  True, False,  True,  True,  True, False,  True, False, False,\n",
      "         False,  True, False, False, False,  True,  True,  True, False, False]],\n",
      "       device='cuda:0')\n",
      "acc torch.Size([1]) tensor([0.0556], device='cuda:0')\n",
      "acc_per_part torch.Size([1, 20]) tensor([[False, False, False,  True, False, False, False, False, False, False,\n",
      "         False, False, False, False, False, False, False, False, False, False]],\n",
      "       device='cuda:0')\n",
      "loss_per_data torch.Size([1, 20]) tensor([[  3.1571,   0.7620,   5.5225,   0.0000,  26.4125,   5.8946,  14.1069,\n",
      "           1.6193,   1.4531,  13.5825,   7.8791,   6.8485,  11.1143,   0.2314,\n",
      "         121.8173,   0.8097,   1.2123,   0.4011,   2.3989, 225.2395]],\n",
      "       device='cuda:0')\n",
      "scores torch.Size([1, 190, 1]) tensor([[[0.4541],\n",
      "         [0.9912],\n",
      "         [0.4451],\n",
      "         [0.4962],\n",
      "         [0.5100],\n",
      "         [0.5112],\n",
      "         [0.9664],\n",
      "         [0.4010],\n",
      "         [0.8672],\n",
      "         [0.4291],\n",
      "         [0.7765],\n",
      "         [0.5629],\n",
      "         [0.7143],\n",
      "         [0.7288],\n",
      "         [0.1315],\n",
      "         [0.1147],\n",
      "         [0.2437],\n",
      "         [0.0883],\n",
      "         [0.8440],\n",
      "         [0.5277],\n",
      "         [0.6245],\n",
      "         [0.7937],\n",
      "         [0.0600],\n",
      "         [0.3125],\n",
      "         [0.9110],\n",
      "         [0.8514],\n",
      "         [0.8563],\n",
      "         [0.3407],\n",
      "         [0.8151],\n",
      "         [0.4199],\n",
      "         [0.4862],\n",
      "         [0.5649],\n",
      "         [0.4570],\n",
      "         [0.9239],\n",
      "         [0.0961],\n",
      "         [0.3868],\n",
      "         [0.4625],\n",
      "         [0.5466],\n",
      "         [0.0513],\n",
      "         [0.9238],\n",
      "         [0.5949],\n",
      "         [0.6504],\n",
      "         [0.1197],\n",
      "         [0.6376],\n",
      "         [0.0776],\n",
      "         [0.9674],\n",
      "         [0.1878],\n",
      "         [0.3753],\n",
      "         [0.3636],\n",
      "         [0.2062],\n",
      "         [0.8320],\n",
      "         [0.6898],\n",
      "         [0.6741],\n",
      "         [0.1170],\n",
      "         [0.0660],\n",
      "         [0.8569],\n",
      "         [0.1599],\n",
      "         [0.5553],\n",
      "         [0.7008],\n",
      "         [0.7567],\n",
      "         [0.0751],\n",
      "         [0.5766],\n",
      "         [0.6236],\n",
      "         [0.6529],\n",
      "         [0.9839],\n",
      "         [0.4323],\n",
      "         [0.5547],\n",
      "         [0.6337],\n",
      "         [0.9622],\n",
      "         [0.5325],\n",
      "         [0.9165],\n",
      "         [0.0475],\n",
      "         [0.8930],\n",
      "         [0.5180],\n",
      "         [0.7196],\n",
      "         [0.8588],\n",
      "         [0.7272],\n",
      "         [0.5047],\n",
      "         [0.3980],\n",
      "         [0.4103],\n",
      "         [0.3262],\n",
      "         [0.6279],\n",
      "         [0.0636],\n",
      "         [0.7957],\n",
      "         [0.2844],\n",
      "         [0.3583],\n",
      "         [0.1430],\n",
      "         [0.6746],\n",
      "         [0.5509],\n",
      "         [0.8792],\n",
      "         [0.3123],\n",
      "         [0.1676],\n",
      "         [0.3002],\n",
      "         [0.4476],\n",
      "         [0.0910],\n",
      "         [0.5841],\n",
      "         [0.2910],\n",
      "         [0.1266],\n",
      "         [0.0260],\n",
      "         [0.6889],\n",
      "         [0.5851],\n",
      "         [0.4626],\n",
      "         [0.9877],\n",
      "         [0.6304],\n",
      "         [0.1567],\n",
      "         [0.0672],\n",
      "         [0.5404],\n",
      "         [0.5395],\n",
      "         [0.3965],\n",
      "         [0.8411],\n",
      "         [0.1058],\n",
      "         [0.6928],\n",
      "         [0.8762],\n",
      "         [0.4861],\n",
      "         [0.0210],\n",
      "         [0.5833],\n",
      "         [0.4513],\n",
      "         [0.6274],\n",
      "         [0.0874],\n",
      "         [0.5581],\n",
      "         [0.0377],\n",
      "         [0.7771],\n",
      "         [0.0396],\n",
      "         [0.0825],\n",
      "         [0.2957],\n",
      "         [0.1256],\n",
      "         [0.4085],\n",
      "         [0.6327],\n",
      "         [0.3887],\n",
      "         [0.3817],\n",
      "         [0.7017],\n",
      "         [0.0480],\n",
      "         [0.2678],\n",
      "         [0.0399],\n",
      "         [0.0111],\n",
      "         [0.5985],\n",
      "         [0.9990],\n",
      "         [0.3202],\n",
      "         [0.1742],\n",
      "         [0.2520],\n",
      "         [0.5180],\n",
      "         [0.6404],\n",
      "         [0.8937],\n",
      "         [0.0335],\n",
      "         [0.7578],\n",
      "         [0.6964],\n",
      "         [0.1567],\n",
      "         [0.0684],\n",
      "         [0.1459],\n",
      "         [0.3335],\n",
      "         [0.5607],\n",
      "         [0.3207],\n",
      "         [0.7665],\n",
      "         [0.6262],\n",
      "         [0.5368],\n",
      "         [0.8082],\n",
      "         [0.9535],\n",
      "         [0.2126],\n",
      "         [0.1491],\n",
      "         [0.2085],\n",
      "         [0.8880],\n",
      "         [0.7544],\n",
      "         [0.8272],\n",
      "         [0.7228],\n",
      "         [0.3323],\n",
      "         [0.2228],\n",
      "         [0.9704],\n",
      "         [0.0667],\n",
      "         [0.1335],\n",
      "         [0.7658],\n",
      "         [0.5336],\n",
      "         [0.0131],\n",
      "         [0.3103],\n",
      "         [0.5963],\n",
      "         [0.8919],\n",
      "         [0.5698],\n",
      "         [0.4286],\n",
      "         [0.3395],\n",
      "         [0.0283],\n",
      "         [0.6849],\n",
      "         [0.1732],\n",
      "         [0.2986],\n",
      "         [0.3844],\n",
      "         [0.5935],\n",
      "         [0.1410],\n",
      "         [0.8787],\n",
      "         [0.9253],\n",
      "         [0.9015],\n",
      "         [0.1774],\n",
      "         [0.3999]]], device='cuda:0', dtype=torch.float64)\n",
      "================iter 4============\n",
      "['shape/ellipsoid/1/ellipsoid_512_128_64_64_2_0_1']\n",
      "tensor([[ True,  True,  True,  True,  True,  True, False,  True, False,  True,\n",
      "         False,  True,  True, False,  True,  True,  True,  True, False, False]],\n",
      "       device='cuda:0')\n",
      "acc torch.Size([1]) tensor([0.0556], device='cuda:0')\n",
      "acc_per_part torch.Size([1, 20]) tensor([[False, False, False,  True, False, False, False, False, False, False,\n",
      "         False, False, False, False, False, False, False, False, False, False]],\n",
      "       device='cuda:0')\n",
      "loss_per_data torch.Size([1, 20]) tensor([[3.1571e+00, 7.6200e-01, 5.5225e+00, 0.0000e+00, 2.6413e+01, 5.8946e+00,\n",
      "         2.3389e+01, 1.6193e+00, 2.8041e+00, 1.3583e+01, 1.6414e+01, 6.8485e+00,\n",
      "         1.1114e+01, 1.1168e+00, 1.2182e+02, 8.0975e-01, 1.2123e+00, 4.0115e-01,\n",
      "         8.7061e-01, 4.8527e+02]], device='cuda:0')\n",
      "scores torch.Size([1, 190, 1]) tensor([[[6.2009e-01],\n",
      "         [1.4071e-01],\n",
      "         [1.5640e-01],\n",
      "         [8.5818e-01],\n",
      "         [4.3599e-01],\n",
      "         [9.0536e-01],\n",
      "         [8.6598e-01],\n",
      "         [6.1563e-01],\n",
      "         [6.5658e-01],\n",
      "         [4.5441e-01],\n",
      "         [4.7377e-01],\n",
      "         [7.4462e-01],\n",
      "         [8.9736e-01],\n",
      "         [6.7221e-01],\n",
      "         [9.3199e-01],\n",
      "         [5.9997e-01],\n",
      "         [5.1640e-01],\n",
      "         [5.0327e-01],\n",
      "         [8.3816e-02],\n",
      "         [8.4131e-01],\n",
      "         [8.7860e-01],\n",
      "         [6.0977e-01],\n",
      "         [4.5805e-01],\n",
      "         [7.5619e-01],\n",
      "         [6.8376e-01],\n",
      "         [7.8248e-01],\n",
      "         [4.3100e-01],\n",
      "         [3.7073e-01],\n",
      "         [3.2614e-01],\n",
      "         [6.5680e-01],\n",
      "         [2.5938e-01],\n",
      "         [8.7705e-01],\n",
      "         [5.6297e-02],\n",
      "         [8.0194e-01],\n",
      "         [9.0201e-02],\n",
      "         [5.1936e-01],\n",
      "         [5.6754e-01],\n",
      "         [2.3936e-01],\n",
      "         [5.2560e-01],\n",
      "         [7.1194e-01],\n",
      "         [3.8847e-01],\n",
      "         [7.5296e-01],\n",
      "         [5.9787e-02],\n",
      "         [3.0959e-01],\n",
      "         [8.8211e-01],\n",
      "         [7.5195e-01],\n",
      "         [6.5052e-04],\n",
      "         [1.5999e-01],\n",
      "         [9.8296e-01],\n",
      "         [7.4427e-02],\n",
      "         [2.8572e-01],\n",
      "         [3.1524e-01],\n",
      "         [4.2087e-01],\n",
      "         [7.1696e-01],\n",
      "         [9.0169e-01],\n",
      "         [2.3221e-01],\n",
      "         [9.2542e-01],\n",
      "         [9.0740e-01],\n",
      "         [1.6209e-01],\n",
      "         [4.7941e-01],\n",
      "         [8.4065e-01],\n",
      "         [7.6886e-01],\n",
      "         [3.0732e-03],\n",
      "         [5.4467e-01],\n",
      "         [1.7916e-01],\n",
      "         [5.5322e-01],\n",
      "         [9.0442e-01],\n",
      "         [6.6892e-01],\n",
      "         [6.2806e-01],\n",
      "         [4.2119e-01],\n",
      "         [4.3630e-02],\n",
      "         [9.1947e-01],\n",
      "         [3.1888e-01],\n",
      "         [6.1880e-01],\n",
      "         [2.8305e-01],\n",
      "         [4.2086e-01],\n",
      "         [3.6077e-01],\n",
      "         [3.9094e-02],\n",
      "         [4.3933e-01],\n",
      "         [4.4744e-01],\n",
      "         [7.1874e-01],\n",
      "         [1.7189e-01],\n",
      "         [3.9867e-01],\n",
      "         [5.0816e-01],\n",
      "         [8.8896e-02],\n",
      "         [8.9446e-01],\n",
      "         [5.7743e-01],\n",
      "         [8.1388e-01],\n",
      "         [7.8793e-01],\n",
      "         [4.2726e-02],\n",
      "         [4.0328e-02],\n",
      "         [7.2226e-01],\n",
      "         [3.1132e-01],\n",
      "         [4.6524e-01],\n",
      "         [7.2027e-01],\n",
      "         [5.5320e-01],\n",
      "         [1.3398e-01],\n",
      "         [7.2183e-01],\n",
      "         [7.8694e-01],\n",
      "         [1.4694e-01],\n",
      "         [9.8523e-01],\n",
      "         [9.0179e-01],\n",
      "         [4.3133e-01],\n",
      "         [7.7725e-01],\n",
      "         [3.8578e-01],\n",
      "         [7.6353e-01],\n",
      "         [3.5907e-01],\n",
      "         [5.9035e-01],\n",
      "         [8.1684e-01],\n",
      "         [9.9144e-01],\n",
      "         [7.7285e-01],\n",
      "         [3.3752e-01],\n",
      "         [2.3109e-02],\n",
      "         [5.0987e-01],\n",
      "         [8.8054e-01],\n",
      "         [3.3516e-01],\n",
      "         [5.7451e-02],\n",
      "         [4.3458e-01],\n",
      "         [8.4571e-01],\n",
      "         [4.2035e-01],\n",
      "         [6.9430e-01],\n",
      "         [5.1310e-01],\n",
      "         [4.5998e-01],\n",
      "         [4.2173e-02],\n",
      "         [8.7754e-01],\n",
      "         [3.0864e-01],\n",
      "         [6.5798e-01],\n",
      "         [7.1121e-01],\n",
      "         [5.6552e-01],\n",
      "         [9.1705e-01],\n",
      "         [6.1116e-01],\n",
      "         [7.1270e-01],\n",
      "         [5.7596e-02],\n",
      "         [5.1042e-01],\n",
      "         [8.4124e-01],\n",
      "         [9.9619e-01],\n",
      "         [4.1492e-01],\n",
      "         [9.6349e-01],\n",
      "         [6.8718e-01],\n",
      "         [4.7617e-01],\n",
      "         [3.2046e-01],\n",
      "         [6.6926e-01],\n",
      "         [2.9717e-02],\n",
      "         [5.8267e-01],\n",
      "         [6.7501e-01],\n",
      "         [2.5981e-01],\n",
      "         [8.5061e-01],\n",
      "         [6.6195e-01],\n",
      "         [7.0899e-01],\n",
      "         [8.4406e-01],\n",
      "         [8.5476e-01],\n",
      "         [8.2963e-01],\n",
      "         [1.7068e-02],\n",
      "         [4.1738e-01],\n",
      "         [8.6937e-01],\n",
      "         [5.1222e-01],\n",
      "         [4.9146e-01],\n",
      "         [2.4011e-01],\n",
      "         [5.0792e-01],\n",
      "         [6.3611e-01],\n",
      "         [6.6250e-01],\n",
      "         [9.7831e-01],\n",
      "         [1.8170e-01],\n",
      "         [6.2447e-01],\n",
      "         [2.0518e-02],\n",
      "         [6.1780e-01],\n",
      "         [1.7518e-01],\n",
      "         [8.2085e-01],\n",
      "         [2.2404e-01],\n",
      "         [3.0140e-01],\n",
      "         [8.2674e-02],\n",
      "         [8.0113e-02],\n",
      "         [4.4566e-01],\n",
      "         [7.1935e-01],\n",
      "         [8.4111e-01],\n",
      "         [9.5110e-01],\n",
      "         [4.7701e-01],\n",
      "         [2.4596e-01],\n",
      "         [7.9449e-01],\n",
      "         [2.6516e-01],\n",
      "         [5.5130e-01],\n",
      "         [1.2116e-01],\n",
      "         [4.2131e-01],\n",
      "         [2.6564e-01],\n",
      "         [2.5664e-01],\n",
      "         [1.1437e-01],\n",
      "         [8.7982e-01],\n",
      "         [6.1208e-01],\n",
      "         [4.3446e-01],\n",
      "         [7.7658e-02]]], device='cuda:0', dtype=torch.float64)\n",
      "================iter 5============\n",
      "['shape/ellipsoid/1/ellipsoid_512_128_64_64_2_0_1']\n",
      "tensor([[ True,  True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
      "          True,  True,  True, False,  True,  True,  True,  True, False, False]],\n",
      "       device='cuda:0')\n",
      "@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@\n",
      "['shape/ellipsoid/1/ellipsoid_512_128_64_64_2_1_1']\n",
      "gt_trans_torch.Size([1, 20, 3])_tensor([[[-1.6262e-01,  4.3296e-01, -4.3112e-03],\n",
      "         [-1.4832e-01,  4.1224e-01, -1.3967e-02],\n",
      "         [-1.6853e-02,  6.7972e-02,  5.4156e-03],\n",
      "         [-1.1403e-02,  2.6968e-02,  7.0584e-03],\n",
      "         [-5.1070e-18, -1.0658e-17, -5.7732e-18],\n",
      "         [ 6.6874e-03, -3.7126e-02, -4.6883e-04],\n",
      "         [ 2.5735e-02, -7.6369e-02,  3.3665e-03],\n",
      "         [ 4.4628e-02, -1.0912e-01,  2.9635e-03],\n",
      "         [ 4.9109e-02, -1.4521e-01,  1.2439e-03],\n",
      "         [ 6.8645e-02, -1.8965e-01,  8.8555e-03],\n",
      "         [-1.2914e-01,  3.7088e-01, -8.7588e-03],\n",
      "         [-1.2448e-01,  3.3048e-01, -7.6525e-03],\n",
      "         [-1.0104e-01,  2.9433e-01, -4.5023e-03],\n",
      "         [-8.3226e-02,  2.5115e-01,  2.1004e-03],\n",
      "         [-9.1205e-02,  2.1722e-01, -5.6917e-03],\n",
      "         [-7.9580e-02,  1.8203e-01, -7.0083e-03],\n",
      "         [-3.8397e-02,  1.4210e-01,  4.9774e-03],\n",
      "         [-4.4972e-02,  9.9441e-02,  3.1865e-03],\n",
      "         [ 0.0000e+00,  0.0000e+00,  0.0000e+00],\n",
      "         [ 0.0000e+00,  0.0000e+00,  0.0000e+00]]], device='cuda:0')\n",
      "gt_rots_torch.Size([1, 20, 4])_tensor([[[-0.4640, -0.5768,  0.6664,  0.0893],\n",
      "         [-0.1597,  0.1401,  0.0092,  0.9771],\n",
      "         [ 0.4365,  0.4039,  0.8038,  0.0167],\n",
      "         [-0.4792,  0.6229,  0.4145, -0.4587],\n",
      "         [-0.2454,  0.8756, -0.3016, -0.2866],\n",
      "         [ 0.0628, -0.2204,  0.9724, -0.0436],\n",
      "         [-0.4179,  0.8393,  0.1353,  0.3202],\n",
      "         [-0.5682,  0.7341, -0.2710, -0.2544],\n",
      "         [ 0.7668, -0.4037,  0.1779,  0.4662],\n",
      "         [ 0.8357, -0.3259,  0.4050, -0.1775],\n",
      "         [ 0.1170, -0.0929,  0.9007, -0.4080],\n",
      "         [ 0.8923,  0.1424, -0.1972, -0.3804],\n",
      "         [ 0.1752,  0.7563, -0.6295, -0.0331],\n",
      "         [-0.2724,  0.7921, -0.5228,  0.1582],\n",
      "         [ 0.1822, -0.1496,  0.8487, -0.4734],\n",
      "         [ 0.5987,  0.6571, -0.4228,  0.1762],\n",
      "         [-0.5443,  0.5382,  0.6188, -0.1767],\n",
      "         [-0.1136,  0.4212,  0.5695,  0.6967],\n",
      "         [ 0.0000,  0.0000,  0.0000,  0.0000],\n",
      "         [ 0.0000,  0.0000,  0.0000,  0.0000]]], device='cuda:0')\n",
      "noisy_trans_and_rots_torch.Size([1, 20, 7])_tensor([[[ 1.1050,  0.0000, -1.6133,  2.0488,  0.0000,  0.0000,  0.6675],\n",
      "         [-0.3028,  0.0000, -0.1463,  0.2971,  0.0000,  0.0000,  1.2131],\n",
      "         [-1.8711,  0.0000,  0.1996, -0.5843,  0.0000,  0.0000,  0.3903],\n",
      "         [-1.2839,  0.0000, -0.0795,  1.8957,  0.0000,  0.0000,  0.3395],\n",
      "         [ 1.7632,  0.0000,  1.3797, -0.7991,  0.0000,  0.0000,  0.6498],\n",
      "         [-0.7614,  0.0000, -0.6333,  1.6321,  0.0000,  0.0000, -0.3645],\n",
      "         [-0.2574,  0.0000,  0.9892,  2.4273,  0.0000,  0.0000, -0.8885],\n",
      "         [ 0.1932,  0.0000,  0.2535, -1.2879,  0.0000,  0.0000,  1.0228],\n",
      "         [-0.7673,  0.0000, -0.9748, -0.6447,  0.0000,  0.0000, -0.4982],\n",
      "         [-1.0539,  0.0000, -0.5633,  1.1344,  0.0000,  0.0000, -0.6888],\n",
      "         [-1.7143,  0.0000, -1.9749,  0.5131,  0.0000,  0.0000,  0.7323],\n",
      "         [ 0.9312,  0.0000, -1.9581,  0.0119,  0.0000,  0.0000,  0.0831],\n",
      "         [-1.7060,  0.0000, -0.4552,  1.5255,  0.0000,  0.0000, -0.0927],\n",
      "         [-0.6327,  0.0000, -1.1031,  1.8875,  0.0000,  0.0000,  0.4940],\n",
      "         [-1.9685,  0.0000,  1.9534, -1.1756,  0.0000,  0.0000, -0.3413],\n",
      "         [-1.0525,  0.0000, -1.4526,  0.7968,  0.0000,  0.0000,  0.7932],\n",
      "         [ 0.1572,  0.0000,  1.6148,  0.9742,  0.0000,  0.0000,  0.8953],\n",
      "         [ 1.5025,  0.0000,  0.5548, -2.8501,  0.0000,  0.0000, -0.3623],\n",
      "         [ 0.6781,  0.0000,  0.1204,  0.0775,  0.0000,  0.0000, -0.5454],\n",
      "         [ 0.8444,  0.0000,  1.4051,  0.4344,  0.0000,  0.0000,  1.4548]]],\n",
      "       device='cuda:0')\n",
      "================iter 0============\n",
      "['shape/ellipsoid/1/ellipsoid_512_128_64_64_2_1_1']\n",
      "tensor([[False, False, False, False,  True, False, False, False, False, False,\n",
      "         False, False, False, False, False, False, False, False, False, False]],\n",
      "       device='cuda:0')\n",
      "acc torch.Size([1]) tensor([0.0556], device='cuda:0')\n",
      "acc_per_part torch.Size([1, 20]) tensor([[False, False, False, False,  True, False, False, False, False, False,\n",
      "         False, False, False, False, False, False, False, False, False, False]],\n",
      "       device='cuda:0')\n",
      "loss_per_data torch.Size([1, 20]) tensor([[ 1.6370,  1.4787,  1.2972,  7.0596,  0.0000,  0.2593,  5.3456,  0.9553,\n",
      "          1.1220,  0.6461,  9.8114,  8.7072, 10.2195,  1.2711,  5.7196,  4.4014,\n",
      "          3.6599,  2.6194,  0.4069,  1.4247]], device='cuda:0')\n",
      "scores torch.Size([1, 190, 1]) tensor([[[0.1244],\n",
      "         [0.5086],\n",
      "         [0.2165],\n",
      "         [0.5127],\n",
      "         [0.5638],\n",
      "         [0.7127],\n",
      "         [0.7300],\n",
      "         [0.0774],\n",
      "         [0.0838],\n",
      "         [0.5643],\n",
      "         [0.2913],\n",
      "         [0.6884],\n",
      "         [0.4216],\n",
      "         [0.8593],\n",
      "         [0.0699],\n",
      "         [0.3911],\n",
      "         [0.6546],\n",
      "         [0.3054],\n",
      "         [0.8248],\n",
      "         [0.5505],\n",
      "         [0.5292],\n",
      "         [0.3542],\n",
      "         [0.3358],\n",
      "         [0.7337],\n",
      "         [0.4692],\n",
      "         [0.2596],\n",
      "         [0.0911],\n",
      "         [0.4533],\n",
      "         [0.3127],\n",
      "         [0.7741],\n",
      "         [0.5747],\n",
      "         [0.0277],\n",
      "         [0.0501],\n",
      "         [0.0658],\n",
      "         [0.2589],\n",
      "         [0.8217],\n",
      "         [0.1009],\n",
      "         [0.9132],\n",
      "         [0.1548],\n",
      "         [0.0398],\n",
      "         [0.2030],\n",
      "         [0.7372],\n",
      "         [0.3269],\n",
      "         [0.0463],\n",
      "         [0.6719],\n",
      "         [0.4435],\n",
      "         [0.6717],\n",
      "         [0.0861],\n",
      "         [0.3966],\n",
      "         [0.9099],\n",
      "         [0.4054],\n",
      "         [0.8972],\n",
      "         [0.5947],\n",
      "         [0.4746],\n",
      "         [0.0398],\n",
      "         [0.1140],\n",
      "         [0.7630],\n",
      "         [0.3434],\n",
      "         [0.5984],\n",
      "         [0.2176],\n",
      "         [0.4032],\n",
      "         [0.3324],\n",
      "         [0.7213],\n",
      "         [0.7503],\n",
      "         [0.8031],\n",
      "         [0.1754],\n",
      "         [0.9576],\n",
      "         [0.8717],\n",
      "         [0.5290],\n",
      "         [0.2112],\n",
      "         [0.1695],\n",
      "         [0.9831],\n",
      "         [0.9872],\n",
      "         [0.3282],\n",
      "         [0.9276],\n",
      "         [0.4186],\n",
      "         [0.9536],\n",
      "         [0.8104],\n",
      "         [0.1289],\n",
      "         [0.7565],\n",
      "         [0.4127],\n",
      "         [0.8733],\n",
      "         [0.6643],\n",
      "         [0.8565],\n",
      "         [0.3906],\n",
      "         [0.1707],\n",
      "         [0.3369],\n",
      "         [0.1187],\n",
      "         [0.6837],\n",
      "         [0.1417],\n",
      "         [0.2868],\n",
      "         [0.8112],\n",
      "         [0.4738],\n",
      "         [0.5295],\n",
      "         [0.5764],\n",
      "         [0.1174],\n",
      "         [0.5563],\n",
      "         [0.1380],\n",
      "         [0.9017],\n",
      "         [0.7458],\n",
      "         [0.2469],\n",
      "         [0.8200],\n",
      "         [0.8205],\n",
      "         [0.3688],\n",
      "         [0.4847],\n",
      "         [0.8718],\n",
      "         [0.9138],\n",
      "         [0.6678],\n",
      "         [0.3545],\n",
      "         [0.5523],\n",
      "         [0.1886],\n",
      "         [0.6100],\n",
      "         [0.4825],\n",
      "         [0.0665],\n",
      "         [0.5772],\n",
      "         [0.2717],\n",
      "         [0.8982],\n",
      "         [0.3254],\n",
      "         [0.2497],\n",
      "         [0.6421],\n",
      "         [0.3736],\n",
      "         [0.4491],\n",
      "         [0.7600],\n",
      "         [0.7473],\n",
      "         [0.3456],\n",
      "         [0.5076],\n",
      "         [0.1181],\n",
      "         [0.3541],\n",
      "         [0.5042],\n",
      "         [0.0627],\n",
      "         [0.5553],\n",
      "         [0.5390],\n",
      "         [0.4445],\n",
      "         [0.8790],\n",
      "         [0.3897],\n",
      "         [0.9159],\n",
      "         [0.0085],\n",
      "         [0.7694],\n",
      "         [0.4748],\n",
      "         [0.8764],\n",
      "         [0.7511],\n",
      "         [0.3500],\n",
      "         [0.9107],\n",
      "         [0.0177],\n",
      "         [0.3926],\n",
      "         [0.3855],\n",
      "         [0.5005],\n",
      "         [0.5236],\n",
      "         [0.6909],\n",
      "         [0.8963],\n",
      "         [0.2804],\n",
      "         [0.2588],\n",
      "         [0.3706],\n",
      "         [0.8716],\n",
      "         [0.1292],\n",
      "         [0.7143],\n",
      "         [0.5560],\n",
      "         [0.1828],\n",
      "         [0.7550],\n",
      "         [0.9574],\n",
      "         [0.7245],\n",
      "         [0.7684],\n",
      "         [0.0942],\n",
      "         [0.4180],\n",
      "         [0.3161],\n",
      "         [0.8625],\n",
      "         [0.8456],\n",
      "         [0.4558],\n",
      "         [0.5502],\n",
      "         [0.5523],\n",
      "         [0.0944],\n",
      "         [0.2489],\n",
      "         [0.5290],\n",
      "         [0.9275],\n",
      "         [0.1295],\n",
      "         [0.8520],\n",
      "         [0.8067],\n",
      "         [0.6000],\n",
      "         [0.6185],\n",
      "         [0.6559],\n",
      "         [0.1484],\n",
      "         [0.5169],\n",
      "         [0.1486],\n",
      "         [0.9698],\n",
      "         [0.0749],\n",
      "         [0.3165],\n",
      "         [0.8834],\n",
      "         [0.0044],\n",
      "         [0.0089],\n",
      "         [0.4921]]], device='cuda:0', dtype=torch.float64)\n",
      "================iter 1============\n",
      "['shape/ellipsoid/1/ellipsoid_512_128_64_64_2_1_1']\n",
      "tensor([[False, False, False, False,  True, False,  True,  True, False,  True,\n",
      "         False,  True, False, False, False, False, False, False, False, False]],\n",
      "       device='cuda:0')\n",
      "acc torch.Size([1]) tensor([0.0556], device='cuda:0')\n",
      "acc_per_part torch.Size([1, 20]) tensor([[False, False, False, False,  True, False, False, False, False, False,\n",
      "         False, False, False, False, False, False, False, False, False, False]],\n",
      "       device='cuda:0')\n",
      "loss_per_data torch.Size([1, 20]) tensor([[ 3.8121,  9.2821,  3.8168,  9.5776,  0.0000,  6.1736,  5.3456,  0.9553,\n",
      "         14.4670,  0.6461,  5.4151,  8.7072, 41.9617, 34.7663,  4.0780,  9.2553,\n",
      "          7.7522,  0.9766,  1.4743,  1.0059]], device='cuda:0')\n",
      "scores torch.Size([1, 190, 1]) tensor([[[6.4120e-02],\n",
      "         [3.9355e-01],\n",
      "         [6.6640e-01],\n",
      "         [6.2830e-01],\n",
      "         [1.0473e-01],\n",
      "         [1.5467e-01],\n",
      "         [4.0256e-01],\n",
      "         [1.3223e-01],\n",
      "         [8.3360e-02],\n",
      "         [1.0820e-02],\n",
      "         [4.6239e-01],\n",
      "         [2.1020e-01],\n",
      "         [5.0155e-01],\n",
      "         [4.6161e-01],\n",
      "         [4.4714e-01],\n",
      "         [7.8443e-01],\n",
      "         [7.2584e-01],\n",
      "         [6.0652e-01],\n",
      "         [2.7394e-01],\n",
      "         [3.0249e-01],\n",
      "         [7.6411e-01],\n",
      "         [2.1187e-01],\n",
      "         [9.5048e-01],\n",
      "         [5.1696e-01],\n",
      "         [9.9104e-01],\n",
      "         [4.3073e-01],\n",
      "         [5.6910e-01],\n",
      "         [6.8374e-02],\n",
      "         [7.1164e-01],\n",
      "         [8.2960e-01],\n",
      "         [9.3209e-01],\n",
      "         [5.3750e-01],\n",
      "         [6.6528e-01],\n",
      "         [7.3827e-02],\n",
      "         [7.5341e-02],\n",
      "         [6.9509e-01],\n",
      "         [4.1111e-01],\n",
      "         [1.0417e-01],\n",
      "         [8.4307e-01],\n",
      "         [9.7488e-01],\n",
      "         [6.5788e-01],\n",
      "         [9.6327e-01],\n",
      "         [4.4915e-01],\n",
      "         [5.0569e-02],\n",
      "         [7.0649e-01],\n",
      "         [2.3582e-01],\n",
      "         [5.9430e-01],\n",
      "         [8.3283e-01],\n",
      "         [3.6581e-01],\n",
      "         [7.4216e-01],\n",
      "         [7.9792e-01],\n",
      "         [1.1332e-01],\n",
      "         [6.5719e-01],\n",
      "         [3.1612e-01],\n",
      "         [9.8577e-01],\n",
      "         [8.2257e-01],\n",
      "         [6.2199e-01],\n",
      "         [7.7417e-01],\n",
      "         [5.5812e-01],\n",
      "         [4.7725e-02],\n",
      "         [5.3665e-01],\n",
      "         [8.7237e-01],\n",
      "         [7.7655e-01],\n",
      "         [1.7826e-01],\n",
      "         [3.8626e-01],\n",
      "         [8.7890e-01],\n",
      "         [2.6156e-01],\n",
      "         [1.6311e-01],\n",
      "         [9.0623e-01],\n",
      "         [1.2595e-01],\n",
      "         [1.8279e-01],\n",
      "         [6.6355e-01],\n",
      "         [8.9687e-01],\n",
      "         [1.9395e-01],\n",
      "         [7.7094e-01],\n",
      "         [9.5379e-01],\n",
      "         [4.1041e-01],\n",
      "         [8.5679e-01],\n",
      "         [9.0848e-01],\n",
      "         [7.8356e-01],\n",
      "         [3.0884e-01],\n",
      "         [9.6465e-01],\n",
      "         [8.5652e-01],\n",
      "         [5.0968e-01],\n",
      "         [1.2843e-01],\n",
      "         [2.4924e-01],\n",
      "         [6.4508e-02],\n",
      "         [7.1439e-02],\n",
      "         [8.0438e-01],\n",
      "         [3.8073e-01],\n",
      "         [7.4012e-01],\n",
      "         [6.1216e-01],\n",
      "         [7.5335e-01],\n",
      "         [4.6032e-01],\n",
      "         [4.6992e-01],\n",
      "         [4.4241e-01],\n",
      "         [3.2875e-01],\n",
      "         [8.4067e-01],\n",
      "         [2.8894e-01],\n",
      "         [5.6591e-02],\n",
      "         [1.6345e-01],\n",
      "         [2.4303e-01],\n",
      "         [5.6957e-01],\n",
      "         [6.9209e-01],\n",
      "         [8.9552e-02],\n",
      "         [5.5325e-01],\n",
      "         [4.4526e-01],\n",
      "         [1.7796e-01],\n",
      "         [5.8811e-02],\n",
      "         [7.1466e-01],\n",
      "         [9.7978e-01],\n",
      "         [1.3905e-01],\n",
      "         [3.6593e-01],\n",
      "         [8.0052e-01],\n",
      "         [9.1162e-01],\n",
      "         [2.3875e-01],\n",
      "         [2.5235e-01],\n",
      "         [9.0999e-01],\n",
      "         [6.6980e-01],\n",
      "         [4.9245e-01],\n",
      "         [9.4454e-01],\n",
      "         [9.8737e-01],\n",
      "         [1.4217e-01],\n",
      "         [4.5709e-01],\n",
      "         [9.2204e-01],\n",
      "         [1.0635e-01],\n",
      "         [4.0063e-01],\n",
      "         [4.7733e-01],\n",
      "         [5.4864e-02],\n",
      "         [1.9151e-02],\n",
      "         [5.6087e-01],\n",
      "         [2.3263e-01],\n",
      "         [7.7652e-01],\n",
      "         [6.4396e-01],\n",
      "         [7.2924e-02],\n",
      "         [2.2378e-01],\n",
      "         [8.7770e-01],\n",
      "         [8.8336e-05],\n",
      "         [5.3695e-01],\n",
      "         [1.7095e-01],\n",
      "         [5.2936e-01],\n",
      "         [8.5722e-01],\n",
      "         [8.2174e-02],\n",
      "         [2.3661e-01],\n",
      "         [3.3044e-01],\n",
      "         [2.0655e-01],\n",
      "         [5.2881e-01],\n",
      "         [1.2559e-01],\n",
      "         [1.8413e-01],\n",
      "         [8.3041e-01],\n",
      "         [8.8844e-01],\n",
      "         [6.4904e-01],\n",
      "         [5.6958e-01],\n",
      "         [3.4387e-01],\n",
      "         [6.3703e-02],\n",
      "         [3.4563e-01],\n",
      "         [5.0155e-03],\n",
      "         [1.8951e-01],\n",
      "         [4.1570e-01],\n",
      "         [9.5596e-01],\n",
      "         [6.2627e-01],\n",
      "         [2.4529e-01],\n",
      "         [5.6931e-01],\n",
      "         [1.9973e-01],\n",
      "         [6.7523e-01],\n",
      "         [1.7866e-01],\n",
      "         [4.2035e-03],\n",
      "         [1.3998e-01],\n",
      "         [8.1851e-01],\n",
      "         [3.9006e-01],\n",
      "         [1.2832e-01],\n",
      "         [8.4803e-01],\n",
      "         [7.3971e-01],\n",
      "         [4.2438e-02],\n",
      "         [4.1855e-01],\n",
      "         [7.8733e-01],\n",
      "         [2.8023e-01],\n",
      "         [6.1311e-01],\n",
      "         [4.5013e-01],\n",
      "         [3.0302e-01],\n",
      "         [2.6311e-01],\n",
      "         [6.8824e-01],\n",
      "         [7.3829e-01],\n",
      "         [2.9393e-01],\n",
      "         [3.8304e-01],\n",
      "         [1.1628e-01],\n",
      "         [8.7266e-01],\n",
      "         [9.3451e-01],\n",
      "         [1.4218e-01],\n",
      "         [7.6691e-01]]], device='cuda:0', dtype=torch.float64)\n",
      "================iter 2============\n",
      "['shape/ellipsoid/1/ellipsoid_512_128_64_64_2_1_1']\n",
      "tensor([[False,  True,  True,  True,  True, False,  True,  True,  True,  True,\n",
      "          True,  True, False,  True, False, False,  True,  True, False, False]],\n",
      "       device='cuda:0')\n",
      "acc torch.Size([1]) tensor([0.0556], device='cuda:0')\n",
      "acc_per_part torch.Size([1, 20]) tensor([[False, False, False, False,  True, False, False, False, False, False,\n",
      "         False, False, False, False, False, False, False, False, False, False]],\n",
      "       device='cuda:0')\n",
      "loss_per_data torch.Size([1, 20]) tensor([[  2.6401,   9.2821,   3.8168,   9.5776,   0.0000,  21.2407,   5.3456,\n",
      "           0.9553,  14.4670,   0.6461,   5.4151,   8.7072, 144.8415,  34.7663,\n",
      "           8.7352,  66.0174,   7.7522,   0.9766,   2.1224,   6.5000]],\n",
      "       device='cuda:0')\n",
      "scores torch.Size([1, 190, 1]) tensor([[[0.6578],\n",
      "         [0.2068],\n",
      "         [0.6144],\n",
      "         [0.8520],\n",
      "         [0.5137],\n",
      "         [0.2684],\n",
      "         [0.4742],\n",
      "         [0.8104],\n",
      "         [0.8748],\n",
      "         [0.5282],\n",
      "         [0.4521],\n",
      "         [0.7099],\n",
      "         [0.5031],\n",
      "         [0.2220],\n",
      "         [0.2866],\n",
      "         [0.4691],\n",
      "         [0.2215],\n",
      "         [0.5445],\n",
      "         [0.5496],\n",
      "         [0.6341],\n",
      "         [0.6581],\n",
      "         [0.4865],\n",
      "         [0.4107],\n",
      "         [0.6176],\n",
      "         [0.7895],\n",
      "         [0.9917],\n",
      "         [0.8934],\n",
      "         [0.7010],\n",
      "         [0.0286],\n",
      "         [0.1832],\n",
      "         [0.4092],\n",
      "         [0.7301],\n",
      "         [0.5425],\n",
      "         [0.0806],\n",
      "         [0.4705],\n",
      "         [0.2556],\n",
      "         [0.4227],\n",
      "         [0.8028],\n",
      "         [0.8018],\n",
      "         [0.2243],\n",
      "         [0.1780],\n",
      "         [0.6991],\n",
      "         [0.0995],\n",
      "         [0.5838],\n",
      "         [0.4486],\n",
      "         [0.2125],\n",
      "         [0.6604],\n",
      "         [0.9455],\n",
      "         [0.4977],\n",
      "         [0.7805],\n",
      "         [0.3178],\n",
      "         [0.5605],\n",
      "         [0.7558],\n",
      "         [0.5763],\n",
      "         [0.3430],\n",
      "         [0.9589],\n",
      "         [0.8978],\n",
      "         [0.3179],\n",
      "         [0.2392],\n",
      "         [0.1071],\n",
      "         [0.4682],\n",
      "         [0.2117],\n",
      "         [0.2511],\n",
      "         [0.6934],\n",
      "         [0.5524],\n",
      "         [0.8895],\n",
      "         [0.8697],\n",
      "         [0.8706],\n",
      "         [0.4892],\n",
      "         [0.6793],\n",
      "         [0.1348],\n",
      "         [0.0579],\n",
      "         [0.5898],\n",
      "         [0.4304],\n",
      "         [0.4161],\n",
      "         [0.5886],\n",
      "         [0.3907],\n",
      "         [0.5580],\n",
      "         [0.6705],\n",
      "         [0.8423],\n",
      "         [0.9639],\n",
      "         [0.3088],\n",
      "         [0.4714],\n",
      "         [0.8822],\n",
      "         [0.4701],\n",
      "         [0.1267],\n",
      "         [0.5531],\n",
      "         [0.3659],\n",
      "         [0.7306],\n",
      "         [0.4606],\n",
      "         [0.5578],\n",
      "         [0.8071],\n",
      "         [0.5801],\n",
      "         [0.1355],\n",
      "         [0.4841],\n",
      "         [0.8363],\n",
      "         [0.1389],\n",
      "         [0.2517],\n",
      "         [0.2900],\n",
      "         [0.6869],\n",
      "         [0.8681],\n",
      "         [0.3660],\n",
      "         [0.3503],\n",
      "         [0.4500],\n",
      "         [0.2714],\n",
      "         [0.9100],\n",
      "         [0.2774],\n",
      "         [0.0713],\n",
      "         [0.5175],\n",
      "         [0.5408],\n",
      "         [0.3296],\n",
      "         [0.5178],\n",
      "         [0.1458],\n",
      "         [0.0231],\n",
      "         [0.7314],\n",
      "         [0.0792],\n",
      "         [0.9848],\n",
      "         [0.3833],\n",
      "         [0.9973],\n",
      "         [0.1577],\n",
      "         [0.4765],\n",
      "         [0.2462],\n",
      "         [0.9331],\n",
      "         [0.7264],\n",
      "         [0.3916],\n",
      "         [0.6660],\n",
      "         [0.4467],\n",
      "         [0.6496],\n",
      "         [0.2990],\n",
      "         [0.1793],\n",
      "         [0.3702],\n",
      "         [0.2018],\n",
      "         [0.2394],\n",
      "         [0.4738],\n",
      "         [0.3386],\n",
      "         [0.2414],\n",
      "         [0.8845],\n",
      "         [0.8002],\n",
      "         [0.3436],\n",
      "         [0.0610],\n",
      "         [0.2322],\n",
      "         [0.2972],\n",
      "         [0.1612],\n",
      "         [0.4236],\n",
      "         [0.8572],\n",
      "         [0.1464],\n",
      "         [0.2686],\n",
      "         [0.6086],\n",
      "         [0.2132],\n",
      "         [0.1325],\n",
      "         [0.5250],\n",
      "         [0.1820],\n",
      "         [0.2006],\n",
      "         [0.3124],\n",
      "         [0.3363],\n",
      "         [0.4378],\n",
      "         [0.9295],\n",
      "         [0.4442],\n",
      "         [0.2814],\n",
      "         [0.7382],\n",
      "         [0.8420],\n",
      "         [0.2173],\n",
      "         [0.5950],\n",
      "         [0.0022],\n",
      "         [0.8775],\n",
      "         [0.4624],\n",
      "         [0.3165],\n",
      "         [0.6611],\n",
      "         [0.3948],\n",
      "         [0.0841],\n",
      "         [0.4596],\n",
      "         [0.8136],\n",
      "         [0.9014],\n",
      "         [0.8447],\n",
      "         [0.8534],\n",
      "         [0.4941],\n",
      "         [0.3811],\n",
      "         [0.1743],\n",
      "         [0.2140],\n",
      "         [0.5554],\n",
      "         [0.6455],\n",
      "         [0.2664],\n",
      "         [0.1057],\n",
      "         [0.4045],\n",
      "         [0.4204],\n",
      "         [0.9443],\n",
      "         [0.9859],\n",
      "         [0.1903],\n",
      "         [0.4422],\n",
      "         [0.5351]]], device='cuda:0', dtype=torch.float64)\n",
      "================iter 3============\n",
      "['shape/ellipsoid/1/ellipsoid_512_128_64_64_2_1_1']\n",
      "tensor([[False,  True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
      "          True,  True,  True,  True,  True,  True,  True,  True, False, False]],\n",
      "       device='cuda:0')\n",
      "acc torch.Size([1]) tensor([0.0556], device='cuda:0')\n",
      "acc_per_part torch.Size([1, 20]) tensor([[False, False, False, False,  True, False, False, False, False, False,\n",
      "         False, False, False, False, False, False, False, False, False, False]],\n",
      "       device='cuda:0')\n",
      "loss_per_data torch.Size([1, 20]) tensor([[ 26.2400,   9.2821,   3.8168,   9.5776,   0.0000,  21.2407,   5.3456,\n",
      "           0.9553,  14.4670,   0.6461,   5.4151,   8.7072, 144.8415,  34.7663,\n",
      "           8.7352,  66.0174,   7.7522,   0.9766,   5.3949,   1.9297]],\n",
      "       device='cuda:0')\n",
      "scores torch.Size([1, 190, 1]) tensor([[[9.1299e-01],\n",
      "         [8.4492e-01],\n",
      "         [7.4513e-01],\n",
      "         [5.7764e-01],\n",
      "         [9.7425e-01],\n",
      "         [1.3277e-01],\n",
      "         [7.5632e-01],\n",
      "         [7.6527e-01],\n",
      "         [2.0831e-01],\n",
      "         [5.2960e-01],\n",
      "         [6.2931e-01],\n",
      "         [6.7877e-01],\n",
      "         [8.6080e-01],\n",
      "         [4.3925e-01],\n",
      "         [7.3845e-01],\n",
      "         [3.6318e-01],\n",
      "         [1.4259e-01],\n",
      "         [9.4330e-01],\n",
      "         [4.1110e-01],\n",
      "         [1.7736e-01],\n",
      "         [7.4968e-01],\n",
      "         [2.7623e-01],\n",
      "         [5.6357e-01],\n",
      "         [1.2478e-01],\n",
      "         [9.9231e-01],\n",
      "         [8.8528e-01],\n",
      "         [3.1654e-01],\n",
      "         [9.5924e-01],\n",
      "         [5.4852e-01],\n",
      "         [7.9043e-01],\n",
      "         [8.7607e-01],\n",
      "         [9.5303e-01],\n",
      "         [9.4237e-01],\n",
      "         [6.4631e-01],\n",
      "         [8.2295e-01],\n",
      "         [9.4070e-01],\n",
      "         [4.9402e-01],\n",
      "         [6.7339e-01],\n",
      "         [4.3831e-01],\n",
      "         [1.7710e-02],\n",
      "         [5.9773e-01],\n",
      "         [2.5842e-01],\n",
      "         [9.0362e-01],\n",
      "         [8.6105e-01],\n",
      "         [8.9706e-01],\n",
      "         [6.1607e-02],\n",
      "         [4.5215e-01],\n",
      "         [8.8215e-01],\n",
      "         [5.0809e-01],\n",
      "         [8.6334e-01],\n",
      "         [1.0338e-01],\n",
      "         [1.1397e-01],\n",
      "         [1.4367e-02],\n",
      "         [7.5400e-01],\n",
      "         [4.5147e-01],\n",
      "         [7.4499e-04],\n",
      "         [8.6056e-01],\n",
      "         [7.0717e-01],\n",
      "         [2.0949e-01],\n",
      "         [6.1355e-02],\n",
      "         [2.2938e-01],\n",
      "         [3.5302e-01],\n",
      "         [7.0414e-01],\n",
      "         [8.8272e-01],\n",
      "         [5.8519e-01],\n",
      "         [6.9824e-01],\n",
      "         [8.8308e-01],\n",
      "         [2.8966e-01],\n",
      "         [7.2295e-01],\n",
      "         [1.4355e-01],\n",
      "         [9.2993e-01],\n",
      "         [4.5375e-01],\n",
      "         [4.3957e-01],\n",
      "         [2.1568e-02],\n",
      "         [9.2991e-01],\n",
      "         [9.0830e-01],\n",
      "         [2.8263e-01],\n",
      "         [7.3927e-02],\n",
      "         [3.2311e-01],\n",
      "         [5.7389e-01],\n",
      "         [3.5964e-01],\n",
      "         [6.0209e-01],\n",
      "         [4.9981e-01],\n",
      "         [3.5769e-01],\n",
      "         [5.8350e-01],\n",
      "         [5.2868e-01],\n",
      "         [8.5108e-01],\n",
      "         [6.1625e-01],\n",
      "         [3.1085e-01],\n",
      "         [7.2874e-01],\n",
      "         [4.3135e-01],\n",
      "         [6.8825e-01],\n",
      "         [6.5470e-01],\n",
      "         [7.7168e-01],\n",
      "         [8.1392e-02],\n",
      "         [8.1498e-01],\n",
      "         [2.0392e-01],\n",
      "         [3.4333e-01],\n",
      "         [3.2776e-01],\n",
      "         [5.6640e-01],\n",
      "         [5.3654e-01],\n",
      "         [7.5752e-01],\n",
      "         [3.7394e-01],\n",
      "         [9.4302e-01],\n",
      "         [1.3713e-02],\n",
      "         [2.9194e-01],\n",
      "         [8.4843e-01],\n",
      "         [9.6543e-01],\n",
      "         [5.4422e-01],\n",
      "         [1.2315e-01],\n",
      "         [3.8026e-01],\n",
      "         [8.2558e-01],\n",
      "         [7.1897e-01],\n",
      "         [7.4518e-01],\n",
      "         [9.4693e-01],\n",
      "         [1.2990e-01],\n",
      "         [3.9226e-01],\n",
      "         [9.2428e-01],\n",
      "         [1.5435e-01],\n",
      "         [9.9353e-01],\n",
      "         [6.1783e-01],\n",
      "         [4.1695e-01],\n",
      "         [1.1467e-01],\n",
      "         [3.8167e-01],\n",
      "         [7.3950e-01],\n",
      "         [8.9763e-01],\n",
      "         [4.3763e-01],\n",
      "         [4.6584e-01],\n",
      "         [3.6969e-01],\n",
      "         [6.5835e-01],\n",
      "         [7.4132e-01],\n",
      "         [4.1203e-01],\n",
      "         [4.1456e-01],\n",
      "         [7.9563e-01],\n",
      "         [2.6816e-01],\n",
      "         [8.4072e-01],\n",
      "         [4.9352e-01],\n",
      "         [2.1758e-01],\n",
      "         [1.5391e-01],\n",
      "         [6.5601e-01],\n",
      "         [9.3135e-01],\n",
      "         [2.8853e-01],\n",
      "         [4.6512e-01],\n",
      "         [7.8316e-03],\n",
      "         [2.8260e-01],\n",
      "         [5.6614e-01],\n",
      "         [3.6022e-01],\n",
      "         [3.4673e-01],\n",
      "         [4.6541e-01],\n",
      "         [3.6643e-01],\n",
      "         [4.9854e-01],\n",
      "         [8.6058e-01],\n",
      "         [4.8801e-01],\n",
      "         [3.3820e-01],\n",
      "         [3.0487e-01],\n",
      "         [5.8238e-01],\n",
      "         [5.9195e-01],\n",
      "         [7.6405e-01],\n",
      "         [6.0062e-02],\n",
      "         [3.8865e-01],\n",
      "         [5.6072e-01],\n",
      "         [5.5293e-01],\n",
      "         [6.5016e-01],\n",
      "         [8.5682e-01],\n",
      "         [9.9696e-01],\n",
      "         [1.7580e-02],\n",
      "         [2.9214e-01],\n",
      "         [4.3989e-01],\n",
      "         [7.7513e-01],\n",
      "         [8.5103e-01],\n",
      "         [8.8956e-01],\n",
      "         [8.9384e-01],\n",
      "         [4.1492e-01],\n",
      "         [5.1720e-01],\n",
      "         [5.7519e-01],\n",
      "         [7.5926e-01],\n",
      "         [6.4641e-01],\n",
      "         [5.2707e-01],\n",
      "         [4.9882e-01],\n",
      "         [5.5492e-01],\n",
      "         [2.1023e-01],\n",
      "         [4.4338e-01],\n",
      "         [1.4974e-01],\n",
      "         [7.4595e-01],\n",
      "         [1.0669e-01],\n",
      "         [8.7847e-01],\n",
      "         [9.4417e-01],\n",
      "         [8.2272e-01],\n",
      "         [6.6428e-01],\n",
      "         [2.3687e-01]]], device='cuda:0', dtype=torch.float64)\n",
      "================iter 4============\n",
      "['shape/ellipsoid/1/ellipsoid_512_128_64_64_2_1_1']\n",
      "tensor([[ True,  True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
      "          True,  True,  True,  True,  True,  True,  True,  True, False, False]],\n",
      "       device='cuda:0')\n",
      "acc torch.Size([1]) tensor([0.0556], device='cuda:0')\n",
      "acc_per_part torch.Size([1, 20]) tensor([[False, False, False, False,  True, False, False, False, False, False,\n",
      "         False, False, False, False, False, False, False, False, False, False]],\n",
      "       device='cuda:0')\n",
      "loss_per_data torch.Size([1, 20]) tensor([[ 26.2400,   9.2821,   3.8168,   9.5776,   0.0000,  21.2407,   5.3456,\n",
      "           0.9553,  14.4670,   0.6461,   5.4151,   8.7072, 144.8415,  34.7663,\n",
      "           8.7352,  66.0174,   7.7522,   0.9766,  18.1337,   2.6119]],\n",
      "       device='cuda:0')\n",
      "scores torch.Size([1, 190, 1]) tensor([[[0.0537],\n",
      "         [0.0694],\n",
      "         [0.9493],\n",
      "         [0.3258],\n",
      "         [0.7834],\n",
      "         [0.4377],\n",
      "         [0.5894],\n",
      "         [0.4732],\n",
      "         [0.3219],\n",
      "         [0.4708],\n",
      "         [0.3064],\n",
      "         [0.4403],\n",
      "         [0.0444],\n",
      "         [0.0846],\n",
      "         [0.8497],\n",
      "         [0.3880],\n",
      "         [0.6876],\n",
      "         [0.7227],\n",
      "         [0.5329],\n",
      "         [0.4391],\n",
      "         [0.3207],\n",
      "         [0.8331],\n",
      "         [0.4076],\n",
      "         [0.2720],\n",
      "         [0.0451],\n",
      "         [0.6030],\n",
      "         [0.2249],\n",
      "         [0.5721],\n",
      "         [0.9362],\n",
      "         [0.1583],\n",
      "         [0.6232],\n",
      "         [0.0911],\n",
      "         [0.4482],\n",
      "         [0.8487],\n",
      "         [0.7236],\n",
      "         [0.3422],\n",
      "         [0.2156],\n",
      "         [0.7429],\n",
      "         [0.9633],\n",
      "         [0.6710],\n",
      "         [0.5011],\n",
      "         [0.7832],\n",
      "         [0.5700],\n",
      "         [0.1252],\n",
      "         [0.3263],\n",
      "         [0.4691],\n",
      "         [0.3960],\n",
      "         [0.4743],\n",
      "         [0.9172],\n",
      "         [0.6221],\n",
      "         [0.9632],\n",
      "         [0.6183],\n",
      "         [0.8143],\n",
      "         [0.9034],\n",
      "         [0.5041],\n",
      "         [0.6468],\n",
      "         [0.8975],\n",
      "         [0.5658],\n",
      "         [0.1960],\n",
      "         [0.6179],\n",
      "         [0.4361],\n",
      "         [0.2141],\n",
      "         [0.8980],\n",
      "         [0.0017],\n",
      "         [0.5870],\n",
      "         [0.2985],\n",
      "         [0.6546],\n",
      "         [0.5165],\n",
      "         [0.7891],\n",
      "         [0.0369],\n",
      "         [0.8087],\n",
      "         [0.5763],\n",
      "         [0.9834],\n",
      "         [0.7804],\n",
      "         [0.6592],\n",
      "         [0.1885],\n",
      "         [0.2314],\n",
      "         [0.7861],\n",
      "         [0.3431],\n",
      "         [0.4733],\n",
      "         [0.5417],\n",
      "         [0.9073],\n",
      "         [0.6653],\n",
      "         [0.3409],\n",
      "         [0.9433],\n",
      "         [0.3765],\n",
      "         [0.3463],\n",
      "         [0.0923],\n",
      "         [0.1113],\n",
      "         [0.3448],\n",
      "         [0.3272],\n",
      "         [0.3211],\n",
      "         [0.1984],\n",
      "         [0.1233],\n",
      "         [0.1429],\n",
      "         [0.6464],\n",
      "         [0.2837],\n",
      "         [0.5145],\n",
      "         [0.7645],\n",
      "         [0.4644],\n",
      "         [0.4348],\n",
      "         [0.0259],\n",
      "         [0.5565],\n",
      "         [0.8531],\n",
      "         [0.2621],\n",
      "         [0.2147],\n",
      "         [0.8620],\n",
      "         [0.2418],\n",
      "         [0.4669],\n",
      "         [0.2436],\n",
      "         [0.2337],\n",
      "         [0.9151],\n",
      "         [0.9361],\n",
      "         [0.8466],\n",
      "         [0.9497],\n",
      "         [0.8357],\n",
      "         [0.9917],\n",
      "         [0.0175],\n",
      "         [0.8110],\n",
      "         [0.2559],\n",
      "         [0.0234],\n",
      "         [0.3211],\n",
      "         [0.7215],\n",
      "         [0.7682],\n",
      "         [0.6892],\n",
      "         [0.2172],\n",
      "         [0.6983],\n",
      "         [0.8742],\n",
      "         [0.3529],\n",
      "         [0.4670],\n",
      "         [0.6077],\n",
      "         [0.3874],\n",
      "         [0.0704],\n",
      "         [0.2466],\n",
      "         [0.8664],\n",
      "         [0.9936],\n",
      "         [0.9992],\n",
      "         [0.0810],\n",
      "         [0.0348],\n",
      "         [0.4587],\n",
      "         [0.0970],\n",
      "         [0.4804],\n",
      "         [0.1563],\n",
      "         [0.5786],\n",
      "         [0.6644],\n",
      "         [0.9935],\n",
      "         [0.1890],\n",
      "         [0.2299],\n",
      "         [0.1810],\n",
      "         [0.6182],\n",
      "         [0.8241],\n",
      "         [0.4441],\n",
      "         [0.7170],\n",
      "         [0.4037],\n",
      "         [0.1415],\n",
      "         [0.8661],\n",
      "         [0.5210],\n",
      "         [0.5174],\n",
      "         [0.8589],\n",
      "         [0.8581],\n",
      "         [0.7966],\n",
      "         [0.7851],\n",
      "         [0.2767],\n",
      "         [0.1352],\n",
      "         [0.7291],\n",
      "         [0.0311],\n",
      "         [0.1608],\n",
      "         [0.3752],\n",
      "         [0.3413],\n",
      "         [0.6893],\n",
      "         [0.2191],\n",
      "         [0.4332],\n",
      "         [0.2619],\n",
      "         [0.4467],\n",
      "         [0.3810],\n",
      "         [0.8964],\n",
      "         [0.4257],\n",
      "         [0.9090],\n",
      "         [0.6319],\n",
      "         [0.1761],\n",
      "         [0.5800],\n",
      "         [0.6004],\n",
      "         [0.4475],\n",
      "         [0.9984],\n",
      "         [0.3757],\n",
      "         [0.1285],\n",
      "         [0.2830],\n",
      "         [0.8988],\n",
      "         [0.2890],\n",
      "         [0.7057]]], device='cuda:0', dtype=torch.float64)\n",
      "================iter 5============\n",
      "['shape/ellipsoid/1/ellipsoid_512_128_64_64_2_1_1']\n",
      "tensor([[ True,  True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
      "          True,  True,  True,  True,  True,  True,  True,  True, False, False]],\n",
      "       device='cuda:0')\n",
      "@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@\n",
      "['shape/ellipsoid/1/ellipsoid_512_128_64_64_2_2_1']\n",
      "gt_trans_torch.Size([1, 20, 3])_tensor([[[ 1.5548e-01, -5.7505e-02, -3.6494e-03],\n",
      "         [ 1.1046e-01, -2.9718e-02, -7.2270e-03],\n",
      "         [-2.2724e-01,  6.3042e-02,  1.8633e-02],\n",
      "         [-2.4617e-01,  5.1320e-02,  1.6175e-02],\n",
      "         [-2.9891e-01,  7.3762e-02,  2.9622e-02],\n",
      "         [-3.4416e-01,  1.0836e-01,  1.9313e-02],\n",
      "         [-3.5971e-01,  8.6133e-02,  2.3075e-02],\n",
      "         [-3.9903e-01,  9.9986e-02,  2.4065e-02],\n",
      "         [-4.4515e-01,  1.2735e-01,  2.3618e-02],\n",
      "         [ 7.2469e-02, -1.8263e-02, -5.0721e-03],\n",
      "         [ 3.7316e-02, -6.7279e-03, -6.6227e-03],\n",
      "         [ 3.5527e-18, -3.1086e-18, -3.5527e-18],\n",
      "         [-3.7114e-02,  1.0544e-02,  1.2928e-03],\n",
      "         [-7.6124e-02,  1.2457e-02,  1.4262e-02],\n",
      "         [-1.2281e-01,  3.3500e-02,  2.0095e-02],\n",
      "         [-1.4985e-01,  4.3875e-02,  7.7605e-03],\n",
      "         [-1.8439e-01,  4.6029e-02,  1.4558e-02],\n",
      "         [ 0.0000e+00,  0.0000e+00,  0.0000e+00],\n",
      "         [ 0.0000e+00,  0.0000e+00,  0.0000e+00],\n",
      "         [ 0.0000e+00,  0.0000e+00,  0.0000e+00]]], device='cuda:0')\n",
      "gt_rots_torch.Size([1, 20, 4])_tensor([[[ 0.7248, -0.2864,  0.3429, -0.5244],\n",
      "         [ 0.9503,  0.0858, -0.0826, -0.2876],\n",
      "         [ 0.7173,  0.1685, -0.5907, -0.3289],\n",
      "         [ 0.3500,  0.3849,  0.1039,  0.8477],\n",
      "         [ 0.3265,  0.3233, -0.3263,  0.8261],\n",
      "         [-0.1432,  0.5392,  0.6355,  0.5338],\n",
      "         [-0.4368,  0.0394,  0.5551,  0.7067],\n",
      "         [-0.5675,  0.3562,  0.6123,  0.4197],\n",
      "         [-0.6007,  0.7457, -0.1787,  0.2260],\n",
      "         [ 0.7246,  0.4142, -0.4044,  0.3739],\n",
      "         [ 0.5636,  0.6280,  0.4017,  0.3558],\n",
      "         [ 0.6385,  0.3059,  0.3294,  0.6247],\n",
      "         [ 0.5489, -0.1165,  0.7350, -0.3807],\n",
      "         [-0.0896,  0.4754, -0.5180,  0.7054],\n",
      "         [ 0.6155,  0.7459, -0.2342, -0.0997],\n",
      "         [ 0.7070,  0.1575,  0.6023, -0.3356],\n",
      "         [ 0.1220, -0.6290,  0.3895,  0.6617],\n",
      "         [ 0.0000,  0.0000,  0.0000,  0.0000],\n",
      "         [ 0.0000,  0.0000,  0.0000,  0.0000],\n",
      "         [ 0.0000,  0.0000,  0.0000,  0.0000]]], device='cuda:0')\n",
      "noisy_trans_and_rots_torch.Size([1, 20, 7])_tensor([[[ 1.2233,  0.0000, -0.9481,  0.3488,  0.0000,  0.0000,  0.8633],\n",
      "         [-2.0744,  0.0000,  1.0056,  1.2894,  0.0000,  0.0000, -0.3739],\n",
      "         [ 0.9417,  0.0000,  0.1900,  0.6889,  0.0000,  0.0000, -2.1847],\n",
      "         [ 0.0769,  0.0000, -1.1573, -0.8158,  0.0000,  0.0000, -0.1633],\n",
      "         [-0.5750,  0.0000,  0.7427, -0.2765,  0.0000,  0.0000, -1.0952],\n",
      "         [-0.0096,  0.0000,  0.0083,  0.1600,  0.0000,  0.0000, -1.6722],\n",
      "         [-1.1674,  0.0000,  1.0243, -0.8571,  0.0000,  0.0000,  0.8129],\n",
      "         [ 0.7547,  0.0000,  0.4738, -1.2774,  0.0000,  0.0000,  0.0443],\n",
      "         [-0.4176,  0.0000,  0.1476, -0.6427,  0.0000,  0.0000, -1.9839],\n",
      "         [-0.4296,  0.0000,  1.3412, -0.5323,  0.0000,  0.0000, -2.8315],\n",
      "         [-1.8793,  0.0000, -1.0727,  0.7483,  0.0000,  0.0000, -1.0149],\n",
      "         [ 0.0172,  0.0000, -0.5079, -1.7961,  0.0000,  0.0000,  0.4992],\n",
      "         [-0.1982,  0.0000,  0.6910, -0.8384,  0.0000,  0.0000,  0.3236],\n",
      "         [-2.3176,  0.0000, -1.5161,  0.7277,  0.0000,  0.0000,  0.3273],\n",
      "         [-1.0107,  0.0000, -1.6896,  2.1709,  0.0000,  0.0000, -1.1642],\n",
      "         [ 1.2303,  0.0000, -0.8941,  1.2344,  0.0000,  0.0000, -0.7801],\n",
      "         [ 0.8349,  0.0000,  1.2566, -2.3591,  0.0000,  0.0000, -0.1805],\n",
      "         [ 1.2124,  0.0000, -1.2538, -0.3733,  0.0000,  0.0000,  0.5660],\n",
      "         [ 0.7329,  0.0000,  1.6670, -0.8814,  0.0000,  0.0000, -0.3648],\n",
      "         [ 0.2677,  0.0000,  0.8152, -0.3161,  0.0000,  0.0000,  0.4747]]],\n",
      "       device='cuda:0')\n",
      "================iter 0============\n",
      "['shape/ellipsoid/1/ellipsoid_512_128_64_64_2_2_1']\n",
      "tensor([[False, False, False, False, False, False, False, False, False, False,\n",
      "         False,  True, False, False, False, False, False, False, False, False]],\n",
      "       device='cuda:0')\n",
      "acc torch.Size([1]) tensor([0.0588], device='cuda:0')\n",
      "acc_per_part torch.Size([1, 20]) tensor([[False, False, False, False, False, False, False, False, False, False,\n",
      "         False,  True, False, False, False, False, False, False, False, False]],\n",
      "       device='cuda:0')\n",
      "loss_per_data torch.Size([1, 20]) tensor([[ 1.2942, 11.3944,  1.3310,  1.2024,  2.1342,  1.3971,  0.5927,  3.4377,\n",
      "          2.6946,  7.1307,  2.9240,  0.0000,  0.5307, 14.7389,  1.4005,  0.2867,\n",
      "          3.6860,  6.7628, 20.4945,  1.3490]], device='cuda:0')\n",
      "scores torch.Size([1, 190, 1]) tensor([[[0.0252],\n",
      "         [0.6792],\n",
      "         [0.8113],\n",
      "         [0.2141],\n",
      "         [0.3121],\n",
      "         [0.7852],\n",
      "         [0.1960],\n",
      "         [0.8449],\n",
      "         [0.4546],\n",
      "         [0.3532],\n",
      "         [0.6439],\n",
      "         [0.9568],\n",
      "         [0.8200],\n",
      "         [0.9636],\n",
      "         [0.7648],\n",
      "         [0.9679],\n",
      "         [0.7629],\n",
      "         [0.3634],\n",
      "         [0.1710],\n",
      "         [0.2036],\n",
      "         [0.4319],\n",
      "         [0.3948],\n",
      "         [0.7914],\n",
      "         [0.3987],\n",
      "         [0.7490],\n",
      "         [0.3689],\n",
      "         [0.6266],\n",
      "         [0.6639],\n",
      "         [0.2951],\n",
      "         [0.6789],\n",
      "         [0.2510],\n",
      "         [0.4733],\n",
      "         [0.3673],\n",
      "         [0.9930],\n",
      "         [0.0982],\n",
      "         [0.2100],\n",
      "         [0.8827],\n",
      "         [0.2078],\n",
      "         [0.4252],\n",
      "         [0.7304],\n",
      "         [0.2293],\n",
      "         [0.1992],\n",
      "         [0.8060],\n",
      "         [0.1826],\n",
      "         [0.8937],\n",
      "         [0.1872],\n",
      "         [0.8343],\n",
      "         [0.2797],\n",
      "         [0.2456],\n",
      "         [0.4823],\n",
      "         [0.2238],\n",
      "         [0.1983],\n",
      "         [0.7432],\n",
      "         [0.8349],\n",
      "         [0.4760],\n",
      "         [0.9500],\n",
      "         [0.6225],\n",
      "         [0.7344],\n",
      "         [0.3042],\n",
      "         [0.8871],\n",
      "         [0.9306],\n",
      "         [0.7276],\n",
      "         [0.4080],\n",
      "         [0.0155],\n",
      "         [0.4261],\n",
      "         [0.2412],\n",
      "         [0.5981],\n",
      "         [0.9069],\n",
      "         [0.3025],\n",
      "         [0.6112],\n",
      "         [0.7729],\n",
      "         [0.8447],\n",
      "         [0.8194],\n",
      "         [0.2261],\n",
      "         [0.3671],\n",
      "         [0.5595],\n",
      "         [0.3192],\n",
      "         [0.7920],\n",
      "         [0.9311],\n",
      "         [0.1777],\n",
      "         [0.1982],\n",
      "         [0.9691],\n",
      "         [0.7714],\n",
      "         [0.3712],\n",
      "         [0.5674],\n",
      "         [0.9018],\n",
      "         [0.0224],\n",
      "         [0.8413],\n",
      "         [0.2695],\n",
      "         [0.8154],\n",
      "         [0.8269],\n",
      "         [0.9169],\n",
      "         [0.5915],\n",
      "         [0.5218],\n",
      "         [0.5216],\n",
      "         [0.5454],\n",
      "         [0.6725],\n",
      "         [0.4818],\n",
      "         [0.1902],\n",
      "         [0.6608],\n",
      "         [0.2878],\n",
      "         [0.2242],\n",
      "         [0.7209],\n",
      "         [0.2791],\n",
      "         [0.8567],\n",
      "         [0.6573],\n",
      "         [0.0610],\n",
      "         [0.0198],\n",
      "         [0.4869],\n",
      "         [0.4946],\n",
      "         [0.9009],\n",
      "         [0.4259],\n",
      "         [0.4130],\n",
      "         [0.0115],\n",
      "         [0.9973],\n",
      "         [0.0012],\n",
      "         [0.3084],\n",
      "         [0.6222],\n",
      "         [0.8126],\n",
      "         [0.0408],\n",
      "         [0.0812],\n",
      "         [0.5981],\n",
      "         [0.6273],\n",
      "         [0.2987],\n",
      "         [0.3161],\n",
      "         [0.7642],\n",
      "         [0.8100],\n",
      "         [0.3158],\n",
      "         [0.0887],\n",
      "         [0.7433],\n",
      "         [0.9866],\n",
      "         [0.1353],\n",
      "         [0.5978],\n",
      "         [0.8275],\n",
      "         [0.3812],\n",
      "         [0.6645],\n",
      "         [0.0611],\n",
      "         [0.5782],\n",
      "         [0.4553],\n",
      "         [0.7681],\n",
      "         [0.2276],\n",
      "         [0.5085],\n",
      "         [0.3091],\n",
      "         [0.0785],\n",
      "         [0.4388],\n",
      "         [0.3145],\n",
      "         [0.8289],\n",
      "         [0.4900],\n",
      "         [0.3432],\n",
      "         [0.9636],\n",
      "         [0.9325],\n",
      "         [0.6591],\n",
      "         [0.9479],\n",
      "         [0.7389],\n",
      "         [0.6562],\n",
      "         [0.9183],\n",
      "         [0.0474],\n",
      "         [0.9811],\n",
      "         [0.7135],\n",
      "         [0.1524],\n",
      "         [0.8986],\n",
      "         [0.4610],\n",
      "         [0.5677],\n",
      "         [0.0531],\n",
      "         [0.0303],\n",
      "         [0.0082],\n",
      "         [0.8749],\n",
      "         [0.3304],\n",
      "         [0.0555],\n",
      "         [0.0688],\n",
      "         [0.2416],\n",
      "         [0.8748],\n",
      "         [0.8201],\n",
      "         [0.6639],\n",
      "         [0.6824],\n",
      "         [0.4030],\n",
      "         [0.6487],\n",
      "         [0.0638],\n",
      "         [0.9346],\n",
      "         [0.2647],\n",
      "         [0.8136],\n",
      "         [0.0439],\n",
      "         [0.6337],\n",
      "         [0.1152],\n",
      "         [0.4962],\n",
      "         [0.7447],\n",
      "         [0.9421],\n",
      "         [0.6218],\n",
      "         [0.7078],\n",
      "         [0.8473]]], device='cuda:0', dtype=torch.float64)\n",
      "================iter 1============\n",
      "['shape/ellipsoid/1/ellipsoid_512_128_64_64_2_2_1']\n",
      "tensor([[False, False, False, False, False, False, False, False, False, False,\n",
      "         False,  True, False,  True, False,  True, False, False, False, False]],\n",
      "       device='cuda:0')\n",
      "acc torch.Size([1]) tensor([0.0588], device='cuda:0')\n",
      "acc_per_part torch.Size([1, 20]) tensor([[False, False, False, False, False, False, False, False, False, False,\n",
      "         False,  True, False, False, False, False, False, False, False, False]],\n",
      "       device='cuda:0')\n",
      "loss_per_data torch.Size([1, 20]) tensor([[ 1.4565,  6.3943,  1.1973, 10.0366,  2.9424,  6.5169,  2.8922,  1.3055,\n",
      "          3.8077, 10.3001,  1.5748,  0.0000,  0.3551, 14.7389,  5.2016,  0.2867,\n",
      "          0.6693,  0.0915, 26.8642,  2.1329]], device='cuda:0')\n",
      "scores torch.Size([1, 190, 1]) tensor([[[0.6651],\n",
      "         [0.7984],\n",
      "         [0.6496],\n",
      "         [0.3166],\n",
      "         [0.4326],\n",
      "         [0.8338],\n",
      "         [0.4373],\n",
      "         [0.1816],\n",
      "         [0.2463],\n",
      "         [0.1808],\n",
      "         [0.8774],\n",
      "         [0.8501],\n",
      "         [0.9858],\n",
      "         [0.3245],\n",
      "         [0.9467],\n",
      "         [0.3126],\n",
      "         [0.9087],\n",
      "         [0.1404],\n",
      "         [0.4605],\n",
      "         [0.4787],\n",
      "         [0.0797],\n",
      "         [0.0720],\n",
      "         [0.8888],\n",
      "         [0.6664],\n",
      "         [0.3827],\n",
      "         [0.3921],\n",
      "         [0.6849],\n",
      "         [0.6057],\n",
      "         [0.5805],\n",
      "         [0.1939],\n",
      "         [0.5485],\n",
      "         [0.0911],\n",
      "         [0.5816],\n",
      "         [0.0110],\n",
      "         [0.0692],\n",
      "         [0.9041],\n",
      "         [0.6951],\n",
      "         [0.6458],\n",
      "         [0.9424],\n",
      "         [0.6870],\n",
      "         [0.8769],\n",
      "         [0.4184],\n",
      "         [0.5553],\n",
      "         [0.1759],\n",
      "         [0.5862],\n",
      "         [0.2446],\n",
      "         [0.0356],\n",
      "         [0.3893],\n",
      "         [0.8287],\n",
      "         [0.7187],\n",
      "         [0.6302],\n",
      "         [0.6686],\n",
      "         [0.7299],\n",
      "         [0.2034],\n",
      "         [0.4084],\n",
      "         [0.8131],\n",
      "         [0.8127],\n",
      "         [0.4440],\n",
      "         [0.8158],\n",
      "         [0.9100],\n",
      "         [0.9164],\n",
      "         [0.6534],\n",
      "         [0.3495],\n",
      "         [0.1928],\n",
      "         [0.4481],\n",
      "         [0.1888],\n",
      "         [0.5856],\n",
      "         [0.6590],\n",
      "         [0.0077],\n",
      "         [0.2663],\n",
      "         [0.8788],\n",
      "         [0.4807],\n",
      "         [0.1169],\n",
      "         [0.3882],\n",
      "         [0.6902],\n",
      "         [0.1447],\n",
      "         [0.4650],\n",
      "         [0.9172],\n",
      "         [0.6755],\n",
      "         [0.8470],\n",
      "         [0.3600],\n",
      "         [0.8700],\n",
      "         [0.4686],\n",
      "         [0.2012],\n",
      "         [0.3399],\n",
      "         [0.8041],\n",
      "         [0.6661],\n",
      "         [0.8856],\n",
      "         [0.9983],\n",
      "         [0.3524],\n",
      "         [0.4630],\n",
      "         [0.6753],\n",
      "         [0.9835],\n",
      "         [0.6674],\n",
      "         [0.1184],\n",
      "         [0.6274],\n",
      "         [0.9190],\n",
      "         [0.2354],\n",
      "         [0.2733],\n",
      "         [0.1946],\n",
      "         [0.2794],\n",
      "         [0.7918],\n",
      "         [0.8792],\n",
      "         [0.0511],\n",
      "         [0.1832],\n",
      "         [0.2663],\n",
      "         [0.4334],\n",
      "         [0.2972],\n",
      "         [0.7642],\n",
      "         [0.7469],\n",
      "         [0.6052],\n",
      "         [0.1143],\n",
      "         [0.7822],\n",
      "         [0.4818],\n",
      "         [0.2927],\n",
      "         [0.4192],\n",
      "         [0.2480],\n",
      "         [0.6342],\n",
      "         [0.3692],\n",
      "         [0.9218],\n",
      "         [0.6279],\n",
      "         [0.6622],\n",
      "         [0.1820],\n",
      "         [0.0822],\n",
      "         [0.3905],\n",
      "         [0.9715],\n",
      "         [0.9866],\n",
      "         [0.4531],\n",
      "         [0.3782],\n",
      "         [0.3888],\n",
      "         [0.6740],\n",
      "         [0.9735],\n",
      "         [0.7644],\n",
      "         [0.9972],\n",
      "         [0.1339],\n",
      "         [0.0237],\n",
      "         [0.4447],\n",
      "         [0.8326],\n",
      "         [0.4370],\n",
      "         [0.0732],\n",
      "         [0.0829],\n",
      "         [0.3778],\n",
      "         [0.6249],\n",
      "         [0.6966],\n",
      "         [0.9091],\n",
      "         [0.5364],\n",
      "         [0.0845],\n",
      "         [0.4039],\n",
      "         [0.1681],\n",
      "         [0.3445],\n",
      "         [0.1812],\n",
      "         [0.7631],\n",
      "         [0.7758],\n",
      "         [0.4358],\n",
      "         [0.1967],\n",
      "         [0.9507],\n",
      "         [0.6238],\n",
      "         [0.2993],\n",
      "         [0.8247],\n",
      "         [0.2567],\n",
      "         [0.9253],\n",
      "         [0.7826],\n",
      "         [0.1010],\n",
      "         [0.9723],\n",
      "         [0.3193],\n",
      "         [0.7003],\n",
      "         [0.6703],\n",
      "         [0.0388],\n",
      "         [0.9810],\n",
      "         [0.5704],\n",
      "         [0.6558],\n",
      "         [0.5040],\n",
      "         [0.4146],\n",
      "         [0.2417],\n",
      "         [0.0151],\n",
      "         [0.8379],\n",
      "         [0.5988],\n",
      "         [0.6475],\n",
      "         [0.0622],\n",
      "         [0.9017],\n",
      "         [0.8772],\n",
      "         [0.3793],\n",
      "         [0.8148],\n",
      "         [0.0704],\n",
      "         [0.6023],\n",
      "         [0.1945],\n",
      "         [0.0637],\n",
      "         [0.5714],\n",
      "         [0.0705],\n",
      "         [0.1768]]], device='cuda:0', dtype=torch.float64)\n",
      "================iter 2============\n",
      "['shape/ellipsoid/1/ellipsoid_512_128_64_64_2_2_1']\n",
      "tensor([[ True, False, False, False, False,  True, False,  True,  True, False,\n",
      "         False,  True, False,  True, False,  True, False, False, False, False]],\n",
      "       device='cuda:0')\n",
      "acc torch.Size([1]) tensor([0.0588], device='cuda:0')\n",
      "acc_per_part torch.Size([1, 20]) tensor([[False, False, False, False, False, False, False, False, False, False,\n",
      "         False,  True, False, False, False, False, False, False, False, False]],\n",
      "       device='cuda:0')\n",
      "loss_per_data torch.Size([1, 20]) tensor([[  1.4565,   8.9112,   1.4180, 142.0754,   1.3381,   6.5169,   1.7101,\n",
      "           1.3055,   3.8077,  15.7336,   9.5194,   0.0000,   1.1863,  14.7389,\n",
      "           5.5863,   0.2867,   1.8347,   3.3542,  34.7512,   2.2723]],\n",
      "       device='cuda:0')\n",
      "scores torch.Size([1, 190, 1]) tensor([[[0.9214],\n",
      "         [0.0847],\n",
      "         [0.7814],\n",
      "         [0.3410],\n",
      "         [0.3492],\n",
      "         [0.2458],\n",
      "         [0.3685],\n",
      "         [0.1219],\n",
      "         [0.3520],\n",
      "         [0.5494],\n",
      "         [0.3455],\n",
      "         [0.8887],\n",
      "         [0.6729],\n",
      "         [0.7457],\n",
      "         [0.8103],\n",
      "         [0.4888],\n",
      "         [0.3231],\n",
      "         [0.0608],\n",
      "         [0.9857],\n",
      "         [0.5676],\n",
      "         [0.1654],\n",
      "         [0.9402],\n",
      "         [0.8802],\n",
      "         [0.8526],\n",
      "         [0.0228],\n",
      "         [0.9392],\n",
      "         [0.6514],\n",
      "         [0.5813],\n",
      "         [0.0965],\n",
      "         [0.1263],\n",
      "         [0.1027],\n",
      "         [0.2818],\n",
      "         [0.0721],\n",
      "         [0.4713],\n",
      "         [0.5026],\n",
      "         [0.4415],\n",
      "         [0.0795],\n",
      "         [0.1912],\n",
      "         [0.7011],\n",
      "         [0.9022],\n",
      "         [0.4460],\n",
      "         [0.3976],\n",
      "         [0.3171],\n",
      "         [0.1562],\n",
      "         [0.6622],\n",
      "         [0.4749],\n",
      "         [0.3840],\n",
      "         [0.0539],\n",
      "         [0.5449],\n",
      "         [0.1479],\n",
      "         [0.7634],\n",
      "         [0.6329],\n",
      "         [0.7773],\n",
      "         [0.8372],\n",
      "         [0.0831],\n",
      "         [0.8069],\n",
      "         [0.1298],\n",
      "         [0.1846],\n",
      "         [0.0106],\n",
      "         [0.5154],\n",
      "         [0.4048],\n",
      "         [0.1730],\n",
      "         [0.9102],\n",
      "         [0.9563],\n",
      "         [0.6597],\n",
      "         [0.8988],\n",
      "         [0.8316],\n",
      "         [0.1051],\n",
      "         [0.0093],\n",
      "         [0.3014],\n",
      "         [0.0869],\n",
      "         [0.5498],\n",
      "         [0.7485],\n",
      "         [0.9197],\n",
      "         [0.2921],\n",
      "         [0.8154],\n",
      "         [0.6105],\n",
      "         [0.1646],\n",
      "         [0.1344],\n",
      "         [0.3208],\n",
      "         [0.6729],\n",
      "         [0.4421],\n",
      "         [0.1036],\n",
      "         [0.4630],\n",
      "         [0.7775],\n",
      "         [0.2893],\n",
      "         [0.8153],\n",
      "         [0.0989],\n",
      "         [0.3452],\n",
      "         [0.3943],\n",
      "         [0.6491],\n",
      "         [0.6915],\n",
      "         [0.9922],\n",
      "         [0.2119],\n",
      "         [0.8317],\n",
      "         [0.5140],\n",
      "         [0.2999],\n",
      "         [0.1772],\n",
      "         [0.2251],\n",
      "         [0.7993],\n",
      "         [0.9410],\n",
      "         [0.5428],\n",
      "         [0.5567],\n",
      "         [0.2423],\n",
      "         [0.2874],\n",
      "         [0.9496],\n",
      "         [0.8582],\n",
      "         [0.8092],\n",
      "         [0.0962],\n",
      "         [0.5835],\n",
      "         [0.0576],\n",
      "         [0.9690],\n",
      "         [0.4650],\n",
      "         [0.1574],\n",
      "         [0.2017],\n",
      "         [0.6141],\n",
      "         [0.6506],\n",
      "         [0.1134],\n",
      "         [0.8027],\n",
      "         [0.8084],\n",
      "         [0.4552],\n",
      "         [0.2501],\n",
      "         [0.0163],\n",
      "         [0.0185],\n",
      "         [0.2788],\n",
      "         [0.8750],\n",
      "         [0.7175],\n",
      "         [0.9652],\n",
      "         [0.7338],\n",
      "         [0.9739],\n",
      "         [0.7184],\n",
      "         [0.8630],\n",
      "         [0.6204],\n",
      "         [0.5868],\n",
      "         [0.5516],\n",
      "         [0.3370],\n",
      "         [0.8620],\n",
      "         [0.0073],\n",
      "         [0.2522],\n",
      "         [0.7508],\n",
      "         [0.5264],\n",
      "         [0.5830],\n",
      "         [0.9360],\n",
      "         [0.7351],\n",
      "         [0.4901],\n",
      "         [0.2127],\n",
      "         [0.3574],\n",
      "         [0.9610],\n",
      "         [0.7746],\n",
      "         [0.5560],\n",
      "         [0.2673],\n",
      "         [0.0244],\n",
      "         [0.1969],\n",
      "         [0.5867],\n",
      "         [0.9947],\n",
      "         [0.1203],\n",
      "         [0.0542],\n",
      "         [0.9491],\n",
      "         [0.5642],\n",
      "         [0.4386],\n",
      "         [0.8901],\n",
      "         [0.2536],\n",
      "         [0.3904],\n",
      "         [0.1089],\n",
      "         [0.1540],\n",
      "         [0.9455],\n",
      "         [0.5439],\n",
      "         [0.2644],\n",
      "         [0.3612],\n",
      "         [0.0263],\n",
      "         [0.8658],\n",
      "         [0.7489],\n",
      "         [0.8260],\n",
      "         [0.6168],\n",
      "         [0.1643],\n",
      "         [0.5300],\n",
      "         [0.4214],\n",
      "         [0.3418],\n",
      "         [0.3210],\n",
      "         [0.7166],\n",
      "         [0.9687],\n",
      "         [0.1262],\n",
      "         [0.1706],\n",
      "         [0.2789],\n",
      "         [0.2142],\n",
      "         [0.6818],\n",
      "         [0.5627],\n",
      "         [0.4160],\n",
      "         [0.5656],\n",
      "         [0.6854]]], device='cuda:0', dtype=torch.float64)\n",
      "================iter 3============\n",
      "['shape/ellipsoid/1/ellipsoid_512_128_64_64_2_2_1']\n",
      "tensor([[ True,  True,  True,  True,  True,  True,  True,  True,  True, False,\n",
      "          True,  True,  True,  True,  True,  True,  True, False, False, False]],\n",
      "       device='cuda:0')\n",
      "acc torch.Size([1]) tensor([0.0588], device='cuda:0')\n",
      "acc_per_part torch.Size([1, 20]) tensor([[False, False, False, False, False, False, False, False, False, False,\n",
      "         False,  True, False, False, False, False, False, False, False, False]],\n",
      "       device='cuda:0')\n",
      "loss_per_data torch.Size([1, 20]) tensor([[  1.4565,   8.9112,   1.4180, 142.0754,   1.3381,   6.5169,   1.7101,\n",
      "           1.3055,   3.8077,  35.9864,   9.5194,   0.0000,   1.1863,  14.7389,\n",
      "           5.5863,   0.2867,   1.8347,   5.8912,  57.4814,  23.3979]],\n",
      "       device='cuda:0')\n",
      "scores torch.Size([1, 190, 1]) tensor([[[8.8838e-01],\n",
      "         [1.7979e-01],\n",
      "         [9.1761e-02],\n",
      "         [8.5839e-01],\n",
      "         [3.1867e-01],\n",
      "         [7.9064e-01],\n",
      "         [7.5440e-02],\n",
      "         [1.8095e-01],\n",
      "         [4.0037e-01],\n",
      "         [3.2792e-01],\n",
      "         [8.5093e-02],\n",
      "         [8.4510e-02],\n",
      "         [6.1946e-02],\n",
      "         [1.5653e-01],\n",
      "         [4.5769e-01],\n",
      "         [3.1611e-01],\n",
      "         [7.1806e-03],\n",
      "         [8.4206e-01],\n",
      "         [2.4015e-01],\n",
      "         [2.2234e-01],\n",
      "         [3.4310e-01],\n",
      "         [1.6419e-02],\n",
      "         [3.0823e-01],\n",
      "         [2.4478e-01],\n",
      "         [9.1873e-01],\n",
      "         [1.5873e-01],\n",
      "         [8.2581e-01],\n",
      "         [5.9815e-01],\n",
      "         [7.8110e-01],\n",
      "         [8.3697e-01],\n",
      "         [6.1719e-01],\n",
      "         [9.2806e-01],\n",
      "         [9.8807e-02],\n",
      "         [8.2565e-01],\n",
      "         [1.4209e-01],\n",
      "         [3.1231e-01],\n",
      "         [5.2119e-01],\n",
      "         [6.4780e-01],\n",
      "         [7.4374e-01],\n",
      "         [3.9605e-01],\n",
      "         [4.5978e-01],\n",
      "         [5.2104e-01],\n",
      "         [7.5349e-01],\n",
      "         [9.8514e-01],\n",
      "         [3.4287e-01],\n",
      "         [5.5776e-01],\n",
      "         [6.2135e-01],\n",
      "         [8.5998e-01],\n",
      "         [8.4274e-01],\n",
      "         [8.4593e-01],\n",
      "         [7.3043e-01],\n",
      "         [4.4431e-01],\n",
      "         [2.6905e-01],\n",
      "         [9.3877e-01],\n",
      "         [7.3604e-01],\n",
      "         [6.2520e-01],\n",
      "         [6.6747e-01],\n",
      "         [6.2445e-01],\n",
      "         [9.6054e-01],\n",
      "         [1.6307e-01],\n",
      "         [7.3150e-02],\n",
      "         [2.3372e-01],\n",
      "         [9.8516e-01],\n",
      "         [3.7721e-01],\n",
      "         [7.5511e-01],\n",
      "         [4.1252e-01],\n",
      "         [1.7576e-01],\n",
      "         [3.4129e-01],\n",
      "         [2.8447e-01],\n",
      "         [4.7725e-01],\n",
      "         [6.1148e-01],\n",
      "         [1.9374e-01],\n",
      "         [5.9887e-01],\n",
      "         [3.5479e-01],\n",
      "         [2.2938e-01],\n",
      "         [1.7872e-01],\n",
      "         [8.1002e-01],\n",
      "         [8.8517e-01],\n",
      "         [1.5705e-01],\n",
      "         [9.2774e-02],\n",
      "         [2.9336e-01],\n",
      "         [7.0839e-01],\n",
      "         [1.2931e-01],\n",
      "         [5.2064e-01],\n",
      "         [2.2302e-01],\n",
      "         [9.6288e-01],\n",
      "         [7.4686e-01],\n",
      "         [9.5555e-01],\n",
      "         [4.8536e-01],\n",
      "         [5.2169e-01],\n",
      "         [4.7796e-01],\n",
      "         [6.8422e-01],\n",
      "         [4.1987e-01],\n",
      "         [6.7460e-01],\n",
      "         [1.9034e-01],\n",
      "         [8.5645e-01],\n",
      "         [8.3678e-01],\n",
      "         [1.7565e-01],\n",
      "         [4.5426e-01],\n",
      "         [8.6936e-01],\n",
      "         [8.6212e-01],\n",
      "         [4.6060e-01],\n",
      "         [4.4728e-01],\n",
      "         [9.5817e-02],\n",
      "         [6.8252e-01],\n",
      "         [9.2991e-01],\n",
      "         [7.6255e-01],\n",
      "         [5.0092e-01],\n",
      "         [4.8432e-01],\n",
      "         [6.8814e-01],\n",
      "         [3.1346e-02],\n",
      "         [4.0822e-01],\n",
      "         [3.3421e-01],\n",
      "         [8.9864e-01],\n",
      "         [6.0531e-01],\n",
      "         [6.9730e-02],\n",
      "         [7.9827e-01],\n",
      "         [1.2745e-01],\n",
      "         [1.7696e-01],\n",
      "         [4.5744e-01],\n",
      "         [8.7916e-01],\n",
      "         [8.6452e-01],\n",
      "         [4.8246e-01],\n",
      "         [4.4575e-01],\n",
      "         [4.7643e-01],\n",
      "         [2.5879e-01],\n",
      "         [1.9434e-01],\n",
      "         [1.1213e-01],\n",
      "         [9.8417e-01],\n",
      "         [5.9867e-01],\n",
      "         [1.8275e-04],\n",
      "         [9.1565e-01],\n",
      "         [5.5998e-01],\n",
      "         [3.5009e-01],\n",
      "         [6.6821e-01],\n",
      "         [7.4863e-01],\n",
      "         [3.4227e-01],\n",
      "         [9.7840e-01],\n",
      "         [6.2280e-01],\n",
      "         [1.9968e-01],\n",
      "         [7.8720e-01],\n",
      "         [6.1864e-01],\n",
      "         [9.6665e-01],\n",
      "         [9.7285e-03],\n",
      "         [2.8952e-01],\n",
      "         [8.1028e-01],\n",
      "         [6.2336e-01],\n",
      "         [3.1754e-01],\n",
      "         [7.4593e-01],\n",
      "         [3.5757e-01],\n",
      "         [5.0148e-01],\n",
      "         [7.3441e-01],\n",
      "         [7.7525e-01],\n",
      "         [7.9137e-01],\n",
      "         [5.0599e-01],\n",
      "         [4.5446e-01],\n",
      "         [7.3521e-01],\n",
      "         [1.2251e-01],\n",
      "         [3.1966e-01],\n",
      "         [5.2408e-01],\n",
      "         [8.9589e-01],\n",
      "         [9.7057e-01],\n",
      "         [7.6211e-01],\n",
      "         [9.4706e-01],\n",
      "         [7.7452e-01],\n",
      "         [3.9886e-01],\n",
      "         [8.7100e-01],\n",
      "         [9.2983e-01],\n",
      "         [7.7614e-01],\n",
      "         [9.4171e-02],\n",
      "         [6.9189e-01],\n",
      "         [4.5416e-01],\n",
      "         [4.9507e-01],\n",
      "         [2.6890e-01],\n",
      "         [2.0874e-01],\n",
      "         [6.0388e-02],\n",
      "         [4.7966e-01],\n",
      "         [9.9792e-01],\n",
      "         [9.6386e-01],\n",
      "         [7.7982e-01],\n",
      "         [4.4882e-01],\n",
      "         [5.2171e-01],\n",
      "         [8.4654e-01],\n",
      "         [3.9491e-01],\n",
      "         [3.8404e-01],\n",
      "         [1.5718e-02],\n",
      "         [8.4500e-02],\n",
      "         [1.5618e-01],\n",
      "         [6.7064e-01],\n",
      "         [2.5988e-01]]], device='cuda:0', dtype=torch.float64)\n",
      "================iter 4============\n",
      "['shape/ellipsoid/1/ellipsoid_512_128_64_64_2_2_1']\n",
      "tensor([[ True,  True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
      "          True,  True,  True,  True,  True,  True,  True, False, False, False]],\n",
      "       device='cuda:0')\n",
      "acc torch.Size([1]) tensor([0.0588], device='cuda:0')\n",
      "acc_per_part torch.Size([1, 20]) tensor([[False, False, False, False, False, False, False, False, False, False,\n",
      "         False,  True, False, False, False, False, False, False, False, False]],\n",
      "       device='cuda:0')\n",
      "loss_per_data torch.Size([1, 20]) tensor([[  1.4565,   8.9112,   1.4180, 142.0754,   1.3381,   6.5169,   1.7101,\n",
      "           1.3055,   3.8077,  35.9864,   9.5194,   0.0000,   1.1863,  14.7389,\n",
      "           5.5863,   0.2867,   1.8347,  14.3605,  84.9076,  86.7405]],\n",
      "       device='cuda:0')\n",
      "scores torch.Size([1, 190, 1]) tensor([[[0.4002],\n",
      "         [0.2046],\n",
      "         [0.7238],\n",
      "         [0.7772],\n",
      "         [0.4451],\n",
      "         [0.6014],\n",
      "         [0.4706],\n",
      "         [0.2412],\n",
      "         [0.7012],\n",
      "         [0.4094],\n",
      "         [0.2783],\n",
      "         [0.3781],\n",
      "         [0.4777],\n",
      "         [0.8266],\n",
      "         [0.7660],\n",
      "         [0.1690],\n",
      "         [0.1082],\n",
      "         [0.8662],\n",
      "         [0.4800],\n",
      "         [0.5982],\n",
      "         [0.0442],\n",
      "         [0.0176],\n",
      "         [0.6817],\n",
      "         [0.7920],\n",
      "         [0.1105],\n",
      "         [0.5546],\n",
      "         [0.8541],\n",
      "         [0.9672],\n",
      "         [0.3578],\n",
      "         [0.2625],\n",
      "         [0.0453],\n",
      "         [0.3378],\n",
      "         [0.1018],\n",
      "         [0.9211],\n",
      "         [0.2487],\n",
      "         [0.8720],\n",
      "         [0.2956],\n",
      "         [0.5213],\n",
      "         [0.9480],\n",
      "         [0.4287],\n",
      "         [0.1224],\n",
      "         [0.8515],\n",
      "         [0.0083],\n",
      "         [0.2926],\n",
      "         [0.3037],\n",
      "         [0.9282],\n",
      "         [0.1562],\n",
      "         [0.3313],\n",
      "         [0.2524],\n",
      "         [0.2305],\n",
      "         [0.7652],\n",
      "         [0.0852],\n",
      "         [0.9674],\n",
      "         [0.0148],\n",
      "         [0.3827],\n",
      "         [0.3659],\n",
      "         [0.2015],\n",
      "         [0.3346],\n",
      "         [0.4118],\n",
      "         [0.9563],\n",
      "         [0.9502],\n",
      "         [0.5588],\n",
      "         [0.8452],\n",
      "         [0.3062],\n",
      "         [0.0037],\n",
      "         [0.9109],\n",
      "         [0.3264],\n",
      "         [0.2751],\n",
      "         [0.9857],\n",
      "         [0.1741],\n",
      "         [0.4155],\n",
      "         [0.1919],\n",
      "         [0.8432],\n",
      "         [0.4552],\n",
      "         [0.5697],\n",
      "         [0.6199],\n",
      "         [0.2252],\n",
      "         [0.8069],\n",
      "         [0.7650],\n",
      "         [0.5117],\n",
      "         [0.7076],\n",
      "         [0.7265],\n",
      "         [0.5477],\n",
      "         [0.1638],\n",
      "         [0.8769],\n",
      "         [0.9515],\n",
      "         [0.8454],\n",
      "         [0.9755],\n",
      "         [0.8141],\n",
      "         [0.2238],\n",
      "         [0.5351],\n",
      "         [0.8991],\n",
      "         [0.7757],\n",
      "         [0.6046],\n",
      "         [0.4942],\n",
      "         [0.4980],\n",
      "         [0.6967],\n",
      "         [0.4107],\n",
      "         [0.0278],\n",
      "         [0.4755],\n",
      "         [0.7307],\n",
      "         [0.7309],\n",
      "         [0.7596],\n",
      "         [0.1332],\n",
      "         [0.1200],\n",
      "         [0.0800],\n",
      "         [0.3675],\n",
      "         [0.3180],\n",
      "         [0.8294],\n",
      "         [0.6818],\n",
      "         [0.3526],\n",
      "         [0.1756],\n",
      "         [0.8125],\n",
      "         [0.6238],\n",
      "         [0.9789],\n",
      "         [0.6011],\n",
      "         [0.1149],\n",
      "         [0.8088],\n",
      "         [0.4985],\n",
      "         [0.8354],\n",
      "         [0.3537],\n",
      "         [0.4449],\n",
      "         [0.1642],\n",
      "         [0.2079],\n",
      "         [0.4774],\n",
      "         [0.9525],\n",
      "         [0.4796],\n",
      "         [0.3448],\n",
      "         [0.3830],\n",
      "         [0.8758],\n",
      "         [0.5537],\n",
      "         [0.7146],\n",
      "         [0.5518],\n",
      "         [0.7199],\n",
      "         [0.1015],\n",
      "         [0.1770],\n",
      "         [0.9896],\n",
      "         [0.2174],\n",
      "         [0.1801],\n",
      "         [0.0953],\n",
      "         [0.3523],\n",
      "         [0.8875],\n",
      "         [0.6599],\n",
      "         [0.8267],\n",
      "         [0.2436],\n",
      "         [0.3643],\n",
      "         [0.2128],\n",
      "         [0.7447],\n",
      "         [0.4739],\n",
      "         [0.7946],\n",
      "         [0.2207],\n",
      "         [0.1973],\n",
      "         [0.8234],\n",
      "         [0.1349],\n",
      "         [0.3957],\n",
      "         [0.7411],\n",
      "         [0.3606],\n",
      "         [0.4769],\n",
      "         [0.3301],\n",
      "         [0.8701],\n",
      "         [0.0233],\n",
      "         [0.9358],\n",
      "         [0.4734],\n",
      "         [0.5768],\n",
      "         [0.4440],\n",
      "         [0.6895],\n",
      "         [0.4066],\n",
      "         [0.6437],\n",
      "         [0.2184],\n",
      "         [0.4807],\n",
      "         [0.0874],\n",
      "         [0.4371],\n",
      "         [0.1984],\n",
      "         [0.9469],\n",
      "         [0.4687],\n",
      "         [0.3175],\n",
      "         [0.0937],\n",
      "         [0.1604],\n",
      "         [0.2238],\n",
      "         [0.2318],\n",
      "         [0.8922],\n",
      "         [0.1008],\n",
      "         [0.1055],\n",
      "         [0.7680],\n",
      "         [0.4943],\n",
      "         [0.7087],\n",
      "         [0.5376],\n",
      "         [0.9224],\n",
      "         [0.4278],\n",
      "         [0.8408]]], device='cuda:0', dtype=torch.float64)\n",
      "================iter 5============\n",
      "['shape/ellipsoid/1/ellipsoid_512_128_64_64_2_2_1']\n",
      "tensor([[ True,  True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
      "          True,  True,  True,  True,  True,  True,  True, False, False, False]],\n",
      "       device='cuda:0')\n",
      "@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@\n",
      "['shape/ellipsoid/1/ellipsoid_512_128_64_64_2_3_1']\n",
      "gt_trans_torch.Size([1, 20, 3])_tensor([[[-2.1820e-01,  1.4533e-02,  3.9386e-01],\n",
      "         [-2.0697e-01,  1.6429e-02,  3.4641e-01],\n",
      "         [-3.5881e-02,  4.9030e-03,  7.6276e-02],\n",
      "         [-1.2861e-02, -1.2446e-03,  4.3938e-02],\n",
      "         [ 2.4425e-18, -2.2204e-19,  1.3323e-17],\n",
      "         [ 1.9461e-02, -1.1297e-03, -2.8507e-02],\n",
      "         [ 2.1352e-02,  1.4422e-02, -6.0406e-02],\n",
      "         [ 5.1745e-02, -1.9013e-03, -1.0405e-01],\n",
      "         [ 6.9199e-02,  9.0149e-04, -1.2575e-01],\n",
      "         [-1.8386e-01,  1.3141e-02,  3.2456e-01],\n",
      "         [-1.6347e-01,  8.6218e-03,  2.8747e-01],\n",
      "         [-1.4447e-01,  5.7737e-03,  2.5220e-01],\n",
      "         [-1.3026e-01,  1.0551e-02,  2.2622e-01],\n",
      "         [-1.0668e-01,  3.1802e-03,  1.9149e-01],\n",
      "         [-1.0516e-01,  1.9148e-02,  1.5631e-01],\n",
      "         [-6.8791e-02,  2.4658e-03,  1.3470e-01],\n",
      "         [-6.7694e-02,  2.4073e-02,  1.2054e-01],\n",
      "         [ 0.0000e+00,  0.0000e+00,  0.0000e+00],\n",
      "         [ 0.0000e+00,  0.0000e+00,  0.0000e+00],\n",
      "         [ 0.0000e+00,  0.0000e+00,  0.0000e+00]]], device='cuda:0')\n",
      "gt_rots_torch.Size([1, 20, 4])_tensor([[[ 0.5058, -0.0266,  0.8614, -0.0373],\n",
      "         [ 0.6431, -0.0690,  0.7118,  0.2739],\n",
      "         [-0.0691,  0.8948,  0.4078,  0.1682],\n",
      "         [ 0.1280,  0.9822,  0.1338,  0.0327],\n",
      "         [-0.1366, -0.0502,  0.5726,  0.8068],\n",
      "         [ 0.3192,  0.5876,  0.0650,  0.7407],\n",
      "         [ 0.1583,  0.1627,  0.5821,  0.7808],\n",
      "         [-0.1696,  0.8319, -0.5134, -0.1250],\n",
      "         [ 0.1002, -0.5555,  0.7875,  0.2475],\n",
      "         [ 0.5960,  0.0164,  0.6105, -0.5214],\n",
      "         [-0.0637,  0.9585, -0.2729,  0.0527],\n",
      "         [ 0.1134,  0.2845,  0.0281,  0.9515],\n",
      "         [ 0.6896, -0.0140,  0.7240, -0.0126],\n",
      "         [ 0.5909,  0.5853, -0.5542,  0.0330],\n",
      "         [ 0.6618, -0.5431,  0.1038,  0.5063],\n",
      "         [ 0.9554, -0.2557, -0.0198, -0.1465],\n",
      "         [ 0.7227,  0.6388, -0.2569, -0.0612],\n",
      "         [ 0.0000,  0.0000,  0.0000,  0.0000],\n",
      "         [ 0.0000,  0.0000,  0.0000,  0.0000],\n",
      "         [ 0.0000,  0.0000,  0.0000,  0.0000]]], device='cuda:0')\n",
      "noisy_trans_and_rots_torch.Size([1, 20, 7])_tensor([[[ 7.4811e-01,  0.0000e+00, -2.4788e-01,  6.5322e-01,  0.0000e+00,\n",
      "           0.0000e+00, -7.6950e-03],\n",
      "         [ 1.3179e+00,  0.0000e+00, -1.4639e-04,  1.8475e+00,  0.0000e+00,\n",
      "           0.0000e+00, -9.7819e-01],\n",
      "         [-6.4854e-01,  0.0000e+00, -1.7320e+00, -1.2535e+00,  0.0000e+00,\n",
      "           0.0000e+00,  1.2431e+00],\n",
      "         [ 1.1910e+00,  0.0000e+00,  1.0987e+00, -1.5993e+00,  0.0000e+00,\n",
      "           0.0000e+00, -6.6183e-01],\n",
      "         [ 9.1742e-01,  0.0000e+00,  7.8867e-01,  7.1578e-01,  0.0000e+00,\n",
      "           0.0000e+00, -1.0924e+00],\n",
      "         [ 4.4614e-01,  0.0000e+00,  7.1791e-01,  7.5806e-01,  0.0000e+00,\n",
      "           0.0000e+00,  1.5318e+00],\n",
      "         [-9.5036e-01,  0.0000e+00,  5.4451e-01, -2.5069e+00,  0.0000e+00,\n",
      "           0.0000e+00, -2.2299e-01],\n",
      "         [-1.0218e+00,  0.0000e+00, -1.6102e+00,  1.9760e+00,  0.0000e+00,\n",
      "           0.0000e+00, -6.2895e-01],\n",
      "         [ 6.4570e-01,  0.0000e+00,  6.5489e-01,  2.3831e-01,  0.0000e+00,\n",
      "           0.0000e+00, -3.9361e-01],\n",
      "         [ 7.2704e-01,  0.0000e+00,  7.7817e-01,  1.2198e+00,  0.0000e+00,\n",
      "           0.0000e+00, -4.4145e-01],\n",
      "         [ 3.3309e-01,  0.0000e+00,  1.5657e+00, -4.9770e-02,  0.0000e+00,\n",
      "           0.0000e+00, -9.5426e-01],\n",
      "         [ 8.4528e-01,  0.0000e+00,  1.6374e+00, -3.7157e-01,  0.0000e+00,\n",
      "           0.0000e+00,  2.0299e-01],\n",
      "         [ 1.1117e+00,  0.0000e+00,  3.3231e-01, -6.9027e-01,  0.0000e+00,\n",
      "           0.0000e+00,  2.3536e-01],\n",
      "         [-1.9330e+00,  0.0000e+00,  6.3056e-01, -2.2113e-01,  0.0000e+00,\n",
      "           0.0000e+00, -6.0055e-01],\n",
      "         [ 1.4344e+00,  0.0000e+00, -7.3366e-02,  4.0022e-01,  0.0000e+00,\n",
      "           0.0000e+00,  2.1884e-01],\n",
      "         [ 2.2388e+00,  0.0000e+00, -1.2044e-01, -6.2437e-01,  0.0000e+00,\n",
      "           0.0000e+00, -5.1010e-01],\n",
      "         [-6.0600e-01,  0.0000e+00, -5.5349e-01, -1.9502e+00,  0.0000e+00,\n",
      "           0.0000e+00,  1.0435e+00],\n",
      "         [ 2.1660e-01,  0.0000e+00, -6.0722e-01, -8.4364e-01,  0.0000e+00,\n",
      "           0.0000e+00,  2.0227e+00],\n",
      "         [-5.3015e-01,  0.0000e+00, -1.4102e+00, -2.0701e-01,  0.0000e+00,\n",
      "           0.0000e+00,  7.6319e-01],\n",
      "         [ 6.3167e-01,  0.0000e+00, -4.2213e-01,  9.0734e-02,  0.0000e+00,\n",
      "           0.0000e+00, -1.1925e+00]]], device='cuda:0')\n",
      "================iter 0============\n",
      "['shape/ellipsoid/1/ellipsoid_512_128_64_64_2_3_1']\n",
      "tensor([[False, False, False, False,  True, False, False, False, False, False,\n",
      "         False, False, False, False, False, False, False, False, False, False]],\n",
      "       device='cuda:0')\n",
      "acc torch.Size([1]) tensor([0.0588], device='cuda:0')\n",
      "acc_per_part torch.Size([1, 20]) tensor([[False, False, False, False,  True, False, False, False, False, False,\n",
      "         False, False, False, False, False, False, False, False, False, False]],\n",
      "       device='cuda:0')\n",
      "loss_per_data torch.Size([1, 20]) tensor([[ 0.8729,  1.3349, 12.1326,  2.5624,  0.0000,  1.4123,  0.8948,  0.9760,\n",
      "          1.5044,  0.6337,  2.4709,  2.9542,  0.6275, 13.0067,  4.7159, 17.6410,\n",
      "          2.3197,  4.9329,  0.7704,  1.4979]], device='cuda:0')\n",
      "scores torch.Size([1, 190, 1]) tensor([[[0.7270],\n",
      "         [0.0344],\n",
      "         [0.1913],\n",
      "         [0.7081],\n",
      "         [0.9868],\n",
      "         [0.4836],\n",
      "         [0.4614],\n",
      "         [0.9095],\n",
      "         [0.3666],\n",
      "         [0.0510],\n",
      "         [0.1540],\n",
      "         [0.3062],\n",
      "         [0.8860],\n",
      "         [0.4260],\n",
      "         [0.2040],\n",
      "         [0.9394],\n",
      "         [0.7632],\n",
      "         [0.5956],\n",
      "         [0.2133],\n",
      "         [0.6614],\n",
      "         [0.5266],\n",
      "         [0.6680],\n",
      "         [0.0720],\n",
      "         [0.5281],\n",
      "         [0.6219],\n",
      "         [0.4127],\n",
      "         [0.5420],\n",
      "         [0.1920],\n",
      "         [0.2571],\n",
      "         [0.3261],\n",
      "         [0.5629],\n",
      "         [0.2119],\n",
      "         [0.1239],\n",
      "         [0.4632],\n",
      "         [0.0727],\n",
      "         [0.9504],\n",
      "         [0.0547],\n",
      "         [0.2257],\n",
      "         [0.7788],\n",
      "         [0.0262],\n",
      "         [0.4444],\n",
      "         [0.6371],\n",
      "         [0.5982],\n",
      "         [0.5586],\n",
      "         [0.1052],\n",
      "         [0.5080],\n",
      "         [0.3914],\n",
      "         [0.9920],\n",
      "         [0.8851],\n",
      "         [0.9978],\n",
      "         [0.6027],\n",
      "         [0.1552],\n",
      "         [0.0960],\n",
      "         [0.8444],\n",
      "         [0.7884],\n",
      "         [0.9816],\n",
      "         [0.5913],\n",
      "         [0.6001],\n",
      "         [0.8908],\n",
      "         [0.0534],\n",
      "         [0.0961],\n",
      "         [0.6400],\n",
      "         [0.3775],\n",
      "         [0.8672],\n",
      "         [0.5237],\n",
      "         [0.5223],\n",
      "         [0.2579],\n",
      "         [0.7217],\n",
      "         [0.6521],\n",
      "         [0.9229],\n",
      "         [0.7442],\n",
      "         [0.1545],\n",
      "         [0.5050],\n",
      "         [0.0409],\n",
      "         [0.4295],\n",
      "         [0.7422],\n",
      "         [0.0148],\n",
      "         [0.5980],\n",
      "         [0.7001],\n",
      "         [0.6407],\n",
      "         [0.3764],\n",
      "         [0.9746],\n",
      "         [0.3474],\n",
      "         [0.5795],\n",
      "         [0.4322],\n",
      "         [0.6081],\n",
      "         [0.6529],\n",
      "         [0.8872],\n",
      "         [0.1955],\n",
      "         [0.1576],\n",
      "         [0.0639],\n",
      "         [0.3369],\n",
      "         [0.8760],\n",
      "         [0.6171],\n",
      "         [0.2931],\n",
      "         [0.8511],\n",
      "         [0.7673],\n",
      "         [0.3732],\n",
      "         [0.4104],\n",
      "         [0.4633],\n",
      "         [0.0373],\n",
      "         [0.7543],\n",
      "         [0.0643],\n",
      "         [0.7770],\n",
      "         [0.6421],\n",
      "         [0.5554],\n",
      "         [0.5632],\n",
      "         [0.9387],\n",
      "         [0.5699],\n",
      "         [0.8743],\n",
      "         [0.7242],\n",
      "         [0.4388],\n",
      "         [0.3433],\n",
      "         [0.6270],\n",
      "         [0.8860],\n",
      "         [0.0769],\n",
      "         [0.0674],\n",
      "         [0.7518],\n",
      "         [0.0343],\n",
      "         [0.4833],\n",
      "         [0.6930],\n",
      "         [0.1022],\n",
      "         [0.2486],\n",
      "         [0.7229],\n",
      "         [0.8460],\n",
      "         [0.9722],\n",
      "         [0.1999],\n",
      "         [0.7943],\n",
      "         [0.6408],\n",
      "         [0.7228],\n",
      "         [0.2991],\n",
      "         [0.2516],\n",
      "         [0.1436],\n",
      "         [0.8550],\n",
      "         [0.7489],\n",
      "         [0.5347],\n",
      "         [0.8798],\n",
      "         [0.6969],\n",
      "         [0.9803],\n",
      "         [0.7113],\n",
      "         [0.3741],\n",
      "         [0.8770],\n",
      "         [0.2175],\n",
      "         [0.0407],\n",
      "         [0.2782],\n",
      "         [0.8863],\n",
      "         [0.5595],\n",
      "         [0.3551],\n",
      "         [0.7332],\n",
      "         [0.9818],\n",
      "         [0.3971],\n",
      "         [0.3236],\n",
      "         [0.6330],\n",
      "         [0.1039],\n",
      "         [0.8286],\n",
      "         [0.9009],\n",
      "         [0.6282],\n",
      "         [0.7185],\n",
      "         [0.2509],\n",
      "         [0.0252],\n",
      "         [0.5107],\n",
      "         [0.2736],\n",
      "         [0.2868],\n",
      "         [0.8779],\n",
      "         [0.4848],\n",
      "         [0.6494],\n",
      "         [0.8466],\n",
      "         [0.9494],\n",
      "         [0.0955],\n",
      "         [0.8091],\n",
      "         [0.2586],\n",
      "         [0.4868],\n",
      "         [0.4182],\n",
      "         [0.4229],\n",
      "         [0.5929],\n",
      "         [0.3568],\n",
      "         [0.4529],\n",
      "         [0.7470],\n",
      "         [0.0595],\n",
      "         [0.7765],\n",
      "         [0.0943],\n",
      "         [0.3521],\n",
      "         [0.7919],\n",
      "         [0.6257],\n",
      "         [0.7099],\n",
      "         [0.2342],\n",
      "         [0.0667],\n",
      "         [0.6018],\n",
      "         [0.3123],\n",
      "         [0.9949]]], device='cuda:0', dtype=torch.float64)\n",
      "================iter 1============\n",
      "['shape/ellipsoid/1/ellipsoid_512_128_64_64_2_3_1']\n",
      "tensor([[False, False, False, False,  True, False, False, False, False, False,\n",
      "         False, False, False, False, False, False,  True, False, False, False]],\n",
      "       device='cuda:0')\n",
      "acc torch.Size([1]) tensor([0.0588], device='cuda:0')\n",
      "acc_per_part torch.Size([1, 20]) tensor([[False, False, False, False,  True, False, False, False, False, False,\n",
      "         False, False, False, False, False, False, False, False, False, False]],\n",
      "       device='cuda:0')\n",
      "loss_per_data torch.Size([1, 20]) tensor([[ 2.8753,  3.7121,  9.9931,  0.3576,  0.0000,  2.2690,  1.2890,  1.4282,\n",
      "          6.2953,  1.1965,  0.8378,  6.3018,  1.3978,  3.2468,  5.3384, 20.8131,\n",
      "          2.3197,  1.8861,  3.1840,  3.2224]], device='cuda:0')\n",
      "scores torch.Size([1, 190, 1]) tensor([[[0.9877],\n",
      "         [0.3922],\n",
      "         [0.1189],\n",
      "         [0.0736],\n",
      "         [0.3936],\n",
      "         [0.8048],\n",
      "         [0.4683],\n",
      "         [0.0989],\n",
      "         [0.0310],\n",
      "         [0.6093],\n",
      "         [0.3255],\n",
      "         [0.2546],\n",
      "         [0.6689],\n",
      "         [0.6680],\n",
      "         [0.0976],\n",
      "         [0.0047],\n",
      "         [0.4763],\n",
      "         [0.8681],\n",
      "         [0.7118],\n",
      "         [0.8713],\n",
      "         [0.7341],\n",
      "         [0.1056],\n",
      "         [0.4849],\n",
      "         [0.0532],\n",
      "         [0.7100],\n",
      "         [0.6146],\n",
      "         [0.3691],\n",
      "         [0.5003],\n",
      "         [0.7610],\n",
      "         [0.5079],\n",
      "         [0.2524],\n",
      "         [0.7463],\n",
      "         [0.5806],\n",
      "         [0.8049],\n",
      "         [0.3356],\n",
      "         [0.9200],\n",
      "         [0.4964],\n",
      "         [0.1433],\n",
      "         [0.1479],\n",
      "         [0.2169],\n",
      "         [0.6059],\n",
      "         [0.4629],\n",
      "         [0.7149],\n",
      "         [0.9459],\n",
      "         [0.7640],\n",
      "         [0.6823],\n",
      "         [0.9041],\n",
      "         [0.5480],\n",
      "         [0.1334],\n",
      "         [0.5447],\n",
      "         [0.9959],\n",
      "         [0.6278],\n",
      "         [0.3641],\n",
      "         [0.5710],\n",
      "         [0.6371],\n",
      "         [0.5101],\n",
      "         [0.3839],\n",
      "         [0.1085],\n",
      "         [0.6923],\n",
      "         [0.8583],\n",
      "         [0.3305],\n",
      "         [0.9534],\n",
      "         [0.0571],\n",
      "         [0.9156],\n",
      "         [0.4735],\n",
      "         [0.1848],\n",
      "         [0.4484],\n",
      "         [0.5742],\n",
      "         [0.9882],\n",
      "         [0.7774],\n",
      "         [0.2567],\n",
      "         [0.9818],\n",
      "         [0.2858],\n",
      "         [0.9967],\n",
      "         [0.3232],\n",
      "         [0.0566],\n",
      "         [0.6596],\n",
      "         [0.7911],\n",
      "         [0.6566],\n",
      "         [0.5215],\n",
      "         [0.4933],\n",
      "         [0.6119],\n",
      "         [0.0300],\n",
      "         [0.9051],\n",
      "         [0.9525],\n",
      "         [0.7971],\n",
      "         [0.9007],\n",
      "         [0.9542],\n",
      "         [0.9419],\n",
      "         [0.1761],\n",
      "         [0.6766],\n",
      "         [0.1764],\n",
      "         [0.8395],\n",
      "         [0.0901],\n",
      "         [0.5555],\n",
      "         [0.3095],\n",
      "         [0.7347],\n",
      "         [0.5133],\n",
      "         [0.0430],\n",
      "         [0.1059],\n",
      "         [0.7414],\n",
      "         [0.6384],\n",
      "         [0.6764],\n",
      "         [0.3077],\n",
      "         [0.3905],\n",
      "         [0.1116],\n",
      "         [0.4508],\n",
      "         [0.0388],\n",
      "         [0.5083],\n",
      "         [0.6976],\n",
      "         [0.6339],\n",
      "         [0.1257],\n",
      "         [0.8838],\n",
      "         [0.1324],\n",
      "         [0.8081],\n",
      "         [0.0290],\n",
      "         [0.8856],\n",
      "         [0.1138],\n",
      "         [0.0358],\n",
      "         [0.5105],\n",
      "         [0.5392],\n",
      "         [0.2979],\n",
      "         [0.1939],\n",
      "         [0.6010],\n",
      "         [0.8401],\n",
      "         [0.2850],\n",
      "         [0.0220],\n",
      "         [0.9950],\n",
      "         [0.3658],\n",
      "         [0.4847],\n",
      "         [0.7472],\n",
      "         [0.9626],\n",
      "         [0.3178],\n",
      "         [0.9017],\n",
      "         [0.6238],\n",
      "         [0.0441],\n",
      "         [0.9123],\n",
      "         [0.1688],\n",
      "         [0.3389],\n",
      "         [0.6702],\n",
      "         [0.7453],\n",
      "         [0.4184],\n",
      "         [0.8099],\n",
      "         [0.2026],\n",
      "         [0.1077],\n",
      "         [0.0300],\n",
      "         [0.3609],\n",
      "         [0.2681],\n",
      "         [0.6213],\n",
      "         [0.8499],\n",
      "         [0.1140],\n",
      "         [0.5336],\n",
      "         [0.8095],\n",
      "         [0.2546],\n",
      "         [0.0826],\n",
      "         [0.3579],\n",
      "         [0.0240],\n",
      "         [0.6453],\n",
      "         [0.1122],\n",
      "         [0.4380],\n",
      "         [0.3526],\n",
      "         [0.0160],\n",
      "         [0.0855],\n",
      "         [0.4159],\n",
      "         [0.3353],\n",
      "         [0.7667],\n",
      "         [0.2449],\n",
      "         [0.4813],\n",
      "         [0.3701],\n",
      "         [0.1540],\n",
      "         [0.3488],\n",
      "         [0.1274],\n",
      "         [0.4984],\n",
      "         [0.2702],\n",
      "         [0.2756],\n",
      "         [0.9550],\n",
      "         [0.0695],\n",
      "         [0.9818],\n",
      "         [0.3790],\n",
      "         [0.6017],\n",
      "         [0.0759],\n",
      "         [0.5049],\n",
      "         [0.6736],\n",
      "         [0.2454],\n",
      "         [0.2207],\n",
      "         [0.6875],\n",
      "         [0.1777],\n",
      "         [0.5824],\n",
      "         [0.6240],\n",
      "         [0.1335]]], device='cuda:0', dtype=torch.float64)\n",
      "================iter 2============\n",
      "['shape/ellipsoid/1/ellipsoid_512_128_64_64_2_3_1']\n",
      "tensor([[False, False,  True, False,  True, False,  True, False,  True, False,\n",
      "         False, False, False, False, False, False,  True, False, False, False]],\n",
      "       device='cuda:0')\n",
      "acc torch.Size([1]) tensor([0.0588], device='cuda:0')\n",
      "acc_per_part torch.Size([1, 20]) tensor([[False, False, False, False,  True, False, False, False, False, False,\n",
      "         False, False, False, False, False, False, False, False, False, False]],\n",
      "       device='cuda:0')\n",
      "loss_per_data torch.Size([1, 20]) tensor([[ 0.4891,  3.3192,  9.9931,  0.7770,  0.0000,  1.0743,  1.2890,  2.1218,\n",
      "          6.2953,  0.3606,  0.4622, 21.2397,  4.5179,  6.3565, 10.5620, 26.1074,\n",
      "          2.3197,  5.1529,  0.7317,  2.4536]], device='cuda:0')\n",
      "scores torch.Size([1, 190, 1]) tensor([[[0.9264],\n",
      "         [0.3197],\n",
      "         [0.1574],\n",
      "         [0.8966],\n",
      "         [0.3137],\n",
      "         [0.9392],\n",
      "         [0.4112],\n",
      "         [0.9248],\n",
      "         [0.8715],\n",
      "         [0.7495],\n",
      "         [0.4371],\n",
      "         [0.6741],\n",
      "         [0.4123],\n",
      "         [0.4450],\n",
      "         [0.3998],\n",
      "         [0.9878],\n",
      "         [0.8601],\n",
      "         [0.8377],\n",
      "         [0.1168],\n",
      "         [0.9925],\n",
      "         [0.2503],\n",
      "         [0.1221],\n",
      "         [0.2574],\n",
      "         [0.0298],\n",
      "         [0.6375],\n",
      "         [0.2111],\n",
      "         [0.6902],\n",
      "         [0.4637],\n",
      "         [0.6643],\n",
      "         [0.9964],\n",
      "         [0.1341],\n",
      "         [0.2379],\n",
      "         [0.3637],\n",
      "         [0.0231],\n",
      "         [0.9956],\n",
      "         [0.1819],\n",
      "         [0.7323],\n",
      "         [0.3797],\n",
      "         [0.9705],\n",
      "         [0.0273],\n",
      "         [0.1238],\n",
      "         [0.4859],\n",
      "         [0.7166],\n",
      "         [0.4373],\n",
      "         [0.4086],\n",
      "         [0.8328],\n",
      "         [0.9383],\n",
      "         [0.5971],\n",
      "         [0.7337],\n",
      "         [0.5379],\n",
      "         [0.8944],\n",
      "         [0.1217],\n",
      "         [0.3566],\n",
      "         [0.6886],\n",
      "         [0.9942],\n",
      "         [0.1630],\n",
      "         [0.7156],\n",
      "         [0.1215],\n",
      "         [0.3733],\n",
      "         [0.3656],\n",
      "         [0.5219],\n",
      "         [0.9288],\n",
      "         [0.4993],\n",
      "         [0.5605],\n",
      "         [0.3248],\n",
      "         [0.4244],\n",
      "         [0.9340],\n",
      "         [0.0071],\n",
      "         [0.6053],\n",
      "         [0.1825],\n",
      "         [0.6624],\n",
      "         [0.1740],\n",
      "         [0.5764],\n",
      "         [0.1984],\n",
      "         [0.9822],\n",
      "         [0.3701],\n",
      "         [0.4827],\n",
      "         [0.6260],\n",
      "         [0.9927],\n",
      "         [0.1359],\n",
      "         [0.4841],\n",
      "         [0.8921],\n",
      "         [0.1498],\n",
      "         [0.2437],\n",
      "         [0.0652],\n",
      "         [0.6543],\n",
      "         [0.6688],\n",
      "         [0.7277],\n",
      "         [0.7170],\n",
      "         [0.9130],\n",
      "         [0.8165],\n",
      "         [0.0408],\n",
      "         [0.1644],\n",
      "         [0.8622],\n",
      "         [0.0927],\n",
      "         [0.7223],\n",
      "         [0.1732],\n",
      "         [0.7911],\n",
      "         [0.8927],\n",
      "         [0.1418],\n",
      "         [0.9753],\n",
      "         [0.8592],\n",
      "         [0.1364],\n",
      "         [0.4844],\n",
      "         [0.2425],\n",
      "         [0.9250],\n",
      "         [0.9906],\n",
      "         [0.9354],\n",
      "         [0.8490],\n",
      "         [0.5995],\n",
      "         [0.8707],\n",
      "         [0.3508],\n",
      "         [0.2075],\n",
      "         [0.0937],\n",
      "         [0.7966],\n",
      "         [0.0966],\n",
      "         [0.6731],\n",
      "         [0.3974],\n",
      "         [0.0733],\n",
      "         [0.1285],\n",
      "         [0.7198],\n",
      "         [0.2991],\n",
      "         [0.4680],\n",
      "         [0.7240],\n",
      "         [0.4051],\n",
      "         [0.3143],\n",
      "         [0.8609],\n",
      "         [0.6624],\n",
      "         [0.8383],\n",
      "         [0.2194],\n",
      "         [0.7377],\n",
      "         [0.7794],\n",
      "         [0.6723],\n",
      "         [0.6662],\n",
      "         [0.8393],\n",
      "         [0.5066],\n",
      "         [0.7699],\n",
      "         [0.9818],\n",
      "         [0.6729],\n",
      "         [0.9928],\n",
      "         [0.6965],\n",
      "         [0.9919],\n",
      "         [0.9353],\n",
      "         [0.6338],\n",
      "         [0.5712],\n",
      "         [0.3342],\n",
      "         [0.1277],\n",
      "         [0.9061],\n",
      "         [0.1703],\n",
      "         [0.9108],\n",
      "         [0.3193],\n",
      "         [0.0475],\n",
      "         [0.2477],\n",
      "         [0.4591],\n",
      "         [0.0754],\n",
      "         [0.5243],\n",
      "         [0.2523],\n",
      "         [0.0717],\n",
      "         [0.6651],\n",
      "         [0.8883],\n",
      "         [0.5250],\n",
      "         [0.0567],\n",
      "         [0.3753],\n",
      "         [0.1805],\n",
      "         [0.7537],\n",
      "         [0.7454],\n",
      "         [0.6470],\n",
      "         [0.4990],\n",
      "         [0.5482],\n",
      "         [0.8847],\n",
      "         [0.5093],\n",
      "         [0.8906],\n",
      "         [0.7698],\n",
      "         [0.4224],\n",
      "         [0.8895],\n",
      "         [0.9229],\n",
      "         [0.0258],\n",
      "         [0.6499],\n",
      "         [0.3255],\n",
      "         [0.6759],\n",
      "         [0.5110],\n",
      "         [0.5256],\n",
      "         [0.8838],\n",
      "         [0.9384],\n",
      "         [0.0740],\n",
      "         [0.6218],\n",
      "         [0.6865],\n",
      "         [0.7133],\n",
      "         [0.7566],\n",
      "         [0.0896]]], device='cuda:0', dtype=torch.float64)\n",
      "================iter 3============\n",
      "['shape/ellipsoid/1/ellipsoid_512_128_64_64_2_3_1']\n",
      "tensor([[ True,  True,  True,  True,  True, False,  True, False,  True,  True,\n",
      "         False, False,  True,  True,  True,  True,  True, False, False, False]],\n",
      "       device='cuda:0')\n",
      "acc torch.Size([1]) tensor([0.0588], device='cuda:0')\n",
      "acc_per_part torch.Size([1, 20]) tensor([[False, False, False, False,  True, False, False, False, False, False,\n",
      "         False, False, False, False, False, False, False, False, False, False]],\n",
      "       device='cuda:0')\n",
      "loss_per_data torch.Size([1, 20]) tensor([[ 0.4891,  3.3192,  9.9931,  0.7770,  0.0000,  8.5703,  1.2890,  3.8170,\n",
      "          6.2953,  0.3606,  0.6183, 25.6222,  4.5179,  6.3565, 10.5620, 26.1074,\n",
      "          2.3197, 15.4762,  4.6313,  3.0040]], device='cuda:0')\n",
      "scores torch.Size([1, 190, 1]) tensor([[[0.6521],\n",
      "         [0.0096],\n",
      "         [0.6199],\n",
      "         [0.9881],\n",
      "         [0.5880],\n",
      "         [0.0125],\n",
      "         [0.7881],\n",
      "         [0.0449],\n",
      "         [0.4195],\n",
      "         [0.7582],\n",
      "         [0.2622],\n",
      "         [0.9455],\n",
      "         [0.8932],\n",
      "         [0.7762],\n",
      "         [0.6607],\n",
      "         [0.3830],\n",
      "         [0.0219],\n",
      "         [0.8135],\n",
      "         [0.0994],\n",
      "         [0.5851],\n",
      "         [0.8867],\n",
      "         [0.6722],\n",
      "         [0.7457],\n",
      "         [0.4474],\n",
      "         [0.0337],\n",
      "         [0.8817],\n",
      "         [0.0737],\n",
      "         [0.8166],\n",
      "         [0.5416],\n",
      "         [0.4820],\n",
      "         [0.6372],\n",
      "         [0.5687],\n",
      "         [0.8440],\n",
      "         [0.7312],\n",
      "         [0.4853],\n",
      "         [0.2504],\n",
      "         [0.2189],\n",
      "         [0.9170],\n",
      "         [0.4698],\n",
      "         [0.8497],\n",
      "         [0.6222],\n",
      "         [0.6950],\n",
      "         [0.4308],\n",
      "         [0.4286],\n",
      "         [0.1555],\n",
      "         [0.4503],\n",
      "         [0.1976],\n",
      "         [0.2144],\n",
      "         [0.3238],\n",
      "         [0.3383],\n",
      "         [0.9270],\n",
      "         [0.2115],\n",
      "         [0.3898],\n",
      "         [0.0048],\n",
      "         [0.0911],\n",
      "         [0.3843],\n",
      "         [0.2175],\n",
      "         [0.7677],\n",
      "         [0.3935],\n",
      "         [0.7129],\n",
      "         [0.9791],\n",
      "         [0.5088],\n",
      "         [0.1224],\n",
      "         [0.8170],\n",
      "         [0.2866],\n",
      "         [0.5505],\n",
      "         [0.9259],\n",
      "         [0.3390],\n",
      "         [0.8125],\n",
      "         [0.7579],\n",
      "         [0.3809],\n",
      "         [0.4298],\n",
      "         [0.2197],\n",
      "         [0.7614],\n",
      "         [0.8613],\n",
      "         [0.1145],\n",
      "         [0.5466],\n",
      "         [0.4950],\n",
      "         [0.7212],\n",
      "         [0.6016],\n",
      "         [0.5227],\n",
      "         [0.6426],\n",
      "         [0.6953],\n",
      "         [0.7915],\n",
      "         [0.4259],\n",
      "         [0.9049],\n",
      "         [0.3896],\n",
      "         [0.3057],\n",
      "         [0.0934],\n",
      "         [0.1351],\n",
      "         [0.9787],\n",
      "         [0.1675],\n",
      "         [0.8455],\n",
      "         [0.5696],\n",
      "         [0.4821],\n",
      "         [0.0494],\n",
      "         [0.4493],\n",
      "         [0.6184],\n",
      "         [0.5313],\n",
      "         [0.1003],\n",
      "         [0.1972],\n",
      "         [0.3477],\n",
      "         [0.4572],\n",
      "         [0.2925],\n",
      "         [0.8061],\n",
      "         [0.0945],\n",
      "         [0.3247],\n",
      "         [0.8511],\n",
      "         [0.2469],\n",
      "         [0.8324],\n",
      "         [0.7367],\n",
      "         [0.7184],\n",
      "         [0.3489],\n",
      "         [0.8996],\n",
      "         [0.3216],\n",
      "         [0.6054],\n",
      "         [0.7052],\n",
      "         [0.6607],\n",
      "         [0.6046],\n",
      "         [0.9143],\n",
      "         [0.7129],\n",
      "         [0.5468],\n",
      "         [0.7886],\n",
      "         [0.7965],\n",
      "         [0.9656],\n",
      "         [0.0903],\n",
      "         [0.9750],\n",
      "         [0.8599],\n",
      "         [0.4307],\n",
      "         [0.5956],\n",
      "         [0.6505],\n",
      "         [0.6626],\n",
      "         [0.0173],\n",
      "         [0.2224],\n",
      "         [0.0656],\n",
      "         [0.2790],\n",
      "         [0.2560],\n",
      "         [0.1678],\n",
      "         [0.7386],\n",
      "         [0.4148],\n",
      "         [0.2713],\n",
      "         [0.0654],\n",
      "         [0.7934],\n",
      "         [0.2164],\n",
      "         [0.8429],\n",
      "         [0.2089],\n",
      "         [0.9449],\n",
      "         [0.1301],\n",
      "         [0.2500],\n",
      "         [0.7758],\n",
      "         [0.8474],\n",
      "         [0.8145],\n",
      "         [0.2172],\n",
      "         [0.6440],\n",
      "         [0.2141],\n",
      "         [0.8646],\n",
      "         [0.3316],\n",
      "         [0.8594],\n",
      "         [0.1321],\n",
      "         [0.2047],\n",
      "         [0.8668],\n",
      "         [0.6218],\n",
      "         [0.6011],\n",
      "         [0.1959],\n",
      "         [0.8611],\n",
      "         [0.8438],\n",
      "         [0.6870],\n",
      "         [0.9977],\n",
      "         [0.4872],\n",
      "         [0.1132],\n",
      "         [0.6852],\n",
      "         [0.2659],\n",
      "         [0.0462],\n",
      "         [0.8399],\n",
      "         [0.9405],\n",
      "         [0.2937],\n",
      "         [0.9548],\n",
      "         [0.0235],\n",
      "         [0.8744],\n",
      "         [0.3495],\n",
      "         [0.1145],\n",
      "         [0.3509],\n",
      "         [0.7564],\n",
      "         [0.5735],\n",
      "         [0.3344],\n",
      "         [0.0543],\n",
      "         [0.9112],\n",
      "         [0.5758],\n",
      "         [0.8271],\n",
      "         [0.1844]]], device='cuda:0', dtype=torch.float64)\n",
      "================iter 4============\n",
      "['shape/ellipsoid/1/ellipsoid_512_128_64_64_2_3_1']\n",
      "tensor([[ True,  True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
      "          True,  True,  True,  True,  True,  True,  True, False, False, False]],\n",
      "       device='cuda:0')\n",
      "acc torch.Size([1]) tensor([0.0588], device='cuda:0')\n",
      "acc_per_part torch.Size([1, 20]) tensor([[False, False, False, False,  True, False, False, False, False, False,\n",
      "         False, False, False, False, False, False, False, False, False, False]],\n",
      "       device='cuda:0')\n",
      "loss_per_data torch.Size([1, 20]) tensor([[ 0.4891,  3.3192,  9.9931,  0.7770,  0.0000,  8.5703,  1.2890,  3.8170,\n",
      "          6.2953,  0.3606,  0.6183, 25.6222,  4.5179,  6.3565, 10.5620, 26.1074,\n",
      "          2.3197, 11.1521,  8.2171,  1.9009]], device='cuda:0')\n",
      "scores torch.Size([1, 190, 1]) tensor([[[0.1636],\n",
      "         [0.5751],\n",
      "         [0.5275],\n",
      "         [0.6924],\n",
      "         [0.1490],\n",
      "         [0.9711],\n",
      "         [0.8081],\n",
      "         [0.4749],\n",
      "         [0.5462],\n",
      "         [0.9263],\n",
      "         [0.5015],\n",
      "         [0.6196],\n",
      "         [0.1044],\n",
      "         [0.7685],\n",
      "         [0.7579],\n",
      "         [0.0455],\n",
      "         [0.0755],\n",
      "         [0.0164],\n",
      "         [0.7688],\n",
      "         [0.3785],\n",
      "         [0.0971],\n",
      "         [0.9046],\n",
      "         [0.6667],\n",
      "         [0.2092],\n",
      "         [0.8132],\n",
      "         [0.6201],\n",
      "         [0.0285],\n",
      "         [0.1113],\n",
      "         [0.5911],\n",
      "         [0.9159],\n",
      "         [0.4639],\n",
      "         [0.3527],\n",
      "         [0.4048],\n",
      "         [0.2509],\n",
      "         [0.0966],\n",
      "         [0.2840],\n",
      "         [0.3525],\n",
      "         [0.4991],\n",
      "         [0.1588],\n",
      "         [0.5363],\n",
      "         [0.8596],\n",
      "         [0.9750],\n",
      "         [0.8633],\n",
      "         [0.3487],\n",
      "         [0.0178],\n",
      "         [0.1977],\n",
      "         [0.2466],\n",
      "         [0.2997],\n",
      "         [0.4277],\n",
      "         [0.1111],\n",
      "         [0.1919],\n",
      "         [0.2467],\n",
      "         [0.6332],\n",
      "         [0.9798],\n",
      "         [0.3832],\n",
      "         [0.6261],\n",
      "         [0.9730],\n",
      "         [0.2159],\n",
      "         [0.6935],\n",
      "         [0.8972],\n",
      "         [0.9969],\n",
      "         [0.8556],\n",
      "         [0.3128],\n",
      "         [0.0984],\n",
      "         [0.8215],\n",
      "         [0.6151],\n",
      "         [0.1741],\n",
      "         [0.0630],\n",
      "         [0.3693],\n",
      "         [0.0827],\n",
      "         [0.6224],\n",
      "         [0.6812],\n",
      "         [0.6848],\n",
      "         [0.6004],\n",
      "         [0.0561],\n",
      "         [0.1044],\n",
      "         [0.3265],\n",
      "         [0.4553],\n",
      "         [0.1997],\n",
      "         [0.5933],\n",
      "         [0.5351],\n",
      "         [0.9058],\n",
      "         [0.7338],\n",
      "         [0.7414],\n",
      "         [0.2054],\n",
      "         [0.8119],\n",
      "         [0.8556],\n",
      "         [0.4323],\n",
      "         [0.0949],\n",
      "         [0.6504],\n",
      "         [0.0544],\n",
      "         [0.8243],\n",
      "         [0.9675],\n",
      "         [0.1755],\n",
      "         [0.4225],\n",
      "         [0.3466],\n",
      "         [0.7318],\n",
      "         [0.1907],\n",
      "         [0.7686],\n",
      "         [0.2733],\n",
      "         [0.2928],\n",
      "         [0.9867],\n",
      "         [0.0189],\n",
      "         [0.1560],\n",
      "         [0.8097],\n",
      "         [0.0464],\n",
      "         [0.3858],\n",
      "         [0.9094],\n",
      "         [0.1598],\n",
      "         [0.3920],\n",
      "         [0.7938],\n",
      "         [0.3299],\n",
      "         [0.4038],\n",
      "         [0.8310],\n",
      "         [0.9966],\n",
      "         [0.4006],\n",
      "         [0.8244],\n",
      "         [0.6747],\n",
      "         [0.5046],\n",
      "         [0.7638],\n",
      "         [0.3203],\n",
      "         [0.8923],\n",
      "         [0.6599],\n",
      "         [0.0727],\n",
      "         [0.2294],\n",
      "         [0.4430],\n",
      "         [0.7969],\n",
      "         [0.6518],\n",
      "         [0.0998],\n",
      "         [0.6338],\n",
      "         [0.7842],\n",
      "         [0.3228],\n",
      "         [0.5017],\n",
      "         [0.3473],\n",
      "         [0.3522],\n",
      "         [0.2597],\n",
      "         [0.1623],\n",
      "         [0.1353],\n",
      "         [0.9229],\n",
      "         [0.3988],\n",
      "         [0.6783],\n",
      "         [0.3393],\n",
      "         [0.9569],\n",
      "         [0.2665],\n",
      "         [0.3206],\n",
      "         [0.0869],\n",
      "         [0.6433],\n",
      "         [0.4778],\n",
      "         [0.3765],\n",
      "         [0.5042],\n",
      "         [0.6112],\n",
      "         [0.7723],\n",
      "         [0.9735],\n",
      "         [0.3813],\n",
      "         [0.8494],\n",
      "         [0.5202],\n",
      "         [0.4468],\n",
      "         [0.1990],\n",
      "         [0.8762],\n",
      "         [0.8941],\n",
      "         [0.3129],\n",
      "         [0.7610],\n",
      "         [0.0419],\n",
      "         [0.5037],\n",
      "         [0.5134],\n",
      "         [0.8927],\n",
      "         [0.9481],\n",
      "         [0.2192],\n",
      "         [0.6800],\n",
      "         [0.3086],\n",
      "         [0.2791],\n",
      "         [0.7667],\n",
      "         [0.0501],\n",
      "         [0.1461],\n",
      "         [0.6428],\n",
      "         [0.9027],\n",
      "         [0.0628],\n",
      "         [0.5819],\n",
      "         [0.9540],\n",
      "         [0.8405],\n",
      "         [0.6154],\n",
      "         [0.6092],\n",
      "         [0.5035],\n",
      "         [0.2021],\n",
      "         [0.9674],\n",
      "         [0.2047],\n",
      "         [0.1462],\n",
      "         [0.0228],\n",
      "         [0.5137],\n",
      "         [0.8686]]], device='cuda:0', dtype=torch.float64)\n",
      "================iter 5============\n",
      "['shape/ellipsoid/1/ellipsoid_512_128_64_64_2_3_1']\n",
      "tensor([[ True,  True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
      "          True,  True,  True,  True,  True,  True,  True, False, False, False]],\n",
      "       device='cuda:0')\n",
      "@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@\n",
      "['shape/ellipsoid/1/ellipsoid_512_128_64_64_3_0_1']\n",
      "gt_trans_torch.Size([1, 20, 3])_tensor([[[-2.7028e-01, -6.6022e-02, -2.1946e-01],\n",
      "         [-2.5282e-01, -4.9213e-02, -2.0096e-01],\n",
      "         [-5.3291e-18, -1.7764e-18,  2.4425e-18],\n",
      "         [ 3.7593e-02,  1.0187e-02,  1.7688e-02],\n",
      "         [ 5.5406e-02, -3.4503e-03,  5.2216e-02],\n",
      "         [ 7.9399e-02, -9.7345e-03,  8.1238e-02],\n",
      "         [ 9.8274e-02,  1.3704e-02,  9.6581e-02],\n",
      "         [ 1.2673e-01,  1.0713e-02,  1.2280e-01],\n",
      "         [ 1.6253e-01,  1.5851e-02,  1.4421e-01],\n",
      "         [-2.2126e-01, -5.9120e-02, -1.7140e-01],\n",
      "         [-1.8244e-01, -5.9542e-02, -1.4868e-01],\n",
      "         [-1.6622e-01, -5.9547e-02, -1.2130e-01],\n",
      "         [-1.3063e-01, -4.3361e-02, -1.0568e-01],\n",
      "         [-1.0847e-01, -3.1204e-02, -8.5172e-02],\n",
      "         [-8.2638e-02, -3.0538e-02, -6.0438e-02],\n",
      "         [-5.5742e-02, -3.0516e-02, -3.5204e-02],\n",
      "         [-2.2647e-02, -2.3753e-02, -1.4541e-02],\n",
      "         [ 0.0000e+00,  0.0000e+00,  0.0000e+00],\n",
      "         [ 0.0000e+00,  0.0000e+00,  0.0000e+00],\n",
      "         [ 0.0000e+00,  0.0000e+00,  0.0000e+00]]], device='cuda:0')\n",
      "gt_rots_torch.Size([1, 20, 4])_tensor([[[ 0.2413,  0.6771,  0.5210, -0.4602],\n",
      "         [-0.4648, -0.5483, -0.2423,  0.6517],\n",
      "         [ 0.0610, -0.2983,  0.2492,  0.9194],\n",
      "         [ 0.5452,  0.5971, -0.5882, -0.0185],\n",
      "         [ 0.8217,  0.0955,  0.3120,  0.4672],\n",
      "         [ 0.0011, -0.5098,  0.7919, -0.3362],\n",
      "         [-0.2641, -0.2604, -0.5970,  0.7114],\n",
      "         [ 0.1283,  0.3354,  0.0122,  0.9332],\n",
      "         [-0.5270,  0.6021,  0.4052, -0.4423],\n",
      "         [-0.0846,  0.8532, -0.3382,  0.3880],\n",
      "         [ 0.3998,  0.5950, -0.4270, -0.5512],\n",
      "         [ 0.1871,  0.8748,  0.2109, -0.3941],\n",
      "         [ 0.1791,  0.3761,  0.5055,  0.7556],\n",
      "         [ 0.0539,  0.2023,  0.9634,  0.1674],\n",
      "         [-0.0483,  0.2208,  0.8035, -0.5506],\n",
      "         [-0.2524,  0.8082, -0.3736, -0.3790],\n",
      "         [ 0.3014,  0.8832, -0.0486, -0.3559],\n",
      "         [ 0.0000,  0.0000,  0.0000,  0.0000],\n",
      "         [ 0.0000,  0.0000,  0.0000,  0.0000],\n",
      "         [ 0.0000,  0.0000,  0.0000,  0.0000]]], device='cuda:0')\n",
      "noisy_trans_and_rots_torch.Size([1, 20, 7])_tensor([[[ 0.5585,  0.0000,  0.4161, -1.1609,  0.0000,  0.0000, -1.2738],\n",
      "         [ 0.4938,  0.0000,  0.8181, -1.0718,  0.0000,  0.0000,  1.1247],\n",
      "         [ 0.2755,  0.0000,  0.6515, -0.5232,  0.0000,  0.0000,  0.7164],\n",
      "         [-2.0573,  0.0000,  0.7801, -0.6401,  0.0000,  0.0000,  1.4375],\n",
      "         [-0.9588,  0.0000, -1.2024, -0.7908,  0.0000,  0.0000,  2.3551],\n",
      "         [ 0.8032,  0.0000, -0.0252, -1.0401,  0.0000,  0.0000, -0.1121],\n",
      "         [ 1.0116,  0.0000, -0.1518, -0.2422,  0.0000,  0.0000,  1.1502],\n",
      "         [ 0.6259,  0.0000,  0.9101, -0.1177,  0.0000,  0.0000, -0.1529],\n",
      "         [ 1.2789,  0.0000, -0.9372,  0.2434,  0.0000,  0.0000,  0.9722],\n",
      "         [-0.6787,  0.0000, -0.4973,  0.2205,  0.0000,  0.0000, -1.2503],\n",
      "         [ 1.3788,  0.0000, -0.1301,  0.4779,  0.0000,  0.0000, -1.0063],\n",
      "         [-1.3289,  0.0000, -0.1947,  0.6388,  0.0000,  0.0000,  0.2907],\n",
      "         [ 0.8760,  0.0000,  0.5163, -0.1004,  0.0000,  0.0000,  0.1055],\n",
      "         [ 1.3702,  0.0000,  0.1519,  0.0406,  0.0000,  0.0000, -1.3692],\n",
      "         [-2.0850,  0.0000,  0.5757,  0.7719,  0.0000,  0.0000,  0.2647],\n",
      "         [ 0.9646,  0.0000, -0.7428,  0.5192,  0.0000,  0.0000, -0.3910],\n",
      "         [-0.7209,  0.0000,  1.6735, -0.4659,  0.0000,  0.0000,  0.0690],\n",
      "         [-1.2130,  0.0000, -0.6201, -0.6997,  0.0000,  0.0000, -0.2387],\n",
      "         [ 2.0253,  0.0000, -0.4557, -1.2550,  0.0000,  0.0000,  0.6066],\n",
      "         [-1.6800,  0.0000, -0.2623, -0.1345,  0.0000,  0.0000, -0.6019]]],\n",
      "       device='cuda:0')\n",
      "================iter 0============\n",
      "['shape/ellipsoid/1/ellipsoid_512_128_64_64_3_0_1']\n",
      "tensor([[False, False,  True, False, False, False, False, False, False, False,\n",
      "         False, False, False, False, False, False, False, False, False, False]],\n",
      "       device='cuda:0')\n",
      "acc torch.Size([1]) tensor([0.0588], device='cuda:0')\n",
      "acc_per_part torch.Size([1, 20]) tensor([[False, False,  True, False, False, False, False, False, False, False,\n",
      "         False, False, False, False, False, False, False, False, False, False]],\n",
      "       device='cuda:0')\n",
      "loss_per_data torch.Size([1, 20]) tensor([[ 2.8741,  3.2094,  0.0000,  0.8310,  8.5930,  0.2756,  1.1276,  2.4742,\n",
      "          1.5898,  1.0055,  1.2474,  1.0859,  9.9125,  9.4749,  2.2533,  1.6713,\n",
      "          1.9696,  1.8435, 12.2809,  0.3638]], device='cuda:0')\n",
      "scores torch.Size([1, 190, 1]) tensor([[[0.8475],\n",
      "         [0.9703],\n",
      "         [0.1676],\n",
      "         [0.4099],\n",
      "         [0.7410],\n",
      "         [0.6743],\n",
      "         [0.4143],\n",
      "         [0.5912],\n",
      "         [0.0523],\n",
      "         [0.1913],\n",
      "         [0.7322],\n",
      "         [0.0742],\n",
      "         [0.9472],\n",
      "         [0.6596],\n",
      "         [0.2325],\n",
      "         [0.3946],\n",
      "         [0.0700],\n",
      "         [0.9356],\n",
      "         [0.6656],\n",
      "         [0.2401],\n",
      "         [0.4378],\n",
      "         [0.8671],\n",
      "         [0.1848],\n",
      "         [0.1141],\n",
      "         [0.1752],\n",
      "         [0.0859],\n",
      "         [0.7852],\n",
      "         [0.0310],\n",
      "         [0.2731],\n",
      "         [0.6144],\n",
      "         [0.1374],\n",
      "         [0.5925],\n",
      "         [0.4054],\n",
      "         [0.1808],\n",
      "         [0.6192],\n",
      "         [0.5507],\n",
      "         [0.5144],\n",
      "         [0.8300],\n",
      "         [0.2471],\n",
      "         [0.8396],\n",
      "         [0.9251],\n",
      "         [0.6985],\n",
      "         [0.7682],\n",
      "         [0.8510],\n",
      "         [0.0212],\n",
      "         [0.4957],\n",
      "         [0.6005],\n",
      "         [0.8655],\n",
      "         [0.8398],\n",
      "         [0.3992],\n",
      "         [0.6473],\n",
      "         [0.8626],\n",
      "         [0.6738],\n",
      "         [0.4392],\n",
      "         [0.8440],\n",
      "         [0.0127],\n",
      "         [0.3242],\n",
      "         [0.8751],\n",
      "         [0.6728],\n",
      "         [0.1402],\n",
      "         [0.1935],\n",
      "         [0.2004],\n",
      "         [0.1510],\n",
      "         [0.9766],\n",
      "         [0.9738],\n",
      "         [0.1431],\n",
      "         [0.2796],\n",
      "         [0.1493],\n",
      "         [0.3118],\n",
      "         [0.4229],\n",
      "         [0.7965],\n",
      "         [0.0408],\n",
      "         [0.0268],\n",
      "         [0.1407],\n",
      "         [0.5396],\n",
      "         [0.2152],\n",
      "         [0.9259],\n",
      "         [0.4392],\n",
      "         [0.7167],\n",
      "         [0.0177],\n",
      "         [0.3371],\n",
      "         [0.2237],\n",
      "         [0.6219],\n",
      "         [0.4618],\n",
      "         [0.0146],\n",
      "         [0.5557],\n",
      "         [0.9464],\n",
      "         [0.9837],\n",
      "         [0.5443],\n",
      "         [0.0127],\n",
      "         [0.6051],\n",
      "         [0.3219],\n",
      "         [0.5120],\n",
      "         [0.0376],\n",
      "         [0.1484],\n",
      "         [0.7872],\n",
      "         [0.7232],\n",
      "         [0.9166],\n",
      "         [0.8121],\n",
      "         [0.3471],\n",
      "         [0.7423],\n",
      "         [0.5944],\n",
      "         [0.2744],\n",
      "         [0.0601],\n",
      "         [0.5988],\n",
      "         [0.3255],\n",
      "         [0.5794],\n",
      "         [0.1282],\n",
      "         [0.1417],\n",
      "         [0.4015],\n",
      "         [0.9726],\n",
      "         [0.3137],\n",
      "         [0.2339],\n",
      "         [0.6823],\n",
      "         [0.5667],\n",
      "         [0.6449],\n",
      "         [0.2868],\n",
      "         [0.7869],\n",
      "         [0.9311],\n",
      "         [0.9308],\n",
      "         [0.7188],\n",
      "         [0.5166],\n",
      "         [0.2703],\n",
      "         [0.7107],\n",
      "         [0.7875],\n",
      "         [0.6783],\n",
      "         [0.1949],\n",
      "         [0.3663],\n",
      "         [0.5836],\n",
      "         [0.7191],\n",
      "         [0.9645],\n",
      "         [0.6839],\n",
      "         [0.2393],\n",
      "         [0.8435],\n",
      "         [0.3714],\n",
      "         [0.1808],\n",
      "         [0.5304],\n",
      "         [0.2707],\n",
      "         [0.8483],\n",
      "         [0.3142],\n",
      "         [0.9977],\n",
      "         [0.2774],\n",
      "         [0.8473],\n",
      "         [0.5806],\n",
      "         [0.2625],\n",
      "         [0.9094],\n",
      "         [0.7572],\n",
      "         [0.8874],\n",
      "         [0.7856],\n",
      "         [0.2492],\n",
      "         [0.6154],\n",
      "         [0.5001],\n",
      "         [0.6086],\n",
      "         [0.5328],\n",
      "         [0.4238],\n",
      "         [0.1713],\n",
      "         [0.4136],\n",
      "         [0.2343],\n",
      "         [0.5938],\n",
      "         [0.2661],\n",
      "         [0.5933],\n",
      "         [0.8912],\n",
      "         [0.7362],\n",
      "         [0.2101],\n",
      "         [0.3023],\n",
      "         [0.6210],\n",
      "         [0.9107],\n",
      "         [0.6217],\n",
      "         [0.6393],\n",
      "         [0.1201],\n",
      "         [0.7745],\n",
      "         [0.6628],\n",
      "         [0.8597],\n",
      "         [0.5045],\n",
      "         [0.7972],\n",
      "         [0.4749],\n",
      "         [0.5552],\n",
      "         [0.5492],\n",
      "         [0.8067],\n",
      "         [0.0662],\n",
      "         [0.6334],\n",
      "         [0.8232],\n",
      "         [0.9387],\n",
      "         [0.9517],\n",
      "         [0.7831],\n",
      "         [0.5291],\n",
      "         [0.9341],\n",
      "         [0.5709],\n",
      "         [0.2437],\n",
      "         [0.5085]]], device='cuda:0', dtype=torch.float64)\n",
      "================iter 1============\n",
      "['shape/ellipsoid/1/ellipsoid_512_128_64_64_3_0_1']\n",
      "tensor([[ True, False,  True, False, False, False,  True, False, False, False,\n",
      "         False, False, False, False, False, False, False, False, False, False]],\n",
      "       device='cuda:0')\n",
      "acc torch.Size([1]) tensor([0.0588], device='cuda:0')\n",
      "acc_per_part torch.Size([1, 20]) tensor([[False, False,  True, False, False, False, False, False, False, False,\n",
      "         False, False, False, False, False, False, False, False, False, False]],\n",
      "       device='cuda:0')\n",
      "loss_per_data torch.Size([1, 20]) tensor([[ 2.8741,  7.6164,  0.0000,  0.2374, 71.9260,  1.2995,  1.1276,  0.8060,\n",
      "          0.4750,  6.5464,  6.1943,  8.5612,  3.7000,  0.9580,  4.9787,  0.9621,\n",
      "          4.6039, 24.2606,  3.8082,  4.2210]], device='cuda:0')\n",
      "scores torch.Size([1, 190, 1]) tensor([[[0.3434],\n",
      "         [0.9283],\n",
      "         [0.7113],\n",
      "         [0.1791],\n",
      "         [0.3739],\n",
      "         [0.3609],\n",
      "         [0.9491],\n",
      "         [0.9073],\n",
      "         [0.2338],\n",
      "         [0.1879],\n",
      "         [0.7382],\n",
      "         [0.5897],\n",
      "         [0.6731],\n",
      "         [0.0781],\n",
      "         [0.5418],\n",
      "         [0.7349],\n",
      "         [0.6693],\n",
      "         [0.7551],\n",
      "         [0.0404],\n",
      "         [0.7610],\n",
      "         [0.9483],\n",
      "         [0.9384],\n",
      "         [0.9916],\n",
      "         [0.1617],\n",
      "         [0.8038],\n",
      "         [0.7313],\n",
      "         [0.9978],\n",
      "         [0.5677],\n",
      "         [0.0480],\n",
      "         [0.0117],\n",
      "         [0.7943],\n",
      "         [0.4401],\n",
      "         [0.3773],\n",
      "         [0.4823],\n",
      "         [0.1520],\n",
      "         [0.5029],\n",
      "         [0.7581],\n",
      "         [0.0386],\n",
      "         [0.2531],\n",
      "         [0.0751],\n",
      "         [0.7825],\n",
      "         [0.4422],\n",
      "         [0.3384],\n",
      "         [0.7793],\n",
      "         [0.3067],\n",
      "         [0.8110],\n",
      "         [0.6073],\n",
      "         [0.8554],\n",
      "         [0.7518],\n",
      "         [0.0696],\n",
      "         [0.0668],\n",
      "         [0.1977],\n",
      "         [0.2500],\n",
      "         [0.1603],\n",
      "         [0.4791],\n",
      "         [0.8488],\n",
      "         [0.0872],\n",
      "         [0.7049],\n",
      "         [0.4876],\n",
      "         [0.0315],\n",
      "         [0.8719],\n",
      "         [0.7607],\n",
      "         [0.4668],\n",
      "         [0.2734],\n",
      "         [0.6322],\n",
      "         [0.2503],\n",
      "         [0.1528],\n",
      "         [0.5786],\n",
      "         [0.8332],\n",
      "         [0.9580],\n",
      "         [0.3310],\n",
      "         [0.2591],\n",
      "         [0.5935],\n",
      "         [0.5628],\n",
      "         [0.0709],\n",
      "         [0.4317],\n",
      "         [0.9038],\n",
      "         [0.6402],\n",
      "         [0.3971],\n",
      "         [0.1244],\n",
      "         [0.2726],\n",
      "         [0.9029],\n",
      "         [0.2445],\n",
      "         [0.5411],\n",
      "         [0.9810],\n",
      "         [0.0296],\n",
      "         [0.3961],\n",
      "         [0.3882],\n",
      "         [0.7564],\n",
      "         [0.4036],\n",
      "         [0.6357],\n",
      "         [0.2608],\n",
      "         [0.3418],\n",
      "         [0.0377],\n",
      "         [0.1780],\n",
      "         [0.4322],\n",
      "         [0.9117],\n",
      "         [0.1833],\n",
      "         [0.4495],\n",
      "         [0.6488],\n",
      "         [0.5685],\n",
      "         [0.9123],\n",
      "         [0.4911],\n",
      "         [0.2116],\n",
      "         [0.9620],\n",
      "         [0.4216],\n",
      "         [0.1454],\n",
      "         [0.7331],\n",
      "         [0.9638],\n",
      "         [0.5546],\n",
      "         [0.4188],\n",
      "         [0.1030],\n",
      "         [0.9217],\n",
      "         [0.9980],\n",
      "         [0.4153],\n",
      "         [0.1303],\n",
      "         [0.6125],\n",
      "         [0.6747],\n",
      "         [0.3348],\n",
      "         [0.5736],\n",
      "         [0.5622],\n",
      "         [0.1894],\n",
      "         [0.3802],\n",
      "         [0.7955],\n",
      "         [0.7947],\n",
      "         [0.1380],\n",
      "         [0.2494],\n",
      "         [0.3128],\n",
      "         [0.3995],\n",
      "         [0.2184],\n",
      "         [0.9077],\n",
      "         [0.9493],\n",
      "         [0.0324],\n",
      "         [0.7449],\n",
      "         [0.7682],\n",
      "         [0.2996],\n",
      "         [0.4910],\n",
      "         [0.1138],\n",
      "         [0.8715],\n",
      "         [0.6798],\n",
      "         [0.8758],\n",
      "         [0.5046],\n",
      "         [0.7667],\n",
      "         [0.7144],\n",
      "         [0.0506],\n",
      "         [0.7293],\n",
      "         [0.3911],\n",
      "         [0.5392],\n",
      "         [0.7343],\n",
      "         [0.8826],\n",
      "         [0.5643],\n",
      "         [0.1991],\n",
      "         [0.0906],\n",
      "         [0.0709],\n",
      "         [0.9324],\n",
      "         [0.4190],\n",
      "         [0.2693],\n",
      "         [0.1838],\n",
      "         [0.7408],\n",
      "         [0.4453],\n",
      "         [0.3874],\n",
      "         [0.4273],\n",
      "         [0.0223],\n",
      "         [0.5730],\n",
      "         [0.5408],\n",
      "         [0.3066],\n",
      "         [0.7271],\n",
      "         [0.2943],\n",
      "         [0.5681],\n",
      "         [0.1250],\n",
      "         [0.2790],\n",
      "         [0.7628],\n",
      "         [0.6275],\n",
      "         [0.8203],\n",
      "         [0.0299],\n",
      "         [0.8522],\n",
      "         [0.0705],\n",
      "         [0.1369],\n",
      "         [0.0984],\n",
      "         [0.2489],\n",
      "         [0.7924],\n",
      "         [0.5148],\n",
      "         [0.5879],\n",
      "         [0.0680],\n",
      "         [0.9495],\n",
      "         [0.4611],\n",
      "         [0.3161],\n",
      "         [0.1764],\n",
      "         [0.8455],\n",
      "         [0.9432]]], device='cuda:0', dtype=torch.float64)\n",
      "================iter 2============\n",
      "['shape/ellipsoid/1/ellipsoid_512_128_64_64_3_0_1']\n",
      "tensor([[ True, False,  True, False, False, False,  True,  True,  True,  True,\n",
      "         False, False,  True, False, False, False,  True, False, False, False]],\n",
      "       device='cuda:0')\n",
      "acc torch.Size([1]) tensor([0.0588], device='cuda:0')\n",
      "acc_per_part torch.Size([1, 20]) tensor([[False, False,  True, False, False, False, False, False, False, False,\n",
      "         False, False, False, False, False, False, False, False, False, False]],\n",
      "       device='cuda:0')\n",
      "loss_per_data torch.Size([1, 20]) tensor([[  2.8741,   6.6727,   0.0000,  10.4913, 107.3339,   3.5349,   1.1276,\n",
      "           0.8060,   0.4750,   6.5464,   4.8602,   9.5780,   3.7000,   0.2970,\n",
      "         210.4131,   8.2373,   4.6039,  44.4166,  19.2547,  12.9616]],\n",
      "       device='cuda:0')\n",
      "scores torch.Size([1, 190, 1]) tensor([[[0.5842],\n",
      "         [0.5997],\n",
      "         [0.3638],\n",
      "         [0.0591],\n",
      "         [0.0796],\n",
      "         [0.3508],\n",
      "         [0.3574],\n",
      "         [0.3608],\n",
      "         [0.7950],\n",
      "         [0.2626],\n",
      "         [0.6269],\n",
      "         [0.2706],\n",
      "         [0.7623],\n",
      "         [0.3664],\n",
      "         [0.3005],\n",
      "         [0.1740],\n",
      "         [0.2438],\n",
      "         [0.8522],\n",
      "         [0.9205],\n",
      "         [0.9692],\n",
      "         [0.1604],\n",
      "         [0.5297],\n",
      "         [0.0445],\n",
      "         [0.6123],\n",
      "         [0.2841],\n",
      "         [0.4428],\n",
      "         [0.9504],\n",
      "         [0.5605],\n",
      "         [0.2921],\n",
      "         [0.1634],\n",
      "         [0.4258],\n",
      "         [0.1173],\n",
      "         [0.8392],\n",
      "         [0.1144],\n",
      "         [0.1621],\n",
      "         [0.9250],\n",
      "         [0.0655],\n",
      "         [0.3369],\n",
      "         [0.4944],\n",
      "         [0.9610],\n",
      "         [0.4759],\n",
      "         [0.9744],\n",
      "         [0.3717],\n",
      "         [0.1011],\n",
      "         [0.3653],\n",
      "         [0.4508],\n",
      "         [0.4006],\n",
      "         [0.8347],\n",
      "         [0.2040],\n",
      "         [0.0971],\n",
      "         [0.4704],\n",
      "         [0.3455],\n",
      "         [0.6275],\n",
      "         [0.6226],\n",
      "         [0.8053],\n",
      "         [0.4684],\n",
      "         [0.4937],\n",
      "         [0.2152],\n",
      "         [0.0900],\n",
      "         [0.2861],\n",
      "         [0.3665],\n",
      "         [0.8747],\n",
      "         [0.8129],\n",
      "         [0.6282],\n",
      "         [0.0125],\n",
      "         [0.9264],\n",
      "         [0.4107],\n",
      "         [0.3410],\n",
      "         [0.4683],\n",
      "         [0.0658],\n",
      "         [0.6548],\n",
      "         [0.1505],\n",
      "         [0.7104],\n",
      "         [0.8978],\n",
      "         [0.0481],\n",
      "         [0.4394],\n",
      "         [0.8860],\n",
      "         [0.4407],\n",
      "         [0.5942],\n",
      "         [0.2971],\n",
      "         [0.8469],\n",
      "         [0.2776],\n",
      "         [0.9018],\n",
      "         [0.1143],\n",
      "         [0.8656],\n",
      "         [0.7725],\n",
      "         [0.9533],\n",
      "         [0.7737],\n",
      "         [0.9041],\n",
      "         [0.2924],\n",
      "         [0.1659],\n",
      "         [0.4724],\n",
      "         [0.3402],\n",
      "         [0.0518],\n",
      "         [0.2516],\n",
      "         [0.5719],\n",
      "         [0.6696],\n",
      "         [0.8749],\n",
      "         [0.2569],\n",
      "         [0.3797],\n",
      "         [0.3157],\n",
      "         [0.1509],\n",
      "         [0.1241],\n",
      "         [0.7730],\n",
      "         [0.4660],\n",
      "         [0.0568],\n",
      "         [0.3310],\n",
      "         [0.7821],\n",
      "         [0.0153],\n",
      "         [0.9073],\n",
      "         [0.4746],\n",
      "         [0.3547],\n",
      "         [0.3075],\n",
      "         [0.9504],\n",
      "         [0.7735],\n",
      "         [0.8120],\n",
      "         [0.3461],\n",
      "         [0.8849],\n",
      "         [0.9335],\n",
      "         [0.0282],\n",
      "         [0.6296],\n",
      "         [0.5479],\n",
      "         [0.5224],\n",
      "         [0.4571],\n",
      "         [0.4627],\n",
      "         [0.1699],\n",
      "         [0.2964],\n",
      "         [0.0383],\n",
      "         [0.9160],\n",
      "         [0.4782],\n",
      "         [0.3893],\n",
      "         [0.2047],\n",
      "         [0.2192],\n",
      "         [0.7124],\n",
      "         [0.6699],\n",
      "         [0.2745],\n",
      "         [0.8268],\n",
      "         [0.3871],\n",
      "         [0.5692],\n",
      "         [0.1634],\n",
      "         [0.7834],\n",
      "         [0.5786],\n",
      "         [0.2155],\n",
      "         [0.0682],\n",
      "         [0.0071],\n",
      "         [0.1261],\n",
      "         [0.7749],\n",
      "         [0.3149],\n",
      "         [0.3947],\n",
      "         [0.6312],\n",
      "         [0.6149],\n",
      "         [0.5388],\n",
      "         [0.1454],\n",
      "         [0.7845],\n",
      "         [0.6828],\n",
      "         [0.6258],\n",
      "         [0.4326],\n",
      "         [0.3909],\n",
      "         [0.1991],\n",
      "         [0.0817],\n",
      "         [0.8027],\n",
      "         [0.2584],\n",
      "         [0.3428],\n",
      "         [0.8990],\n",
      "         [0.0378],\n",
      "         [0.3522],\n",
      "         [0.2712],\n",
      "         [0.8627],\n",
      "         [0.7788],\n",
      "         [0.8133],\n",
      "         [0.8775],\n",
      "         [0.5748],\n",
      "         [0.4585],\n",
      "         [0.3220],\n",
      "         [0.4487],\n",
      "         [0.3931],\n",
      "         [0.5829],\n",
      "         [0.7071],\n",
      "         [0.3450],\n",
      "         [0.2383],\n",
      "         [0.7602],\n",
      "         [0.2983],\n",
      "         [0.3088],\n",
      "         [0.5999],\n",
      "         [0.6577],\n",
      "         [0.2600],\n",
      "         [0.3943],\n",
      "         [0.8430],\n",
      "         [0.4776],\n",
      "         [0.1103]]], device='cuda:0', dtype=torch.float64)\n",
      "================iter 3============\n",
      "['shape/ellipsoid/1/ellipsoid_512_128_64_64_3_0_1']\n",
      "tensor([[ True,  True,  True, False, False,  True,  True,  True,  True,  True,\n",
      "         False, False,  True,  True,  True, False,  True, False, False, False]],\n",
      "       device='cuda:0')\n",
      "acc torch.Size([1]) tensor([0.0588], device='cuda:0')\n",
      "acc_per_part torch.Size([1, 20]) tensor([[False, False,  True, False, False, False, False, False, False, False,\n",
      "         False, False, False, False, False, False, False, False, False, False]],\n",
      "       device='cuda:0')\n",
      "loss_per_data torch.Size([1, 20]) tensor([[  2.8741,   6.6727,   0.0000,  22.6513, 191.5784,   3.5349,   1.1276,\n",
      "           0.8060,   0.4750,   6.5464,  39.3248,   4.7989,   3.7000,   0.2970,\n",
      "         210.4131, 102.6730,   4.6039,  77.2522,  30.9849,  10.5436]],\n",
      "       device='cuda:0')\n",
      "scores torch.Size([1, 190, 1]) tensor([[[0.1089],\n",
      "         [0.5392],\n",
      "         [0.4169],\n",
      "         [0.8608],\n",
      "         [0.8726],\n",
      "         [0.3514],\n",
      "         [0.2694],\n",
      "         [0.4470],\n",
      "         [0.3162],\n",
      "         [0.5303],\n",
      "         [0.6398],\n",
      "         [0.3817],\n",
      "         [0.7230],\n",
      "         [0.8532],\n",
      "         [0.7144],\n",
      "         [0.6819],\n",
      "         [0.7752],\n",
      "         [0.3680],\n",
      "         [0.8690],\n",
      "         [0.2341],\n",
      "         [0.6013],\n",
      "         [0.0921],\n",
      "         [0.4251],\n",
      "         [0.4644],\n",
      "         [0.7889],\n",
      "         [0.0970],\n",
      "         [0.1243],\n",
      "         [0.3470],\n",
      "         [0.7965],\n",
      "         [0.1512],\n",
      "         [0.0948],\n",
      "         [0.0340],\n",
      "         [0.9391],\n",
      "         [0.7082],\n",
      "         [0.4052],\n",
      "         [0.9700],\n",
      "         [0.0526],\n",
      "         [0.0166],\n",
      "         [0.2136],\n",
      "         [0.7728],\n",
      "         [0.0587],\n",
      "         [0.5572],\n",
      "         [0.8929],\n",
      "         [0.5881],\n",
      "         [0.4631],\n",
      "         [0.5862],\n",
      "         [0.5128],\n",
      "         [0.0996],\n",
      "         [0.4448],\n",
      "         [0.3086],\n",
      "         [0.7811],\n",
      "         [0.0371],\n",
      "         [0.7311],\n",
      "         [0.9549],\n",
      "         [0.8671],\n",
      "         [0.6374],\n",
      "         [0.0897],\n",
      "         [0.1561],\n",
      "         [0.7071],\n",
      "         [0.9513],\n",
      "         [0.4101],\n",
      "         [0.3307],\n",
      "         [0.9669],\n",
      "         [0.9938],\n",
      "         [0.1831],\n",
      "         [0.1403],\n",
      "         [0.9700],\n",
      "         [0.9814],\n",
      "         [0.2759],\n",
      "         [0.0913],\n",
      "         [0.0990],\n",
      "         [0.1642],\n",
      "         [0.6433],\n",
      "         [0.8742],\n",
      "         [0.7291],\n",
      "         [0.6534],\n",
      "         [0.0764],\n",
      "         [0.9718],\n",
      "         [0.7658],\n",
      "         [0.8560],\n",
      "         [0.3707],\n",
      "         [0.2256],\n",
      "         [0.3094],\n",
      "         [0.5439],\n",
      "         [0.4522],\n",
      "         [0.4295],\n",
      "         [0.7981],\n",
      "         [0.7084],\n",
      "         [0.1441],\n",
      "         [0.1306],\n",
      "         [0.8015],\n",
      "         [0.9406],\n",
      "         [0.9165],\n",
      "         [0.1626],\n",
      "         [0.9217],\n",
      "         [0.7293],\n",
      "         [0.6432],\n",
      "         [0.1994],\n",
      "         [0.4799],\n",
      "         [0.5127],\n",
      "         [0.6793],\n",
      "         [0.6449],\n",
      "         [0.4224],\n",
      "         [0.0556],\n",
      "         [0.5299],\n",
      "         [0.3367],\n",
      "         [0.4610],\n",
      "         [0.5182],\n",
      "         [0.0734],\n",
      "         [0.4506],\n",
      "         [0.3302],\n",
      "         [0.7300],\n",
      "         [0.1694],\n",
      "         [0.3019],\n",
      "         [0.9432],\n",
      "         [0.6315],\n",
      "         [0.6978],\n",
      "         [0.3400],\n",
      "         [0.9420],\n",
      "         [0.4733],\n",
      "         [0.0216],\n",
      "         [0.7658],\n",
      "         [0.1658],\n",
      "         [0.7585],\n",
      "         [0.4795],\n",
      "         [0.2361],\n",
      "         [0.2114],\n",
      "         [0.4169],\n",
      "         [0.4756],\n",
      "         [0.1131],\n",
      "         [0.2357],\n",
      "         [0.7572],\n",
      "         [0.9335],\n",
      "         [0.2285],\n",
      "         [0.1568],\n",
      "         [0.8108],\n",
      "         [0.3016],\n",
      "         [0.2763],\n",
      "         [0.5786],\n",
      "         [0.9213],\n",
      "         [0.8501],\n",
      "         [0.9145],\n",
      "         [0.8718],\n",
      "         [0.2674],\n",
      "         [0.5705],\n",
      "         [0.4945],\n",
      "         [0.1817],\n",
      "         [0.2394],\n",
      "         [0.7188],\n",
      "         [0.5706],\n",
      "         [0.2403],\n",
      "         [0.3292],\n",
      "         [0.1127],\n",
      "         [0.5406],\n",
      "         [0.3810],\n",
      "         [0.8752],\n",
      "         [0.0790],\n",
      "         [0.3522],\n",
      "         [0.2011],\n",
      "         [0.1338],\n",
      "         [0.1552],\n",
      "         [0.6535],\n",
      "         [0.0201],\n",
      "         [0.9988],\n",
      "         [0.7010],\n",
      "         [0.8488],\n",
      "         [0.9843],\n",
      "         [0.3951],\n",
      "         [0.7813],\n",
      "         [0.8687],\n",
      "         [0.4652],\n",
      "         [0.6908],\n",
      "         [0.4161],\n",
      "         [0.3411],\n",
      "         [0.7847],\n",
      "         [0.2349],\n",
      "         [0.5657],\n",
      "         [0.7538],\n",
      "         [0.9707],\n",
      "         [0.4766],\n",
      "         [0.1435],\n",
      "         [0.1274],\n",
      "         [0.1031],\n",
      "         [0.2280],\n",
      "         [0.9411],\n",
      "         [0.5659],\n",
      "         [0.2031],\n",
      "         [0.7243],\n",
      "         [0.2109],\n",
      "         [0.1647]]], device='cuda:0', dtype=torch.float64)\n",
      "================iter 4============\n",
      "['shape/ellipsoid/1/ellipsoid_512_128_64_64_3_0_1']\n",
      "tensor([[ True,  True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
      "          True, False,  True,  True,  True,  True,  True, False, False, False]],\n",
      "       device='cuda:0')\n",
      "acc torch.Size([1]) tensor([0.0588], device='cuda:0')\n",
      "acc_per_part torch.Size([1, 20]) tensor([[False, False,  True, False, False, False, False, False, False, False,\n",
      "         False, False, False, False, False, False, False, False, False, False]],\n",
      "       device='cuda:0')\n",
      "loss_per_data torch.Size([1, 20]) tensor([[  2.8741,   6.6727,   0.0000,  22.6513, 191.5784,   3.5349,   1.1276,\n",
      "           0.8060,   0.4750,   6.5464,  39.3248,   8.3334,   3.7000,   0.2970,\n",
      "         210.4131, 102.6730,   4.6039, 187.2440,  93.5733,   6.7265]],\n",
      "       device='cuda:0')\n",
      "scores torch.Size([1, 190, 1]) tensor([[[0.5671],\n",
      "         [0.7123],\n",
      "         [0.9627],\n",
      "         [0.2448],\n",
      "         [0.4337],\n",
      "         [0.0213],\n",
      "         [0.0876],\n",
      "         [0.9640],\n",
      "         [0.0539],\n",
      "         [0.6606],\n",
      "         [0.9657],\n",
      "         [0.3158],\n",
      "         [0.4959],\n",
      "         [0.8548],\n",
      "         [0.1674],\n",
      "         [0.4268],\n",
      "         [0.9182],\n",
      "         [0.0500],\n",
      "         [0.1541],\n",
      "         [0.1036],\n",
      "         [0.4651],\n",
      "         [0.5677],\n",
      "         [0.6232],\n",
      "         [0.9210],\n",
      "         [0.2838],\n",
      "         [0.5886],\n",
      "         [0.6140],\n",
      "         [0.7025],\n",
      "         [0.9756],\n",
      "         [0.4286],\n",
      "         [0.6835],\n",
      "         [0.8233],\n",
      "         [0.5207],\n",
      "         [0.3226],\n",
      "         [0.9324],\n",
      "         [0.2791],\n",
      "         [0.7086],\n",
      "         [0.3866],\n",
      "         [0.3385],\n",
      "         [0.9758],\n",
      "         [0.7211],\n",
      "         [0.3098],\n",
      "         [0.4435],\n",
      "         [0.0472],\n",
      "         [0.8356],\n",
      "         [0.9582],\n",
      "         [0.2331],\n",
      "         [0.1946],\n",
      "         [0.4388],\n",
      "         [0.1208],\n",
      "         [0.1498],\n",
      "         [0.4506],\n",
      "         [0.1477],\n",
      "         [0.4534],\n",
      "         [0.0342],\n",
      "         [0.8556],\n",
      "         [0.7875],\n",
      "         [0.2149],\n",
      "         [0.3191],\n",
      "         [0.3168],\n",
      "         [0.5043],\n",
      "         [0.8945],\n",
      "         [0.2452],\n",
      "         [0.1992],\n",
      "         [0.4106],\n",
      "         [0.4808],\n",
      "         [0.5486],\n",
      "         [0.7553],\n",
      "         [0.2504],\n",
      "         [0.6022],\n",
      "         [0.2490],\n",
      "         [0.0638],\n",
      "         [0.4813],\n",
      "         [0.1564],\n",
      "         [0.4345],\n",
      "         [0.1017],\n",
      "         [0.8292],\n",
      "         [0.2390],\n",
      "         [0.2028],\n",
      "         [0.8331],\n",
      "         [0.9382],\n",
      "         [0.5064],\n",
      "         [0.4343],\n",
      "         [0.3213],\n",
      "         [0.0538],\n",
      "         [0.4232],\n",
      "         [0.1616],\n",
      "         [0.3489],\n",
      "         [0.2010],\n",
      "         [0.3567],\n",
      "         [0.2849],\n",
      "         [0.7455],\n",
      "         [0.2750],\n",
      "         [0.6420],\n",
      "         [0.4832],\n",
      "         [0.9396],\n",
      "         [0.3908],\n",
      "         [0.1461],\n",
      "         [0.7805],\n",
      "         [0.9252],\n",
      "         [0.1458],\n",
      "         [0.5919],\n",
      "         [0.4010],\n",
      "         [0.9943],\n",
      "         [0.7263],\n",
      "         [0.2517],\n",
      "         [0.4616],\n",
      "         [0.2315],\n",
      "         [0.8087],\n",
      "         [0.5454],\n",
      "         [0.8032],\n",
      "         [0.6179],\n",
      "         [0.4255],\n",
      "         [0.3859],\n",
      "         [0.6866],\n",
      "         [0.4938],\n",
      "         [0.0386],\n",
      "         [0.4246],\n",
      "         [0.5672],\n",
      "         [0.3196],\n",
      "         [0.0114],\n",
      "         [0.8574],\n",
      "         [0.1531],\n",
      "         [0.6197],\n",
      "         [0.1450],\n",
      "         [0.3504],\n",
      "         [0.8301],\n",
      "         [0.3068],\n",
      "         [0.3604],\n",
      "         [0.0185],\n",
      "         [0.7236],\n",
      "         [0.9312],\n",
      "         [0.1402],\n",
      "         [0.0700],\n",
      "         [0.4123],\n",
      "         [0.9786],\n",
      "         [0.6301],\n",
      "         [0.2401],\n",
      "         [0.8008],\n",
      "         [0.1971],\n",
      "         [0.8492],\n",
      "         [0.2230],\n",
      "         [0.5733],\n",
      "         [0.9569],\n",
      "         [0.6088],\n",
      "         [0.1945],\n",
      "         [0.5566],\n",
      "         [0.5544],\n",
      "         [0.0088],\n",
      "         [0.9287],\n",
      "         [0.4178],\n",
      "         [0.5630],\n",
      "         [0.8595],\n",
      "         [0.3588],\n",
      "         [0.6773],\n",
      "         [0.8964],\n",
      "         [0.2570],\n",
      "         [0.6173],\n",
      "         [0.9677],\n",
      "         [0.9080],\n",
      "         [0.5420],\n",
      "         [0.9178],\n",
      "         [0.4003],\n",
      "         [0.7850],\n",
      "         [0.9906],\n",
      "         [0.5060],\n",
      "         [0.9403],\n",
      "         [0.2147],\n",
      "         [0.9006],\n",
      "         [0.6240],\n",
      "         [0.4780],\n",
      "         [0.6419],\n",
      "         [0.7827],\n",
      "         [0.2541],\n",
      "         [0.4527],\n",
      "         [0.4599],\n",
      "         [0.1436],\n",
      "         [0.5267],\n",
      "         [0.1279],\n",
      "         [0.2391],\n",
      "         [0.0180],\n",
      "         [0.1050],\n",
      "         [0.8176],\n",
      "         [0.0624],\n",
      "         [0.3434],\n",
      "         [0.7291],\n",
      "         [0.5796],\n",
      "         [0.5858],\n",
      "         [0.2622],\n",
      "         [0.6750]]], device='cuda:0', dtype=torch.float64)\n",
      "================iter 5============\n",
      "['shape/ellipsoid/1/ellipsoid_512_128_64_64_3_0_1']\n",
      "tensor([[ True,  True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
      "          True,  True,  True,  True,  True,  True,  True, False, False, False]],\n",
      "       device='cuda:0')\n",
      "@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@\n",
      "['shape/ellipsoid/1/ellipsoid_512_128_64_64_3_1_1']\n",
      "gt_trans_torch.Size([1, 20, 3])_tensor([[[ 9.7204e-02,  1.0424e-01,  1.3698e-01],\n",
      "         [ 9.4072e-02,  7.6590e-02,  1.1874e-01],\n",
      "         [-4.2944e-02, -8.9413e-02, -1.2513e-01],\n",
      "         [-9.4840e-02, -1.1293e-01, -1.6325e-01],\n",
      "         [-1.0990e-01, -1.2705e-01, -1.9263e-01],\n",
      "         [-1.1729e-01, -1.6302e-01, -2.0842e-01],\n",
      "         [-1.3782e-01, -1.7126e-01, -2.4199e-01],\n",
      "         [-1.4514e-01, -1.7800e-01, -2.7201e-01],\n",
      "         [-1.8089e-01, -2.1612e-01, -2.9658e-01],\n",
      "         [-1.8704e-01, -2.3237e-01, -3.2163e-01],\n",
      "         [ 7.8086e-02,  5.9507e-02,  9.0845e-02],\n",
      "         [ 4.9496e-02,  4.3924e-02,  5.7677e-02],\n",
      "         [ 3.6974e-02,  2.2712e-02,  3.2600e-02],\n",
      "         [ 2.8866e-18, -1.5543e-18, -1.9651e-17],\n",
      "         [ 1.4846e-02, -7.2579e-03, -2.1912e-02],\n",
      "         [-1.9699e-02, -3.4335e-02, -5.1634e-02],\n",
      "         [-4.2629e-02, -4.0787e-02, -8.7712e-02],\n",
      "         [-6.2707e-02, -5.2056e-02, -1.2043e-01],\n",
      "         [ 0.0000e+00,  0.0000e+00,  0.0000e+00],\n",
      "         [ 0.0000e+00,  0.0000e+00,  0.0000e+00]]], device='cuda:0')\n",
      "gt_rots_torch.Size([1, 20, 4])_tensor([[[ 0.5418,  0.8370, -0.0174,  0.0746],\n",
      "         [-0.1144,  0.8699, -0.1617, -0.4517],\n",
      "         [-0.2685, -0.0074, -0.6197,  0.7374],\n",
      "         [-0.0739,  0.9592,  0.2418,  0.1267],\n",
      "         [ 0.7459,  0.3357,  0.4539, -0.3534],\n",
      "         [-0.2147,  0.2869,  0.9277, -0.1049],\n",
      "         [-0.3948,  0.6694, -0.6274, -0.0497],\n",
      "         [ 0.2139, -0.2736,  0.8084,  0.4752],\n",
      "         [ 0.2458,  0.7912,  0.4732, -0.2995],\n",
      "         [-0.4770, -0.0946,  0.8516,  0.1957],\n",
      "         [-0.3243,  0.1186,  0.4691,  0.8128],\n",
      "         [-0.4924, -0.1420,  0.6686,  0.5389],\n",
      "         [-0.3866,  0.2348,  0.8461,  0.2820],\n",
      "         [-0.6702, -0.0768, -0.2145,  0.7063],\n",
      "         [ 0.6187,  0.0205, -0.6146,  0.4889],\n",
      "         [-0.1455,  0.3621,  0.6792, -0.6216],\n",
      "         [-0.6183,  0.7510, -0.0899, -0.2137],\n",
      "         [ 0.8684, -0.4480,  0.2095,  0.0351],\n",
      "         [ 0.0000,  0.0000,  0.0000,  0.0000],\n",
      "         [ 0.0000,  0.0000,  0.0000,  0.0000]]], device='cuda:0')\n",
      "noisy_trans_and_rots_torch.Size([1, 20, 7])_tensor([[[ 0.2184,  0.0000,  1.8282, -1.7097,  0.0000,  0.0000,  0.5559],\n",
      "         [ 0.8927,  0.0000,  0.6623, -0.5634,  0.0000,  0.0000,  0.2300],\n",
      "         [ 1.0549,  0.0000,  0.9691, -0.3487,  0.0000,  0.0000,  1.5195],\n",
      "         [-2.7239,  0.0000,  0.4688,  2.1214,  0.0000,  0.0000, -1.3011],\n",
      "         [-0.9092,  0.0000, -0.6615, -0.3073,  0.0000,  0.0000,  1.1112],\n",
      "         [-0.2270,  0.0000, -1.7653,  0.3289,  0.0000,  0.0000,  0.6270],\n",
      "         [ 0.2910,  0.0000, -0.0512, -0.6042,  0.0000,  0.0000, -0.0187],\n",
      "         [-2.5286,  0.0000, -0.1858,  1.7312,  0.0000,  0.0000,  0.8437],\n",
      "         [ 0.4935,  0.0000, -0.0342,  1.4026,  0.0000,  0.0000,  1.4589],\n",
      "         [-0.5696,  0.0000,  1.8960, -0.8841,  0.0000,  0.0000, -0.1163],\n",
      "         [ 0.0089,  0.0000, -0.5646,  1.4541,  0.0000,  0.0000, -0.0141],\n",
      "         [ 0.7635,  0.0000, -2.0089,  0.7481,  0.0000,  0.0000,  0.6052],\n",
      "         [-1.1287,  0.0000, -1.0409, -0.2844,  0.0000,  0.0000, -0.7020],\n",
      "         [ 1.6233,  0.0000,  1.5095, -1.2484,  0.0000,  0.0000,  0.7455],\n",
      "         [ 0.8207,  0.0000, -0.4953, -0.2305,  0.0000,  0.0000,  0.3790],\n",
      "         [-0.3143,  0.0000,  0.1690,  1.2629,  0.0000,  0.0000, -2.0258],\n",
      "         [ 1.0191,  0.0000,  1.6139,  0.8122,  0.0000,  0.0000,  0.7284],\n",
      "         [-0.2000,  0.0000,  0.1135,  0.2020,  0.0000,  0.0000, -0.4617],\n",
      "         [ 1.4391,  0.0000,  0.3051,  0.8331,  0.0000,  0.0000,  0.5994],\n",
      "         [-0.8245,  0.0000, -0.2724, -0.9330,  0.0000,  0.0000,  0.4027]]],\n",
      "       device='cuda:0')\n",
      "================iter 0============\n",
      "['shape/ellipsoid/1/ellipsoid_512_128_64_64_3_1_1']\n",
      "tensor([[False, False, False, False, False, False, False, False, False, False,\n",
      "         False, False, False,  True, False, False, False, False, False, False]],\n",
      "       device='cuda:0')\n",
      "acc torch.Size([1]) tensor([0.0556], device='cuda:0')\n",
      "acc_per_part torch.Size([1, 20]) tensor([[False, False, False, False, False, False, False, False, False, False,\n",
      "         False, False, False,  True, False, False, False, False, False, False]],\n",
      "       device='cuda:0')\n",
      "loss_per_data torch.Size([1, 20]) tensor([[ 0.0489,  1.9742,  3.7397,  1.5808,  1.9850,  3.2392,  0.8041,  6.2104,\n",
      "          6.5373, 12.2602,  0.5028, 27.5575,  3.5278,  0.0000,  2.1493,  5.6900,\n",
      "          1.4929,  0.6255,  0.4407,  1.7390]], device='cuda:0')\n",
      "scores torch.Size([1, 190, 1]) tensor([[[3.7779e-01],\n",
      "         [6.5202e-01],\n",
      "         [7.6347e-01],\n",
      "         [6.2599e-01],\n",
      "         [4.3707e-01],\n",
      "         [4.7271e-01],\n",
      "         [4.6392e-01],\n",
      "         [7.8491e-01],\n",
      "         [9.7559e-01],\n",
      "         [9.9273e-01],\n",
      "         [5.0264e-01],\n",
      "         [3.7249e-01],\n",
      "         [3.8925e-01],\n",
      "         [2.8805e-01],\n",
      "         [4.5403e-01],\n",
      "         [3.0031e-01],\n",
      "         [1.1928e-01],\n",
      "         [2.8843e-01],\n",
      "         [9.7980e-01],\n",
      "         [8.1736e-01],\n",
      "         [8.5785e-01],\n",
      "         [2.4755e-01],\n",
      "         [3.3636e-02],\n",
      "         [2.7073e-01],\n",
      "         [4.5570e-01],\n",
      "         [6.5221e-01],\n",
      "         [3.7869e-01],\n",
      "         [9.6249e-02],\n",
      "         [3.2874e-02],\n",
      "         [3.9327e-01],\n",
      "         [2.5898e-01],\n",
      "         [1.6140e-01],\n",
      "         [7.0159e-01],\n",
      "         [7.1818e-01],\n",
      "         [9.6661e-01],\n",
      "         [3.0957e-01],\n",
      "         [2.7974e-01],\n",
      "         [3.8139e-01],\n",
      "         [7.6388e-04],\n",
      "         [4.1565e-01],\n",
      "         [4.4255e-01],\n",
      "         [4.8353e-01],\n",
      "         [3.7291e-01],\n",
      "         [9.4201e-01],\n",
      "         [8.3129e-01],\n",
      "         [4.3794e-01],\n",
      "         [4.5559e-01],\n",
      "         [2.6074e-01],\n",
      "         [8.8110e-01],\n",
      "         [8.2874e-01],\n",
      "         [4.7228e-01],\n",
      "         [6.3072e-02],\n",
      "         [7.5796e-01],\n",
      "         [1.1049e-01],\n",
      "         [7.3996e-01],\n",
      "         [1.9518e-01],\n",
      "         [3.9782e-01],\n",
      "         [2.0151e-01],\n",
      "         [8.4488e-01],\n",
      "         [9.2388e-01],\n",
      "         [9.9627e-01],\n",
      "         [5.1393e-02],\n",
      "         [4.4002e-02],\n",
      "         [7.5557e-01],\n",
      "         [2.7029e-01],\n",
      "         [9.0714e-01],\n",
      "         [1.5057e-01],\n",
      "         [1.5039e-01],\n",
      "         [3.9148e-01],\n",
      "         [5.1597e-01],\n",
      "         [8.9351e-01],\n",
      "         [6.1483e-01],\n",
      "         [7.1301e-01],\n",
      "         [3.6003e-01],\n",
      "         [6.7828e-02],\n",
      "         [7.7756e-01],\n",
      "         [5.4131e-01],\n",
      "         [5.6031e-01],\n",
      "         [3.6857e-01],\n",
      "         [4.6223e-01],\n",
      "         [5.1079e-01],\n",
      "         [2.3926e-01],\n",
      "         [5.8539e-01],\n",
      "         [9.2621e-01],\n",
      "         [1.2906e-01],\n",
      "         [6.4352e-01],\n",
      "         [7.7627e-01],\n",
      "         [8.7951e-01],\n",
      "         [7.4001e-01],\n",
      "         [3.2704e-01],\n",
      "         [1.6717e-01],\n",
      "         [6.4265e-01],\n",
      "         [8.3651e-01],\n",
      "         [4.4702e-01],\n",
      "         [1.0317e-01],\n",
      "         [8.0629e-01],\n",
      "         [9.8636e-02],\n",
      "         [8.1621e-01],\n",
      "         [7.4450e-01],\n",
      "         [3.7747e-01],\n",
      "         [6.8475e-01],\n",
      "         [4.8785e-01],\n",
      "         [4.0097e-01],\n",
      "         [4.7693e-01],\n",
      "         [4.6982e-01],\n",
      "         [7.7891e-01],\n",
      "         [9.7581e-01],\n",
      "         [7.9136e-01],\n",
      "         [4.2084e-01],\n",
      "         [7.3795e-01],\n",
      "         [1.2704e-01],\n",
      "         [9.9990e-01],\n",
      "         [6.3309e-01],\n",
      "         [8.7521e-01],\n",
      "         [6.8623e-01],\n",
      "         [2.5461e-01],\n",
      "         [3.5082e-01],\n",
      "         [7.9712e-01],\n",
      "         [9.9874e-01],\n",
      "         [7.1014e-01],\n",
      "         [4.4407e-01],\n",
      "         [7.6134e-01],\n",
      "         [8.5051e-02],\n",
      "         [3.3735e-01],\n",
      "         [4.9864e-01],\n",
      "         [4.8530e-01],\n",
      "         [9.7586e-01],\n",
      "         [5.2000e-01],\n",
      "         [9.8114e-01],\n",
      "         [4.8886e-01],\n",
      "         [1.8294e-01],\n",
      "         [7.4786e-01],\n",
      "         [9.5961e-01],\n",
      "         [6.2301e-01],\n",
      "         [5.5651e-01],\n",
      "         [8.6441e-01],\n",
      "         [6.3037e-01],\n",
      "         [9.4811e-01],\n",
      "         [5.7243e-01],\n",
      "         [6.3894e-01],\n",
      "         [1.6861e-01],\n",
      "         [9.0333e-01],\n",
      "         [4.6711e-01],\n",
      "         [2.2916e-01],\n",
      "         [1.1618e-01],\n",
      "         [4.7085e-01],\n",
      "         [7.8411e-01],\n",
      "         [4.7328e-02],\n",
      "         [1.2811e-01],\n",
      "         [1.2467e-01],\n",
      "         [7.4901e-01],\n",
      "         [8.8611e-01],\n",
      "         [9.4360e-01],\n",
      "         [3.4784e-01],\n",
      "         [9.7715e-01],\n",
      "         [1.4999e-02],\n",
      "         [9.0922e-03],\n",
      "         [4.5548e-01],\n",
      "         [8.9029e-02],\n",
      "         [2.8378e-01],\n",
      "         [2.0591e-01],\n",
      "         [5.0375e-01],\n",
      "         [6.2377e-01],\n",
      "         [5.5383e-01],\n",
      "         [2.7751e-02],\n",
      "         [9.6803e-01],\n",
      "         [7.8691e-02],\n",
      "         [7.9803e-01],\n",
      "         [1.7579e-01],\n",
      "         [3.1311e-01],\n",
      "         [9.3923e-01],\n",
      "         [3.3453e-01],\n",
      "         [7.8631e-01],\n",
      "         [5.7048e-01],\n",
      "         [9.5752e-01],\n",
      "         [7.6251e-01],\n",
      "         [8.4759e-01],\n",
      "         [5.8263e-01],\n",
      "         [5.1102e-01],\n",
      "         [9.8827e-01],\n",
      "         [3.0584e-01],\n",
      "         [5.8491e-01],\n",
      "         [7.7431e-02],\n",
      "         [3.1562e-01],\n",
      "         [6.4054e-02],\n",
      "         [4.5445e-01],\n",
      "         [7.5935e-01],\n",
      "         [6.5644e-01],\n",
      "         [8.5741e-01],\n",
      "         [7.3439e-01]]], device='cuda:0', dtype=torch.float64)\n",
      "================iter 1============\n",
      "['shape/ellipsoid/1/ellipsoid_512_128_64_64_3_1_1']\n",
      "tensor([[False, False, False, False, False, False, False, False,  True, False,\n",
      "         False, False, False,  True, False,  True, False, False, False, False]],\n",
      "       device='cuda:0')\n",
      "acc torch.Size([1]) tensor([0.0556], device='cuda:0')\n",
      "acc_per_part torch.Size([1, 20]) tensor([[False, False, False, False, False, False, False, False, False, False,\n",
      "         False, False, False,  True, False, False, False, False, False, False]],\n",
      "       device='cuda:0')\n",
      "loss_per_data torch.Size([1, 20]) tensor([[ 0.5372,  2.7593, 23.5335, 10.3048, 13.7953,  9.3210,  6.4796, 18.0119,\n",
      "          6.5373,  7.9374,  9.8059, 35.6999, 10.3819,  0.0000,  3.6614,  5.6900,\n",
      "          2.9595,  3.2138,  3.2071,  1.1957]], device='cuda:0')\n",
      "scores torch.Size([1, 190, 1]) tensor([[[0.2090],\n",
      "         [0.8256],\n",
      "         [0.5390],\n",
      "         [0.2254],\n",
      "         [0.2543],\n",
      "         [0.1334],\n",
      "         [0.2831],\n",
      "         [0.6365],\n",
      "         [0.8589],\n",
      "         [0.7282],\n",
      "         [0.6615],\n",
      "         [0.1371],\n",
      "         [0.6085],\n",
      "         [0.2757],\n",
      "         [0.4973],\n",
      "         [0.2050],\n",
      "         [0.2549],\n",
      "         [0.5568],\n",
      "         [0.3351],\n",
      "         [0.0333],\n",
      "         [0.1060],\n",
      "         [0.8319],\n",
      "         [0.9137],\n",
      "         [0.7644],\n",
      "         [0.3443],\n",
      "         [0.5122],\n",
      "         [0.2882],\n",
      "         [0.2438],\n",
      "         [0.9927],\n",
      "         [0.2886],\n",
      "         [0.6475],\n",
      "         [0.6117],\n",
      "         [0.4792],\n",
      "         [0.7232],\n",
      "         [0.1159],\n",
      "         [0.7449],\n",
      "         [0.9239],\n",
      "         [0.4470],\n",
      "         [0.4264],\n",
      "         [0.0616],\n",
      "         [0.9870],\n",
      "         [0.2064],\n",
      "         [0.4005],\n",
      "         [0.9420],\n",
      "         [0.4918],\n",
      "         [0.5931],\n",
      "         [0.1734],\n",
      "         [0.9323],\n",
      "         [0.3461],\n",
      "         [0.4783],\n",
      "         [0.6950],\n",
      "         [0.7489],\n",
      "         [0.6853],\n",
      "         [0.2473],\n",
      "         [0.3790],\n",
      "         [0.6642],\n",
      "         [0.7437],\n",
      "         [0.0508],\n",
      "         [0.7135],\n",
      "         [0.1416],\n",
      "         [0.5770],\n",
      "         [0.9838],\n",
      "         [0.1697],\n",
      "         [0.0989],\n",
      "         [0.8414],\n",
      "         [0.0326],\n",
      "         [0.4552],\n",
      "         [0.6390],\n",
      "         [0.1568],\n",
      "         [0.2916],\n",
      "         [0.1421],\n",
      "         [0.2787],\n",
      "         [0.2979],\n",
      "         [0.2385],\n",
      "         [0.1413],\n",
      "         [0.6378],\n",
      "         [0.6649],\n",
      "         [0.4340],\n",
      "         [0.4544],\n",
      "         [0.9425],\n",
      "         [0.9745],\n",
      "         [0.8710],\n",
      "         [0.5036],\n",
      "         [0.1673],\n",
      "         [0.8956],\n",
      "         [0.1924],\n",
      "         [0.4661],\n",
      "         [0.8282],\n",
      "         [0.9967],\n",
      "         [0.3302],\n",
      "         [0.6118],\n",
      "         [0.9101],\n",
      "         [0.8148],\n",
      "         [0.2233],\n",
      "         [0.0391],\n",
      "         [0.0656],\n",
      "         [0.6477],\n",
      "         [0.2332],\n",
      "         [0.9942],\n",
      "         [0.2325],\n",
      "         [0.5574],\n",
      "         [0.0811],\n",
      "         [0.6477],\n",
      "         [0.8951],\n",
      "         [0.8647],\n",
      "         [0.9233],\n",
      "         [0.4696],\n",
      "         [0.5198],\n",
      "         [0.0879],\n",
      "         [0.1340],\n",
      "         [0.7715],\n",
      "         [0.9778],\n",
      "         [0.6479],\n",
      "         [0.5214],\n",
      "         [0.1707],\n",
      "         [0.4574],\n",
      "         [0.8627],\n",
      "         [0.2927],\n",
      "         [0.9787],\n",
      "         [0.2100],\n",
      "         [0.5154],\n",
      "         [0.4459],\n",
      "         [0.9619],\n",
      "         [0.7054],\n",
      "         [0.5755],\n",
      "         [0.8802],\n",
      "         [0.9662],\n",
      "         [0.3414],\n",
      "         [0.3694],\n",
      "         [0.1748],\n",
      "         [0.7260],\n",
      "         [0.4103],\n",
      "         [0.9064],\n",
      "         [0.6143],\n",
      "         [0.0826],\n",
      "         [0.7851],\n",
      "         [0.7512],\n",
      "         [0.2032],\n",
      "         [0.7195],\n",
      "         [0.5728],\n",
      "         [0.8014],\n",
      "         [0.3858],\n",
      "         [0.0741],\n",
      "         [0.4946],\n",
      "         [0.3117],\n",
      "         [0.2182],\n",
      "         [0.2851],\n",
      "         [0.9007],\n",
      "         [0.0386],\n",
      "         [0.4320],\n",
      "         [0.1623],\n",
      "         [0.0133],\n",
      "         [0.2381],\n",
      "         [0.0491],\n",
      "         [0.3674],\n",
      "         [0.1909],\n",
      "         [0.7712],\n",
      "         [0.6576],\n",
      "         [0.9085],\n",
      "         [0.7767],\n",
      "         [0.1628],\n",
      "         [0.3728],\n",
      "         [0.5736],\n",
      "         [0.8171],\n",
      "         [0.6925],\n",
      "         [0.7082],\n",
      "         [0.7447],\n",
      "         [0.7771],\n",
      "         [0.2263],\n",
      "         [0.1302],\n",
      "         [0.4877],\n",
      "         [0.9904],\n",
      "         [0.4275],\n",
      "         [0.2150],\n",
      "         [0.7915],\n",
      "         [0.7403],\n",
      "         [0.5667],\n",
      "         [0.0720],\n",
      "         [0.0696],\n",
      "         [0.8962],\n",
      "         [0.9129],\n",
      "         [0.3551],\n",
      "         [0.1458],\n",
      "         [0.0513],\n",
      "         [0.2676],\n",
      "         [0.2163],\n",
      "         [0.0168],\n",
      "         [0.4631],\n",
      "         [0.4225],\n",
      "         [0.3404]]], device='cuda:0', dtype=torch.float64)\n",
      "================iter 2============\n",
      "['shape/ellipsoid/1/ellipsoid_512_128_64_64_3_1_1']\n",
      "tensor([[False, False,  True, False,  True, False,  True, False,  True, False,\n",
      "          True,  True, False,  True, False,  True,  True,  True, False, False]],\n",
      "       device='cuda:0')\n",
      "acc torch.Size([1]) tensor([0.0556], device='cuda:0')\n",
      "acc_per_part torch.Size([1, 20]) tensor([[False, False, False, False, False, False, False, False, False, False,\n",
      "         False, False, False,  True, False, False, False, False, False, False]],\n",
      "       device='cuda:0')\n",
      "loss_per_data torch.Size([1, 20]) tensor([[ 0.5034,  0.0972, 23.5335, 40.0993, 13.7953, 30.0443,  6.4796, 68.8510,\n",
      "          6.5373,  5.3516,  9.8059, 35.6999, 40.2114,  0.0000,  8.5226,  5.6900,\n",
      "          2.9595,  3.2138,  1.0698,  2.2625]], device='cuda:0')\n",
      "scores torch.Size([1, 190, 1]) tensor([[[0.5121],\n",
      "         [0.9289],\n",
      "         [0.5608],\n",
      "         [0.0249],\n",
      "         [0.1797],\n",
      "         [0.0374],\n",
      "         [0.9686],\n",
      "         [0.7267],\n",
      "         [0.7775],\n",
      "         [0.3608],\n",
      "         [0.9970],\n",
      "         [0.4601],\n",
      "         [0.0815],\n",
      "         [0.4909],\n",
      "         [0.4312],\n",
      "         [0.0170],\n",
      "         [0.4518],\n",
      "         [0.6054],\n",
      "         [0.3403],\n",
      "         [0.9524],\n",
      "         [0.9111],\n",
      "         [0.2172],\n",
      "         [0.4572],\n",
      "         [0.1953],\n",
      "         [0.7434],\n",
      "         [0.6778],\n",
      "         [0.0776],\n",
      "         [0.2450],\n",
      "         [0.3004],\n",
      "         [0.4711],\n",
      "         [0.3208],\n",
      "         [0.6549],\n",
      "         [0.9240],\n",
      "         [0.9318],\n",
      "         [0.2618],\n",
      "         [0.8687],\n",
      "         [0.5047],\n",
      "         [0.1352],\n",
      "         [0.6393],\n",
      "         [0.9999],\n",
      "         [0.6437],\n",
      "         [0.9031],\n",
      "         [0.3754],\n",
      "         [0.5853],\n",
      "         [0.2599],\n",
      "         [0.7417],\n",
      "         [0.4070],\n",
      "         [0.3242],\n",
      "         [0.8112],\n",
      "         [0.6643],\n",
      "         [0.0355],\n",
      "         [0.4858],\n",
      "         [0.1016],\n",
      "         [0.3297],\n",
      "         [0.9270],\n",
      "         [0.6071],\n",
      "         [0.0738],\n",
      "         [0.8912],\n",
      "         [0.4690],\n",
      "         [0.5539],\n",
      "         [0.4082],\n",
      "         [0.4677],\n",
      "         [0.1359],\n",
      "         [0.0428],\n",
      "         [0.9864],\n",
      "         [0.1417],\n",
      "         [0.9362],\n",
      "         [0.3698],\n",
      "         [0.4864],\n",
      "         [0.2293],\n",
      "         [0.0968],\n",
      "         [0.3867],\n",
      "         [0.2852],\n",
      "         [0.7323],\n",
      "         [0.8308],\n",
      "         [0.2529],\n",
      "         [0.1792],\n",
      "         [0.1061],\n",
      "         [0.5471],\n",
      "         [0.7632],\n",
      "         [0.4084],\n",
      "         [0.5433],\n",
      "         [0.1653],\n",
      "         [0.1092],\n",
      "         [0.5867],\n",
      "         [0.9922],\n",
      "         [0.8565],\n",
      "         [0.6542],\n",
      "         [0.6761],\n",
      "         [0.6214],\n",
      "         [0.6915],\n",
      "         [0.1934],\n",
      "         [0.1324],\n",
      "         [0.7899],\n",
      "         [0.2119],\n",
      "         [0.8324],\n",
      "         [0.1990],\n",
      "         [0.6813],\n",
      "         [0.5906],\n",
      "         [0.1477],\n",
      "         [0.9185],\n",
      "         [0.6997],\n",
      "         [0.3810],\n",
      "         [0.3416],\n",
      "         [0.8720],\n",
      "         [0.7522],\n",
      "         [0.0482],\n",
      "         [0.8422],\n",
      "         [0.2720],\n",
      "         [0.2341],\n",
      "         [0.8990],\n",
      "         [0.4626],\n",
      "         [0.4665],\n",
      "         [0.2860],\n",
      "         [0.4864],\n",
      "         [0.3030],\n",
      "         [0.7719],\n",
      "         [0.4992],\n",
      "         [0.5161],\n",
      "         [0.9824],\n",
      "         [0.3948],\n",
      "         [0.0452],\n",
      "         [0.4437],\n",
      "         [0.5720],\n",
      "         [0.3109],\n",
      "         [0.5173],\n",
      "         [0.6144],\n",
      "         [0.7697],\n",
      "         [0.6939],\n",
      "         [0.2213],\n",
      "         [0.0919],\n",
      "         [0.1285],\n",
      "         [0.3046],\n",
      "         [0.2924],\n",
      "         [0.3902],\n",
      "         [0.5762],\n",
      "         [0.2744],\n",
      "         [0.6496],\n",
      "         [0.2684],\n",
      "         [0.9638],\n",
      "         [0.3160],\n",
      "         [0.6395],\n",
      "         [0.2644],\n",
      "         [0.2411],\n",
      "         [0.9896],\n",
      "         [0.0487],\n",
      "         [0.2051],\n",
      "         [0.3576],\n",
      "         [0.8865],\n",
      "         [0.0256],\n",
      "         [0.2579],\n",
      "         [0.2052],\n",
      "         [0.6811],\n",
      "         [0.9627],\n",
      "         [0.1627],\n",
      "         [0.0559],\n",
      "         [0.1233],\n",
      "         [0.5438],\n",
      "         [0.6064],\n",
      "         [0.0093],\n",
      "         [0.2830],\n",
      "         [0.9329],\n",
      "         [0.9928],\n",
      "         [0.8226],\n",
      "         [0.9537],\n",
      "         [0.7506],\n",
      "         [0.5906],\n",
      "         [0.2510],\n",
      "         [0.0255],\n",
      "         [0.8773],\n",
      "         [0.2751],\n",
      "         [0.7972],\n",
      "         [0.8002],\n",
      "         [0.4853],\n",
      "         [0.9964],\n",
      "         [0.8979],\n",
      "         [0.9833],\n",
      "         [0.2150],\n",
      "         [0.6340],\n",
      "         [0.5629],\n",
      "         [0.0959],\n",
      "         [0.6302],\n",
      "         [0.5559],\n",
      "         [0.5649],\n",
      "         [0.3234],\n",
      "         [0.5041],\n",
      "         [0.2825],\n",
      "         [0.8213],\n",
      "         [0.1119],\n",
      "         [0.3082]]], device='cuda:0', dtype=torch.float64)\n",
      "================iter 3============\n",
      "['shape/ellipsoid/1/ellipsoid_512_128_64_64_3_1_1']\n",
      "tensor([[ True,  True,  True,  True,  True,  True,  True,  True,  True, False,\n",
      "          True,  True,  True,  True,  True,  True,  True,  True, False, False]],\n",
      "       device='cuda:0')\n",
      "acc torch.Size([1]) tensor([0.0556], device='cuda:0')\n",
      "acc_per_part torch.Size([1, 20]) tensor([[False, False, False, False, False, False, False, False, False, False,\n",
      "         False, False, False,  True, False, False, False, False, False, False]],\n",
      "       device='cuda:0')\n",
      "loss_per_data torch.Size([1, 20]) tensor([[ 0.5034,  0.0972, 23.5335, 40.0993, 13.7953, 30.0443,  6.4796, 68.8510,\n",
      "          6.5373, 16.4846,  9.8059, 35.6999, 40.2114,  0.0000,  8.5226,  5.6900,\n",
      "          2.9595,  3.2138,  0.4173, 16.2863]], device='cuda:0')\n",
      "scores torch.Size([1, 190, 1]) tensor([[[0.5159],\n",
      "         [0.6455],\n",
      "         [0.9699],\n",
      "         [0.8588],\n",
      "         [0.9283],\n",
      "         [0.1586],\n",
      "         [0.6737],\n",
      "         [0.1621],\n",
      "         [0.8636],\n",
      "         [0.9283],\n",
      "         [0.2942],\n",
      "         [0.6737],\n",
      "         [0.0922],\n",
      "         [0.3638],\n",
      "         [0.9200],\n",
      "         [0.2818],\n",
      "         [0.9918],\n",
      "         [0.2660],\n",
      "         [0.2154],\n",
      "         [0.1245],\n",
      "         [0.4058],\n",
      "         [0.7731],\n",
      "         [0.8471],\n",
      "         [0.3905],\n",
      "         [0.3290],\n",
      "         [0.0259],\n",
      "         [0.3141],\n",
      "         [0.9898],\n",
      "         [0.1536],\n",
      "         [0.2224],\n",
      "         [0.3347],\n",
      "         [0.3392],\n",
      "         [0.8557],\n",
      "         [0.8779],\n",
      "         [0.0641],\n",
      "         [0.2777],\n",
      "         [0.2469],\n",
      "         [0.3486],\n",
      "         [0.7691],\n",
      "         [0.9944],\n",
      "         [0.1804],\n",
      "         [0.8889],\n",
      "         [0.6561],\n",
      "         [0.0175],\n",
      "         [0.5028],\n",
      "         [0.0285],\n",
      "         [0.2353],\n",
      "         [0.5521],\n",
      "         [0.6700],\n",
      "         [0.5750],\n",
      "         [0.0161],\n",
      "         [0.5004],\n",
      "         [0.9562],\n",
      "         [0.9384],\n",
      "         [0.8768],\n",
      "         [0.3831],\n",
      "         [0.2368],\n",
      "         [0.5358],\n",
      "         [0.9513],\n",
      "         [0.3432],\n",
      "         [0.6233],\n",
      "         [0.4154],\n",
      "         [0.6708],\n",
      "         [0.0840],\n",
      "         [0.2383],\n",
      "         [0.1441],\n",
      "         [0.5039],\n",
      "         [0.4993],\n",
      "         [0.0332],\n",
      "         [0.8687],\n",
      "         [0.5445],\n",
      "         [0.1312],\n",
      "         [0.9117],\n",
      "         [0.9962],\n",
      "         [0.9562],\n",
      "         [0.3719],\n",
      "         [0.8534],\n",
      "         [0.8101],\n",
      "         [0.0785],\n",
      "         [0.1717],\n",
      "         [0.5607],\n",
      "         [0.3036],\n",
      "         [0.9110],\n",
      "         [0.9616],\n",
      "         [0.4814],\n",
      "         [0.9319],\n",
      "         [0.0436],\n",
      "         [0.1070],\n",
      "         [0.6510],\n",
      "         [0.7968],\n",
      "         [0.1497],\n",
      "         [0.4130],\n",
      "         [0.5856],\n",
      "         [0.8082],\n",
      "         [0.9982],\n",
      "         [0.0916],\n",
      "         [0.6290],\n",
      "         [0.7882],\n",
      "         [0.3234],\n",
      "         [0.8552],\n",
      "         [0.7691],\n",
      "         [0.0207],\n",
      "         [0.4955],\n",
      "         [0.2275],\n",
      "         [0.8615],\n",
      "         [0.6415],\n",
      "         [0.5085],\n",
      "         [0.4330],\n",
      "         [0.5204],\n",
      "         [0.2126],\n",
      "         [0.5320],\n",
      "         [0.8942],\n",
      "         [0.5632],\n",
      "         [0.6391],\n",
      "         [0.0901],\n",
      "         [0.0077],\n",
      "         [0.8957],\n",
      "         [0.9102],\n",
      "         [0.4830],\n",
      "         [0.4317],\n",
      "         [0.2408],\n",
      "         [0.4450],\n",
      "         [0.4512],\n",
      "         [0.5735],\n",
      "         [0.2866],\n",
      "         [0.7457],\n",
      "         [0.8647],\n",
      "         [0.0739],\n",
      "         [0.2885],\n",
      "         [0.1815],\n",
      "         [0.0454],\n",
      "         [0.2334],\n",
      "         [0.3937],\n",
      "         [0.1433],\n",
      "         [0.3215],\n",
      "         [0.3147],\n",
      "         [0.8953],\n",
      "         [0.7197],\n",
      "         [0.0580],\n",
      "         [0.4395],\n",
      "         [0.9345],\n",
      "         [0.8945],\n",
      "         [0.9902],\n",
      "         [0.8286],\n",
      "         [0.0569],\n",
      "         [0.7190],\n",
      "         [0.3065],\n",
      "         [0.7671],\n",
      "         [0.4867],\n",
      "         [0.7910],\n",
      "         [0.0113],\n",
      "         [0.7004],\n",
      "         [0.3106],\n",
      "         [0.7918],\n",
      "         [0.2910],\n",
      "         [0.3514],\n",
      "         [0.1218],\n",
      "         [0.1842],\n",
      "         [0.3118],\n",
      "         [0.0345],\n",
      "         [0.0836],\n",
      "         [0.4043],\n",
      "         [0.8218],\n",
      "         [0.0011],\n",
      "         [0.7737],\n",
      "         [0.6259],\n",
      "         [0.5627],\n",
      "         [0.1479],\n",
      "         [0.3830],\n",
      "         [0.5956],\n",
      "         [0.2730],\n",
      "         [0.1937],\n",
      "         [0.3684],\n",
      "         [0.2536],\n",
      "         [0.0925],\n",
      "         [0.8379],\n",
      "         [0.5330],\n",
      "         [0.0328],\n",
      "         [0.7180],\n",
      "         [0.2533],\n",
      "         [0.6910],\n",
      "         [0.8997],\n",
      "         [0.4590],\n",
      "         [0.7933],\n",
      "         [0.3332],\n",
      "         [0.5827],\n",
      "         [0.4969],\n",
      "         [0.8395],\n",
      "         [0.5088],\n",
      "         [0.3792]]], device='cuda:0', dtype=torch.float64)\n",
      "================iter 4============\n",
      "['shape/ellipsoid/1/ellipsoid_512_128_64_64_3_1_1']\n",
      "tensor([[ True,  True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
      "          True,  True,  True,  True,  True,  True,  True,  True, False, False]],\n",
      "       device='cuda:0')\n",
      "acc torch.Size([1]) tensor([0.0556], device='cuda:0')\n",
      "acc_per_part torch.Size([1, 20]) tensor([[False, False, False, False, False, False, False, False, False, False,\n",
      "         False, False, False,  True, False, False, False, False, False, False]],\n",
      "       device='cuda:0')\n",
      "loss_per_data torch.Size([1, 20]) tensor([[ 0.5034,  0.0972, 23.5335, 40.0993, 13.7953, 30.0443,  6.4796, 68.8510,\n",
      "          6.5373, 16.4846,  9.8059, 35.6999, 40.2114,  0.0000,  8.5226,  5.6900,\n",
      "          2.9595,  3.2138,  4.5644, 55.2291]], device='cuda:0')\n",
      "scores torch.Size([1, 190, 1]) tensor([[[0.4798],\n",
      "         [0.3653],\n",
      "         [0.4555],\n",
      "         [0.8946],\n",
      "         [0.4648],\n",
      "         [0.4879],\n",
      "         [0.3083],\n",
      "         [0.2963],\n",
      "         [0.2647],\n",
      "         [0.0338],\n",
      "         [0.4511],\n",
      "         [0.3310],\n",
      "         [0.5787],\n",
      "         [0.9547],\n",
      "         [0.2018],\n",
      "         [0.9748],\n",
      "         [0.6744],\n",
      "         [0.6479],\n",
      "         [0.2948],\n",
      "         [0.3631],\n",
      "         [0.7385],\n",
      "         [0.8267],\n",
      "         [0.9840],\n",
      "         [0.1090],\n",
      "         [0.5503],\n",
      "         [0.9498],\n",
      "         [0.8841],\n",
      "         [0.3324],\n",
      "         [0.1319],\n",
      "         [0.8250],\n",
      "         [0.8787],\n",
      "         [0.5716],\n",
      "         [0.9174],\n",
      "         [0.4103],\n",
      "         [0.9252],\n",
      "         [0.4957],\n",
      "         [0.7739],\n",
      "         [0.0579],\n",
      "         [0.5421],\n",
      "         [0.3067],\n",
      "         [0.9139],\n",
      "         [0.3261],\n",
      "         [0.3768],\n",
      "         [0.4700],\n",
      "         [0.2675],\n",
      "         [0.2441],\n",
      "         [0.0902],\n",
      "         [0.0990],\n",
      "         [0.6599],\n",
      "         [0.1124],\n",
      "         [0.9534],\n",
      "         [0.4865],\n",
      "         [0.8094],\n",
      "         [0.6049],\n",
      "         [0.7869],\n",
      "         [0.4144],\n",
      "         [0.6685],\n",
      "         [0.6441],\n",
      "         [0.5683],\n",
      "         [0.5281],\n",
      "         [0.4979],\n",
      "         [0.8531],\n",
      "         [0.8227],\n",
      "         [0.0552],\n",
      "         [0.5346],\n",
      "         [0.5083],\n",
      "         [0.5991],\n",
      "         [0.8472],\n",
      "         [0.5774],\n",
      "         [0.1213],\n",
      "         [0.0484],\n",
      "         [0.4696],\n",
      "         [0.1653],\n",
      "         [0.2225],\n",
      "         [0.9493],\n",
      "         [0.0863],\n",
      "         [0.1006],\n",
      "         [0.4181],\n",
      "         [0.2350],\n",
      "         [0.8517],\n",
      "         [0.7702],\n",
      "         [0.3291],\n",
      "         [0.3995],\n",
      "         [0.5963],\n",
      "         [0.1831],\n",
      "         [0.5686],\n",
      "         [0.4895],\n",
      "         [0.8418],\n",
      "         [0.4172],\n",
      "         [0.8943],\n",
      "         [0.9430],\n",
      "         [0.9778],\n",
      "         [0.5602],\n",
      "         [0.1134],\n",
      "         [0.8725],\n",
      "         [0.2157],\n",
      "         [0.6461],\n",
      "         [0.9862],\n",
      "         [0.7520],\n",
      "         [0.3847],\n",
      "         [0.2183],\n",
      "         [0.4832],\n",
      "         [0.1080],\n",
      "         [0.5766],\n",
      "         [0.6788],\n",
      "         [0.9417],\n",
      "         [0.0796],\n",
      "         [0.3229],\n",
      "         [0.0167],\n",
      "         [0.9504],\n",
      "         [0.0116],\n",
      "         [0.7394],\n",
      "         [0.2162],\n",
      "         [0.9607],\n",
      "         [0.0570],\n",
      "         [0.9183],\n",
      "         [0.3931],\n",
      "         [0.9366],\n",
      "         [0.6702],\n",
      "         [0.4356],\n",
      "         [0.3619],\n",
      "         [0.2591],\n",
      "         [0.0075],\n",
      "         [0.1160],\n",
      "         [0.3647],\n",
      "         [0.0604],\n",
      "         [0.8486],\n",
      "         [0.4514],\n",
      "         [0.3517],\n",
      "         [0.0115],\n",
      "         [0.4706],\n",
      "         [0.0556],\n",
      "         [0.0994],\n",
      "         [0.7093],\n",
      "         [0.7651],\n",
      "         [0.5095],\n",
      "         [0.5999],\n",
      "         [0.0769],\n",
      "         [0.0810],\n",
      "         [0.8453],\n",
      "         [0.4459],\n",
      "         [0.7761],\n",
      "         [0.2729],\n",
      "         [0.5641],\n",
      "         [0.6593],\n",
      "         [0.4643],\n",
      "         [0.3847],\n",
      "         [0.0647],\n",
      "         [0.1668],\n",
      "         [0.4398],\n",
      "         [0.8699],\n",
      "         [0.3898],\n",
      "         [0.0336],\n",
      "         [0.0288],\n",
      "         [0.6351],\n",
      "         [0.9966],\n",
      "         [0.2440],\n",
      "         [0.3454],\n",
      "         [0.8722],\n",
      "         [0.1438],\n",
      "         [0.6649],\n",
      "         [0.1453],\n",
      "         [0.7826],\n",
      "         [0.4915],\n",
      "         [0.5972],\n",
      "         [0.2912],\n",
      "         [0.7809],\n",
      "         [0.0588],\n",
      "         [0.4942],\n",
      "         [0.8233],\n",
      "         [0.8977],\n",
      "         [0.1279],\n",
      "         [0.3588],\n",
      "         [0.1026],\n",
      "         [0.5306],\n",
      "         [0.5671],\n",
      "         [0.3683],\n",
      "         [0.2962],\n",
      "         [0.7357],\n",
      "         [0.9826],\n",
      "         [0.2428],\n",
      "         [0.5261],\n",
      "         [0.9649],\n",
      "         [0.2700],\n",
      "         [0.7415],\n",
      "         [0.2659],\n",
      "         [0.1645],\n",
      "         [0.4581],\n",
      "         [0.4286],\n",
      "         [0.7034]]], device='cuda:0', dtype=torch.float64)\n",
      "================iter 5============\n",
      "['shape/ellipsoid/1/ellipsoid_512_128_64_64_3_1_1']\n",
      "tensor([[ True,  True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
      "          True,  True,  True,  True,  True,  True,  True,  True, False, False]],\n",
      "       device='cuda:0')\n",
      "@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@\n",
      "['shape/ellipsoid/1/ellipsoid_512_128_64_64_3_2_1']\n",
      "gt_trans_torch.Size([1, 20, 3])_tensor([[[ 6.3956e-02,  1.2402e-01,  6.8652e-02],\n",
      "         [ 5.2210e-02,  8.6354e-02,  5.0396e-02],\n",
      "         [-7.8985e-02, -2.2073e-01, -1.2130e-01],\n",
      "         [-9.4106e-02, -2.4116e-01, -1.1842e-01],\n",
      "         [-1.0683e-01, -2.8056e-01, -1.4193e-01],\n",
      "         [-1.2343e-01, -3.0750e-01, -1.5264e-01],\n",
      "         [-1.3878e-01, -3.4912e-01, -1.8789e-01],\n",
      "         [-1.4920e-01, -3.8429e-01, -1.9727e-01],\n",
      "         [-1.6154e-01, -4.2227e-01, -2.1777e-01],\n",
      "         [-1.7911e-01, -4.5359e-01, -2.3944e-01],\n",
      "         [ 3.5032e-02,  6.3020e-02,  4.3858e-02],\n",
      "         [ 1.1262e-02,  3.0939e-02,  3.3845e-03],\n",
      "         [ 0.0000e+00, -1.4211e-17, -3.1086e-18],\n",
      "         [-7.3262e-03, -4.8905e-02, -2.6781e-02],\n",
      "         [-1.8358e-02, -7.7949e-02, -2.8794e-02],\n",
      "         [-3.1835e-02, -1.2057e-01, -5.8791e-02],\n",
      "         [-4.8798e-02, -1.5226e-01, -8.0353e-02],\n",
      "         [-6.8597e-02, -1.6830e-01, -8.2420e-02],\n",
      "         [ 0.0000e+00,  0.0000e+00,  0.0000e+00],\n",
      "         [ 0.0000e+00,  0.0000e+00,  0.0000e+00]]], device='cuda:0')\n",
      "gt_rots_torch.Size([1, 20, 4])_tensor([[[ 0.6981, -0.5150,  0.4390,  0.2338],\n",
      "         [ 0.8734, -0.4202,  0.1189, -0.2157],\n",
      "         [ 0.6409,  0.3774,  0.2625, -0.6148],\n",
      "         [-0.4223,  0.4898,  0.7220,  0.2460],\n",
      "         [ 0.8287, -0.4076, -0.3694,  0.1034],\n",
      "         [-0.1633,  0.4146,  0.8471,  0.2896],\n",
      "         [-0.0705, -0.4058,  0.8505, -0.3271],\n",
      "         [-0.1231,  0.9601, -0.2167, -0.1268],\n",
      "         [ 0.6072,  0.5783, -0.5254,  0.1443],\n",
      "         [-0.3367,  0.5946,  0.1425,  0.7161],\n",
      "         [ 0.8467, -0.0170, -0.0211, -0.5314],\n",
      "         [-0.6928,  0.7151, -0.0870, -0.0338],\n",
      "         [ 0.1176,  0.2343,  0.3485,  0.8999],\n",
      "         [ 0.7420, -0.5816, -0.2109,  0.2581],\n",
      "         [ 0.5129,  0.5815, -0.2836,  0.5642],\n",
      "         [-0.5180,  0.3428,  0.7812,  0.0624],\n",
      "         [ 0.3348, -0.5463,  0.7675, -0.0191],\n",
      "         [-0.4265, -0.5461,  0.6994,  0.1751],\n",
      "         [ 0.0000,  0.0000,  0.0000,  0.0000],\n",
      "         [ 0.0000,  0.0000,  0.0000,  0.0000]]], device='cuda:0')\n",
      "noisy_trans_and_rots_torch.Size([1, 20, 7])_tensor([[[-1.4143,  0.0000,  1.1747, -0.2480,  0.0000,  0.0000, -1.0596],\n",
      "         [-1.3498,  0.0000,  0.0049,  1.6068,  0.0000,  0.0000, -0.2870],\n",
      "         [ 0.3703,  0.0000,  1.5758,  1.1618,  0.0000,  0.0000,  0.8998],\n",
      "         [-0.6862,  0.0000,  0.1485, -1.4631,  0.0000,  0.0000,  0.4301],\n",
      "         [-0.7780,  0.0000, -0.3340,  1.4475,  0.0000,  0.0000,  0.8263],\n",
      "         [-1.7164,  0.0000, -1.2909, -0.5286,  0.0000,  0.0000,  0.2007],\n",
      "         [ 1.4465,  0.0000, -1.1876,  0.0148,  0.0000,  0.0000,  0.3703],\n",
      "         [-0.8081,  0.0000,  0.3391, -0.0085,  0.0000,  0.0000,  0.7362],\n",
      "         [-1.0366,  0.0000, -0.7615, -1.5073,  0.0000,  0.0000,  2.1685],\n",
      "         [-0.3607,  0.0000, -0.9236,  3.0202,  0.0000,  0.0000, -1.1344],\n",
      "         [-0.2496,  0.0000,  1.0000, -2.0761,  0.0000,  0.0000, -0.1353],\n",
      "         [ 0.3449,  0.0000,  1.4374,  0.4920,  0.0000,  0.0000, -1.1327],\n",
      "         [-0.3267,  0.0000,  0.9402,  0.9996,  0.0000,  0.0000,  0.7427],\n",
      "         [ 1.6659,  0.0000,  0.3433, -0.7617,  0.0000,  0.0000,  1.3117],\n",
      "         [ 0.3073,  0.0000,  0.7655, -0.3861,  0.0000,  0.0000, -1.1522],\n",
      "         [-0.2826,  0.0000,  1.2226,  0.0678,  0.0000,  0.0000,  1.4239],\n",
      "         [ 0.6082,  0.0000,  3.0236,  0.6165,  0.0000,  0.0000,  1.1909],\n",
      "         [-0.1379,  0.0000, -0.8603, -0.1159,  0.0000,  0.0000, -0.3015],\n",
      "         [-0.4848,  0.0000, -2.2539, -0.1488,  0.0000,  0.0000, -0.6618],\n",
      "         [-1.2806,  0.0000, -1.0327,  0.1965,  0.0000,  0.0000, -0.6680]]],\n",
      "       device='cuda:0')\n",
      "================iter 0============\n",
      "['shape/ellipsoid/1/ellipsoid_512_128_64_64_3_2_1']\n",
      "tensor([[False, False, False, False, False, False, False, False, False, False,\n",
      "         False, False,  True, False, False, False, False, False, False, False]],\n",
      "       device='cuda:0')\n",
      "acc torch.Size([1]) tensor([0.0556], device='cuda:0')\n",
      "acc_per_part torch.Size([1, 20]) tensor([[False, False, False, False, False, False, False, False, False, False,\n",
      "         False, False,  True, False, False, False, False, False, False, False]],\n",
      "       device='cuda:0')\n",
      "loss_per_data torch.Size([1, 20]) tensor([[ 5.4281,  4.2292,  7.7102,  0.8535,  1.3782, 12.3802,  3.0872,  1.2461,\n",
      "          3.9971,  3.8411,  2.2556,  0.8622,  0.0000,  3.6359,  1.4929,  2.9797,\n",
      "         28.4111,  2.1003,  3.5207,  0.7230]], device='cuda:0')\n",
      "scores torch.Size([1, 190, 1]) tensor([[[0.9992],\n",
      "         [0.1632],\n",
      "         [0.2456],\n",
      "         [0.6060],\n",
      "         [0.5807],\n",
      "         [0.5803],\n",
      "         [0.0737],\n",
      "         [0.2376],\n",
      "         [0.6262],\n",
      "         [0.2148],\n",
      "         [0.7917],\n",
      "         [0.0844],\n",
      "         [0.3721],\n",
      "         [0.7964],\n",
      "         [0.6759],\n",
      "         [0.0238],\n",
      "         [0.6364],\n",
      "         [0.9902],\n",
      "         [0.4020],\n",
      "         [0.4007],\n",
      "         [0.9633],\n",
      "         [0.6982],\n",
      "         [0.9826],\n",
      "         [0.3375],\n",
      "         [0.5286],\n",
      "         [0.5502],\n",
      "         [0.0072],\n",
      "         [0.8614],\n",
      "         [0.5231],\n",
      "         [0.4039],\n",
      "         [0.4513],\n",
      "         [0.8867],\n",
      "         [0.6893],\n",
      "         [0.2922],\n",
      "         [0.7398],\n",
      "         [0.9412],\n",
      "         [0.3853],\n",
      "         [0.2963],\n",
      "         [0.9532],\n",
      "         [0.5939],\n",
      "         [0.0618],\n",
      "         [0.5672],\n",
      "         [0.7086],\n",
      "         [0.9005],\n",
      "         [0.8824],\n",
      "         [0.5208],\n",
      "         [0.8454],\n",
      "         [0.4958],\n",
      "         [0.6919],\n",
      "         [0.8854],\n",
      "         [0.9297],\n",
      "         [0.7901],\n",
      "         [0.8078],\n",
      "         [0.1405],\n",
      "         [0.7568],\n",
      "         [0.7234],\n",
      "         [0.6702],\n",
      "         [0.3781],\n",
      "         [0.4950],\n",
      "         [0.4359],\n",
      "         [0.5661],\n",
      "         [0.2319],\n",
      "         [0.5874],\n",
      "         [0.8030],\n",
      "         [0.1185],\n",
      "         [0.1486],\n",
      "         [0.5191],\n",
      "         [0.3738],\n",
      "         [0.7616],\n",
      "         [0.3728],\n",
      "         [0.8589],\n",
      "         [0.3011],\n",
      "         [0.9455],\n",
      "         [0.3218],\n",
      "         [0.0569],\n",
      "         [0.2304],\n",
      "         [0.0098],\n",
      "         [0.7103],\n",
      "         [0.5496],\n",
      "         [0.7315],\n",
      "         [0.6318],\n",
      "         [0.0185],\n",
      "         [0.7956],\n",
      "         [0.0456],\n",
      "         [0.4519],\n",
      "         [0.0206],\n",
      "         [0.8322],\n",
      "         [0.5658],\n",
      "         [0.1607],\n",
      "         [0.2962],\n",
      "         [0.5003],\n",
      "         [0.7324],\n",
      "         [0.9214],\n",
      "         [0.5561],\n",
      "         [0.2044],\n",
      "         [0.3340],\n",
      "         [0.7747],\n",
      "         [0.4935],\n",
      "         [0.7530],\n",
      "         [0.6766],\n",
      "         [0.6159],\n",
      "         [0.4814],\n",
      "         [0.0075],\n",
      "         [0.7259],\n",
      "         [0.2215],\n",
      "         [0.2517],\n",
      "         [0.2771],\n",
      "         [0.8791],\n",
      "         [0.6296],\n",
      "         [0.7557],\n",
      "         [0.8416],\n",
      "         [0.2833],\n",
      "         [0.0471],\n",
      "         [0.0885],\n",
      "         [0.3602],\n",
      "         [0.9449],\n",
      "         [0.8949],\n",
      "         [0.6223],\n",
      "         [0.0513],\n",
      "         [0.3816],\n",
      "         [0.9481],\n",
      "         [0.9889],\n",
      "         [0.1453],\n",
      "         [0.0703],\n",
      "         [0.1103],\n",
      "         [0.7225],\n",
      "         [0.3055],\n",
      "         [0.0351],\n",
      "         [0.3671],\n",
      "         [0.3258],\n",
      "         [0.8527],\n",
      "         [0.8855],\n",
      "         [0.7252],\n",
      "         [0.8707],\n",
      "         [0.8691],\n",
      "         [0.9224],\n",
      "         [0.4132],\n",
      "         [0.2493],\n",
      "         [0.9451],\n",
      "         [0.5227],\n",
      "         [0.8926],\n",
      "         [0.0623],\n",
      "         [0.8703],\n",
      "         [0.6062],\n",
      "         [0.5023],\n",
      "         [0.7336],\n",
      "         [0.9631],\n",
      "         [0.4270],\n",
      "         [0.0222],\n",
      "         [0.6496],\n",
      "         [0.3077],\n",
      "         [0.7846],\n",
      "         [0.6469],\n",
      "         [0.1662],\n",
      "         [0.6058],\n",
      "         [0.6138],\n",
      "         [0.8542],\n",
      "         [0.2306],\n",
      "         [0.7514],\n",
      "         [0.9848],\n",
      "         [0.6281],\n",
      "         [0.5554],\n",
      "         [0.2453],\n",
      "         [0.5773],\n",
      "         [0.9889],\n",
      "         [0.2407],\n",
      "         [0.7001],\n",
      "         [0.7829],\n",
      "         [0.9842],\n",
      "         [0.4292],\n",
      "         [0.6673],\n",
      "         [0.9943],\n",
      "         [0.3769],\n",
      "         [0.2112],\n",
      "         [0.6081],\n",
      "         [0.1103],\n",
      "         [0.4326],\n",
      "         [0.1102],\n",
      "         [0.5511],\n",
      "         [0.6927],\n",
      "         [0.4857],\n",
      "         [0.6586],\n",
      "         [0.0206],\n",
      "         [0.4812],\n",
      "         [0.6679],\n",
      "         [0.9818],\n",
      "         [0.2771],\n",
      "         [0.2548],\n",
      "         [0.9272],\n",
      "         [0.3825]]], device='cuda:0', dtype=torch.float64)\n",
      "================iter 1============\n",
      "['shape/ellipsoid/1/ellipsoid_512_128_64_64_3_2_1']\n",
      "tensor([[False, False, False, False, False, False, False, False, False, False,\n",
      "          True, False,  True, False, False,  True, False, False, False, False]],\n",
      "       device='cuda:0')\n",
      "acc torch.Size([1]) tensor([0.0556], device='cuda:0')\n",
      "acc_per_part torch.Size([1, 20]) tensor([[False, False, False, False, False, False, False, False, False, False,\n",
      "         False, False,  True, False, False, False, False, False, False, False]],\n",
      "       device='cuda:0')\n",
      "loss_per_data torch.Size([1, 20]) tensor([[ 4.4879,  2.2562,  3.5824,  1.7266,  1.8012, 11.4986,  1.8079,  9.1186,\n",
      "          1.9289,  2.7734,  2.2556,  0.4720,  0.0000,  2.6923,  1.3348,  2.9797,\n",
      "         42.9169,  7.3878,  6.0644,  2.3582]], device='cuda:0')\n",
      "scores torch.Size([1, 190, 1]) tensor([[[0.1517],\n",
      "         [0.4452],\n",
      "         [0.3295],\n",
      "         [0.1339],\n",
      "         [0.9454],\n",
      "         [0.3396],\n",
      "         [0.8838],\n",
      "         [0.8620],\n",
      "         [0.1312],\n",
      "         [0.6602],\n",
      "         [0.1215],\n",
      "         [0.4109],\n",
      "         [0.7242],\n",
      "         [0.0462],\n",
      "         [0.5351],\n",
      "         [0.9969],\n",
      "         [0.2186],\n",
      "         [0.9341],\n",
      "         [0.0983],\n",
      "         [0.8927],\n",
      "         [0.2375],\n",
      "         [0.2315],\n",
      "         [0.0810],\n",
      "         [0.8741],\n",
      "         [0.1750],\n",
      "         [0.6498],\n",
      "         [0.4623],\n",
      "         [0.3902],\n",
      "         [0.0604],\n",
      "         [0.9110],\n",
      "         [0.0160],\n",
      "         [0.1473],\n",
      "         [0.2642],\n",
      "         [0.7368],\n",
      "         [0.9843],\n",
      "         [0.7402],\n",
      "         [0.4446],\n",
      "         [0.2293],\n",
      "         [0.3104],\n",
      "         [0.0193],\n",
      "         [0.8714],\n",
      "         [0.8295],\n",
      "         [0.3307],\n",
      "         [0.3431],\n",
      "         [0.9082],\n",
      "         [0.1006],\n",
      "         [0.4982],\n",
      "         [0.1584],\n",
      "         [0.7704],\n",
      "         [0.5356],\n",
      "         [0.2897],\n",
      "         [0.7980],\n",
      "         [0.3024],\n",
      "         [0.8916],\n",
      "         [0.1593],\n",
      "         [0.5659],\n",
      "         [0.7418],\n",
      "         [0.1741],\n",
      "         [0.2195],\n",
      "         [0.0515],\n",
      "         [0.2413],\n",
      "         [0.5268],\n",
      "         [0.2912],\n",
      "         [0.4408],\n",
      "         [0.6224],\n",
      "         [0.3500],\n",
      "         [0.2515],\n",
      "         [0.6682],\n",
      "         [0.7814],\n",
      "         [0.0768],\n",
      "         [0.5701],\n",
      "         [0.9701],\n",
      "         [0.1492],\n",
      "         [0.7152],\n",
      "         [0.6126],\n",
      "         [0.5569],\n",
      "         [0.2285],\n",
      "         [0.5933],\n",
      "         [0.3289],\n",
      "         [0.0827],\n",
      "         [0.6943],\n",
      "         [0.2748],\n",
      "         [0.7938],\n",
      "         [0.1135],\n",
      "         [0.8644],\n",
      "         [0.3505],\n",
      "         [0.1848],\n",
      "         [0.2189],\n",
      "         [0.4688],\n",
      "         [0.9915],\n",
      "         [0.4791],\n",
      "         [0.7081],\n",
      "         [0.7675],\n",
      "         [0.0307],\n",
      "         [0.7355],\n",
      "         [0.5238],\n",
      "         [0.1176],\n",
      "         [0.3868],\n",
      "         [0.1605],\n",
      "         [0.7317],\n",
      "         [0.4410],\n",
      "         [0.5943],\n",
      "         [0.8381],\n",
      "         [0.3085],\n",
      "         [0.6106],\n",
      "         [0.8490],\n",
      "         [0.0984],\n",
      "         [0.1805],\n",
      "         [0.8387],\n",
      "         [0.4681],\n",
      "         [0.0940],\n",
      "         [0.2575],\n",
      "         [0.3414],\n",
      "         [0.8850],\n",
      "         [0.8888],\n",
      "         [0.6858],\n",
      "         [0.3948],\n",
      "         [0.1167],\n",
      "         [0.0870],\n",
      "         [0.6289],\n",
      "         [0.7731],\n",
      "         [0.7849],\n",
      "         [0.6455],\n",
      "         [0.9852],\n",
      "         [0.7337],\n",
      "         [0.0981],\n",
      "         [0.4622],\n",
      "         [0.0438],\n",
      "         [0.2525],\n",
      "         [0.0058],\n",
      "         [0.7234],\n",
      "         [0.0116],\n",
      "         [0.8674],\n",
      "         [0.8686],\n",
      "         [0.4306],\n",
      "         [0.5997],\n",
      "         [0.9238],\n",
      "         [0.9927],\n",
      "         [0.7893],\n",
      "         [0.1509],\n",
      "         [0.5861],\n",
      "         [0.8387],\n",
      "         [0.2086],\n",
      "         [0.3810],\n",
      "         [0.3492],\n",
      "         [0.4392],\n",
      "         [0.8601],\n",
      "         [0.1724],\n",
      "         [0.7306],\n",
      "         [0.0195],\n",
      "         [0.3554],\n",
      "         [0.4277],\n",
      "         [0.5492],\n",
      "         [0.0135],\n",
      "         [0.8662],\n",
      "         [0.5187],\n",
      "         [0.0467],\n",
      "         [0.7306],\n",
      "         [0.5031],\n",
      "         [0.3683],\n",
      "         [0.3701],\n",
      "         [0.2450],\n",
      "         [0.4476],\n",
      "         [0.1604],\n",
      "         [0.3772],\n",
      "         [0.9374],\n",
      "         [0.6705],\n",
      "         [0.3978],\n",
      "         [0.7136],\n",
      "         [0.2899],\n",
      "         [0.9872],\n",
      "         [0.7310],\n",
      "         [0.3622],\n",
      "         [0.0230],\n",
      "         [0.8609],\n",
      "         [0.8201],\n",
      "         [0.9924],\n",
      "         [0.3045],\n",
      "         [0.9230],\n",
      "         [0.4743],\n",
      "         [0.3227],\n",
      "         [0.3408],\n",
      "         [0.9295],\n",
      "         [0.2417],\n",
      "         [0.7512],\n",
      "         [0.4853],\n",
      "         [0.1513],\n",
      "         [0.7561],\n",
      "         [0.3475],\n",
      "         [0.2402]]], device='cuda:0', dtype=torch.float64)\n",
      "================iter 2============\n",
      "['shape/ellipsoid/1/ellipsoid_512_128_64_64_3_2_1']\n",
      "tensor([[False,  True,  True, False, False,  True, False, False, False,  True,\n",
      "          True, False,  True,  True, False,  True,  True, False, False, False]],\n",
      "       device='cuda:0')\n",
      "acc torch.Size([1]) tensor([0.0556], device='cuda:0')\n",
      "acc_per_part torch.Size([1, 20]) tensor([[False, False, False, False, False, False, False, False, False, False,\n",
      "         False, False,  True, False, False, False, False, False, False, False]],\n",
      "       device='cuda:0')\n",
      "loss_per_data torch.Size([1, 20]) tensor([[15.2199,  2.2562,  3.5824, 12.4790,  2.9902, 11.4986,  3.3485, 19.1861,\n",
      "          7.0836,  2.7734,  2.2556,  0.3147,  0.0000,  2.6923,  8.8503,  2.9797,\n",
      "         42.9169, 15.0776, 12.2521,  2.3269]], device='cuda:0')\n",
      "scores torch.Size([1, 190, 1]) tensor([[[0.3863],\n",
      "         [0.0941],\n",
      "         [0.6266],\n",
      "         [0.0904],\n",
      "         [0.1485],\n",
      "         [0.5345],\n",
      "         [0.7450],\n",
      "         [0.4242],\n",
      "         [0.7444],\n",
      "         [0.2552],\n",
      "         [0.1673],\n",
      "         [0.1040],\n",
      "         [0.5280],\n",
      "         [0.7553],\n",
      "         [0.1301],\n",
      "         [0.0962],\n",
      "         [0.9881],\n",
      "         [0.5413],\n",
      "         [0.4584],\n",
      "         [0.0577],\n",
      "         [0.0025],\n",
      "         [0.8457],\n",
      "         [0.8597],\n",
      "         [0.7100],\n",
      "         [0.9667],\n",
      "         [0.1767],\n",
      "         [0.0024],\n",
      "         [0.9900],\n",
      "         [0.8940],\n",
      "         [0.3380],\n",
      "         [0.2169],\n",
      "         [0.4743],\n",
      "         [0.6020],\n",
      "         [0.1603],\n",
      "         [0.7313],\n",
      "         [0.9391],\n",
      "         [0.2555],\n",
      "         [0.8689],\n",
      "         [0.6313],\n",
      "         [0.0180],\n",
      "         [0.0565],\n",
      "         [0.2493],\n",
      "         [0.4186],\n",
      "         [0.2577],\n",
      "         [0.7550],\n",
      "         [0.0192],\n",
      "         [0.6242],\n",
      "         [0.5206],\n",
      "         [0.7220],\n",
      "         [0.9100],\n",
      "         [0.7323],\n",
      "         [0.8607],\n",
      "         [0.7350],\n",
      "         [0.1897],\n",
      "         [0.8358],\n",
      "         [0.7479],\n",
      "         [0.7936],\n",
      "         [0.6146],\n",
      "         [0.1658],\n",
      "         [0.3584],\n",
      "         [0.6341],\n",
      "         [0.5578],\n",
      "         [0.5224],\n",
      "         [0.5990],\n",
      "         [0.6001],\n",
      "         [0.1287],\n",
      "         [0.1125],\n",
      "         [0.2027],\n",
      "         [0.7730],\n",
      "         [0.3555],\n",
      "         [0.2547],\n",
      "         [0.0701],\n",
      "         [0.3912],\n",
      "         [0.3804],\n",
      "         [0.7396],\n",
      "         [0.8629],\n",
      "         [0.2251],\n",
      "         [0.5874],\n",
      "         [0.0449],\n",
      "         [0.1726],\n",
      "         [0.1509],\n",
      "         [0.0502],\n",
      "         [0.5680],\n",
      "         [0.1147],\n",
      "         [0.8826],\n",
      "         [0.0085],\n",
      "         [0.7747],\n",
      "         [0.8641],\n",
      "         [0.7825],\n",
      "         [0.4718],\n",
      "         [0.8124],\n",
      "         [0.5116],\n",
      "         [0.4826],\n",
      "         [0.6359],\n",
      "         [0.9460],\n",
      "         [0.3487],\n",
      "         [0.2025],\n",
      "         [0.3153],\n",
      "         [0.9673],\n",
      "         [0.6172],\n",
      "         [0.6638],\n",
      "         [0.1473],\n",
      "         [0.3540],\n",
      "         [0.4995],\n",
      "         [0.2560],\n",
      "         [0.4117],\n",
      "         [0.4861],\n",
      "         [0.9192],\n",
      "         [0.8275],\n",
      "         [0.4669],\n",
      "         [0.1043],\n",
      "         [0.8816],\n",
      "         [0.6206],\n",
      "         [0.9143],\n",
      "         [0.0817],\n",
      "         [0.9333],\n",
      "         [0.2269],\n",
      "         [0.0392],\n",
      "         [0.8914],\n",
      "         [0.9086],\n",
      "         [0.0253],\n",
      "         [0.3847],\n",
      "         [0.7032],\n",
      "         [0.5411],\n",
      "         [0.0487],\n",
      "         [0.5168],\n",
      "         [0.2088],\n",
      "         [0.7105],\n",
      "         [0.0782],\n",
      "         [0.0830],\n",
      "         [0.2080],\n",
      "         [0.2174],\n",
      "         [0.0347],\n",
      "         [0.1354],\n",
      "         [0.4542],\n",
      "         [0.9997],\n",
      "         [0.0973],\n",
      "         [0.1662],\n",
      "         [0.3687],\n",
      "         [0.2537],\n",
      "         [0.7437],\n",
      "         [0.9899],\n",
      "         [0.8884],\n",
      "         [0.5048],\n",
      "         [0.7898],\n",
      "         [0.6603],\n",
      "         [0.7734],\n",
      "         [0.6815],\n",
      "         [0.1568],\n",
      "         [0.6115],\n",
      "         [0.8072],\n",
      "         [0.1233],\n",
      "         [0.8903],\n",
      "         [0.6103],\n",
      "         [0.8818],\n",
      "         [0.4365],\n",
      "         [0.4617],\n",
      "         [0.0963],\n",
      "         [0.1731],\n",
      "         [0.9435],\n",
      "         [0.8665],\n",
      "         [0.7062],\n",
      "         [0.9254],\n",
      "         [0.5523],\n",
      "         [0.4602],\n",
      "         [0.3252],\n",
      "         [0.5837],\n",
      "         [0.7427],\n",
      "         [0.7652],\n",
      "         [0.4963],\n",
      "         [0.3286],\n",
      "         [0.1918],\n",
      "         [0.0080],\n",
      "         [0.8828],\n",
      "         [0.5000],\n",
      "         [0.9176],\n",
      "         [0.4587],\n",
      "         [0.1940],\n",
      "         [0.2228],\n",
      "         [0.6398],\n",
      "         [0.8159],\n",
      "         [0.2627],\n",
      "         [0.7165],\n",
      "         [0.7780],\n",
      "         [0.9044],\n",
      "         [0.8643],\n",
      "         [0.0928],\n",
      "         [0.8780],\n",
      "         [0.2949],\n",
      "         [0.6219]]], device='cuda:0', dtype=torch.float64)\n",
      "================iter 3============\n",
      "['shape/ellipsoid/1/ellipsoid_512_128_64_64_3_2_1']\n",
      "tensor([[False,  True,  True, False, False,  True,  True,  True, False,  True,\n",
      "          True, False,  True,  True,  True,  True,  True,  True, False, False]],\n",
      "       device='cuda:0')\n",
      "acc torch.Size([1]) tensor([0.0556], device='cuda:0')\n",
      "acc_per_part torch.Size([1, 20]) tensor([[False, False, False, False, False, False, False, False, False, False,\n",
      "         False, False,  True, False, False, False, False, False, False, False]],\n",
      "       device='cuda:0')\n",
      "loss_per_data torch.Size([1, 20]) tensor([[17.7974,  2.2562,  3.5824, 40.5619, 16.2203, 11.4986,  3.3485, 19.1861,\n",
      "         27.7741,  2.7734,  2.2556,  0.1544,  0.0000,  2.6923,  8.8503,  2.9797,\n",
      "         42.9169, 15.0776, 11.5378,  3.0139]], device='cuda:0')\n",
      "scores torch.Size([1, 190, 1]) tensor([[[0.3232],\n",
      "         [0.6695],\n",
      "         [0.8903],\n",
      "         [0.2083],\n",
      "         [0.8688],\n",
      "         [0.2898],\n",
      "         [0.8934],\n",
      "         [0.4876],\n",
      "         [0.6438],\n",
      "         [0.6650],\n",
      "         [0.5570],\n",
      "         [0.6370],\n",
      "         [0.6583],\n",
      "         [0.2699],\n",
      "         [0.8429],\n",
      "         [0.9808],\n",
      "         [0.5095],\n",
      "         [0.2513],\n",
      "         [0.9470],\n",
      "         [0.2747],\n",
      "         [0.5259],\n",
      "         [0.6217],\n",
      "         [0.8067],\n",
      "         [0.1930],\n",
      "         [0.3285],\n",
      "         [0.1273],\n",
      "         [0.3656],\n",
      "         [0.3530],\n",
      "         [0.6169],\n",
      "         [0.1290],\n",
      "         [0.2216],\n",
      "         [0.2411],\n",
      "         [0.2164],\n",
      "         [0.9071],\n",
      "         [0.1824],\n",
      "         [0.9386],\n",
      "         [0.0802],\n",
      "         [0.8047],\n",
      "         [0.8283],\n",
      "         [0.5910],\n",
      "         [0.5624],\n",
      "         [0.0583],\n",
      "         [0.0750],\n",
      "         [0.0653],\n",
      "         [0.6333],\n",
      "         [0.1396],\n",
      "         [0.7548],\n",
      "         [0.6958],\n",
      "         [0.2866],\n",
      "         [0.3015],\n",
      "         [0.9697],\n",
      "         [0.0417],\n",
      "         [0.0607],\n",
      "         [0.5330],\n",
      "         [0.9182],\n",
      "         [0.6930],\n",
      "         [0.8138],\n",
      "         [0.1077],\n",
      "         [0.3948],\n",
      "         [0.3960],\n",
      "         [0.6280],\n",
      "         [0.3887],\n",
      "         [0.6589],\n",
      "         [0.0634],\n",
      "         [0.7751],\n",
      "         [0.3769],\n",
      "         [0.0686],\n",
      "         [0.5917],\n",
      "         [0.0628],\n",
      "         [0.5629],\n",
      "         [0.9479],\n",
      "         [0.0964],\n",
      "         [0.2813],\n",
      "         [0.3610],\n",
      "         [0.7672],\n",
      "         [0.8079],\n",
      "         [0.2273],\n",
      "         [0.7288],\n",
      "         [0.0082],\n",
      "         [0.3163],\n",
      "         [0.1011],\n",
      "         [0.1291],\n",
      "         [0.6579],\n",
      "         [0.5595],\n",
      "         [0.6523],\n",
      "         [0.5696],\n",
      "         [0.5124],\n",
      "         [0.6794],\n",
      "         [0.8122],\n",
      "         [0.6112],\n",
      "         [0.8860],\n",
      "         [0.1514],\n",
      "         [0.8740],\n",
      "         [0.1827],\n",
      "         [0.9990],\n",
      "         [0.6804],\n",
      "         [0.5289],\n",
      "         [0.2759],\n",
      "         [0.1666],\n",
      "         [0.6263],\n",
      "         [0.6636],\n",
      "         [0.0180],\n",
      "         [0.0918],\n",
      "         [0.9803],\n",
      "         [0.2895],\n",
      "         [0.7531],\n",
      "         [0.4902],\n",
      "         [0.2669],\n",
      "         [0.0770],\n",
      "         [0.8604],\n",
      "         [0.0473],\n",
      "         [0.6922],\n",
      "         [0.1882],\n",
      "         [0.9949],\n",
      "         [0.5917],\n",
      "         [0.4856],\n",
      "         [0.7001],\n",
      "         [0.9177],\n",
      "         [0.7847],\n",
      "         [0.6206],\n",
      "         [0.7159],\n",
      "         [0.7620],\n",
      "         [0.0935],\n",
      "         [0.5949],\n",
      "         [0.0340],\n",
      "         [0.7123],\n",
      "         [0.9855],\n",
      "         [0.7396],\n",
      "         [0.3060],\n",
      "         [0.4903],\n",
      "         [0.4032],\n",
      "         [0.5851],\n",
      "         [0.9609],\n",
      "         [0.3962],\n",
      "         [0.1188],\n",
      "         [0.7085],\n",
      "         [0.6157],\n",
      "         [0.4802],\n",
      "         [0.9191],\n",
      "         [0.7730],\n",
      "         [0.0513],\n",
      "         [0.5218],\n",
      "         [0.3158],\n",
      "         [0.3874],\n",
      "         [0.7618],\n",
      "         [0.2116],\n",
      "         [0.2322],\n",
      "         [0.3452],\n",
      "         [0.9669],\n",
      "         [0.8894],\n",
      "         [0.0142],\n",
      "         [0.5787],\n",
      "         [0.9964],\n",
      "         [0.7932],\n",
      "         [0.4330],\n",
      "         [0.4524],\n",
      "         [0.5936],\n",
      "         [0.2090],\n",
      "         [0.4408],\n",
      "         [0.6678],\n",
      "         [0.1727],\n",
      "         [0.3014],\n",
      "         [0.1082],\n",
      "         [0.8875],\n",
      "         [0.4756],\n",
      "         [0.5885],\n",
      "         [0.1365],\n",
      "         [0.4964],\n",
      "         [0.2921],\n",
      "         [0.3374],\n",
      "         [0.3199],\n",
      "         [0.3970],\n",
      "         [0.0797],\n",
      "         [0.2517],\n",
      "         [0.2581],\n",
      "         [0.7804],\n",
      "         [0.1017],\n",
      "         [0.5976],\n",
      "         [0.7678],\n",
      "         [0.2916],\n",
      "         [0.2869],\n",
      "         [0.1685],\n",
      "         [0.2336],\n",
      "         [0.1213],\n",
      "         [0.0639],\n",
      "         [0.9867],\n",
      "         [0.7684],\n",
      "         [0.4402],\n",
      "         [0.5422],\n",
      "         [0.8555]]], device='cuda:0', dtype=torch.float64)\n",
      "================iter 4============\n",
      "['shape/ellipsoid/1/ellipsoid_512_128_64_64_3_2_1']\n",
      "tensor([[ True,  True,  True, False,  True,  True,  True,  True,  True,  True,\n",
      "          True,  True,  True,  True,  True,  True,  True,  True, False, False]],\n",
      "       device='cuda:0')\n",
      "acc torch.Size([1]) tensor([0.0556], device='cuda:0')\n",
      "acc_per_part torch.Size([1, 20]) tensor([[False, False, False, False, False, False, False, False, False, False,\n",
      "         False, False,  True, False, False, False, False, False, False, False]],\n",
      "       device='cuda:0')\n",
      "loss_per_data torch.Size([1, 20]) tensor([[ 17.7974,   2.2562,   3.5824, 126.0834,  16.2203,  11.4986,   3.3485,\n",
      "          19.1861,  27.7741,   2.7734,   2.2556,   0.1544,   0.0000,   2.6923,\n",
      "           8.8503,   2.9797,  42.9169,  15.0776,  26.7249,   1.6499]],\n",
      "       device='cuda:0')\n",
      "scores torch.Size([1, 190, 1]) tensor([[[0.4468],\n",
      "         [0.3238],\n",
      "         [0.6233],\n",
      "         [0.1995],\n",
      "         [0.8518],\n",
      "         [0.2125],\n",
      "         [0.3545],\n",
      "         [0.4193],\n",
      "         [0.4511],\n",
      "         [0.9867],\n",
      "         [0.0862],\n",
      "         [0.7876],\n",
      "         [0.3992],\n",
      "         [0.8366],\n",
      "         [0.8274],\n",
      "         [0.7044],\n",
      "         [0.1603],\n",
      "         [0.0901],\n",
      "         [0.0634],\n",
      "         [0.4562],\n",
      "         [0.4153],\n",
      "         [0.0708],\n",
      "         [0.6272],\n",
      "         [0.2714],\n",
      "         [0.7012],\n",
      "         [0.7981],\n",
      "         [0.2948],\n",
      "         [0.2269],\n",
      "         [0.2245],\n",
      "         [0.9748],\n",
      "         [0.7235],\n",
      "         [0.2451],\n",
      "         [0.8209],\n",
      "         [0.3160],\n",
      "         [0.0455],\n",
      "         [0.3137],\n",
      "         [0.6018],\n",
      "         [0.1153],\n",
      "         [0.1474],\n",
      "         [0.7056],\n",
      "         [0.8280],\n",
      "         [0.0323],\n",
      "         [0.4698],\n",
      "         [0.0913],\n",
      "         [0.1183],\n",
      "         [0.5022],\n",
      "         [0.0998],\n",
      "         [0.3426],\n",
      "         [0.0682],\n",
      "         [0.7168],\n",
      "         [0.1148],\n",
      "         [0.3798],\n",
      "         [0.1448],\n",
      "         [0.4452],\n",
      "         [0.6524],\n",
      "         [0.3297],\n",
      "         [0.7349],\n",
      "         [0.5617],\n",
      "         [0.6232],\n",
      "         [0.2346],\n",
      "         [0.8700],\n",
      "         [0.3942],\n",
      "         [0.4813],\n",
      "         [0.3850],\n",
      "         [0.5807],\n",
      "         [0.7174],\n",
      "         [0.4212],\n",
      "         [0.4998],\n",
      "         [0.5415],\n",
      "         [0.2975],\n",
      "         [0.4026],\n",
      "         [0.7687],\n",
      "         [0.9388],\n",
      "         [0.7334],\n",
      "         [0.0862],\n",
      "         [0.4386],\n",
      "         [0.3115],\n",
      "         [0.7985],\n",
      "         [0.3278],\n",
      "         [0.4650],\n",
      "         [0.6949],\n",
      "         [0.7525],\n",
      "         [0.2245],\n",
      "         [0.5730],\n",
      "         [0.5178],\n",
      "         [0.8090],\n",
      "         [0.9615],\n",
      "         [0.4790],\n",
      "         [0.4916],\n",
      "         [0.6985],\n",
      "         [0.8877],\n",
      "         [0.3594],\n",
      "         [0.3578],\n",
      "         [0.3043],\n",
      "         [0.9267],\n",
      "         [0.2773],\n",
      "         [0.6703],\n",
      "         [0.2815],\n",
      "         [0.8006],\n",
      "         [0.3141],\n",
      "         [0.8646],\n",
      "         [0.1131],\n",
      "         [0.0639],\n",
      "         [0.8441],\n",
      "         [0.4136],\n",
      "         [0.2370],\n",
      "         [0.4502],\n",
      "         [0.6317],\n",
      "         [0.3352],\n",
      "         [0.6829],\n",
      "         [0.9679],\n",
      "         [0.0921],\n",
      "         [0.8229],\n",
      "         [0.4960],\n",
      "         [0.3966],\n",
      "         [0.7380],\n",
      "         [0.1820],\n",
      "         [0.9051],\n",
      "         [0.8845],\n",
      "         [0.7829],\n",
      "         [0.9636],\n",
      "         [0.7896],\n",
      "         [0.7519],\n",
      "         [0.7145],\n",
      "         [0.9453],\n",
      "         [0.3518],\n",
      "         [0.3653],\n",
      "         [0.5374],\n",
      "         [0.2309],\n",
      "         [0.0382],\n",
      "         [0.3881],\n",
      "         [0.2784],\n",
      "         [0.1145],\n",
      "         [0.8333],\n",
      "         [0.4552],\n",
      "         [0.8314],\n",
      "         [0.9977],\n",
      "         [0.7094],\n",
      "         [0.5480],\n",
      "         [0.8136],\n",
      "         [0.7685],\n",
      "         [0.0302],\n",
      "         [0.5842],\n",
      "         [0.3488],\n",
      "         [0.6000],\n",
      "         [0.9407],\n",
      "         [0.6050],\n",
      "         [0.6948],\n",
      "         [0.8561],\n",
      "         [0.4291],\n",
      "         [0.8336],\n",
      "         [0.9159],\n",
      "         [0.8648],\n",
      "         [0.3224],\n",
      "         [0.8934],\n",
      "         [0.3923],\n",
      "         [0.7603],\n",
      "         [0.0526],\n",
      "         [0.7302],\n",
      "         [0.2832],\n",
      "         [0.3931],\n",
      "         [0.3719],\n",
      "         [0.9504],\n",
      "         [0.3609],\n",
      "         [0.0532],\n",
      "         [0.6727],\n",
      "         [0.9297],\n",
      "         [0.8061],\n",
      "         [0.3211],\n",
      "         [0.7552],\n",
      "         [0.1845],\n",
      "         [0.2297],\n",
      "         [0.9338],\n",
      "         [0.2666],\n",
      "         [0.6249],\n",
      "         [0.4376],\n",
      "         [0.9646],\n",
      "         [0.7996],\n",
      "         [0.0101],\n",
      "         [0.1181],\n",
      "         [0.9439],\n",
      "         [0.6285],\n",
      "         [0.4858],\n",
      "         [0.8362],\n",
      "         [0.6341],\n",
      "         [0.0700],\n",
      "         [0.9514],\n",
      "         [0.9393],\n",
      "         [0.2918],\n",
      "         [0.7461]]], device='cuda:0', dtype=torch.float64)\n",
      "================iter 5============\n",
      "['shape/ellipsoid/1/ellipsoid_512_128_64_64_3_2_1']\n",
      "tensor([[ True,  True,  True, False,  True,  True,  True,  True,  True,  True,\n",
      "          True,  True,  True,  True,  True,  True,  True,  True, False, False]],\n",
      "       device='cuda:0')\n",
      "@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@\n",
      "['shape/ellipsoid/1/ellipsoid_512_128_64_64_3_3_1']\n",
      "gt_trans_torch.Size([1, 20, 3])_tensor([[[ 1.2660e-01, -1.2415e-03, -5.7780e-02],\n",
      "         [ 9.0483e-02, -4.8052e-03, -3.5816e-02],\n",
      "         [-2.1702e-01, -6.5760e-03,  1.3822e-01],\n",
      "         [-2.5873e-01,  2.9634e-03,  1.7443e-01],\n",
      "         [-2.8546e-01,  9.1291e-03,  1.8085e-01],\n",
      "         [-3.2372e-01, -8.9359e-04,  2.0544e-01],\n",
      "         [-3.5532e-01,  2.8250e-02,  2.2868e-01],\n",
      "         [-3.8452e-01,  2.0305e-03,  2.3004e-01],\n",
      "         [-4.2169e-01,  9.8889e-03,  2.5789e-01],\n",
      "         [-4.6879e-01,  2.9301e-03,  3.0055e-01],\n",
      "         [ 5.6310e-02, -1.0509e-02, -1.7451e-02],\n",
      "         [ 2.4429e-02,  7.7697e-03,  1.7982e-03],\n",
      "         [ 2.4425e-18,  0.0000e+00, -1.1990e-17],\n",
      "         [-4.6429e-02, -1.8918e-02,  3.8717e-02],\n",
      "         [-7.7417e-02,  1.0836e-02,  5.9875e-02],\n",
      "         [-1.1540e-01, -4.6900e-03,  8.2433e-02],\n",
      "         [-1.5194e-01,  1.7054e-02,  1.1155e-01],\n",
      "         [-1.8465e-01, -2.9677e-03,  1.2286e-01],\n",
      "         [ 0.0000e+00,  0.0000e+00,  0.0000e+00],\n",
      "         [ 0.0000e+00,  0.0000e+00,  0.0000e+00]]], device='cuda:0')\n",
      "gt_rots_torch.Size([1, 20, 4])_tensor([[[ 0.1652, -0.0576,  0.5642,  0.8069],\n",
      "         [-0.2647,  0.5841,  0.4009,  0.6542],\n",
      "         [ 0.1683, -0.2383, -0.1810,  0.9392],\n",
      "         [ 0.8314, -0.2418,  0.4843, -0.1257],\n",
      "         [ 0.6573, -0.5969,  0.2277,  0.3998],\n",
      "         [-0.4318,  0.5562, -0.2887,  0.6487],\n",
      "         [-0.4725, -0.5607,  0.6799, -0.0084],\n",
      "         [-0.6941,  0.1628,  0.7006, -0.0291],\n",
      "         [ 0.3721,  0.2266,  0.2781,  0.8561],\n",
      "         [-0.5156,  0.1795,  0.2588,  0.7968],\n",
      "         [ 0.6477, -0.4648, -0.3956, -0.4560],\n",
      "         [ 0.2512,  0.9542,  0.1450, -0.0737],\n",
      "         [ 0.6687,  0.6437,  0.1889, -0.3208],\n",
      "         [ 0.6731,  0.6565,  0.1586, -0.3012],\n",
      "         [-0.0058,  0.6981, -0.6941,  0.1756],\n",
      "         [ 0.5824, -0.5334,  0.4212, -0.4459],\n",
      "         [-0.0576,  0.7494,  0.5788,  0.3162],\n",
      "         [ 0.2306,  0.6600, -0.4948, -0.5162],\n",
      "         [ 0.0000,  0.0000,  0.0000,  0.0000],\n",
      "         [ 0.0000,  0.0000,  0.0000,  0.0000]]], device='cuda:0')\n",
      "noisy_trans_and_rots_torch.Size([1, 20, 7])_tensor([[[ 1.0925,  0.0000,  0.1946, -0.3596,  0.0000,  0.0000,  0.8519],\n",
      "         [ 1.1710,  0.0000, -0.4416,  0.0886,  0.0000,  0.0000, -2.2341],\n",
      "         [ 0.4819,  0.0000,  0.5601,  1.6878,  0.0000,  0.0000,  2.4909],\n",
      "         [ 0.1545,  0.0000, -1.5407, -0.5074,  0.0000,  0.0000,  0.9117],\n",
      "         [ 0.7556,  0.0000, -0.7447, -1.4828,  0.0000,  0.0000, -0.0070],\n",
      "         [ 0.1661,  0.0000, -1.2430,  0.4703,  0.0000,  0.0000, -0.3589],\n",
      "         [-0.2435,  0.0000,  1.6568, -0.5854,  0.0000,  0.0000, -0.1819],\n",
      "         [ 1.0516,  0.0000,  0.9228, -0.4521,  0.0000,  0.0000,  1.5907],\n",
      "         [-0.6966,  0.0000,  0.7821, -1.2081,  0.0000,  0.0000,  0.1957],\n",
      "         [-0.1410,  0.0000,  0.4871,  0.1730,  0.0000,  0.0000,  0.2438],\n",
      "         [-0.9434,  0.0000, -1.9596, -0.0119,  0.0000,  0.0000,  0.4439],\n",
      "         [ 0.2212,  0.0000, -1.0513, -2.3445,  0.0000,  0.0000, -0.1514],\n",
      "         [-0.2272,  0.0000,  0.9357,  0.0627,  0.0000,  0.0000,  0.0813],\n",
      "         [ 0.4207,  0.0000, -0.0255, -0.0263,  0.0000,  0.0000, -0.1651],\n",
      "         [ 1.2925,  0.0000,  0.0047, -0.2397,  0.0000,  0.0000, -1.4758],\n",
      "         [ 1.0925,  0.0000,  1.5153, -1.0236,  0.0000,  0.0000, -0.5810],\n",
      "         [-0.5416,  0.0000, -0.5781, -0.7730,  0.0000,  0.0000,  0.0721],\n",
      "         [ 0.9421,  0.0000,  0.1573, -0.5780,  0.0000,  0.0000,  1.2938],\n",
      "         [ 0.2984,  0.0000,  0.6410, -0.8000,  0.0000,  0.0000,  0.1002],\n",
      "         [ 0.3153,  0.0000,  1.0883, -1.0748,  0.0000,  0.0000, -1.0773]]],\n",
      "       device='cuda:0')\n",
      "================iter 0============\n",
      "['shape/ellipsoid/1/ellipsoid_512_128_64_64_3_3_1']\n",
      "tensor([[False, False, False, False, False, False, False, False, False, False,\n",
      "         False, False,  True, False, False, False, False, False, False, False]],\n",
      "       device='cuda:0')\n",
      "acc torch.Size([1]) tensor([0.0556], device='cuda:0')\n",
      "acc_per_part torch.Size([1, 20]) tensor([[False, False, False, False, False, False, False, False, False, False,\n",
      "         False, False,  True, False, False, False, False, False, False, False]],\n",
      "       device='cuda:0')\n",
      "loss_per_data torch.Size([1, 20]) tensor([[ 2.7020,  0.9721,  1.0493,  7.8984,  4.5807,  0.9809,  6.6095,  3.9231,\n",
      "          2.9670, 17.3599, 11.8302,  0.9204,  0.0000,  0.7475,  7.6935, 13.7693,\n",
      "          8.9329,  1.2014, 22.9009,  1.1618]], device='cuda:0')\n",
      "scores torch.Size([1, 190, 1]) tensor([[[0.1579],\n",
      "         [0.6200],\n",
      "         [0.6596],\n",
      "         [0.6758],\n",
      "         [0.9936],\n",
      "         [0.5605],\n",
      "         [0.7020],\n",
      "         [0.9749],\n",
      "         [0.5850],\n",
      "         [0.6123],\n",
      "         [0.0580],\n",
      "         [0.6198],\n",
      "         [0.3637],\n",
      "         [0.4312],\n",
      "         [0.4157],\n",
      "         [0.4219],\n",
      "         [0.6335],\n",
      "         [0.2569],\n",
      "         [0.9532],\n",
      "         [0.6490],\n",
      "         [0.7533],\n",
      "         [0.8104],\n",
      "         [0.7274],\n",
      "         [0.5144],\n",
      "         [0.1278],\n",
      "         [0.9598],\n",
      "         [0.5482],\n",
      "         [0.1939],\n",
      "         [0.3834],\n",
      "         [0.5718],\n",
      "         [0.3470],\n",
      "         [0.1234],\n",
      "         [0.0618],\n",
      "         [0.6999],\n",
      "         [0.2206],\n",
      "         [0.0527],\n",
      "         [0.5239],\n",
      "         [0.6489],\n",
      "         [0.9445],\n",
      "         [0.3703],\n",
      "         [0.6581],\n",
      "         [0.2027],\n",
      "         [0.1711],\n",
      "         [0.9469],\n",
      "         [0.5289],\n",
      "         [0.4270],\n",
      "         [0.1938],\n",
      "         [0.9329],\n",
      "         [0.4547],\n",
      "         [0.0232],\n",
      "         [0.1505],\n",
      "         [0.1824],\n",
      "         [0.5560],\n",
      "         [0.7082],\n",
      "         [0.4743],\n",
      "         [0.8455],\n",
      "         [0.1295],\n",
      "         [0.8840],\n",
      "         [0.2594],\n",
      "         [0.2177],\n",
      "         [0.3460],\n",
      "         [0.2739],\n",
      "         [0.5187],\n",
      "         [0.8029],\n",
      "         [0.0901],\n",
      "         [0.5250],\n",
      "         [0.4791],\n",
      "         [0.2267],\n",
      "         [0.9064],\n",
      "         [0.5667],\n",
      "         [0.2937],\n",
      "         [0.1586],\n",
      "         [0.8343],\n",
      "         [0.2964],\n",
      "         [0.4619],\n",
      "         [0.0212],\n",
      "         [0.5094],\n",
      "         [0.6571],\n",
      "         [0.2711],\n",
      "         [0.5262],\n",
      "         [0.8202],\n",
      "         [0.5827],\n",
      "         [0.3943],\n",
      "         [0.4960],\n",
      "         [0.0095],\n",
      "         [0.9971],\n",
      "         [0.8110],\n",
      "         [0.5860],\n",
      "         [0.2129],\n",
      "         [0.2858],\n",
      "         [0.9830],\n",
      "         [0.3044],\n",
      "         [0.4764],\n",
      "         [0.4916],\n",
      "         [0.4150],\n",
      "         [0.9203],\n",
      "         [0.6360],\n",
      "         [0.0090],\n",
      "         [0.5976],\n",
      "         [0.6442],\n",
      "         [0.1068],\n",
      "         [0.3727],\n",
      "         [0.4756],\n",
      "         [0.9807],\n",
      "         [0.9189],\n",
      "         [0.2126],\n",
      "         [0.3830],\n",
      "         [0.0281],\n",
      "         [0.6237],\n",
      "         [0.3716],\n",
      "         [0.7118],\n",
      "         [0.4717],\n",
      "         [0.6102],\n",
      "         [0.5944],\n",
      "         [0.4821],\n",
      "         [0.3534],\n",
      "         [0.0230],\n",
      "         [0.4202],\n",
      "         [0.5703],\n",
      "         [0.9707],\n",
      "         [0.5704],\n",
      "         [0.1504],\n",
      "         [0.1186],\n",
      "         [0.4527],\n",
      "         [0.1667],\n",
      "         [0.7418],\n",
      "         [0.2136],\n",
      "         [0.2084],\n",
      "         [0.1096],\n",
      "         [0.0692],\n",
      "         [0.0742],\n",
      "         [0.2938],\n",
      "         [0.9067],\n",
      "         [0.5898],\n",
      "         [0.4870],\n",
      "         [0.3235],\n",
      "         [0.9449],\n",
      "         [0.6075],\n",
      "         [0.7510],\n",
      "         [0.4949],\n",
      "         [0.0685],\n",
      "         [0.7867],\n",
      "         [0.9684],\n",
      "         [0.6702],\n",
      "         [0.8226],\n",
      "         [0.0591],\n",
      "         [0.6095],\n",
      "         [0.4519],\n",
      "         [0.3443],\n",
      "         [0.4378],\n",
      "         [0.9478],\n",
      "         [0.7708],\n",
      "         [0.8107],\n",
      "         [0.0474],\n",
      "         [0.5001],\n",
      "         [0.2702],\n",
      "         [0.6215],\n",
      "         [0.2123],\n",
      "         [0.2160],\n",
      "         [0.8936],\n",
      "         [0.7863],\n",
      "         [0.9980],\n",
      "         [0.6627],\n",
      "         [0.0549],\n",
      "         [0.6977],\n",
      "         [0.7938],\n",
      "         [0.2077],\n",
      "         [0.2772],\n",
      "         [0.1518],\n",
      "         [0.6703],\n",
      "         [0.4855],\n",
      "         [0.6236],\n",
      "         [0.3775],\n",
      "         [0.4255],\n",
      "         [0.0694],\n",
      "         [0.3269],\n",
      "         [0.3391],\n",
      "         [0.4987],\n",
      "         [0.9643],\n",
      "         [0.1736],\n",
      "         [0.2525],\n",
      "         [0.3161],\n",
      "         [0.7311],\n",
      "         [0.1688],\n",
      "         [0.8849],\n",
      "         [0.7547],\n",
      "         [0.6613],\n",
      "         [0.0199],\n",
      "         [0.4428],\n",
      "         [0.8566]]], device='cuda:0', dtype=torch.float64)\n",
      "================iter 1============\n",
      "['shape/ellipsoid/1/ellipsoid_512_128_64_64_3_3_1']\n",
      "tensor([[False, False, False, False, False, False,  True, False, False, False,\n",
      "         False, False,  True, False, False, False, False, False, False, False]],\n",
      "       device='cuda:0')\n",
      "acc torch.Size([1]) tensor([0.0556], device='cuda:0')\n",
      "acc_per_part torch.Size([1, 20]) tensor([[False, False, False, False, False, False, False, False, False, False,\n",
      "         False, False,  True, False, False, False, False, False, False, False]],\n",
      "       device='cuda:0')\n",
      "loss_per_data torch.Size([1, 20]) tensor([[ 3.1502,  0.1223,  5.5955, 41.8512,  5.9198,  5.6295,  6.6095,  2.4459,\n",
      "          5.1438, 21.1707, 17.8906,  1.1256,  0.0000,  4.6666,  3.5535, 29.1345,\n",
      "          5.1311,  9.6127, 40.9332,  3.3094]], device='cuda:0')\n",
      "scores torch.Size([1, 190, 1]) tensor([[[3.1379e-01],\n",
      "         [6.6709e-01],\n",
      "         [7.6062e-01],\n",
      "         [1.6333e-01],\n",
      "         [2.2775e-01],\n",
      "         [4.8186e-01],\n",
      "         [1.0434e-02],\n",
      "         [8.4137e-01],\n",
      "         [7.5634e-01],\n",
      "         [5.5738e-01],\n",
      "         [7.7155e-01],\n",
      "         [3.3632e-01],\n",
      "         [4.3151e-01],\n",
      "         [7.2119e-01],\n",
      "         [8.5675e-01],\n",
      "         [4.2755e-02],\n",
      "         [1.4158e-01],\n",
      "         [9.4569e-01],\n",
      "         [7.0466e-01],\n",
      "         [6.1279e-04],\n",
      "         [5.8346e-01],\n",
      "         [7.9698e-01],\n",
      "         [7.8480e-01],\n",
      "         [4.6031e-01],\n",
      "         [7.9642e-01],\n",
      "         [4.6390e-01],\n",
      "         [6.2300e-01],\n",
      "         [6.9071e-01],\n",
      "         [3.7107e-01],\n",
      "         [5.2562e-02],\n",
      "         [6.2431e-01],\n",
      "         [3.2809e-01],\n",
      "         [4.5643e-01],\n",
      "         [7.2646e-01],\n",
      "         [4.6406e-01],\n",
      "         [7.7300e-01],\n",
      "         [8.5580e-01],\n",
      "         [7.4344e-01],\n",
      "         [3.1539e-01],\n",
      "         [8.6773e-01],\n",
      "         [5.9196e-01],\n",
      "         [8.4441e-01],\n",
      "         [6.3573e-01],\n",
      "         [1.2069e-01],\n",
      "         [8.9027e-01],\n",
      "         [1.6283e-01],\n",
      "         [8.9425e-01],\n",
      "         [6.3855e-01],\n",
      "         [6.3519e-01],\n",
      "         [8.0594e-01],\n",
      "         [4.9741e-02],\n",
      "         [9.1121e-01],\n",
      "         [4.0203e-02],\n",
      "         [7.8215e-01],\n",
      "         [9.1712e-02],\n",
      "         [2.8628e-01],\n",
      "         [9.7119e-01],\n",
      "         [2.5533e-01],\n",
      "         [9.9513e-02],\n",
      "         [3.3881e-01],\n",
      "         [8.1253e-01],\n",
      "         [5.1062e-02],\n",
      "         [5.3037e-01],\n",
      "         [8.1560e-01],\n",
      "         [7.8720e-01],\n",
      "         [1.6477e-01],\n",
      "         [6.4179e-01],\n",
      "         [1.9296e-01],\n",
      "         [5.4742e-01],\n",
      "         [3.4970e-02],\n",
      "         [3.2103e-01],\n",
      "         [5.7606e-01],\n",
      "         [1.8367e-01],\n",
      "         [6.0517e-01],\n",
      "         [5.1654e-01],\n",
      "         [9.0719e-01],\n",
      "         [7.2700e-01],\n",
      "         [1.2193e-01],\n",
      "         [9.7576e-01],\n",
      "         [4.9722e-01],\n",
      "         [1.2429e-01],\n",
      "         [4.4796e-01],\n",
      "         [9.2590e-01],\n",
      "         [2.8650e-01],\n",
      "         [7.9312e-01],\n",
      "         [1.3077e-01],\n",
      "         [4.6791e-01],\n",
      "         [8.3822e-01],\n",
      "         [9.6141e-01],\n",
      "         [1.5014e-01],\n",
      "         [3.3715e-01],\n",
      "         [2.3360e-01],\n",
      "         [1.0977e-01],\n",
      "         [5.7980e-01],\n",
      "         [4.6774e-01],\n",
      "         [9.8763e-01],\n",
      "         [1.1740e-01],\n",
      "         [2.0841e-01],\n",
      "         [3.9029e-01],\n",
      "         [3.7615e-01],\n",
      "         [5.0608e-01],\n",
      "         [3.1183e-01],\n",
      "         [4.0305e-01],\n",
      "         [8.7704e-01],\n",
      "         [7.6654e-01],\n",
      "         [8.2986e-01],\n",
      "         [6.2577e-01],\n",
      "         [1.3121e-01],\n",
      "         [2.3733e-01],\n",
      "         [6.4530e-01],\n",
      "         [9.9329e-01],\n",
      "         [5.2703e-01],\n",
      "         [4.5705e-01],\n",
      "         [3.8667e-01],\n",
      "         [6.4287e-01],\n",
      "         [6.9234e-01],\n",
      "         [4.4524e-01],\n",
      "         [7.1288e-01],\n",
      "         [7.6068e-01],\n",
      "         [2.8633e-01],\n",
      "         [8.7746e-01],\n",
      "         [7.9522e-01],\n",
      "         [3.2856e-01],\n",
      "         [6.1913e-03],\n",
      "         [3.9376e-01],\n",
      "         [3.7993e-01],\n",
      "         [5.5334e-01],\n",
      "         [3.7694e-01],\n",
      "         [4.1553e-01],\n",
      "         [5.5765e-01],\n",
      "         [9.4234e-01],\n",
      "         [7.0218e-01],\n",
      "         [1.7360e-01],\n",
      "         [9.1791e-01],\n",
      "         [4.5406e-01],\n",
      "         [6.0122e-01],\n",
      "         [3.1796e-01],\n",
      "         [4.7911e-01],\n",
      "         [2.7831e-01],\n",
      "         [4.9779e-01],\n",
      "         [9.8671e-01],\n",
      "         [3.7004e-02],\n",
      "         [1.9347e-01],\n",
      "         [5.2878e-01],\n",
      "         [6.3401e-01],\n",
      "         [4.9337e-01],\n",
      "         [9.5026e-01],\n",
      "         [3.0950e-01],\n",
      "         [3.2760e-01],\n",
      "         [8.0261e-01],\n",
      "         [3.3039e-01],\n",
      "         [4.0432e-01],\n",
      "         [9.7283e-01],\n",
      "         [5.5627e-01],\n",
      "         [7.9144e-01],\n",
      "         [7.8681e-01],\n",
      "         [1.7011e-01],\n",
      "         [1.3317e-02],\n",
      "         [4.3399e-01],\n",
      "         [2.4096e-01],\n",
      "         [2.6027e-01],\n",
      "         [2.3209e-01],\n",
      "         [8.9988e-01],\n",
      "         [4.6223e-01],\n",
      "         [4.9542e-01],\n",
      "         [9.9092e-02],\n",
      "         [7.8607e-01],\n",
      "         [6.8125e-01],\n",
      "         [7.6650e-01],\n",
      "         [1.2732e-01],\n",
      "         [4.2409e-01],\n",
      "         [7.8868e-02],\n",
      "         [8.1899e-01],\n",
      "         [7.2823e-01],\n",
      "         [7.6459e-01],\n",
      "         [4.4251e-02],\n",
      "         [7.2231e-01],\n",
      "         [4.8484e-01],\n",
      "         [4.7789e-01],\n",
      "         [9.0522e-01],\n",
      "         [6.2642e-01],\n",
      "         [3.7934e-01],\n",
      "         [4.4182e-01],\n",
      "         [3.4518e-01],\n",
      "         [6.6174e-01],\n",
      "         [9.8911e-01],\n",
      "         [4.2465e-01],\n",
      "         [1.7798e-01],\n",
      "         [9.7200e-01],\n",
      "         [5.7797e-01]]], device='cuda:0', dtype=torch.float64)\n",
      "================iter 2============\n",
      "['shape/ellipsoid/1/ellipsoid_512_128_64_64_3_3_1']\n",
      "tensor([[False, False, False,  True, False, False,  True, False, False, False,\n",
      "          True, False,  True, False, False, False, False, False, False, False]],\n",
      "       device='cuda:0')\n",
      "acc torch.Size([1]) tensor([0.0556], device='cuda:0')\n",
      "acc_per_part torch.Size([1, 20]) tensor([[False, False, False, False, False, False, False, False, False, False,\n",
      "         False, False,  True, False, False, False, False, False, False, False]],\n",
      "       device='cuda:0')\n",
      "loss_per_data torch.Size([1, 20]) tensor([[ 0.9532,  0.3068, 87.4901, 41.8512, 22.1769, 31.0228,  6.6095, 24.2421,\n",
      "          2.9744, 20.7835, 17.8906,  6.0829,  0.0000, 12.9220, 14.2387, 18.2776,\n",
      "         17.1518, 10.1853, 81.1667,  2.6266]], device='cuda:0')\n",
      "scores torch.Size([1, 190, 1]) tensor([[[0.6944],\n",
      "         [0.6692],\n",
      "         [0.4808],\n",
      "         [0.2600],\n",
      "         [0.1223],\n",
      "         [0.6092],\n",
      "         [0.5003],\n",
      "         [0.7586],\n",
      "         [0.0483],\n",
      "         [0.7505],\n",
      "         [0.0639],\n",
      "         [0.8409],\n",
      "         [0.1365],\n",
      "         [0.7551],\n",
      "         [0.9372],\n",
      "         [0.9755],\n",
      "         [0.7532],\n",
      "         [0.1997],\n",
      "         [0.0974],\n",
      "         [0.1629],\n",
      "         [0.1204],\n",
      "         [0.4821],\n",
      "         [0.7504],\n",
      "         [0.1482],\n",
      "         [0.7185],\n",
      "         [0.4854],\n",
      "         [0.2449],\n",
      "         [0.1321],\n",
      "         [0.9131],\n",
      "         [0.0054],\n",
      "         [0.7268],\n",
      "         [0.7352],\n",
      "         [0.7016],\n",
      "         [0.2267],\n",
      "         [0.4182],\n",
      "         [0.6602],\n",
      "         [0.4220],\n",
      "         [0.5302],\n",
      "         [0.5461],\n",
      "         [0.0926],\n",
      "         [0.6504],\n",
      "         [0.8707],\n",
      "         [0.6321],\n",
      "         [0.9514],\n",
      "         [0.4309],\n",
      "         [0.0350],\n",
      "         [0.9277],\n",
      "         [0.5725],\n",
      "         [0.6103],\n",
      "         [0.3165],\n",
      "         [0.7213],\n",
      "         [0.5270],\n",
      "         [0.6616],\n",
      "         [0.1133],\n",
      "         [0.4229],\n",
      "         [0.9553],\n",
      "         [0.1089],\n",
      "         [0.7137],\n",
      "         [0.4155],\n",
      "         [0.5766],\n",
      "         [0.7220],\n",
      "         [0.8796],\n",
      "         [0.0668],\n",
      "         [0.1024],\n",
      "         [0.8673],\n",
      "         [0.5098],\n",
      "         [0.8075],\n",
      "         [0.6098],\n",
      "         [0.0625],\n",
      "         [0.7279],\n",
      "         [0.3646],\n",
      "         [0.0909],\n",
      "         [0.0602],\n",
      "         [0.4966],\n",
      "         [0.1403],\n",
      "         [0.1585],\n",
      "         [0.6972],\n",
      "         [0.6067],\n",
      "         [0.8256],\n",
      "         [0.5873],\n",
      "         [0.5226],\n",
      "         [0.5292],\n",
      "         [0.3209],\n",
      "         [0.9357],\n",
      "         [0.2507],\n",
      "         [0.3392],\n",
      "         [0.2794],\n",
      "         [0.0424],\n",
      "         [0.5504],\n",
      "         [0.5376],\n",
      "         [0.1256],\n",
      "         [0.4163],\n",
      "         [0.4075],\n",
      "         [0.0203],\n",
      "         [0.1303],\n",
      "         [0.7558],\n",
      "         [0.9255],\n",
      "         [0.9828],\n",
      "         [0.2624],\n",
      "         [0.9731],\n",
      "         [0.5599],\n",
      "         [0.2034],\n",
      "         [0.0078],\n",
      "         [0.4369],\n",
      "         [0.9757],\n",
      "         [0.8686],\n",
      "         [0.6198],\n",
      "         [0.6182],\n",
      "         [0.5868],\n",
      "         [0.4400],\n",
      "         [0.7956],\n",
      "         [0.2722],\n",
      "         [0.1061],\n",
      "         [0.4537],\n",
      "         [0.7581],\n",
      "         [0.5816],\n",
      "         [0.9739],\n",
      "         [0.3021],\n",
      "         [0.7345],\n",
      "         [0.2008],\n",
      "         [0.9245],\n",
      "         [0.5116],\n",
      "         [0.1409],\n",
      "         [0.0252],\n",
      "         [0.1356],\n",
      "         [0.3651],\n",
      "         [0.6814],\n",
      "         [0.1699],\n",
      "         [0.2517],\n",
      "         [0.7255],\n",
      "         [0.3752],\n",
      "         [0.6584],\n",
      "         [0.4083],\n",
      "         [0.1519],\n",
      "         [0.9811],\n",
      "         [0.7147],\n",
      "         [0.4631],\n",
      "         [0.7667],\n",
      "         [0.4649],\n",
      "         [0.8847],\n",
      "         [0.8304],\n",
      "         [0.8090],\n",
      "         [0.9111],\n",
      "         [0.9066],\n",
      "         [0.7714],\n",
      "         [0.5451],\n",
      "         [0.1745],\n",
      "         [0.6160],\n",
      "         [0.3484],\n",
      "         [0.9599],\n",
      "         [0.5013],\n",
      "         [0.4900],\n",
      "         [0.7109],\n",
      "         [0.7414],\n",
      "         [0.2375],\n",
      "         [0.0082],\n",
      "         [0.1879],\n",
      "         [0.3463],\n",
      "         [0.4761],\n",
      "         [0.2860],\n",
      "         [0.6206],\n",
      "         [0.9798],\n",
      "         [0.6202],\n",
      "         [0.9475],\n",
      "         [0.9022],\n",
      "         [0.3398],\n",
      "         [0.8559],\n",
      "         [0.7988],\n",
      "         [0.5110],\n",
      "         [0.6768],\n",
      "         [0.7147],\n",
      "         [0.2220],\n",
      "         [0.1952],\n",
      "         [0.0931],\n",
      "         [0.5283],\n",
      "         [0.7528],\n",
      "         [0.6179],\n",
      "         [0.5150],\n",
      "         [0.2889],\n",
      "         [0.0415],\n",
      "         [0.1212],\n",
      "         [0.1158],\n",
      "         [0.2921],\n",
      "         [0.2060],\n",
      "         [0.0491],\n",
      "         [0.1051],\n",
      "         [0.4621],\n",
      "         [0.3405],\n",
      "         [0.9951],\n",
      "         [0.5457]]], device='cuda:0', dtype=torch.float64)\n",
      "================iter 3============\n",
      "['shape/ellipsoid/1/ellipsoid_512_128_64_64_3_3_1']\n",
      "tensor([[False, False,  True,  True, False,  True,  True,  True, False, False,\n",
      "          True, False,  True, False,  True,  True, False, False, False, False]],\n",
      "       device='cuda:0')\n",
      "acc torch.Size([1]) tensor([0.0556], device='cuda:0')\n",
      "acc_per_part torch.Size([1, 20]) tensor([[False, False, False, False, False, False, False, False, False, False,\n",
      "         False, False,  True, False, False, False, False, False, False, False]],\n",
      "       device='cuda:0')\n",
      "loss_per_data torch.Size([1, 20]) tensor([[  2.0638,   0.6172,  87.4901,  41.8512,  78.1033,  31.0228,   6.6095,\n",
      "          24.2421,   9.5677,  55.5439,  17.8906,   3.8210,   0.0000,  29.1515,\n",
      "          14.2387,  18.2776,  19.4754,  43.4784, 151.8452,   6.9160]],\n",
      "       device='cuda:0')\n",
      "scores torch.Size([1, 190, 1]) tensor([[[3.9538e-02],\n",
      "         [4.9146e-01],\n",
      "         [7.1366e-01],\n",
      "         [9.4425e-01],\n",
      "         [5.6406e-02],\n",
      "         [8.4329e-01],\n",
      "         [6.2679e-01],\n",
      "         [3.1616e-01],\n",
      "         [4.2563e-01],\n",
      "         [8.8126e-01],\n",
      "         [3.2004e-01],\n",
      "         [8.8341e-01],\n",
      "         [9.9909e-01],\n",
      "         [7.6036e-01],\n",
      "         [9.9510e-01],\n",
      "         [9.1185e-01],\n",
      "         [2.6014e-01],\n",
      "         [1.3130e-01],\n",
      "         [3.7652e-01],\n",
      "         [7.4939e-01],\n",
      "         [7.3169e-01],\n",
      "         [5.2349e-01],\n",
      "         [5.4577e-01],\n",
      "         [7.4558e-01],\n",
      "         [8.8871e-01],\n",
      "         [2.0340e-01],\n",
      "         [9.9438e-01],\n",
      "         [4.2595e-04],\n",
      "         [8.5867e-01],\n",
      "         [3.3651e-01],\n",
      "         [3.8501e-01],\n",
      "         [5.0524e-01],\n",
      "         [1.7666e-01],\n",
      "         [2.5338e-01],\n",
      "         [3.4112e-01],\n",
      "         [9.5200e-01],\n",
      "         [8.7464e-01],\n",
      "         [2.5887e-01],\n",
      "         [5.4022e-02],\n",
      "         [2.4825e-01],\n",
      "         [9.0588e-01],\n",
      "         [2.9981e-01],\n",
      "         [5.1425e-01],\n",
      "         [3.0209e-01],\n",
      "         [1.9846e-01],\n",
      "         [4.5221e-01],\n",
      "         [7.0273e-01],\n",
      "         [7.0330e-01],\n",
      "         [7.5310e-01],\n",
      "         [7.8995e-01],\n",
      "         [5.3819e-01],\n",
      "         [9.3267e-01],\n",
      "         [5.7732e-02],\n",
      "         [9.1674e-01],\n",
      "         [4.9561e-02],\n",
      "         [4.0515e-01],\n",
      "         [5.1591e-01],\n",
      "         [9.2211e-01],\n",
      "         [1.8513e-01],\n",
      "         [9.1978e-01],\n",
      "         [7.0899e-01],\n",
      "         [5.9392e-01],\n",
      "         [8.7123e-01],\n",
      "         [2.8863e-01],\n",
      "         [4.2983e-01],\n",
      "         [9.2965e-01],\n",
      "         [1.0208e-01],\n",
      "         [2.1641e-01],\n",
      "         [3.7274e-01],\n",
      "         [7.3570e-01],\n",
      "         [9.8064e-01],\n",
      "         [8.8417e-01],\n",
      "         [9.3013e-01],\n",
      "         [4.4040e-01],\n",
      "         [1.7824e-01],\n",
      "         [1.4226e-01],\n",
      "         [9.5687e-01],\n",
      "         [8.7581e-02],\n",
      "         [2.4931e-01],\n",
      "         [2.5783e-01],\n",
      "         [3.1160e-01],\n",
      "         [2.7844e-01],\n",
      "         [1.5041e-01],\n",
      "         [8.1451e-01],\n",
      "         [2.2803e-01],\n",
      "         [1.5732e-02],\n",
      "         [2.4973e-01],\n",
      "         [8.1191e-01],\n",
      "         [8.9963e-01],\n",
      "         [1.6063e-01],\n",
      "         [7.2531e-01],\n",
      "         [8.6508e-02],\n",
      "         [4.6012e-01],\n",
      "         [7.4683e-01],\n",
      "         [8.2862e-01],\n",
      "         [2.7685e-01],\n",
      "         [7.8310e-01],\n",
      "         [5.9999e-01],\n",
      "         [8.4228e-01],\n",
      "         [9.1927e-01],\n",
      "         [1.7402e-01],\n",
      "         [6.9702e-01],\n",
      "         [1.3844e-01],\n",
      "         [2.8391e-01],\n",
      "         [9.8933e-01],\n",
      "         [4.8964e-01],\n",
      "         [8.9687e-01],\n",
      "         [1.7251e-01],\n",
      "         [3.5196e-01],\n",
      "         [4.8041e-01],\n",
      "         [5.2257e-01],\n",
      "         [9.9355e-01],\n",
      "         [8.9039e-01],\n",
      "         [8.5947e-01],\n",
      "         [3.1339e-02],\n",
      "         [3.6241e-01],\n",
      "         [2.5318e-01],\n",
      "         [9.3204e-01],\n",
      "         [3.6303e-01],\n",
      "         [6.1483e-01],\n",
      "         [7.2599e-01],\n",
      "         [6.7841e-01],\n",
      "         [6.7682e-01],\n",
      "         [2.3578e-02],\n",
      "         [1.4835e-01],\n",
      "         [4.9079e-01],\n",
      "         [7.2424e-01],\n",
      "         [7.7676e-01],\n",
      "         [7.2644e-01],\n",
      "         [7.8653e-01],\n",
      "         [1.4766e-03],\n",
      "         [9.1721e-01],\n",
      "         [3.6636e-01],\n",
      "         [6.1448e-01],\n",
      "         [8.6266e-01],\n",
      "         [1.9561e-01],\n",
      "         [4.6379e-01],\n",
      "         [3.7750e-01],\n",
      "         [3.0502e-01],\n",
      "         [2.5655e-01],\n",
      "         [6.7995e-01],\n",
      "         [1.7267e-01],\n",
      "         [2.1073e-02],\n",
      "         [3.4792e-01],\n",
      "         [7.8635e-01],\n",
      "         [3.8395e-01],\n",
      "         [2.6702e-02],\n",
      "         [9.7118e-01],\n",
      "         [4.3745e-01],\n",
      "         [2.6828e-01],\n",
      "         [6.3449e-01],\n",
      "         [1.9031e-01],\n",
      "         [2.7766e-01],\n",
      "         [2.9878e-01],\n",
      "         [7.8644e-01],\n",
      "         [4.0521e-02],\n",
      "         [3.1223e-01],\n",
      "         [7.7934e-01],\n",
      "         [5.5349e-01],\n",
      "         [3.2971e-01],\n",
      "         [1.2733e-01],\n",
      "         [5.3776e-01],\n",
      "         [1.3191e-01],\n",
      "         [3.8351e-01],\n",
      "         [7.4024e-02],\n",
      "         [6.8143e-01],\n",
      "         [8.9860e-02],\n",
      "         [6.1436e-01],\n",
      "         [6.3956e-01],\n",
      "         [4.5390e-01],\n",
      "         [9.7122e-01],\n",
      "         [3.1538e-01],\n",
      "         [3.4654e-01],\n",
      "         [5.7738e-01],\n",
      "         [6.0907e-01],\n",
      "         [2.6371e-01],\n",
      "         [4.7736e-01],\n",
      "         [1.8587e-01],\n",
      "         [7.5551e-02],\n",
      "         [2.4288e-01],\n",
      "         [3.1399e-02],\n",
      "         [6.5082e-01],\n",
      "         [4.7864e-01],\n",
      "         [7.9506e-01],\n",
      "         [2.1544e-02],\n",
      "         [7.4269e-01],\n",
      "         [9.6426e-01],\n",
      "         [3.7243e-01],\n",
      "         [5.8493e-01],\n",
      "         [4.1191e-01]]], device='cuda:0', dtype=torch.float64)\n",
      "================iter 4============\n",
      "['shape/ellipsoid/1/ellipsoid_512_128_64_64_3_3_1']\n",
      "tensor([[ True, False,  True,  True,  True,  True,  True,  True, False,  True,\n",
      "          True, False,  True,  True,  True,  True, False,  True, False, False]],\n",
      "       device='cuda:0')\n",
      "acc torch.Size([1]) tensor([0.0556], device='cuda:0')\n",
      "acc_per_part torch.Size([1, 20]) tensor([[False, False, False, False, False, False, False, False, False, False,\n",
      "         False, False,  True, False, False, False, False, False, False, False]],\n",
      "       device='cuda:0')\n",
      "loss_per_data torch.Size([1, 20]) tensor([[  2.0638,   0.7650,  87.4901,  41.8512,  78.1033,  31.0228,   6.6095,\n",
      "          24.2421,  11.3339,  55.5439,  17.8906,  17.0250,   0.0000,  29.1515,\n",
      "          14.2387,  18.2776,  71.7738,  43.4784, 393.9678,  59.5993]],\n",
      "       device='cuda:0')\n",
      "scores torch.Size([1, 190, 1]) tensor([[[2.5925e-01],\n",
      "         [5.9022e-01],\n",
      "         [1.8870e-01],\n",
      "         [6.5612e-01],\n",
      "         [3.3389e-01],\n",
      "         [9.9055e-03],\n",
      "         [4.4437e-02],\n",
      "         [1.3343e-01],\n",
      "         [1.4464e-01],\n",
      "         [8.7182e-01],\n",
      "         [8.6831e-01],\n",
      "         [5.7851e-01],\n",
      "         [4.9214e-01],\n",
      "         [4.6816e-01],\n",
      "         [9.3207e-01],\n",
      "         [2.1936e-01],\n",
      "         [3.8769e-01],\n",
      "         [4.4530e-01],\n",
      "         [3.6021e-01],\n",
      "         [1.2626e-01],\n",
      "         [9.0764e-01],\n",
      "         [3.4794e-01],\n",
      "         [2.0420e-01],\n",
      "         [6.3637e-01],\n",
      "         [1.6650e-01],\n",
      "         [2.4125e-01],\n",
      "         [9.0536e-01],\n",
      "         [3.5525e-02],\n",
      "         [9.6324e-01],\n",
      "         [5.2453e-01],\n",
      "         [9.7322e-01],\n",
      "         [6.9314e-01],\n",
      "         [7.0282e-01],\n",
      "         [3.4733e-01],\n",
      "         [2.8219e-01],\n",
      "         [5.6154e-01],\n",
      "         [1.5694e-01],\n",
      "         [4.6199e-01],\n",
      "         [4.7613e-02],\n",
      "         [7.8764e-01],\n",
      "         [9.6444e-01],\n",
      "         [6.9381e-01],\n",
      "         [7.7575e-01],\n",
      "         [4.2726e-01],\n",
      "         [9.8925e-01],\n",
      "         [5.5236e-02],\n",
      "         [9.6411e-01],\n",
      "         [1.1925e-01],\n",
      "         [2.3955e-01],\n",
      "         [7.6131e-01],\n",
      "         [2.2890e-01],\n",
      "         [1.4051e-01],\n",
      "         [2.8486e-01],\n",
      "         [5.9730e-01],\n",
      "         [2.5208e-01],\n",
      "         [6.8729e-01],\n",
      "         [9.7868e-01],\n",
      "         [7.1548e-01],\n",
      "         [4.5835e-01],\n",
      "         [9.4247e-01],\n",
      "         [2.7556e-01],\n",
      "         [8.3955e-01],\n",
      "         [8.1480e-01],\n",
      "         [3.3675e-01],\n",
      "         [2.3497e-01],\n",
      "         [4.7282e-01],\n",
      "         [1.3078e-01],\n",
      "         [5.9057e-01],\n",
      "         [6.2831e-01],\n",
      "         [4.1752e-01],\n",
      "         [2.7702e-01],\n",
      "         [5.5847e-01],\n",
      "         [1.2784e-01],\n",
      "         [7.2625e-01],\n",
      "         [5.0310e-01],\n",
      "         [7.3183e-01],\n",
      "         [4.1590e-01],\n",
      "         [6.0775e-01],\n",
      "         [2.4100e-02],\n",
      "         [9.5273e-01],\n",
      "         [4.5789e-01],\n",
      "         [2.8362e-01],\n",
      "         [7.0422e-01],\n",
      "         [5.6604e-01],\n",
      "         [1.8007e-01],\n",
      "         [5.9161e-01],\n",
      "         [4.1558e-01],\n",
      "         [5.2848e-01],\n",
      "         [4.8693e-01],\n",
      "         [3.9792e-01],\n",
      "         [8.8141e-01],\n",
      "         [5.1113e-02],\n",
      "         [5.6735e-01],\n",
      "         [2.4662e-01],\n",
      "         [6.3515e-01],\n",
      "         [5.2156e-01],\n",
      "         [5.5934e-01],\n",
      "         [7.9710e-01],\n",
      "         [4.8037e-01],\n",
      "         [3.0663e-01],\n",
      "         [9.6555e-01],\n",
      "         [9.1877e-01],\n",
      "         [8.7645e-02],\n",
      "         [4.2451e-01],\n",
      "         [4.9621e-01],\n",
      "         [8.7531e-01],\n",
      "         [4.5419e-01],\n",
      "         [2.3752e-01],\n",
      "         [3.4204e-01],\n",
      "         [2.2562e-01],\n",
      "         [1.5478e-02],\n",
      "         [4.4315e-01],\n",
      "         [7.4218e-01],\n",
      "         [6.9135e-01],\n",
      "         [6.9196e-01],\n",
      "         [1.8967e-01],\n",
      "         [7.3423e-01],\n",
      "         [6.2116e-01],\n",
      "         [8.8206e-02],\n",
      "         [3.2030e-01],\n",
      "         [2.0745e-01],\n",
      "         [4.2222e-01],\n",
      "         [5.9233e-01],\n",
      "         [9.0888e-01],\n",
      "         [9.9100e-01],\n",
      "         [5.5043e-01],\n",
      "         [8.1608e-01],\n",
      "         [8.9282e-01],\n",
      "         [9.6822e-01],\n",
      "         [4.7213e-04],\n",
      "         [4.0584e-01],\n",
      "         [4.2191e-02],\n",
      "         [4.1144e-01],\n",
      "         [4.4735e-01],\n",
      "         [1.3405e-01],\n",
      "         [9.9057e-01],\n",
      "         [1.3347e-01],\n",
      "         [6.2673e-01],\n",
      "         [9.9861e-01],\n",
      "         [8.0283e-02],\n",
      "         [3.0567e-01],\n",
      "         [3.3065e-01],\n",
      "         [7.8672e-01],\n",
      "         [9.3137e-01],\n",
      "         [4.5870e-01],\n",
      "         [4.0257e-01],\n",
      "         [9.7147e-01],\n",
      "         [1.7307e-01],\n",
      "         [2.4367e-01],\n",
      "         [6.9627e-01],\n",
      "         [6.6342e-01],\n",
      "         [2.3963e-01],\n",
      "         [3.0011e-01],\n",
      "         [9.4222e-01],\n",
      "         [6.5961e-01],\n",
      "         [2.7267e-01],\n",
      "         [8.4794e-01],\n",
      "         [7.0275e-01],\n",
      "         [9.2061e-01],\n",
      "         [1.9018e-01],\n",
      "         [8.1823e-01],\n",
      "         [5.1231e-01],\n",
      "         [5.3459e-01],\n",
      "         [1.5062e-01],\n",
      "         [7.3928e-01],\n",
      "         [1.4723e-01],\n",
      "         [6.8666e-01],\n",
      "         [8.1374e-01],\n",
      "         [7.2356e-01],\n",
      "         [3.6993e-01],\n",
      "         [4.1626e-01],\n",
      "         [7.2213e-01],\n",
      "         [1.1881e-01],\n",
      "         [6.0397e-01],\n",
      "         [9.0430e-01],\n",
      "         [5.2305e-01],\n",
      "         [2.1901e-01],\n",
      "         [9.7462e-01],\n",
      "         [5.3728e-02],\n",
      "         [3.4105e-01],\n",
      "         [9.2354e-01],\n",
      "         [6.6549e-02],\n",
      "         [7.5556e-01],\n",
      "         [4.7645e-01],\n",
      "         [8.2957e-01],\n",
      "         [9.3622e-01],\n",
      "         [3.7019e-01],\n",
      "         [7.0165e-02],\n",
      "         [5.4455e-01],\n",
      "         [1.2683e-02]]], device='cuda:0', dtype=torch.float64)\n",
      "================iter 5============\n",
      "['shape/ellipsoid/1/ellipsoid_512_128_64_64_3_3_1']\n",
      "tensor([[ True,  True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
      "          True, False,  True,  True,  True,  True,  True,  True, False, False]],\n",
      "       device='cuda:0')\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "       Test metric             DataLoader 0\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "      eval/part_acc         0.0597761794924736\n",
      "       eval/rmse_r           81.20283508300781\n",
      "       eval/rmse_t           1.631917953491211\n",
      "      eval/shape_cd         11.903953552246094\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[{'eval/part_acc': 0.0597761794924736,\n",
       "  'eval/rmse_t': 1.631917953491211,\n",
       "  'eval/rmse_r': 81.20283508300781,\n",
       "  'eval/shape_cd': 11.903953552246094}]"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "model = AutoAgglomerative(cfg)\n",
    "\n",
    "denoiser_weights = torch.load(cfg.denoiser.ckpt_path)['state_dict']\n",
    "\n",
    "model.denoiser.load_state_dict(\n",
    "    {k.replace('denoiser.', ''): v for k, v in denoiser_weights.items() \n",
    "     if k.startswith('denoiser.')}\n",
    ")\n",
    "\n",
    "model.encoder.load_state_dict(\n",
    "    {k.replace('encoder.', ''): v for k, v in denoiser_weights.items() \n",
    "     if k.startswith('encoder.')}\n",
    ")\n",
    "\n",
    "# load verifier weights    \n",
    "#verifier_weights = torch.load(cfg.verifier.ckpt_path)['state_dict']\n",
    "#model.verifier.load_state_dict({k.replace('verifier.', ''): v for k, v in verifier_weights.items()})\n",
    "\n",
    "\n",
    "trainer = pl.Trainer(accelerator=cfg.accelerator, max_epochs=1, logger=False)\n",
    "trainer.test(model=model, dataloaders=test_loader)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8acfdaf8-912f-4353-8fa1-35f2ad4b334d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9defb7ae-b68e-4b65-8742-7129f4571350",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "812c46d1-47d4-408d-b2f0-994a2f7b1cb7",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "puzzle",
   "language": "python",
   "name": "puzzle"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
